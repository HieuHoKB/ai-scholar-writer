{"version":3,"sources":["turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/app-render/async-local-storage.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/@edge-runtime/cookies/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/status.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/internal/tracestate-validators.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/span_kind.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/trace_flags.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/propagation/TextMapPropagator.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/diag/consoleLogger.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/api/propagation.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/baggage/utils.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/internal/semver.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/api/trace.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/NoopTracer.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/NoopTracerProvider.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/invalid-span-constants.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/ProxyTracer.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/metrics/NoopMeterProvider.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/baggage/context-helpers.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/internal/global-utils.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/ProxyTracerProvider.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/internal/tracestate-impl.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/diag/internal/logLevelLogger.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/api/metrics.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/NonRecordingSpan.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/version.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/spancontext-utils.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/context-utils.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/context/context.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/internal/utils.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/diag-api.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace-api.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/index.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/baggage/internal/symbol.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/metrics/Metric.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/diag/types.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/propagation/NoopTextMapPropagator.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/platform/browser/globalThis.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/trace/SamplingResult.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/api/context.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/context/NoopContextManager.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/metrics/NoopMeter.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/api/diag.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/baggage/internal/baggage-impl.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/@opentelemetry/api/src/diag/ComponentLogger.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/cookie/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/p-queue/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/web/get-edge-preview-props.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/experimental/testmode/context.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/experimental/testmode/fetch.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/experimental/testmode/server-edge.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/path-browserify/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/shared/lib/isomorphic/path.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/path-to-regexp/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/shared/lib/modern-browserslist-target.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/react/cjs/react.react-server.production.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/react/react.react-server.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/work-async-storage-instance.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/i18n/normalize-locale-path.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/cookies.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/trace/constants.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/after/after-context.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/lru-cache.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/async-local-storage.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/picocolors.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/segment-cache/output-export-prefetch-encoding.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/client-component-renderer-logger.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/sorted-routes.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/path-match.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/escape-regexp.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/dynamic-rendering.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/hooks-server-context.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/static-generation-bailout.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/lazy-dynamic/bailout-to-csr.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/clone-response.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/promise-with-resolvers.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/segment.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/response-cache/types.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/stream-utils/encoded-tags.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/errors/constants.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-kind.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/error.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/adapters/reflect.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/invariant-error.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/app-router-headers.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/interception-prefix-from-param-type.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/querystring.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/redirect-status-code.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/action-revalidation-kind.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/dynamic-rendering-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/framework/boundary-constants.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/constants.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/i18n/detect-domain-locale.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/url.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/incremental-cache/file-system-cache.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/is-dynamic.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/use-cache/handlers.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/after-task-async-storage-instance.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/work-unit-async-storage-instance.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/cache-busting-search-param.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/request-meta.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/parse-loader-tree.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/async-storage/draft-mode-provider.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/revalidation-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/incremental-cache/memory-cache.external.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/resolve-param-value.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/trace/tracer.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/interception-routes.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/parse-relative-url.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/parse-url.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/route-matcher.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/build/output/log.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/incremental-cache/tags-manifest.external.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/staged-rendering.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/stream-utils/uint8array-helpers.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/implicit-tags.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/get-next-pathname-info.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/routes/app.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/page-path/ensure-leading-slash.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/api-utils/get-cookie-parser.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/get-segment-param.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/adapters/headers.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/render-result.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/get-dynamic-param.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/next-url.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/response-cache/utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/format-next-pathname-info.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/request.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/api-utils/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/adapters/next-request.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/incremental-cache/shared-cache-controls.external.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/lazy-result.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/add-path-prefix.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/batcher.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/parse-path.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/route-regex.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/prepare-destination.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/dedupe-fetch.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/manifests-singleton.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/response-cache/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/async-storage/work-store.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/pipe-readable.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/is-thenable.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/multi-file-writer.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/decode-query-path-parameter.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/get-hostname.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/detached-promise.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/scheduler.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/add-path-suffix.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/async-storage/request-store.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/add-locale.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/remove-trailing-slash.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/hash.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/work-unit-async-storage.external.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/adapters/request-cookies.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/path-has-prefix.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/remove-path-prefix.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/route-match-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/cache-handlers/default.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/stream-utils/node-web-streams-helper.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/patch-fetch.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/base-http/helpers.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/route-pattern-normalizer.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/page-path/normalize-page-path.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/server-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/incremental-cache/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/app-paths.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/format-url.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/to-route.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/string-hash/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/action-async-storage-instance.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/react-dom/cjs/react-dom.react-server.production.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/react-dom/react-dom.react-server.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-server.edge.production.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/compiled/react-server-dom-turbopack/server.edge.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/shared/lib/app-router-context.shared-runtime.js/__nextjs-internal-proxy.cjs","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/shared/lib/app-router-context.shared-runtime.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/page-path/normalize-data-path.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/generate-interception-routes-rewrites.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/create-error-handler.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/format-server-error.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/redirect-error.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/error-telemetry-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-modules/app-route/shared-modules.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/cache-signal.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/utils/reflect-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/create-deduped-by-callsite-server-error-logger.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/dynamic-access-async-storage-instance.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/constants.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/is-app-route-route.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/entry-constants.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/router-utils/router-server-context.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/http-access-fallback/http-access-fallback.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/is-plain-object.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/use-cache/constants.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/encryption-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-modules/app-route/module.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-modules/route-module.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/is-error.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/lib/metadata/is-metadata-route.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/router-utils/decode-path-params.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-modules/app-route/helpers/auto-implement-methods.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/server-action-request-meta.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/escape-path-delimiters.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/redirect.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/module-loading/track-module-loading.instance.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/react-large-shell-error.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/prospective-render-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/app-render/interop-default.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/http.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/page-path/normalize-path-sep.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-modules/app-route/helpers/parsed-url-query-to-params.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-modules/app-route/helpers/clean-url.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/request/params.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/client/components/is-next-router-error.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/resume-data-cache/cache-store.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-modules/app-route/helpers/is-static-gen-enabled.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/resume-data-cache/resume-data-cache.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/route-modules/app-route/module.compiled.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/route-matchers/route-matcher.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/internal-edge-wait-until.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/base-http/index.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/adapter.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/base-http/node.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/edge-route-module-wrapper.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/send-response.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/lib/cache-control.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/internal/tslib.mjs","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/internal-utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/response.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/after/builtin-request-context.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/_vendor/partial-json-parser/parser.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/no-fallback-error.external.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/instrumentation/utils.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/qs/formats.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/version.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/chatCompletionUtils.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/spec-extension/fetch-event.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/request-options.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/bytes.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/RunnableFunction.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/sleep.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/parser.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/ChatCompletionStreamingRunner.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/qs/stringify.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/route-matchers/route-matcher.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/web/adapter.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/base-http/web.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/shims.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/server/web/web-on-close.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/esm/shared/lib/router/utils/relativize-url.js","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/qs/utils.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/ResponsesParser.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/values.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/headers.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/base-http/web.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/web/spec-extension/response.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/Util.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/audio/speech.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/images.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/AssistantStream.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/uploads.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/webhooks.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/realtime/sessions.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/ChatCompletionStream.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/completions.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/parse.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/to-file.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/audio/transcriptions.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/audio/translations.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/core/error.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/index.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/web/edge-route-module-wrapper.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/base64.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/fine-tuning/alpha/alpha.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/graders/graders.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/ChatCompletionRunner.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/errors.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/core/pagination.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/AbstractChatCompletionRunner.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/moderations.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/realtime/realtime.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/batches.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/evals/runs/runs.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/fine-tuning/jobs/jobs.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/core/api-promise.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/chat/chat.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/path.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/conversations/items.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/fine-tuning/fine-tuning.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/chatkit/chatkit.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/env.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/containers/files/content.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/evals/runs/output-items.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/vector-stores/files.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/realtime/client-secrets.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/index.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/client.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/core/streaming.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/responses/input-tokens.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/vector-stores/file-batches.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/audio/audio.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/uuid.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/EventStream.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/containers/files/files.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/videos.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/vector-stores/vector-stores.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/utils/log.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/chat/completions/completions.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/responses/responses.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/realtime/realtime.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/decoders/line.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/beta.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/conversations/conversations.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/threads/runs/steps.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/threads/messages.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/assistants.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/containers/containers.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/models.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/chatkit/threads.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/embeddings.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/realtime/calls.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/chatkit/sessions.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/lib/responses/ResponseStream.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/chat/completions/messages.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/uploads/parts.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/responses/input-items.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/fine-tuning/jobs/checkpoints.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/realtime/transcription-sessions.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/internal/detect-platform.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/fine-tuning/alpha/graders.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/azure.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/threads/runs/runs.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/fine-tuning/checkpoints/permissions.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/evals/evals.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/beta/threads/threads.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/src/server/send-response.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/uploads/uploads.ts","turbopack:///[project]/Documents/hhkb/ai-scholar-writer/node_modules/openai/src/resources/files.ts"],"sourcesContent":["import type { AsyncLocalStorage } from 'async_hooks'\n\nconst sharedAsyncLocalStorageNotAvailableError = new Error(\n  'Invariant: AsyncLocalStorage accessed in runtime where it is not available'\n)\n\nclass FakeAsyncLocalStorage<Store extends {}>\n  implements AsyncLocalStorage<Store>\n{\n  disable(): void {\n    throw sharedAsyncLocalStorageNotAvailableError\n  }\n\n  getStore(): Store | undefined {\n    // This fake implementation of AsyncLocalStorage always returns `undefined`.\n    return undefined\n  }\n\n  run<R>(): R {\n    throw sharedAsyncLocalStorageNotAvailableError\n  }\n\n  exit<R>(): R {\n    throw sharedAsyncLocalStorageNotAvailableError\n  }\n\n  enterWith(): void {\n    throw sharedAsyncLocalStorageNotAvailableError\n  }\n\n  static bind<T>(fn: T): T {\n    return fn\n  }\n}\n\nconst maybeGlobalAsyncLocalStorage =\n  typeof globalThis !== 'undefined' && (globalThis as any).AsyncLocalStorage\n\nexport function createAsyncLocalStorage<\n  Store extends {},\n>(): AsyncLocalStorage<Store> {\n  if (maybeGlobalAsyncLocalStorage) {\n    return new maybeGlobalAsyncLocalStorage()\n  }\n  return new FakeAsyncLocalStorage()\n}\n\nexport function bindSnapshot<T>(\n  // WARNING: Don't pass a named function to this argument! See: https://github.com/facebook/react/pull/34911\n  fn: T\n): T {\n  if (maybeGlobalAsyncLocalStorage) {\n    return maybeGlobalAsyncLocalStorage.bind(fn)\n  }\n  return FakeAsyncLocalStorage.bind(fn)\n}\n\nexport function createSnapshot(): <R, TArgs extends any[]>(\n  fn: (...args: TArgs) => R,\n  ...args: TArgs\n) => R {\n  if (maybeGlobalAsyncLocalStorage) {\n    return maybeGlobalAsyncLocalStorage.snapshot()\n  }\n  return function (fn: any, ...args: any[]) {\n    return fn(...args)\n  }\n}\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// src/index.ts\nvar src_exports = {};\n__export(src_exports, {\n  RequestCookies: () => RequestCookies,\n  ResponseCookies: () => ResponseCookies,\n  parseCookie: () => parseCookie,\n  parseSetCookie: () => parseSetCookie,\n  stringifyCookie: () => stringifyCookie\n});\nmodule.exports = __toCommonJS(src_exports);\n\n// src/serialize.ts\nfunction stringifyCookie(c) {\n  var _a;\n  const attrs = [\n    \"path\" in c && c.path && `Path=${c.path}`,\n    \"expires\" in c && (c.expires || c.expires === 0) && `Expires=${(typeof c.expires === \"number\" ? new Date(c.expires) : c.expires).toUTCString()}`,\n    \"maxAge\" in c && typeof c.maxAge === \"number\" && `Max-Age=${c.maxAge}`,\n    \"domain\" in c && c.domain && `Domain=${c.domain}`,\n    \"secure\" in c && c.secure && \"Secure\",\n    \"httpOnly\" in c && c.httpOnly && \"HttpOnly\",\n    \"sameSite\" in c && c.sameSite && `SameSite=${c.sameSite}`,\n    \"partitioned\" in c && c.partitioned && \"Partitioned\",\n    \"priority\" in c && c.priority && `Priority=${c.priority}`\n  ].filter(Boolean);\n  const stringified = `${c.name}=${encodeURIComponent((_a = c.value) != null ? _a : \"\")}`;\n  return attrs.length === 0 ? stringified : `${stringified}; ${attrs.join(\"; \")}`;\n}\nfunction parseCookie(cookie) {\n  const map = /* @__PURE__ */ new Map();\n  for (const pair of cookie.split(/; */)) {\n    if (!pair)\n      continue;\n    const splitAt = pair.indexOf(\"=\");\n    if (splitAt === -1) {\n      map.set(pair, \"true\");\n      continue;\n    }\n    const [key, value] = [pair.slice(0, splitAt), pair.slice(splitAt + 1)];\n    try {\n      map.set(key, decodeURIComponent(value != null ? value : \"true\"));\n    } catch {\n    }\n  }\n  return map;\n}\nfunction parseSetCookie(setCookie) {\n  if (!setCookie) {\n    return void 0;\n  }\n  const [[name, value], ...attributes] = parseCookie(setCookie);\n  const {\n    domain,\n    expires,\n    httponly,\n    maxage,\n    path,\n    samesite,\n    secure,\n    partitioned,\n    priority\n  } = Object.fromEntries(\n    attributes.map(([key, value2]) => [\n      key.toLowerCase().replace(/-/g, \"\"),\n      value2\n    ])\n  );\n  const cookie = {\n    name,\n    value: decodeURIComponent(value),\n    domain,\n    ...expires && { expires: new Date(expires) },\n    ...httponly && { httpOnly: true },\n    ...typeof maxage === \"string\" && { maxAge: Number(maxage) },\n    path,\n    ...samesite && { sameSite: parseSameSite(samesite) },\n    ...secure && { secure: true },\n    ...priority && { priority: parsePriority(priority) },\n    ...partitioned && { partitioned: true }\n  };\n  return compact(cookie);\n}\nfunction compact(t) {\n  const newT = {};\n  for (const key in t) {\n    if (t[key]) {\n      newT[key] = t[key];\n    }\n  }\n  return newT;\n}\nvar SAME_SITE = [\"strict\", \"lax\", \"none\"];\nfunction parseSameSite(string) {\n  string = string.toLowerCase();\n  return SAME_SITE.includes(string) ? string : void 0;\n}\nvar PRIORITY = [\"low\", \"medium\", \"high\"];\nfunction parsePriority(string) {\n  string = string.toLowerCase();\n  return PRIORITY.includes(string) ? string : void 0;\n}\nfunction splitCookiesString(cookiesString) {\n  if (!cookiesString)\n    return [];\n  var cookiesStrings = [];\n  var pos = 0;\n  var start;\n  var ch;\n  var lastComma;\n  var nextStart;\n  var cookiesSeparatorFound;\n  function skipWhitespace() {\n    while (pos < cookiesString.length && /\\s/.test(cookiesString.charAt(pos))) {\n      pos += 1;\n    }\n    return pos < cookiesString.length;\n  }\n  function notSpecialChar() {\n    ch = cookiesString.charAt(pos);\n    return ch !== \"=\" && ch !== \";\" && ch !== \",\";\n  }\n  while (pos < cookiesString.length) {\n    start = pos;\n    cookiesSeparatorFound = false;\n    while (skipWhitespace()) {\n      ch = cookiesString.charAt(pos);\n      if (ch === \",\") {\n        lastComma = pos;\n        pos += 1;\n        skipWhitespace();\n        nextStart = pos;\n        while (pos < cookiesString.length && notSpecialChar()) {\n          pos += 1;\n        }\n        if (pos < cookiesString.length && cookiesString.charAt(pos) === \"=\") {\n          cookiesSeparatorFound = true;\n          pos = nextStart;\n          cookiesStrings.push(cookiesString.substring(start, lastComma));\n          start = pos;\n        } else {\n          pos = lastComma + 1;\n        }\n      } else {\n        pos += 1;\n      }\n    }\n    if (!cookiesSeparatorFound || pos >= cookiesString.length) {\n      cookiesStrings.push(cookiesString.substring(start, cookiesString.length));\n    }\n  }\n  return cookiesStrings;\n}\n\n// src/request-cookies.ts\nvar RequestCookies = class {\n  constructor(requestHeaders) {\n    /** @internal */\n    this._parsed = /* @__PURE__ */ new Map();\n    this._headers = requestHeaders;\n    const header = requestHeaders.get(\"cookie\");\n    if (header) {\n      const parsed = parseCookie(header);\n      for (const [name, value] of parsed) {\n        this._parsed.set(name, { name, value });\n      }\n    }\n  }\n  [Symbol.iterator]() {\n    return this._parsed[Symbol.iterator]();\n  }\n  /**\n   * The amount of cookies received from the client\n   */\n  get size() {\n    return this._parsed.size;\n  }\n  get(...args) {\n    const name = typeof args[0] === \"string\" ? args[0] : args[0].name;\n    return this._parsed.get(name);\n  }\n  getAll(...args) {\n    var _a;\n    const all = Array.from(this._parsed);\n    if (!args.length) {\n      return all.map(([_, value]) => value);\n    }\n    const name = typeof args[0] === \"string\" ? args[0] : (_a = args[0]) == null ? void 0 : _a.name;\n    return all.filter(([n]) => n === name).map(([_, value]) => value);\n  }\n  has(name) {\n    return this._parsed.has(name);\n  }\n  set(...args) {\n    const [name, value] = args.length === 1 ? [args[0].name, args[0].value] : args;\n    const map = this._parsed;\n    map.set(name, { name, value });\n    this._headers.set(\n      \"cookie\",\n      Array.from(map).map(([_, value2]) => stringifyCookie(value2)).join(\"; \")\n    );\n    return this;\n  }\n  /**\n   * Delete the cookies matching the passed name or names in the request.\n   */\n  delete(names) {\n    const map = this._parsed;\n    const result = !Array.isArray(names) ? map.delete(names) : names.map((name) => map.delete(name));\n    this._headers.set(\n      \"cookie\",\n      Array.from(map).map(([_, value]) => stringifyCookie(value)).join(\"; \")\n    );\n    return result;\n  }\n  /**\n   * Delete all the cookies in the cookies in the request.\n   */\n  clear() {\n    this.delete(Array.from(this._parsed.keys()));\n    return this;\n  }\n  /**\n   * Format the cookies in the request as a string for logging\n   */\n  [Symbol.for(\"edge-runtime.inspect.custom\")]() {\n    return `RequestCookies ${JSON.stringify(Object.fromEntries(this._parsed))}`;\n  }\n  toString() {\n    return [...this._parsed.values()].map((v) => `${v.name}=${encodeURIComponent(v.value)}`).join(\"; \");\n  }\n};\n\n// src/response-cookies.ts\nvar ResponseCookies = class {\n  constructor(responseHeaders) {\n    /** @internal */\n    this._parsed = /* @__PURE__ */ new Map();\n    var _a, _b, _c;\n    this._headers = responseHeaders;\n    const setCookie = (_c = (_b = (_a = responseHeaders.getSetCookie) == null ? void 0 : _a.call(responseHeaders)) != null ? _b : responseHeaders.get(\"set-cookie\")) != null ? _c : [];\n    const cookieStrings = Array.isArray(setCookie) ? setCookie : splitCookiesString(setCookie);\n    for (const cookieString of cookieStrings) {\n      const parsed = parseSetCookie(cookieString);\n      if (parsed)\n        this._parsed.set(parsed.name, parsed);\n    }\n  }\n  /**\n   * {@link https://wicg.github.io/cookie-store/#CookieStore-get CookieStore#get} without the Promise.\n   */\n  get(...args) {\n    const key = typeof args[0] === \"string\" ? args[0] : args[0].name;\n    return this._parsed.get(key);\n  }\n  /**\n   * {@link https://wicg.github.io/cookie-store/#CookieStore-getAll CookieStore#getAll} without the Promise.\n   */\n  getAll(...args) {\n    var _a;\n    const all = Array.from(this._parsed.values());\n    if (!args.length) {\n      return all;\n    }\n    const key = typeof args[0] === \"string\" ? args[0] : (_a = args[0]) == null ? void 0 : _a.name;\n    return all.filter((c) => c.name === key);\n  }\n  has(name) {\n    return this._parsed.has(name);\n  }\n  /**\n   * {@link https://wicg.github.io/cookie-store/#CookieStore-set CookieStore#set} without the Promise.\n   */\n  set(...args) {\n    const [name, value, cookie] = args.length === 1 ? [args[0].name, args[0].value, args[0]] : args;\n    const map = this._parsed;\n    map.set(name, normalizeCookie({ name, value, ...cookie }));\n    replace(map, this._headers);\n    return this;\n  }\n  /**\n   * {@link https://wicg.github.io/cookie-store/#CookieStore-delete CookieStore#delete} without the Promise.\n   */\n  delete(...args) {\n    const [name, options] = typeof args[0] === \"string\" ? [args[0]] : [args[0].name, args[0]];\n    return this.set({ ...options, name, value: \"\", expires: /* @__PURE__ */ new Date(0) });\n  }\n  [Symbol.for(\"edge-runtime.inspect.custom\")]() {\n    return `ResponseCookies ${JSON.stringify(Object.fromEntries(this._parsed))}`;\n  }\n  toString() {\n    return [...this._parsed.values()].map(stringifyCookie).join(\"; \");\n  }\n};\nfunction replace(bag, headers) {\n  headers.delete(\"set-cookie\");\n  for (const [, value] of bag) {\n    const serialized = stringifyCookie(value);\n    headers.append(\"set-cookie\", serialized);\n  }\n}\nfunction normalizeCookie(cookie = { name: \"\", value: \"\" }) {\n  if (typeof cookie.expires === \"number\") {\n    cookie.expires = new Date(cookie.expires);\n  }\n  if (cookie.maxAge) {\n    cookie.expires = new Date(Date.now() + cookie.maxAge * 1e3);\n  }\n  if (cookie.path === null || cookie.path === void 0) {\n    cookie.path = \"/\";\n  }\n  return cookie;\n}\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  RequestCookies,\n  ResponseCookies,\n  parseCookie,\n  parseSetCookie,\n  stringifyCookie\n});\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nexport interface SpanStatus {\n  /** The status code of this message. */\n  code: SpanStatusCode;\n  /** A developer-facing error message. */\n  message?: string;\n}\n\n/**\n * An enumeration of status codes.\n */\nexport enum SpanStatusCode {\n  /**\n   * The default status.\n   */\n  UNSET = 0,\n  /**\n   * The operation has been validated by an Application developer or\n   * Operator to have completed successfully.\n   */\n  OK = 1,\n  /**\n   * The operation contains an error.\n   */\n  ERROR = 2,\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst VALID_KEY_CHAR_RANGE = '[_0-9a-z-*/]';\nconst VALID_KEY = `[a-z]${VALID_KEY_CHAR_RANGE}{0,255}`;\nconst VALID_VENDOR_KEY = `[a-z0-9]${VALID_KEY_CHAR_RANGE}{0,240}@[a-z]${VALID_KEY_CHAR_RANGE}{0,13}`;\nconst VALID_KEY_REGEX = new RegExp(`^(?:${VALID_KEY}|${VALID_VENDOR_KEY})$`);\nconst VALID_VALUE_BASE_REGEX = /^[ -~]{0,255}[!-~]$/;\nconst INVALID_VALUE_COMMA_EQUAL_REGEX = /,|=/;\n\n/**\n * Key is opaque string up to 256 characters printable. It MUST begin with a\n * lowercase letter, and can only contain lowercase letters a-z, digits 0-9,\n * underscores _, dashes -, asterisks *, and forward slashes /.\n * For multi-tenant vendor scenarios, an at sign (@) can be used to prefix the\n * vendor name. Vendors SHOULD set the tenant ID at the beginning of the key.\n * see https://www.w3.org/TR/trace-context/#key\n */\nexport function validateKey(key: string): boolean {\n  return VALID_KEY_REGEX.test(key);\n}\n\n/**\n * Value is opaque string up to 256 characters printable ASCII RFC0020\n * characters (i.e., the range 0x20 to 0x7E) except comma , and =.\n */\nexport function validateValue(value: string): boolean {\n  return (\n    VALID_VALUE_BASE_REGEX.test(value) &&\n    !INVALID_VALUE_COMMA_EQUAL_REGEX.test(value)\n  );\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nexport enum SpanKind {\n  /** Default value. Indicates that the span is used internally. */\n  INTERNAL = 0,\n\n  /**\n   * Indicates that the span covers server-side handling of an RPC or other\n   * remote request.\n   */\n  SERVER = 1,\n\n  /**\n   * Indicates that the span covers the client-side wrapper around an RPC or\n   * other remote request.\n   */\n  CLIENT = 2,\n\n  /**\n   * Indicates that the span describes producer sending a message to a\n   * broker. Unlike client and server, there is no direct critical path latency\n   * relationship between producer and consumer spans.\n   */\n  PRODUCER = 3,\n\n  /**\n   * Indicates that the span describes consumer receiving a message from a\n   * broker. Unlike client and server, there is no direct critical path latency\n   * relationship between producer and consumer spans.\n   */\n  CONSUMER = 4,\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nexport enum TraceFlags {\n  /** Represents no flag set. */\n  NONE = 0x0,\n  /** Bit to represent whether trace is sampled in trace flags. */\n  SAMPLED = 0x1 << 0,\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context } from '../context/types';\n\n/**\n * Injects `Context` into and extracts it from carriers that travel\n * in-band across process boundaries. Encoding is expected to conform to the\n * HTTP Header Field semantics. Values are often encoded as RPC/HTTP request\n * headers.\n *\n * The carrier of propagated data on both the client (injector) and server\n * (extractor) side is usually an object such as http headers. Propagation is\n * usually implemented via library-specific request interceptors, where the\n * client-side injects values and the server-side extracts them.\n */\nexport interface TextMapPropagator<Carrier = any> {\n  /**\n   * Injects values from a given `Context` into a carrier.\n   *\n   * OpenTelemetry defines a common set of format values (TextMapPropagator),\n   * and each has an expected `carrier` type.\n   *\n   * @param context the Context from which to extract values to transmit over\n   *     the wire.\n   * @param carrier the carrier of propagation fields, such as http request\n   *     headers.\n   * @param setter an optional {@link TextMapSetter}. If undefined, values will be\n   *     set by direct object assignment.\n   */\n  inject(\n    context: Context,\n    carrier: Carrier,\n    setter: TextMapSetter<Carrier>\n  ): void;\n\n  /**\n   * Given a `Context` and a carrier, extract context values from a\n   * carrier and return a new context, created from the old context, with the\n   * extracted values.\n   *\n   * @param context the Context from which to extract values to transmit over\n   *     the wire.\n   * @param carrier the carrier of propagation fields, such as http request\n   *     headers.\n   * @param getter an optional {@link TextMapGetter}. If undefined, keys will be all\n   *     own properties, and keys will be accessed by direct object access.\n   */\n  extract(\n    context: Context,\n    carrier: Carrier,\n    getter: TextMapGetter<Carrier>\n  ): Context;\n\n  /**\n   * Return a list of all fields which may be used by the propagator.\n   */\n  fields(): string[];\n}\n\n/**\n * A setter is specified by the caller to define a specific method\n * to set key/value pairs on the carrier within a propagator.\n */\nexport interface TextMapSetter<Carrier = any> {\n  /**\n   * Callback used to set a key/value pair on an object.\n   *\n   * Should be called by the propagator each time a key/value pair\n   * should be set, and should set that key/value pair on the propagator.\n   *\n   * @param carrier object or class which carries key/value pairs\n   * @param key string key to modify\n   * @param value value to be set to the key on the carrier\n   */\n  set(carrier: Carrier, key: string, value: string): void;\n}\n\n/**\n * A getter is specified by the caller to define a specific method\n * to get the value of a key from a carrier.\n */\nexport interface TextMapGetter<Carrier = any> {\n  /**\n   * Get a list of all keys available on the carrier.\n   *\n   * @param carrier\n   */\n  keys(carrier: Carrier): string[];\n\n  /**\n   * Get the value of a specific key from the carrier.\n   *\n   * @param carrier\n   * @param key\n   */\n  get(carrier: Carrier, key: string): undefined | string | string[];\n}\n\nexport const defaultTextMapGetter: TextMapGetter = {\n  get(carrier, key) {\n    if (carrier == null) {\n      return undefined;\n    }\n    return carrier[key];\n  },\n\n  keys(carrier) {\n    if (carrier == null) {\n      return [];\n    }\n    return Object.keys(carrier);\n  },\n};\n\nexport const defaultTextMapSetter: TextMapSetter = {\n  set(carrier, key, value) {\n    if (carrier == null) {\n      return;\n    }\n\n    carrier[key] = value;\n  },\n};\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DiagLogger, DiagLogFunction } from './types';\n\ntype ConsoleMapKeys = 'error' | 'warn' | 'info' | 'debug' | 'trace';\nconst consoleMap: { n: keyof DiagLogger; c: ConsoleMapKeys }[] = [\n  { n: 'error', c: 'error' },\n  { n: 'warn', c: 'warn' },\n  { n: 'info', c: 'info' },\n  { n: 'debug', c: 'debug' },\n  { n: 'verbose', c: 'trace' },\n];\n\n/**\n * A simple Immutable Console based diagnostic logger which will output any messages to the Console.\n * If you want to limit the amount of logging to a specific level or lower use the\n * {@link createLogLevelDiagLogger}\n */\nexport class DiagConsoleLogger implements DiagLogger {\n  constructor() {\n    function _consoleFunc(funcName: ConsoleMapKeys): DiagLogFunction {\n      return function (...args) {\n        if (console) {\n          // Some environments only expose the console when the F12 developer console is open\n          // eslint-disable-next-line no-console\n          let theFunc = console[funcName];\n          if (typeof theFunc !== 'function') {\n            // Not all environments support all functions\n            // eslint-disable-next-line no-console\n            theFunc = console.log;\n          }\n\n          // One last final check\n          if (typeof theFunc === 'function') {\n            return theFunc.apply(console, args);\n          }\n        }\n      };\n    }\n\n    for (let i = 0; i < consoleMap.length; i++) {\n      this[consoleMap[i].n] = _consoleFunc(consoleMap[i].c);\n    }\n  }\n\n  /** Log an error scenario that was not expected and caused the requested operation to fail. */\n  public error!: DiagLogFunction;\n\n  /**\n   * Log a warning scenario to inform the developer of an issues that should be investigated.\n   * The requested operation may or may not have succeeded or completed.\n   */\n  public warn!: DiagLogFunction;\n\n  /**\n   * Log a general informational message, this should not affect functionality.\n   * This is also the default logging level so this should NOT be used for logging\n   * debugging level information.\n   */\n  public info!: DiagLogFunction;\n\n  /**\n   * Log a general debug message that can be useful for identifying a failure.\n   * Information logged at this level may include diagnostic details that would\n   * help identify a failure scenario. Useful scenarios would be to log the execution\n   * order of async operations\n   */\n  public debug!: DiagLogFunction;\n\n  /**\n   * Log a detailed (verbose) trace level logging that can be used to identify failures\n   * where debug level logging would be insufficient, this level of tracing can include\n   * input and output parameters and as such may include PII information passing through\n   * the API. As such it is recommended that this level of tracing should not be enabled\n   * in a production environment.\n   */\n  public verbose!: DiagLogFunction;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context } from '../context/types';\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\nimport { NoopTextMapPropagator } from '../propagation/NoopTextMapPropagator';\nimport {\n  defaultTextMapGetter,\n  defaultTextMapSetter,\n  TextMapGetter,\n  TextMapPropagator,\n  TextMapSetter,\n} from '../propagation/TextMapPropagator';\nimport {\n  getBaggage,\n  getActiveBaggage,\n  setBaggage,\n  deleteBaggage,\n} from '../baggage/context-helpers';\nimport { createBaggage } from '../baggage/utils';\nimport { DiagAPI } from './diag';\n\nconst API_NAME = 'propagation';\nconst NOOP_TEXT_MAP_PROPAGATOR = new NoopTextMapPropagator();\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry Propagation API\n */\nexport class PropagationAPI {\n  private static _instance?: PropagationAPI;\n\n  /** Empty private constructor prevents end users from constructing a new instance of the API */\n  private constructor() {}\n\n  /** Get the singleton instance of the Propagator API */\n  public static getInstance(): PropagationAPI {\n    if (!this._instance) {\n      this._instance = new PropagationAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Set the current propagator.\n   *\n   * @returns true if the propagator was successfully registered, else false\n   */\n  public setGlobalPropagator(propagator: TextMapPropagator): boolean {\n    return registerGlobal(API_NAME, propagator, DiagAPI.instance());\n  }\n\n  /**\n   * Inject context into a carrier to be propagated inter-process\n   *\n   * @param context Context carrying tracing data to inject\n   * @param carrier carrier to inject context into\n   * @param setter Function used to set values on the carrier\n   */\n  public inject<Carrier>(\n    context: Context,\n    carrier: Carrier,\n    setter: TextMapSetter<Carrier> = defaultTextMapSetter\n  ): void {\n    return this._getGlobalPropagator().inject(context, carrier, setter);\n  }\n\n  /**\n   * Extract context from a carrier\n   *\n   * @param context Context which the newly created context will inherit from\n   * @param carrier Carrier to extract context from\n   * @param getter Function used to extract keys from a carrier\n   */\n  public extract<Carrier>(\n    context: Context,\n    carrier: Carrier,\n    getter: TextMapGetter<Carrier> = defaultTextMapGetter\n  ): Context {\n    return this._getGlobalPropagator().extract(context, carrier, getter);\n  }\n\n  /**\n   * Return a list of all fields which may be used by the propagator.\n   */\n  public fields(): string[] {\n    return this._getGlobalPropagator().fields();\n  }\n\n  /** Remove the global propagator */\n  public disable() {\n    unregisterGlobal(API_NAME, DiagAPI.instance());\n  }\n\n  public createBaggage = createBaggage;\n\n  public getBaggage = getBaggage;\n\n  public getActiveBaggage = getActiveBaggage;\n\n  public setBaggage = setBaggage;\n\n  public deleteBaggage = deleteBaggage;\n\n  private _getGlobalPropagator(): TextMapPropagator {\n    return getGlobal(API_NAME) || NOOP_TEXT_MAP_PROPAGATOR;\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DiagAPI } from '../api/diag';\nimport { BaggageImpl } from './internal/baggage-impl';\nimport { baggageEntryMetadataSymbol } from './internal/symbol';\nimport { Baggage, BaggageEntry, BaggageEntryMetadata } from './types';\n\nconst diag = DiagAPI.instance();\n\n/**\n * Create a new Baggage with optional entries\n *\n * @param entries An array of baggage entries the new baggage should contain\n */\nexport function createBaggage(\n  entries: Record<string, BaggageEntry> = {}\n): Baggage {\n  return new BaggageImpl(new Map(Object.entries(entries)));\n}\n\n/**\n * Create a serializable BaggageEntryMetadata object from a string.\n *\n * @param str string metadata. Format is currently not defined by the spec and has no special meaning.\n *\n */\nexport function baggageEntryMetadataFromString(\n  str: string\n): BaggageEntryMetadata {\n  if (typeof str !== 'string') {\n    diag.error(\n      `Cannot create baggage metadata from unknown type: ${typeof str}`\n    );\n    str = '';\n  }\n\n  return {\n    __TYPE__: baggageEntryMetadataSymbol,\n    toString() {\n      return str;\n    },\n  };\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { VERSION } from '../version';\n\nconst re = /^(\\d+)\\.(\\d+)\\.(\\d+)(-(.+))?$/;\n\n/**\n * Create a function to test an API version to see if it is compatible with the provided ownVersion.\n *\n * The returned function has the following semantics:\n * - Exact match is always compatible\n * - Major versions must match exactly\n *    - 1.x package cannot use global 2.x package\n *    - 2.x package cannot use global 1.x package\n * - The minor version of the API module requesting access to the global API must be less than or equal to the minor version of this API\n *    - 1.3 package may use 1.4 global because the later global contains all functions 1.3 expects\n *    - 1.4 package may NOT use 1.3 global because it may try to call functions which don't exist on 1.3\n * - If the major version is 0, the minor version is treated as the major and the patch is treated as the minor\n * - Patch and build tag differences are not considered at this time\n *\n * @param ownVersion version which should be checked against\n */\nexport function _makeCompatibilityCheck(\n  ownVersion: string\n): (globalVersion: string) => boolean {\n  const acceptedVersions = new Set<string>([ownVersion]);\n  const rejectedVersions = new Set<string>();\n\n  const myVersionMatch = ownVersion.match(re);\n  if (!myVersionMatch) {\n    // we cannot guarantee compatibility so we always return noop\n    return () => false;\n  }\n\n  const ownVersionParsed = {\n    major: +myVersionMatch[1],\n    minor: +myVersionMatch[2],\n    patch: +myVersionMatch[3],\n    prerelease: myVersionMatch[4],\n  };\n\n  // if ownVersion has a prerelease tag, versions must match exactly\n  if (ownVersionParsed.prerelease != null) {\n    return function isExactmatch(globalVersion: string): boolean {\n      return globalVersion === ownVersion;\n    };\n  }\n\n  function _reject(v: string) {\n    rejectedVersions.add(v);\n    return false;\n  }\n\n  function _accept(v: string) {\n    acceptedVersions.add(v);\n    return true;\n  }\n\n  return function isCompatible(globalVersion: string): boolean {\n    if (acceptedVersions.has(globalVersion)) {\n      return true;\n    }\n\n    if (rejectedVersions.has(globalVersion)) {\n      return false;\n    }\n\n    const globalVersionMatch = globalVersion.match(re);\n    if (!globalVersionMatch) {\n      // cannot parse other version\n      // we cannot guarantee compatibility so we always noop\n      return _reject(globalVersion);\n    }\n\n    const globalVersionParsed = {\n      major: +globalVersionMatch[1],\n      minor: +globalVersionMatch[2],\n      patch: +globalVersionMatch[3],\n      prerelease: globalVersionMatch[4],\n    };\n\n    // if globalVersion has a prerelease tag, versions must match exactly\n    if (globalVersionParsed.prerelease != null) {\n      return _reject(globalVersion);\n    }\n\n    // major versions must match\n    if (ownVersionParsed.major !== globalVersionParsed.major) {\n      return _reject(globalVersion);\n    }\n\n    if (ownVersionParsed.major === 0) {\n      if (\n        ownVersionParsed.minor === globalVersionParsed.minor &&\n        ownVersionParsed.patch <= globalVersionParsed.patch\n      ) {\n        return _accept(globalVersion);\n      }\n\n      return _reject(globalVersion);\n    }\n\n    if (ownVersionParsed.minor <= globalVersionParsed.minor) {\n      return _accept(globalVersion);\n    }\n\n    return _reject(globalVersion);\n  };\n}\n\n/**\n * Test an API version to see if it is compatible with this API.\n *\n * - Exact match is always compatible\n * - Major versions must match exactly\n *    - 1.x package cannot use global 2.x package\n *    - 2.x package cannot use global 1.x package\n * - The minor version of the API module requesting access to the global API must be less than or equal to the minor version of this API\n *    - 1.3 package may use 1.4 global because the later global contains all functions 1.3 expects\n *    - 1.4 package may NOT use 1.3 global because it may try to call functions which don't exist on 1.3\n * - If the major version is 0, the minor version is treated as the major and the patch is treated as the minor\n * - Patch and build tag differences are not considered at this time\n *\n * @param version version of the API requesting an instance of the global API\n */\nexport const isCompatible = _makeCompatibilityCheck(VERSION);\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\nimport { ProxyTracerProvider } from '../trace/ProxyTracerProvider';\nimport {\n  isSpanContextValid,\n  wrapSpanContext,\n} from '../trace/spancontext-utils';\nimport { Tracer } from '../trace/tracer';\nimport { TracerProvider } from '../trace/tracer_provider';\nimport {\n  deleteSpan,\n  getActiveSpan,\n  getSpan,\n  getSpanContext,\n  setSpan,\n  setSpanContext,\n} from '../trace/context-utils';\nimport { DiagAPI } from './diag';\n\nconst API_NAME = 'trace';\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry Tracing API\n */\nexport class TraceAPI {\n  private static _instance?: TraceAPI;\n\n  private _proxyTracerProvider = new ProxyTracerProvider();\n\n  /** Empty private constructor prevents end users from constructing a new instance of the API */\n  private constructor() {}\n\n  /** Get the singleton instance of the Trace API */\n  public static getInstance(): TraceAPI {\n    if (!this._instance) {\n      this._instance = new TraceAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Set the current global tracer.\n   *\n   * @returns true if the tracer provider was successfully registered, else false\n   */\n  public setGlobalTracerProvider(provider: TracerProvider): boolean {\n    const success = registerGlobal(\n      API_NAME,\n      this._proxyTracerProvider,\n      DiagAPI.instance()\n    );\n    if (success) {\n      this._proxyTracerProvider.setDelegate(provider);\n    }\n    return success;\n  }\n\n  /**\n   * Returns the global tracer provider.\n   */\n  public getTracerProvider(): TracerProvider {\n    return getGlobal(API_NAME) || this._proxyTracerProvider;\n  }\n\n  /**\n   * Returns a tracer from the global tracer provider.\n   */\n  public getTracer(name: string, version?: string): Tracer {\n    return this.getTracerProvider().getTracer(name, version);\n  }\n\n  /** Remove the global tracer provider */\n  public disable() {\n    unregisterGlobal(API_NAME, DiagAPI.instance());\n    this._proxyTracerProvider = new ProxyTracerProvider();\n  }\n\n  public wrapSpanContext = wrapSpanContext;\n\n  public isSpanContextValid = isSpanContextValid;\n\n  public deleteSpan = deleteSpan;\n\n  public getSpan = getSpan;\n\n  public getActiveSpan = getActiveSpan;\n\n  public getSpanContext = getSpanContext;\n\n  public setSpan = setSpan;\n\n  public setSpanContext = setSpanContext;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ContextAPI } from '../api/context';\nimport { Context } from '../context/types';\nimport { getSpanContext, setSpan } from '../trace/context-utils';\nimport { NonRecordingSpan } from './NonRecordingSpan';\nimport { Span } from './span';\nimport { isSpanContextValid } from './spancontext-utils';\nimport { SpanOptions } from './SpanOptions';\nimport { SpanContext } from './span_context';\nimport { Tracer } from './tracer';\n\nconst contextApi = ContextAPI.getInstance();\n\n/**\n * No-op implementations of {@link Tracer}.\n */\nexport class NoopTracer implements Tracer {\n  // startSpan starts a noop span.\n  startSpan(\n    name: string,\n    options?: SpanOptions,\n    context = contextApi.active()\n  ): Span {\n    const root = Boolean(options?.root);\n    if (root) {\n      return new NonRecordingSpan();\n    }\n\n    const parentFromContext = context && getSpanContext(context);\n\n    if (\n      isSpanContext(parentFromContext) &&\n      isSpanContextValid(parentFromContext)\n    ) {\n      return new NonRecordingSpan(parentFromContext);\n    } else {\n      return new NonRecordingSpan();\n    }\n  }\n\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    fn: F\n  ): ReturnType<F>;\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    opts: SpanOptions | undefined,\n    fn: F\n  ): ReturnType<F>;\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    opts: SpanOptions | undefined,\n    ctx: Context | undefined,\n    fn: F\n  ): ReturnType<F>;\n  startActiveSpan<F extends (span: Span) => ReturnType<F>>(\n    name: string,\n    arg2?: F | SpanOptions,\n    arg3?: F | Context,\n    arg4?: F\n  ): ReturnType<F> | undefined {\n    let opts: SpanOptions | undefined;\n    let ctx: Context | undefined;\n    let fn: F;\n\n    if (arguments.length < 2) {\n      return;\n    } else if (arguments.length === 2) {\n      fn = arg2 as F;\n    } else if (arguments.length === 3) {\n      opts = arg2 as SpanOptions | undefined;\n      fn = arg3 as F;\n    } else {\n      opts = arg2 as SpanOptions | undefined;\n      ctx = arg3 as Context | undefined;\n      fn = arg4 as F;\n    }\n\n    const parentContext = ctx ?? contextApi.active();\n    const span = this.startSpan(name, opts, parentContext);\n    const contextWithSpanSet = setSpan(parentContext, span);\n\n    return contextApi.with(contextWithSpanSet, fn, undefined, span);\n  }\n}\n\nfunction isSpanContext(spanContext: any): spanContext is SpanContext {\n  return (\n    typeof spanContext === 'object' &&\n    typeof spanContext['spanId'] === 'string' &&\n    typeof spanContext['traceId'] === 'string' &&\n    typeof spanContext['traceFlags'] === 'number'\n  );\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NoopTracer } from './NoopTracer';\nimport { Tracer } from './tracer';\nimport { TracerOptions } from './tracer_options';\nimport { TracerProvider } from './tracer_provider';\n\n/**\n * An implementation of the {@link TracerProvider} which returns an impotent\n * Tracer for all calls to `getTracer`.\n *\n * All operations are no-op.\n */\nexport class NoopTracerProvider implements TracerProvider {\n  getTracer(\n    _name?: string,\n    _version?: string,\n    _options?: TracerOptions\n  ): Tracer {\n    return new NoopTracer();\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SpanContext } from './span_context';\nimport { TraceFlags } from './trace_flags';\n\nexport const INVALID_SPANID = '0000000000000000';\nexport const INVALID_TRACEID = '00000000000000000000000000000000';\nexport const INVALID_SPAN_CONTEXT: SpanContext = {\n  traceId: INVALID_TRACEID,\n  spanId: INVALID_SPANID,\n  traceFlags: TraceFlags.NONE,\n};\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context } from '../context/types';\nimport { NoopTracer } from './NoopTracer';\nimport { Span } from './span';\nimport { SpanOptions } from './SpanOptions';\nimport { Tracer } from './tracer';\nimport { TracerOptions } from './tracer_options';\n\nconst NOOP_TRACER = new NoopTracer();\n\n/**\n * Proxy tracer provided by the proxy tracer provider\n */\nexport class ProxyTracer implements Tracer {\n  // When a real implementation is provided, this will be it\n  private _delegate?: Tracer;\n\n  constructor(\n    private _provider: TracerDelegator,\n    public readonly name: string,\n    public readonly version?: string,\n    public readonly options?: TracerOptions\n  ) {}\n\n  startSpan(name: string, options?: SpanOptions, context?: Context): Span {\n    return this._getTracer().startSpan(name, options, context);\n  }\n\n  startActiveSpan<F extends (span: Span) => unknown>(\n    _name: string,\n    _options: F | SpanOptions,\n    _context?: F | Context,\n    _fn?: F\n  ): ReturnType<F> {\n    const tracer = this._getTracer();\n    return Reflect.apply(tracer.startActiveSpan, tracer, arguments);\n  }\n\n  /**\n   * Try to get a tracer from the proxy tracer provider.\n   * If the proxy tracer provider has no delegate, return a noop tracer.\n   */\n  private _getTracer() {\n    if (this._delegate) {\n      return this._delegate;\n    }\n\n    const tracer = this._provider.getDelegateTracer(\n      this.name,\n      this.version,\n      this.options\n    );\n\n    if (!tracer) {\n      return NOOP_TRACER;\n    }\n\n    this._delegate = tracer;\n    return this._delegate;\n  }\n}\n\nexport interface TracerDelegator {\n  getDelegateTracer(\n    name: string,\n    version?: string,\n    options?: TracerOptions\n  ): Tracer | undefined;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Meter, MeterOptions } from './Meter';\nimport { MeterProvider } from './MeterProvider';\nimport { NOOP_METER } from './NoopMeter';\n\n/**\n * An implementation of the {@link MeterProvider} which returns an impotent Meter\n * for all calls to `getMeter`\n */\nexport class NoopMeterProvider implements MeterProvider {\n  getMeter(_name: string, _version?: string, _options?: MeterOptions): Meter {\n    return NOOP_METER;\n  }\n}\n\nexport const NOOP_METER_PROVIDER = new NoopMeterProvider();\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ContextAPI } from '../api/context';\nimport { createContextKey } from '../context/context';\nimport { Context } from '../context/types';\nimport { Baggage } from './types';\n\n/**\n * Baggage key\n */\nconst BAGGAGE_KEY = createContextKey('OpenTelemetry Baggage Key');\n\n/**\n * Retrieve the current baggage from the given context\n *\n * @param {Context} Context that manage all context values\n * @returns {Baggage} Extracted baggage from the context\n */\nexport function getBaggage(context: Context): Baggage | undefined {\n  return (context.getValue(BAGGAGE_KEY) as Baggage) || undefined;\n}\n\n/**\n * Retrieve the current baggage from the active/current context\n *\n * @returns {Baggage} Extracted baggage from the context\n */\nexport function getActiveBaggage(): Baggage | undefined {\n  return getBaggage(ContextAPI.getInstance().active());\n}\n\n/**\n * Store a baggage in the given context\n *\n * @param {Context} Context that manage all context values\n * @param {Baggage} baggage that will be set in the actual context\n */\nexport function setBaggage(context: Context, baggage: Baggage): Context {\n  return context.setValue(BAGGAGE_KEY, baggage);\n}\n\n/**\n * Delete the baggage stored in the given context\n *\n * @param {Context} Context that manage all context values\n */\nexport function deleteBaggage(context: Context): Context {\n  return context.deleteValue(BAGGAGE_KEY);\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { MeterProvider } from '../metrics/MeterProvider';\nimport { ContextManager } from '../context/types';\nimport { DiagLogger } from '../diag/types';\nimport { _globalThis } from '../platform';\nimport { TextMapPropagator } from '../propagation/TextMapPropagator';\nimport type { TracerProvider } from '../trace/tracer_provider';\nimport { VERSION } from '../version';\nimport { isCompatible } from './semver';\n\nconst major = VERSION.split('.')[0];\nconst GLOBAL_OPENTELEMETRY_API_KEY = Symbol.for(\n  `opentelemetry.js.api.${major}`\n);\n\nconst _global = _globalThis as OTelGlobal;\n\nexport function registerGlobal<Type extends keyof OTelGlobalAPI>(\n  type: Type,\n  instance: OTelGlobalAPI[Type],\n  diag: DiagLogger,\n  allowOverride = false\n): boolean {\n  const api = (_global[GLOBAL_OPENTELEMETRY_API_KEY] = _global[\n    GLOBAL_OPENTELEMETRY_API_KEY\n  ] ?? {\n    version: VERSION,\n  });\n\n  if (!allowOverride && api[type]) {\n    // already registered an API of this type\n    const err = new Error(\n      `@opentelemetry/api: Attempted duplicate registration of API: ${type}`\n    );\n    diag.error(err.stack || err.message);\n    return false;\n  }\n\n  if (api.version !== VERSION) {\n    // All registered APIs must be of the same version exactly\n    const err = new Error(\n      `@opentelemetry/api: Registration of version v${api.version} for ${type} does not match previously registered API v${VERSION}`\n    );\n    diag.error(err.stack || err.message);\n    return false;\n  }\n\n  api[type] = instance;\n  diag.debug(\n    `@opentelemetry/api: Registered a global for ${type} v${VERSION}.`\n  );\n\n  return true;\n}\n\nexport function getGlobal<Type extends keyof OTelGlobalAPI>(\n  type: Type\n): OTelGlobalAPI[Type] | undefined {\n  const globalVersion = _global[GLOBAL_OPENTELEMETRY_API_KEY]?.version;\n  if (!globalVersion || !isCompatible(globalVersion)) {\n    return;\n  }\n  return _global[GLOBAL_OPENTELEMETRY_API_KEY]?.[type];\n}\n\nexport function unregisterGlobal(type: keyof OTelGlobalAPI, diag: DiagLogger) {\n  diag.debug(\n    `@opentelemetry/api: Unregistering a global for ${type} v${VERSION}.`\n  );\n  const api = _global[GLOBAL_OPENTELEMETRY_API_KEY];\n\n  if (api) {\n    delete api[type];\n  }\n}\n\ntype OTelGlobal = {\n  [GLOBAL_OPENTELEMETRY_API_KEY]?: OTelGlobalAPI;\n};\n\ntype OTelGlobalAPI = {\n  version: string;\n\n  diag?: DiagLogger;\n  trace?: TracerProvider;\n  context?: ContextManager;\n  metrics?: MeterProvider;\n  propagation?: TextMapPropagator;\n};\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Tracer } from './tracer';\nimport { TracerProvider } from './tracer_provider';\nimport { ProxyTracer } from './ProxyTracer';\nimport { NoopTracerProvider } from './NoopTracerProvider';\nimport { TracerOptions } from './tracer_options';\n\nconst NOOP_TRACER_PROVIDER = new NoopTracerProvider();\n\n/**\n * Tracer provider which provides {@link ProxyTracer}s.\n *\n * Before a delegate is set, tracers provided are NoOp.\n *   When a delegate is set, traces are provided from the delegate.\n *   When a delegate is set after tracers have already been provided,\n *   all tracers already provided will use the provided delegate implementation.\n */\nexport class ProxyTracerProvider implements TracerProvider {\n  private _delegate?: TracerProvider;\n\n  /**\n   * Get a {@link ProxyTracer}\n   */\n  getTracer(name: string, version?: string, options?: TracerOptions): Tracer {\n    return (\n      this.getDelegateTracer(name, version, options) ??\n      new ProxyTracer(this, name, version, options)\n    );\n  }\n\n  getDelegate(): TracerProvider {\n    return this._delegate ?? NOOP_TRACER_PROVIDER;\n  }\n\n  /**\n   * Set the delegate tracer provider\n   */\n  setDelegate(delegate: TracerProvider) {\n    this._delegate = delegate;\n  }\n\n  getDelegateTracer(\n    name: string,\n    version?: string,\n    options?: TracerOptions\n  ): Tracer | undefined {\n    return this._delegate?.getTracer(name, version, options);\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { TraceState } from '../trace_state';\nimport { validateKey, validateValue } from './tracestate-validators';\n\nconst MAX_TRACE_STATE_ITEMS = 32;\nconst MAX_TRACE_STATE_LEN = 512;\nconst LIST_MEMBERS_SEPARATOR = ',';\nconst LIST_MEMBER_KEY_VALUE_SPLITTER = '=';\n\n/**\n * TraceState must be a class and not a simple object type because of the spec\n * requirement (https://www.w3.org/TR/trace-context/#tracestate-field).\n *\n * Here is the list of allowed mutations:\n * - New key-value pair should be added into the beginning of the list\n * - The value of any key can be updated. Modified keys MUST be moved to the\n * beginning of the list.\n */\nexport class TraceStateImpl implements TraceState {\n  private _internalState: Map<string, string> = new Map();\n\n  constructor(rawTraceState?: string) {\n    if (rawTraceState) this._parse(rawTraceState);\n  }\n\n  set(key: string, value: string): TraceStateImpl {\n    // TODO: Benchmark the different approaches(map vs list) and\n    // use the faster one.\n    const traceState = this._clone();\n    if (traceState._internalState.has(key)) {\n      traceState._internalState.delete(key);\n    }\n    traceState._internalState.set(key, value);\n    return traceState;\n  }\n\n  unset(key: string): TraceStateImpl {\n    const traceState = this._clone();\n    traceState._internalState.delete(key);\n    return traceState;\n  }\n\n  get(key: string): string | undefined {\n    return this._internalState.get(key);\n  }\n\n  serialize(): string {\n    return this._keys()\n      .reduce((agg: string[], key) => {\n        agg.push(key + LIST_MEMBER_KEY_VALUE_SPLITTER + this.get(key));\n        return agg;\n      }, [])\n      .join(LIST_MEMBERS_SEPARATOR);\n  }\n\n  private _parse(rawTraceState: string) {\n    if (rawTraceState.length > MAX_TRACE_STATE_LEN) return;\n    this._internalState = rawTraceState\n      .split(LIST_MEMBERS_SEPARATOR)\n      .reverse() // Store in reverse so new keys (.set(...)) will be placed at the beginning\n      .reduce((agg: Map<string, string>, part: string) => {\n        const listMember = part.trim(); // Optional Whitespace (OWS) handling\n        const i = listMember.indexOf(LIST_MEMBER_KEY_VALUE_SPLITTER);\n        if (i !== -1) {\n          const key = listMember.slice(0, i);\n          const value = listMember.slice(i + 1, part.length);\n          if (validateKey(key) && validateValue(value)) {\n            agg.set(key, value);\n          } else {\n            // TODO: Consider to add warning log\n          }\n        }\n        return agg;\n      }, new Map());\n\n    // Because of the reverse() requirement, trunc must be done after map is created\n    if (this._internalState.size > MAX_TRACE_STATE_ITEMS) {\n      this._internalState = new Map(\n        Array.from(this._internalState.entries())\n          .reverse() // Use reverse same as original tracestate parse chain\n          .slice(0, MAX_TRACE_STATE_ITEMS)\n      );\n    }\n  }\n\n  private _keys(): string[] {\n    return Array.from(this._internalState.keys()).reverse();\n  }\n\n  private _clone(): TraceStateImpl {\n    const traceState = new TraceStateImpl();\n    traceState._internalState = new Map(this._internalState);\n    return traceState;\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DiagLogFunction, DiagLogger, DiagLogLevel } from '../types';\n\nexport function createLogLevelDiagLogger(\n  maxLevel: DiagLogLevel,\n  logger: DiagLogger\n): DiagLogger {\n  if (maxLevel < DiagLogLevel.NONE) {\n    maxLevel = DiagLogLevel.NONE;\n  } else if (maxLevel > DiagLogLevel.ALL) {\n    maxLevel = DiagLogLevel.ALL;\n  }\n\n  // In case the logger is null or undefined\n  logger = logger || {};\n\n  function _filterFunc(\n    funcName: keyof DiagLogger,\n    theLevel: DiagLogLevel\n  ): DiagLogFunction {\n    const theFunc = logger[funcName];\n\n    if (typeof theFunc === 'function' && maxLevel >= theLevel) {\n      return theFunc.bind(logger);\n    }\n    return function () {};\n  }\n\n  return {\n    error: _filterFunc('error', DiagLogLevel.ERROR),\n    warn: _filterFunc('warn', DiagLogLevel.WARN),\n    info: _filterFunc('info', DiagLogLevel.INFO),\n    debug: _filterFunc('debug', DiagLogLevel.DEBUG),\n    verbose: _filterFunc('verbose', DiagLogLevel.VERBOSE),\n  };\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Meter, MeterOptions } from '../metrics/Meter';\nimport { MeterProvider } from '../metrics/MeterProvider';\nimport { NOOP_METER_PROVIDER } from '../metrics/NoopMeterProvider';\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\nimport { DiagAPI } from './diag';\n\nconst API_NAME = 'metrics';\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry Metrics API\n */\nexport class MetricsAPI {\n  private static _instance?: MetricsAPI;\n\n  /** Empty private constructor prevents end users from constructing a new instance of the API */\n  private constructor() {}\n\n  /** Get the singleton instance of the Metrics API */\n  public static getInstance(): MetricsAPI {\n    if (!this._instance) {\n      this._instance = new MetricsAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Set the current global meter provider.\n   * Returns true if the meter provider was successfully registered, else false.\n   */\n  public setGlobalMeterProvider(provider: MeterProvider): boolean {\n    return registerGlobal(API_NAME, provider, DiagAPI.instance());\n  }\n\n  /**\n   * Returns the global meter provider.\n   */\n  public getMeterProvider(): MeterProvider {\n    return getGlobal(API_NAME) || NOOP_METER_PROVIDER;\n  }\n\n  /**\n   * Returns a meter from the global meter provider.\n   */\n  public getMeter(\n    name: string,\n    version?: string,\n    options?: MeterOptions\n  ): Meter {\n    return this.getMeterProvider().getMeter(name, version, options);\n  }\n\n  /** Remove the global meter provider */\n  public disable(): void {\n    unregisterGlobal(API_NAME, DiagAPI.instance());\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Exception } from '../common/Exception';\nimport { TimeInput } from '../common/Time';\nimport { SpanAttributes } from './attributes';\nimport { INVALID_SPAN_CONTEXT } from './invalid-span-constants';\nimport { Span } from './span';\nimport { SpanContext } from './span_context';\nimport { SpanStatus } from './status';\nimport { Link } from './link';\n\n/**\n * The NonRecordingSpan is the default {@link Span} that is used when no Span\n * implementation is available. All operations are no-op including context\n * propagation.\n */\nexport class NonRecordingSpan implements Span {\n  constructor(\n    private readonly _spanContext: SpanContext = INVALID_SPAN_CONTEXT\n  ) {}\n\n  // Returns a SpanContext.\n  spanContext(): SpanContext {\n    return this._spanContext;\n  }\n\n  // By default does nothing\n  setAttribute(_key: string, _value: unknown): this {\n    return this;\n  }\n\n  // By default does nothing\n  setAttributes(_attributes: SpanAttributes): this {\n    return this;\n  }\n\n  // By default does nothing\n  addEvent(_name: string, _attributes?: SpanAttributes): this {\n    return this;\n  }\n\n  addLink(_link: Link): this {\n    return this;\n  }\n\n  addLinks(_links: Link[]): this {\n    return this;\n  }\n\n  // By default does nothing\n  setStatus(_status: SpanStatus): this {\n    return this;\n  }\n\n  // By default does nothing\n  updateName(_name: string): this {\n    return this;\n  }\n\n  // By default does nothing\n  end(_endTime?: TimeInput): void {}\n\n  // isRecording always returns false for NonRecordingSpan.\n  isRecording(): boolean {\n    return false;\n  }\n\n  // By default does nothing\n  recordException(_exception: Exception, _time?: TimeInput): void {}\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// this is autogenerated file, see scripts/version-update.js\nexport const VERSION = '1.9.0';\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { INVALID_SPANID, INVALID_TRACEID } from './invalid-span-constants';\nimport { NonRecordingSpan } from './NonRecordingSpan';\nimport { Span } from './span';\nimport { SpanContext } from './span_context';\n\nconst VALID_TRACEID_REGEX = /^([0-9a-f]{32})$/i;\nconst VALID_SPANID_REGEX = /^[0-9a-f]{16}$/i;\n\nexport function isValidTraceId(traceId: string): boolean {\n  return VALID_TRACEID_REGEX.test(traceId) && traceId !== INVALID_TRACEID;\n}\n\nexport function isValidSpanId(spanId: string): boolean {\n  return VALID_SPANID_REGEX.test(spanId) && spanId !== INVALID_SPANID;\n}\n\n/**\n * Returns true if this {@link SpanContext} is valid.\n * @return true if this {@link SpanContext} is valid.\n */\nexport function isSpanContextValid(spanContext: SpanContext): boolean {\n  return (\n    isValidTraceId(spanContext.traceId) && isValidSpanId(spanContext.spanId)\n  );\n}\n\n/**\n * Wrap the given {@link SpanContext} in a new non-recording {@link Span}\n *\n * @param spanContext span context to be wrapped\n * @returns a new non-recording {@link Span} with the provided context\n */\nexport function wrapSpanContext(spanContext: SpanContext): Span {\n  return new NonRecordingSpan(spanContext);\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { createContextKey } from '../context/context';\nimport { Context } from '../context/types';\nimport { Span } from './span';\nimport { SpanContext } from './span_context';\nimport { NonRecordingSpan } from './NonRecordingSpan';\nimport { ContextAPI } from '../api/context';\n\n/**\n * span key\n */\nconst SPAN_KEY = createContextKey('OpenTelemetry Context Key SPAN');\n\n/**\n * Return the span if one exists\n *\n * @param context context to get span from\n */\nexport function getSpan(context: Context): Span | undefined {\n  return (context.getValue(SPAN_KEY) as Span) || undefined;\n}\n\n/**\n * Gets the span from the current context, if one exists.\n */\nexport function getActiveSpan(): Span | undefined {\n  return getSpan(ContextAPI.getInstance().active());\n}\n\n/**\n * Set the span on a context\n *\n * @param context context to use as parent\n * @param span span to set active\n */\nexport function setSpan(context: Context, span: Span): Context {\n  return context.setValue(SPAN_KEY, span);\n}\n\n/**\n * Remove current span stored in the context\n *\n * @param context context to delete span from\n */\nexport function deleteSpan(context: Context): Context {\n  return context.deleteValue(SPAN_KEY);\n}\n\n/**\n * Wrap span context in a NoopSpan and set as span in a new\n * context\n *\n * @param context context to set active span on\n * @param spanContext span context to be wrapped\n */\nexport function setSpanContext(\n  context: Context,\n  spanContext: SpanContext\n): Context {\n  return setSpan(context, new NonRecordingSpan(spanContext));\n}\n\n/**\n * Get the span context of the span if it exists.\n *\n * @param context context to get values from\n */\nexport function getSpanContext(context: Context): SpanContext | undefined {\n  return getSpan(context)?.spanContext();\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context } from './types';\n\n/** Get a key to uniquely identify a context value */\nexport function createContextKey(description: string) {\n  // The specification states that for the same input, multiple calls should\n  // return different keys. Due to the nature of the JS dependency management\n  // system, this creates problems where multiple versions of some package\n  // could hold different keys for the same property.\n  //\n  // Therefore, we use Symbol.for which returns the same key for the same input.\n  return Symbol.for(description);\n}\n\nclass BaseContext implements Context {\n  private _currentContext!: Map<symbol, unknown>;\n\n  /**\n   * Construct a new context which inherits values from an optional parent context.\n   *\n   * @param parentContext a context from which to inherit values\n   */\n  constructor(parentContext?: Map<symbol, unknown>) {\n    // for minification\n    const self = this;\n\n    self._currentContext = parentContext ? new Map(parentContext) : new Map();\n\n    self.getValue = (key: symbol) => self._currentContext.get(key);\n\n    self.setValue = (key: symbol, value: unknown): Context => {\n      const context = new BaseContext(self._currentContext);\n      context._currentContext.set(key, value);\n      return context;\n    };\n\n    self.deleteValue = (key: symbol): Context => {\n      const context = new BaseContext(self._currentContext);\n      context._currentContext.delete(key);\n      return context;\n    };\n  }\n\n  /**\n   * Get a value from the context.\n   *\n   * @param key key which identifies a context value\n   */\n  public getValue!: (key: symbol) => unknown;\n\n  /**\n   * Create a new context which inherits from this context and has\n   * the given key set to the given value.\n   *\n   * @param key context key for which to set the value\n   * @param value value to set for the given key\n   */\n  public setValue!: (key: symbol, value: unknown) => Context;\n\n  /**\n   * Return a new context which inherits from this context but does\n   * not contain a value for the given key.\n   *\n   * @param key context key for which to clear a value\n   */\n  public deleteValue!: (key: symbol) => Context;\n}\n\n/** The root context is used as the default parent context when there is no active context */\nexport const ROOT_CONTEXT: Context = new BaseContext();\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { TraceState } from '../trace_state';\nimport { TraceStateImpl } from './tracestate-impl';\n\nexport function createTraceState(rawTraceState?: string): TraceState {\n  return new TraceStateImpl(rawTraceState);\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Split module-level variable definition into separate files to allow\n// tree-shaking on each api instance.\nimport { DiagAPI } from './api/diag';\n/**\n * Entrypoint for Diag API.\n * Defines Diagnostic handler used for internal diagnostic logging operations.\n * The default provides a Noop DiagLogger implementation which may be changed via the\n * diag.setLogger(logger: DiagLogger) function.\n */\nexport const diag = DiagAPI.instance();\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Split module-level variable definition into separate files to allow\n// tree-shaking on each api instance.\nimport { TraceAPI } from './api/trace';\n/** Entrypoint for trace API */\nexport const trace = TraceAPI.getInstance();\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport { BaggageEntry, BaggageEntryMetadata, Baggage } from './baggage/types';\nexport { baggageEntryMetadataFromString } from './baggage/utils';\nexport { Exception } from './common/Exception';\nexport { HrTime, TimeInput } from './common/Time';\nexport { Attributes, AttributeValue } from './common/Attributes';\n\n// Context APIs\nexport { createContextKey, ROOT_CONTEXT } from './context/context';\nexport { Context, ContextManager } from './context/types';\nexport type { ContextAPI } from './api/context';\n\n// Diag APIs\nexport { DiagConsoleLogger } from './diag/consoleLogger';\nexport {\n  DiagLogFunction,\n  DiagLogger,\n  DiagLogLevel,\n  ComponentLoggerOptions,\n  DiagLoggerOptions,\n} from './diag/types';\nexport type { DiagAPI } from './api/diag';\n\n// Metrics APIs\nexport { createNoopMeter } from './metrics/NoopMeter';\nexport { MeterOptions, Meter } from './metrics/Meter';\nexport { MeterProvider } from './metrics/MeterProvider';\nexport {\n  ValueType,\n  Counter,\n  Gauge,\n  Histogram,\n  MetricOptions,\n  Observable,\n  ObservableCounter,\n  ObservableGauge,\n  ObservableUpDownCounter,\n  UpDownCounter,\n  BatchObservableCallback,\n  MetricAdvice,\n  MetricAttributes,\n  MetricAttributeValue,\n  ObservableCallback,\n} from './metrics/Metric';\nexport {\n  BatchObservableResult,\n  ObservableResult,\n} from './metrics/ObservableResult';\nexport type { MetricsAPI } from './api/metrics';\n\n// Propagation APIs\nexport {\n  TextMapPropagator,\n  TextMapSetter,\n  TextMapGetter,\n  defaultTextMapGetter,\n  defaultTextMapSetter,\n} from './propagation/TextMapPropagator';\nexport type { PropagationAPI } from './api/propagation';\n\n// Trace APIs\nexport { SpanAttributes, SpanAttributeValue } from './trace/attributes';\nexport { Link } from './trace/link';\nexport { ProxyTracer, TracerDelegator } from './trace/ProxyTracer';\nexport { ProxyTracerProvider } from './trace/ProxyTracerProvider';\nexport { Sampler } from './trace/Sampler';\nexport { SamplingDecision, SamplingResult } from './trace/SamplingResult';\nexport { SpanContext } from './trace/span_context';\nexport { SpanKind } from './trace/span_kind';\nexport { Span } from './trace/span';\nexport { SpanOptions } from './trace/SpanOptions';\nexport { SpanStatus, SpanStatusCode } from './trace/status';\nexport { TraceFlags } from './trace/trace_flags';\nexport { TraceState } from './trace/trace_state';\nexport { createTraceState } from './trace/internal/utils';\nexport { TracerProvider } from './trace/tracer_provider';\nexport { Tracer } from './trace/tracer';\nexport { TracerOptions } from './trace/tracer_options';\nexport {\n  isSpanContextValid,\n  isValidTraceId,\n  isValidSpanId,\n} from './trace/spancontext-utils';\nexport {\n  INVALID_SPANID,\n  INVALID_TRACEID,\n  INVALID_SPAN_CONTEXT,\n} from './trace/invalid-span-constants';\nexport type { TraceAPI } from './api/trace';\n\n// Split module-level variable definition into separate files to allow\n// tree-shaking on each api instance.\nimport { context } from './context-api';\nimport { diag } from './diag-api';\nimport { metrics } from './metrics-api';\nimport { propagation } from './propagation-api';\nimport { trace } from './trace-api';\n\n// Named export.\nexport { context, diag, metrics, propagation, trace };\n// Default export.\nexport default {\n  context,\n  diag,\n  metrics,\n  propagation,\n  trace,\n};\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Symbol used to make BaggageEntryMetadata an opaque type\n */\nexport const baggageEntryMetadataSymbol = Symbol('BaggageEntryMetadata');\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Attributes, AttributeValue } from '../common/Attributes';\nimport { Context } from '../context/types';\nimport { BatchObservableResult, ObservableResult } from './ObservableResult';\n\n/**\n * Advisory options influencing aggregation configuration parameters.\n * @experimental\n */\nexport interface MetricAdvice {\n  /**\n   * Hint the explicit bucket boundaries for SDK if the metric is been\n   * aggregated with a HistogramAggregator.\n   */\n  explicitBucketBoundaries?: number[];\n}\n\n/**\n * Options needed for metric creation\n */\nexport interface MetricOptions {\n  /**\n   * The description of the Metric.\n   * @default ''\n   */\n  description?: string;\n\n  /**\n   * The unit of the Metric values.\n   * @default ''\n   */\n  unit?: string;\n\n  /**\n   * Indicates the type of the recorded value.\n   * @default {@link ValueType.DOUBLE}\n   */\n  valueType?: ValueType;\n\n  /**\n   * The advice influencing aggregation configuration parameters.\n   * @experimental\n   */\n  advice?: MetricAdvice;\n}\n\n/** The Type of value. It describes how the data is reported. */\nexport enum ValueType {\n  INT,\n  DOUBLE,\n}\n\n/**\n * Counter is the most common synchronous instrument. This instrument supports\n * an `Add(increment)` function for reporting a sum, and is restricted to\n * non-negative increments. The default aggregation is Sum, as for any additive\n * instrument.\n *\n * Example uses for Counter:\n * <ol>\n *   <li> count the number of bytes received. </li>\n *   <li> count the number of requests completed. </li>\n *   <li> count the number of accounts created. </li>\n *   <li> count the number of checkpoints run. </li>\n *   <li> count the number of 5xx errors. </li>\n * <ol>\n */\nexport interface Counter<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> {\n  /**\n   * Increment value of counter by the input. Inputs must not be negative.\n   */\n  add(value: number, attributes?: AttributesTypes, context?: Context): void;\n}\n\nexport interface UpDownCounter<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> {\n  /**\n   * Increment value of counter by the input. Inputs may be negative.\n   */\n  add(value: number, attributes?: AttributesTypes, context?: Context): void;\n}\n\nexport interface Gauge<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> {\n  /**\n   * Records a measurement.\n   */\n  record(value: number, attributes?: AttributesTypes, context?: Context): void;\n}\n\nexport interface Histogram<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> {\n  /**\n   * Records a measurement. Value of the measurement must not be negative.\n   */\n  record(value: number, attributes?: AttributesTypes, context?: Context): void;\n}\n\n/**\n * @deprecated please use {@link Attributes}\n */\nexport type MetricAttributes = Attributes;\n\n/**\n * @deprecated please use {@link AttributeValue}\n */\nexport type MetricAttributeValue = AttributeValue;\n\n/**\n * The observable callback for Observable instruments.\n */\nexport type ObservableCallback<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> = (\n  observableResult: ObservableResult<AttributesTypes>\n) => void | Promise<void>;\n\n/**\n * The observable callback for a batch of Observable instruments.\n */\nexport type BatchObservableCallback<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> = (\n  observableResult: BatchObservableResult<AttributesTypes>\n) => void | Promise<void>;\n\nexport interface Observable<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> {\n  /**\n   * Sets up a function that will be called whenever a metric collection is initiated.\n   *\n   * If the function is already in the list of callbacks for this Observable, the function is not added a second time.\n   */\n  addCallback(callback: ObservableCallback<AttributesTypes>): void;\n\n  /**\n   * Removes a callback previously registered with {@link Observable.addCallback}.\n   */\n  removeCallback(callback: ObservableCallback<AttributesTypes>): void;\n}\n\nexport type ObservableCounter<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> = Observable<AttributesTypes>;\nexport type ObservableUpDownCounter<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> = Observable<AttributesTypes>;\nexport type ObservableGauge<\n  AttributesTypes extends MetricAttributes = MetricAttributes,\n> = Observable<AttributesTypes>;\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport type DiagLogFunction = (message: string, ...args: unknown[]) => void;\n\n/**\n * Defines an internal diagnostic logger interface which is used to log internal diagnostic\n * messages, you can set the default diagnostic logger via the {@link DiagAPI} setLogger function.\n * API provided implementations include :-\n * - a No-Op {@link createNoopDiagLogger}\n * - a {@link DiagLogLevel} filtering wrapper {@link createLogLevelDiagLogger}\n * - a general Console {@link DiagConsoleLogger} version.\n */\nexport interface DiagLogger {\n  /** Log an error scenario that was not expected and caused the requested operation to fail. */\n  error: DiagLogFunction;\n\n  /**\n   * Log a warning scenario to inform the developer of an issues that should be investigated.\n   * The requested operation may or may not have succeeded or completed.\n   */\n  warn: DiagLogFunction;\n\n  /**\n   * Log a general informational message, this should not affect functionality.\n   * This is also the default logging level so this should NOT be used for logging\n   * debugging level information.\n   */\n  info: DiagLogFunction;\n\n  /**\n   * Log a general debug message that can be useful for identifying a failure.\n   * Information logged at this level may include diagnostic details that would\n   * help identify a failure scenario.\n   * For example: Logging the order of execution of async operations.\n   */\n  debug: DiagLogFunction;\n\n  /**\n   * Log a detailed (verbose) trace level logging that can be used to identify failures\n   * where debug level logging would be insufficient, this level of tracing can include\n   * input and output parameters and as such may include PII information passing through\n   * the API. As such it is recommended that this level of tracing should not be enabled\n   * in a production environment.\n   */\n  verbose: DiagLogFunction;\n}\n\n/**\n * Defines the available internal logging levels for the diagnostic logger, the numeric values\n * of the levels are defined to match the original values from the initial LogLevel to avoid\n * compatibility/migration issues for any implementation that assume the numeric ordering.\n */\nexport enum DiagLogLevel {\n  /** Diagnostic Logging level setting to disable all logging (except and forced logs) */\n  NONE = 0,\n\n  /** Identifies an error scenario */\n  ERROR = 30,\n\n  /** Identifies a warning scenario */\n  WARN = 50,\n\n  /** General informational log message */\n  INFO = 60,\n\n  /** General debug log message */\n  DEBUG = 70,\n\n  /**\n   * Detailed trace level logging should only be used for development, should only be set\n   * in a development environment.\n   */\n  VERBOSE = 80,\n\n  /** Used to set the logging level to include all logging */\n  ALL = 9999,\n}\n\n/**\n * Defines options for ComponentLogger\n */\nexport interface ComponentLoggerOptions {\n  namespace: string;\n}\n\nexport interface DiagLoggerOptions {\n  /**\n   * The {@link DiagLogLevel} used to filter logs sent to the logger.\n   *\n   * @defaultValue DiagLogLevel.INFO\n   */\n  logLevel?: DiagLogLevel;\n\n  /**\n   * Setting this value to `true` will suppress the warning message normally emitted when registering a logger when another logger is already registered.\n   */\n  suppressOverrideMessage?: boolean;\n}\n\nexport interface DiagLoggerApi {\n  /**\n   * Set the global DiagLogger and DiagLogLevel.\n   * If a global diag logger is already set, this will override it.\n   *\n   * @param logger - The {@link DiagLogger} instance to set as the default logger.\n   * @param options - A {@link DiagLoggerOptions} object. If not provided, default values will be set.\n   * @returns `true` if the logger was successfully registered, else `false`\n   */\n  setLogger(logger: DiagLogger, options?: DiagLoggerOptions): boolean;\n\n  /**\n   *\n   * @param logger - The {@link DiagLogger} instance to set as the default logger.\n   * @param logLevel - The {@link DiagLogLevel} used to filter logs sent to the logger. If not provided it will default to {@link DiagLogLevel.INFO}.\n   * @returns `true` if the logger was successfully registered, else `false`\n   */\n  setLogger(logger: DiagLogger, logLevel?: DiagLogLevel): boolean;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context } from '../context/types';\nimport { TextMapPropagator } from './TextMapPropagator';\n\n/**\n * No-op implementations of {@link TextMapPropagator}.\n */\nexport class NoopTextMapPropagator implements TextMapPropagator {\n  /** Noop inject function does nothing */\n  inject(_context: Context, _carrier: unknown): void {}\n  /** Noop extract function does nothing and returns the input context */\n  extract(context: Context, _carrier: unknown): Context {\n    return context;\n  }\n  fields(): string[] {\n    return [];\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Updates to this file should also be replicated to @opentelemetry/core too.\n\n/**\n * - globalThis (New standard)\n * - self (Will return the current window instance for supported browsers)\n * - window (fallback for older browser implementations)\n * - global (NodeJS implementation)\n * - <object> (When all else fails)\n */\n\n/** only globals that common to node and browsers are allowed */\n// eslint-disable-next-line node/no-unsupported-features/es-builtins, no-undef\nexport const _globalThis: typeof globalThis =\n  typeof globalThis === 'object'\n    ? globalThis\n    : typeof self === 'object'\n    ? self\n    : typeof window === 'object'\n    ? window\n    : typeof global === 'object'\n    ? global\n    : ({} as typeof globalThis);\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SpanAttributes } from './attributes';\nimport { TraceState } from './trace_state';\n\n/**\n * @deprecated use the one declared in @opentelemetry/sdk-trace-base instead.\n * A sampling decision that determines how a {@link Span} will be recorded\n * and collected.\n */\nexport enum SamplingDecision {\n  /**\n   * `Span.isRecording() === false`, span will not be recorded and all events\n   * and attributes will be dropped.\n   */\n  NOT_RECORD,\n  /**\n   * `Span.isRecording() === true`, but `Sampled` flag in {@link TraceFlags}\n   * MUST NOT be set.\n   */\n  RECORD,\n  /**\n   * `Span.isRecording() === true` AND `Sampled` flag in {@link TraceFlags}\n   * MUST be set.\n   */\n  RECORD_AND_SAMPLED,\n}\n\n/**\n * @deprecated use the one declared in @opentelemetry/sdk-trace-base instead.\n * A sampling result contains a decision for a {@link Span} and additional\n * attributes the sampler would like to added to the Span.\n */\nexport interface SamplingResult {\n  /**\n   * A sampling decision, refer to {@link SamplingDecision} for details.\n   */\n  decision: SamplingDecision;\n  /**\n   * The list of attributes returned by SamplingResult MUST be immutable.\n   * Caller may call {@link Sampler}.shouldSample any number of times and\n   * can safely cache the returned value.\n   */\n  attributes?: Readonly<SpanAttributes>;\n  /**\n   * A {@link TraceState} that will be associated with the {@link Span} through\n   * the new {@link SpanContext}. Samplers SHOULD return the TraceState from\n   * the passed-in {@link Context} if they do not intend to change it. Leaving\n   * the value undefined will also leave the TraceState unchanged.\n   */\n  traceState?: TraceState;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NoopContextManager } from '../context/NoopContextManager';\nimport { Context, ContextManager } from '../context/types';\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\nimport { DiagAPI } from './diag';\n\nconst API_NAME = 'context';\nconst NOOP_CONTEXT_MANAGER = new NoopContextManager();\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry Context API\n */\nexport class ContextAPI {\n  private static _instance?: ContextAPI;\n\n  /** Empty private constructor prevents end users from constructing a new instance of the API */\n  private constructor() {}\n\n  /** Get the singleton instance of the Context API */\n  public static getInstance(): ContextAPI {\n    if (!this._instance) {\n      this._instance = new ContextAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Set the current context manager.\n   *\n   * @returns true if the context manager was successfully registered, else false\n   */\n  public setGlobalContextManager(contextManager: ContextManager): boolean {\n    return registerGlobal(API_NAME, contextManager, DiagAPI.instance());\n  }\n\n  /**\n   * Get the currently active context\n   */\n  public active(): Context {\n    return this._getContextManager().active();\n  }\n\n  /**\n   * Execute a function with an active context\n   *\n   * @param context context to be active during function execution\n   * @param fn function to execute in a context\n   * @param thisArg optional receiver to be used for calling fn\n   * @param args optional arguments forwarded to fn\n   */\n  public with<A extends unknown[], F extends (...args: A) => ReturnType<F>>(\n    context: Context,\n    fn: F,\n    thisArg?: ThisParameterType<F>,\n    ...args: A\n  ): ReturnType<F> {\n    return this._getContextManager().with(context, fn, thisArg, ...args);\n  }\n\n  /**\n   * Bind a context to a target function or event emitter\n   *\n   * @param context context to bind to the event emitter or function. Defaults to the currently active context\n   * @param target function or event emitter to bind\n   */\n  public bind<T>(context: Context, target: T): T {\n    return this._getContextManager().bind(context, target);\n  }\n\n  private _getContextManager(): ContextManager {\n    return getGlobal(API_NAME) || NOOP_CONTEXT_MANAGER;\n  }\n\n  /** Disable and remove the global context manager */\n  public disable() {\n    this._getContextManager().disable();\n    unregisterGlobal(API_NAME, DiagAPI.instance());\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ROOT_CONTEXT } from './context';\nimport * as types from './types';\n\nexport class NoopContextManager implements types.ContextManager {\n  active(): types.Context {\n    return ROOT_CONTEXT;\n  }\n\n  with<A extends unknown[], F extends (...args: A) => ReturnType<F>>(\n    _context: types.Context,\n    fn: F,\n    thisArg?: ThisParameterType<F>,\n    ...args: A\n  ): ReturnType<F> {\n    return fn.call(thisArg, ...args);\n  }\n\n  bind<T>(_context: types.Context, target: T): T {\n    return target;\n  }\n\n  enable(): this {\n    return this;\n  }\n\n  disable(): this {\n    return this;\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Meter } from './Meter';\nimport {\n  BatchObservableCallback,\n  Counter,\n  Gauge,\n  Histogram,\n  MetricAttributes,\n  MetricOptions,\n  Observable,\n  ObservableCallback,\n  ObservableCounter,\n  ObservableGauge,\n  ObservableUpDownCounter,\n  UpDownCounter,\n} from './Metric';\n\n/**\n * NoopMeter is a noop implementation of the {@link Meter} interface. It reuses\n * constant NoopMetrics for all of its methods.\n */\nexport class NoopMeter implements Meter {\n  constructor() {}\n\n  /**\n   * @see {@link Meter.createGauge}\n   */\n  createGauge(_name: string, _options?: MetricOptions): Gauge {\n    return NOOP_GAUGE_METRIC;\n  }\n\n  /**\n   * @see {@link Meter.createHistogram}\n   */\n  createHistogram(_name: string, _options?: MetricOptions): Histogram {\n    return NOOP_HISTOGRAM_METRIC;\n  }\n\n  /**\n   * @see {@link Meter.createCounter}\n   */\n  createCounter(_name: string, _options?: MetricOptions): Counter {\n    return NOOP_COUNTER_METRIC;\n  }\n\n  /**\n   * @see {@link Meter.createUpDownCounter}\n   */\n  createUpDownCounter(_name: string, _options?: MetricOptions): UpDownCounter {\n    return NOOP_UP_DOWN_COUNTER_METRIC;\n  }\n\n  /**\n   * @see {@link Meter.createObservableGauge}\n   */\n  createObservableGauge(\n    _name: string,\n    _options?: MetricOptions\n  ): ObservableGauge {\n    return NOOP_OBSERVABLE_GAUGE_METRIC;\n  }\n\n  /**\n   * @see {@link Meter.createObservableCounter}\n   */\n  createObservableCounter(\n    _name: string,\n    _options?: MetricOptions\n  ): ObservableCounter {\n    return NOOP_OBSERVABLE_COUNTER_METRIC;\n  }\n\n  /**\n   * @see {@link Meter.createObservableUpDownCounter}\n   */\n  createObservableUpDownCounter(\n    _name: string,\n    _options?: MetricOptions\n  ): ObservableUpDownCounter {\n    return NOOP_OBSERVABLE_UP_DOWN_COUNTER_METRIC;\n  }\n\n  /**\n   * @see {@link Meter.addBatchObservableCallback}\n   */\n  addBatchObservableCallback(\n    _callback: BatchObservableCallback,\n    _observables: Observable[]\n  ): void {}\n\n  /**\n   * @see {@link Meter.removeBatchObservableCallback}\n   */\n  removeBatchObservableCallback(_callback: BatchObservableCallback): void {}\n}\n\nexport class NoopMetric {}\n\nexport class NoopCounterMetric extends NoopMetric implements Counter {\n  add(_value: number, _attributes: MetricAttributes): void {}\n}\n\nexport class NoopUpDownCounterMetric\n  extends NoopMetric\n  implements UpDownCounter\n{\n  add(_value: number, _attributes: MetricAttributes): void {}\n}\n\nexport class NoopGaugeMetric extends NoopMetric implements Gauge {\n  record(_value: number, _attributes: MetricAttributes): void {}\n}\n\nexport class NoopHistogramMetric extends NoopMetric implements Histogram {\n  record(_value: number, _attributes: MetricAttributes): void {}\n}\n\nexport class NoopObservableMetric {\n  addCallback(_callback: ObservableCallback) {}\n\n  removeCallback(_callback: ObservableCallback) {}\n}\n\nexport class NoopObservableCounterMetric\n  extends NoopObservableMetric\n  implements ObservableCounter {}\n\nexport class NoopObservableGaugeMetric\n  extends NoopObservableMetric\n  implements ObservableGauge {}\n\nexport class NoopObservableUpDownCounterMetric\n  extends NoopObservableMetric\n  implements ObservableUpDownCounter {}\n\nexport const NOOP_METER = new NoopMeter();\n\n// Synchronous instruments\nexport const NOOP_COUNTER_METRIC = new NoopCounterMetric();\nexport const NOOP_GAUGE_METRIC = new NoopGaugeMetric();\nexport const NOOP_HISTOGRAM_METRIC = new NoopHistogramMetric();\nexport const NOOP_UP_DOWN_COUNTER_METRIC = new NoopUpDownCounterMetric();\n\n// Asynchronous instruments\nexport const NOOP_OBSERVABLE_COUNTER_METRIC = new NoopObservableCounterMetric();\nexport const NOOP_OBSERVABLE_GAUGE_METRIC = new NoopObservableGaugeMetric();\nexport const NOOP_OBSERVABLE_UP_DOWN_COUNTER_METRIC =\n  new NoopObservableUpDownCounterMetric();\n\n/**\n * Create a no-op Meter\n */\nexport function createNoopMeter(): Meter {\n  return NOOP_METER;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DiagComponentLogger } from '../diag/ComponentLogger';\nimport { createLogLevelDiagLogger } from '../diag/internal/logLevelLogger';\nimport {\n  ComponentLoggerOptions,\n  DiagLogFunction,\n  DiagLogger,\n  DiagLoggerApi,\n  DiagLogLevel,\n} from '../diag/types';\nimport {\n  getGlobal,\n  registerGlobal,\n  unregisterGlobal,\n} from '../internal/global-utils';\n\nconst API_NAME = 'diag';\n\n/**\n * Singleton object which represents the entry point to the OpenTelemetry internal\n * diagnostic API\n */\nexport class DiagAPI implements DiagLogger, DiagLoggerApi {\n  private static _instance?: DiagAPI;\n\n  /** Get the singleton instance of the DiagAPI API */\n  public static instance(): DiagAPI {\n    if (!this._instance) {\n      this._instance = new DiagAPI();\n    }\n\n    return this._instance;\n  }\n\n  /**\n   * Private internal constructor\n   * @private\n   */\n  private constructor() {\n    function _logProxy(funcName: keyof DiagLogger): DiagLogFunction {\n      return function (...args) {\n        const logger = getGlobal('diag');\n        // shortcut if logger not set\n        if (!logger) return;\n        return logger[funcName](...args);\n      };\n    }\n\n    // Using self local variable for minification purposes as 'this' cannot be minified\n    const self = this;\n\n    // DiagAPI specific functions\n\n    const setLogger: DiagLoggerApi['setLogger'] = (\n      logger,\n      optionsOrLogLevel = { logLevel: DiagLogLevel.INFO }\n    ) => {\n      if (logger === self) {\n        // There isn't much we can do here.\n        // Logging to the console might break the user application.\n        // Try to log to self. If a logger was previously registered it will receive the log.\n        const err = new Error(\n          'Cannot use diag as the logger for itself. Please use a DiagLogger implementation like ConsoleDiagLogger or a custom implementation'\n        );\n        self.error(err.stack ?? err.message);\n        return false;\n      }\n\n      if (typeof optionsOrLogLevel === 'number') {\n        optionsOrLogLevel = {\n          logLevel: optionsOrLogLevel,\n        };\n      }\n\n      const oldLogger = getGlobal('diag');\n      const newLogger = createLogLevelDiagLogger(\n        optionsOrLogLevel.logLevel ?? DiagLogLevel.INFO,\n        logger\n      );\n      // There already is an logger registered. We'll let it know before overwriting it.\n      if (oldLogger && !optionsOrLogLevel.suppressOverrideMessage) {\n        const stack = new Error().stack ?? '<failed to generate stacktrace>';\n        oldLogger.warn(`Current logger will be overwritten from ${stack}`);\n        newLogger.warn(\n          `Current logger will overwrite one already registered from ${stack}`\n        );\n      }\n\n      return registerGlobal('diag', newLogger, self, true);\n    };\n\n    self.setLogger = setLogger;\n\n    self.disable = () => {\n      unregisterGlobal(API_NAME, self);\n    };\n\n    self.createComponentLogger = (options: ComponentLoggerOptions) => {\n      return new DiagComponentLogger(options);\n    };\n\n    self.verbose = _logProxy('verbose');\n    self.debug = _logProxy('debug');\n    self.info = _logProxy('info');\n    self.warn = _logProxy('warn');\n    self.error = _logProxy('error');\n  }\n\n  public setLogger!: DiagLoggerApi['setLogger'];\n  /**\n   *\n   */\n  public createComponentLogger!: (\n    options: ComponentLoggerOptions\n  ) => DiagLogger;\n\n  // DiagLogger implementation\n  public verbose!: DiagLogFunction;\n  public debug!: DiagLogFunction;\n  public info!: DiagLogFunction;\n  public warn!: DiagLogFunction;\n  public error!: DiagLogFunction;\n\n  /**\n   * Unregister the global logger and return to Noop\n   */\n  public disable!: () => void;\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport type { Baggage, BaggageEntry } from '../types';\n\nexport class BaggageImpl implements Baggage {\n  private _entries: Map<string, BaggageEntry>;\n\n  constructor(entries?: Map<string, BaggageEntry>) {\n    this._entries = entries ? new Map(entries) : new Map();\n  }\n\n  getEntry(key: string): BaggageEntry | undefined {\n    const entry = this._entries.get(key);\n    if (!entry) {\n      return undefined;\n    }\n\n    return Object.assign({}, entry);\n  }\n\n  getAllEntries(): [string, BaggageEntry][] {\n    return Array.from(this._entries.entries()).map(([k, v]) => [k, v]);\n  }\n\n  setEntry(key: string, entry: BaggageEntry): BaggageImpl {\n    const newBaggage = new BaggageImpl(this._entries);\n    newBaggage._entries.set(key, entry);\n    return newBaggage;\n  }\n\n  removeEntry(key: string): BaggageImpl {\n    const newBaggage = new BaggageImpl(this._entries);\n    newBaggage._entries.delete(key);\n    return newBaggage;\n  }\n\n  removeEntries(...keys: string[]): BaggageImpl {\n    const newBaggage = new BaggageImpl(this._entries);\n    for (const key of keys) {\n      newBaggage._entries.delete(key);\n    }\n    return newBaggage;\n  }\n\n  clear(): BaggageImpl {\n    return new BaggageImpl();\n  }\n}\n","/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { getGlobal } from '../internal/global-utils';\nimport { ComponentLoggerOptions, DiagLogger, DiagLogFunction } from './types';\n\n/**\n * Component Logger which is meant to be used as part of any component which\n * will add automatically additional namespace in front of the log message.\n * It will then forward all message to global diag logger\n * @example\n * const cLogger = diag.createComponentLogger({ namespace: '@opentelemetry/instrumentation-http' });\n * cLogger.debug('test');\n * // @opentelemetry/instrumentation-http test\n */\nexport class DiagComponentLogger implements DiagLogger {\n  private _namespace: string;\n\n  constructor(props: ComponentLoggerOptions) {\n    this._namespace = props.namespace || 'DiagComponentLogger';\n  }\n\n  public debug(...args: any[]): void {\n    return logProxy('debug', this._namespace, args);\n  }\n\n  public error(...args: any[]): void {\n    return logProxy('error', this._namespace, args);\n  }\n\n  public info(...args: any[]): void {\n    return logProxy('info', this._namespace, args);\n  }\n\n  public warn(...args: any[]): void {\n    return logProxy('warn', this._namespace, args);\n  }\n\n  public verbose(...args: any[]): void {\n    return logProxy('verbose', this._namespace, args);\n  }\n}\n\nfunction logProxy(\n  funcName: keyof DiagLogger,\n  namespace: string,\n  args: any\n): void {\n  const logger = getGlobal('diag');\n  // shortcut if logger not set\n  if (!logger) {\n    return;\n  }\n\n  args.unshift(namespace);\n  return logger[funcName](...(args as Parameters<DiagLogFunction>));\n}\n","(()=>{\"use strict\";if(typeof __nccwpck_require__!==\"undefined\")__nccwpck_require__.ab=__dirname+\"/\";var e={};(()=>{var r=e;\n/*!\n * cookie\n * Copyright(c) 2012-2014 Roman Shtylman\n * Copyright(c) 2015 Douglas Christopher Wilson\n * MIT Licensed\n */r.parse=parse;r.serialize=serialize;var i=decodeURIComponent;var t=encodeURIComponent;var a=/; */;var n=/^[\\u0009\\u0020-\\u007e\\u0080-\\u00ff]+$/;function parse(e,r){if(typeof e!==\"string\"){throw new TypeError(\"argument str must be a string\")}var t={};var n=r||{};var o=e.split(a);var s=n.decode||i;for(var p=0;p<o.length;p++){var f=o[p];var u=f.indexOf(\"=\");if(u<0){continue}var v=f.substr(0,u).trim();var c=f.substr(++u,f.length).trim();if('\"'==c[0]){c=c.slice(1,-1)}if(undefined==t[v]){t[v]=tryDecode(c,s)}}return t}function serialize(e,r,i){var a=i||{};var o=a.encode||t;if(typeof o!==\"function\"){throw new TypeError(\"option encode is invalid\")}if(!n.test(e)){throw new TypeError(\"argument name is invalid\")}var s=o(r);if(s&&!n.test(s)){throw new TypeError(\"argument val is invalid\")}var p=e+\"=\"+s;if(null!=a.maxAge){var f=a.maxAge-0;if(isNaN(f)||!isFinite(f)){throw new TypeError(\"option maxAge is invalid\")}p+=\"; Max-Age=\"+Math.floor(f)}if(a.domain){if(!n.test(a.domain)){throw new TypeError(\"option domain is invalid\")}p+=\"; Domain=\"+a.domain}if(a.path){if(!n.test(a.path)){throw new TypeError(\"option path is invalid\")}p+=\"; Path=\"+a.path}if(a.expires){if(typeof a.expires.toUTCString!==\"function\"){throw new TypeError(\"option expires is invalid\")}p+=\"; Expires=\"+a.expires.toUTCString()}if(a.httpOnly){p+=\"; HttpOnly\"}if(a.secure){p+=\"; Secure\"}if(a.sameSite){var u=typeof a.sameSite===\"string\"?a.sameSite.toLowerCase():a.sameSite;switch(u){case true:p+=\"; SameSite=Strict\";break;case\"lax\":p+=\"; SameSite=Lax\";break;case\"strict\":p+=\"; SameSite=Strict\";break;case\"none\":p+=\"; SameSite=None\";break;default:throw new TypeError(\"option sameSite is invalid\")}}return p}function tryDecode(e,r){try{return r(e)}catch(r){return e}}})();module.exports=e})();","(()=>{\"use strict\";var e={993:e=>{var t=Object.prototype.hasOwnProperty,n=\"~\";function Events(){}if(Object.create){Events.prototype=Object.create(null);if(!(new Events).__proto__)n=false}function EE(e,t,n){this.fn=e;this.context=t;this.once=n||false}function addListener(e,t,r,i,s){if(typeof r!==\"function\"){throw new TypeError(\"The listener must be a function\")}var o=new EE(r,i||e,s),u=n?n+t:t;if(!e._events[u])e._events[u]=o,e._eventsCount++;else if(!e._events[u].fn)e._events[u].push(o);else e._events[u]=[e._events[u],o];return e}function clearEvent(e,t){if(--e._eventsCount===0)e._events=new Events;else delete e._events[t]}function EventEmitter(){this._events=new Events;this._eventsCount=0}EventEmitter.prototype.eventNames=function eventNames(){var e=[],r,i;if(this._eventsCount===0)return e;for(i in r=this._events){if(t.call(r,i))e.push(n?i.slice(1):i)}if(Object.getOwnPropertySymbols){return e.concat(Object.getOwnPropertySymbols(r))}return e};EventEmitter.prototype.listeners=function listeners(e){var t=n?n+e:e,r=this._events[t];if(!r)return[];if(r.fn)return[r.fn];for(var i=0,s=r.length,o=new Array(s);i<s;i++){o[i]=r[i].fn}return o};EventEmitter.prototype.listenerCount=function listenerCount(e){var t=n?n+e:e,r=this._events[t];if(!r)return 0;if(r.fn)return 1;return r.length};EventEmitter.prototype.emit=function emit(e,t,r,i,s,o){var u=n?n+e:e;if(!this._events[u])return false;var a=this._events[u],l=arguments.length,c,h;if(a.fn){if(a.once)this.removeListener(e,a.fn,undefined,true);switch(l){case 1:return a.fn.call(a.context),true;case 2:return a.fn.call(a.context,t),true;case 3:return a.fn.call(a.context,t,r),true;case 4:return a.fn.call(a.context,t,r,i),true;case 5:return a.fn.call(a.context,t,r,i,s),true;case 6:return a.fn.call(a.context,t,r,i,s,o),true}for(h=1,c=new Array(l-1);h<l;h++){c[h-1]=arguments[h]}a.fn.apply(a.context,c)}else{var _=a.length,f;for(h=0;h<_;h++){if(a[h].once)this.removeListener(e,a[h].fn,undefined,true);switch(l){case 1:a[h].fn.call(a[h].context);break;case 2:a[h].fn.call(a[h].context,t);break;case 3:a[h].fn.call(a[h].context,t,r);break;case 4:a[h].fn.call(a[h].context,t,r,i);break;default:if(!c)for(f=1,c=new Array(l-1);f<l;f++){c[f-1]=arguments[f]}a[h].fn.apply(a[h].context,c)}}}return true};EventEmitter.prototype.on=function on(e,t,n){return addListener(this,e,t,n,false)};EventEmitter.prototype.once=function once(e,t,n){return addListener(this,e,t,n,true)};EventEmitter.prototype.removeListener=function removeListener(e,t,r,i){var s=n?n+e:e;if(!this._events[s])return this;if(!t){clearEvent(this,s);return this}var o=this._events[s];if(o.fn){if(o.fn===t&&(!i||o.once)&&(!r||o.context===r)){clearEvent(this,s)}}else{for(var u=0,a=[],l=o.length;u<l;u++){if(o[u].fn!==t||i&&!o[u].once||r&&o[u].context!==r){a.push(o[u])}}if(a.length)this._events[s]=a.length===1?a[0]:a;else clearEvent(this,s)}return this};EventEmitter.prototype.removeAllListeners=function removeAllListeners(e){var t;if(e){t=n?n+e:e;if(this._events[t])clearEvent(this,t)}else{this._events=new Events;this._eventsCount=0}return this};EventEmitter.prototype.off=EventEmitter.prototype.removeListener;EventEmitter.prototype.addListener=EventEmitter.prototype.on;EventEmitter.prefixed=n;EventEmitter.EventEmitter=EventEmitter;if(true){e.exports=EventEmitter}},213:e=>{e.exports=(e,t)=>{t=t||(()=>{});return e.then((e=>new Promise((e=>{e(t())})).then((()=>e))),(e=>new Promise((e=>{e(t())})).then((()=>{throw e}))))}},574:(e,t)=>{Object.defineProperty(t,\"__esModule\",{value:true});function lowerBound(e,t,n){let r=0;let i=e.length;while(i>0){const s=i/2|0;let o=r+s;if(n(e[o],t)<=0){r=++o;i-=s+1}else{i=s}}return r}t[\"default\"]=lowerBound},821:(e,t,n)=>{Object.defineProperty(t,\"__esModule\",{value:true});const r=n(574);class PriorityQueue{constructor(){this._queue=[]}enqueue(e,t){t=Object.assign({priority:0},t);const n={priority:t.priority,run:e};if(this.size&&this._queue[this.size-1].priority>=t.priority){this._queue.push(n);return}const i=r.default(this._queue,n,((e,t)=>t.priority-e.priority));this._queue.splice(i,0,n)}dequeue(){const e=this._queue.shift();return e===null||e===void 0?void 0:e.run}filter(e){return this._queue.filter((t=>t.priority===e.priority)).map((e=>e.run))}get size(){return this._queue.length}}t[\"default\"]=PriorityQueue},816:(e,t,n)=>{const r=n(213);class TimeoutError extends Error{constructor(e){super(e);this.name=\"TimeoutError\"}}const pTimeout=(e,t,n)=>new Promise(((i,s)=>{if(typeof t!==\"number\"||t<0){throw new TypeError(\"Expected `milliseconds` to be a positive number\")}if(t===Infinity){i(e);return}const o=setTimeout((()=>{if(typeof n===\"function\"){try{i(n())}catch(e){s(e)}return}const r=typeof n===\"string\"?n:`Promise timed out after ${t} milliseconds`;const o=n instanceof Error?n:new TimeoutError(r);if(typeof e.cancel===\"function\"){e.cancel()}s(o)}),t);r(e.then(i,s),(()=>{clearTimeout(o)}))}));e.exports=pTimeout;e.exports[\"default\"]=pTimeout;e.exports.TimeoutError=TimeoutError}};var t={};function __nccwpck_require__(n){var r=t[n];if(r!==undefined){return r.exports}var i=t[n]={exports:{}};var s=true;try{e[n](i,i.exports,__nccwpck_require__);s=false}finally{if(s)delete t[n]}return i.exports}if(typeof __nccwpck_require__!==\"undefined\")__nccwpck_require__.ab=__dirname+\"/\";var n={};(()=>{var e=n;Object.defineProperty(e,\"__esModule\",{value:true});const t=__nccwpck_require__(993);const r=__nccwpck_require__(816);const i=__nccwpck_require__(821);const empty=()=>{};const s=new r.TimeoutError;class PQueue extends t{constructor(e){var t,n,r,s;super();this._intervalCount=0;this._intervalEnd=0;this._pendingCount=0;this._resolveEmpty=empty;this._resolveIdle=empty;e=Object.assign({carryoverConcurrencyCount:false,intervalCap:Infinity,interval:0,concurrency:Infinity,autoStart:true,queueClass:i.default},e);if(!(typeof e.intervalCap===\"number\"&&e.intervalCap>=1)){throw new TypeError(`Expected \\`intervalCap\\` to be a number from 1 and up, got \\`${(n=(t=e.intervalCap)===null||t===void 0?void 0:t.toString())!==null&&n!==void 0?n:\"\"}\\` (${typeof e.intervalCap})`)}if(e.interval===undefined||!(Number.isFinite(e.interval)&&e.interval>=0)){throw new TypeError(`Expected \\`interval\\` to be a finite number >= 0, got \\`${(s=(r=e.interval)===null||r===void 0?void 0:r.toString())!==null&&s!==void 0?s:\"\"}\\` (${typeof e.interval})`)}this._carryoverConcurrencyCount=e.carryoverConcurrencyCount;this._isIntervalIgnored=e.intervalCap===Infinity||e.interval===0;this._intervalCap=e.intervalCap;this._interval=e.interval;this._queue=new e.queueClass;this._queueClass=e.queueClass;this.concurrency=e.concurrency;this._timeout=e.timeout;this._throwOnTimeout=e.throwOnTimeout===true;this._isPaused=e.autoStart===false}get _doesIntervalAllowAnother(){return this._isIntervalIgnored||this._intervalCount<this._intervalCap}get _doesConcurrentAllowAnother(){return this._pendingCount<this._concurrency}_next(){this._pendingCount--;this._tryToStartAnother();this.emit(\"next\")}_resolvePromises(){this._resolveEmpty();this._resolveEmpty=empty;if(this._pendingCount===0){this._resolveIdle();this._resolveIdle=empty;this.emit(\"idle\")}}_onResumeInterval(){this._onInterval();this._initializeIntervalIfNeeded();this._timeoutId=undefined}_isIntervalPaused(){const e=Date.now();if(this._intervalId===undefined){const t=this._intervalEnd-e;if(t<0){this._intervalCount=this._carryoverConcurrencyCount?this._pendingCount:0}else{if(this._timeoutId===undefined){this._timeoutId=setTimeout((()=>{this._onResumeInterval()}),t)}return true}}return false}_tryToStartAnother(){if(this._queue.size===0){if(this._intervalId){clearInterval(this._intervalId)}this._intervalId=undefined;this._resolvePromises();return false}if(!this._isPaused){const e=!this._isIntervalPaused();if(this._doesIntervalAllowAnother&&this._doesConcurrentAllowAnother){const t=this._queue.dequeue();if(!t){return false}this.emit(\"active\");t();if(e){this._initializeIntervalIfNeeded()}return true}}return false}_initializeIntervalIfNeeded(){if(this._isIntervalIgnored||this._intervalId!==undefined){return}this._intervalId=setInterval((()=>{this._onInterval()}),this._interval);this._intervalEnd=Date.now()+this._interval}_onInterval(){if(this._intervalCount===0&&this._pendingCount===0&&this._intervalId){clearInterval(this._intervalId);this._intervalId=undefined}this._intervalCount=this._carryoverConcurrencyCount?this._pendingCount:0;this._processQueue()}_processQueue(){while(this._tryToStartAnother()){}}get concurrency(){return this._concurrency}set concurrency(e){if(!(typeof e===\"number\"&&e>=1)){throw new TypeError(`Expected \\`concurrency\\` to be a number from 1 and up, got \\`${e}\\` (${typeof e})`)}this._concurrency=e;this._processQueue()}async add(e,t={}){return new Promise(((n,i)=>{const run=async()=>{this._pendingCount++;this._intervalCount++;try{const o=this._timeout===undefined&&t.timeout===undefined?e():r.default(Promise.resolve(e()),t.timeout===undefined?this._timeout:t.timeout,(()=>{if(t.throwOnTimeout===undefined?this._throwOnTimeout:t.throwOnTimeout){i(s)}return undefined}));n(await o)}catch(e){i(e)}this._next()};this._queue.enqueue(run,t);this._tryToStartAnother();this.emit(\"add\")}))}async addAll(e,t){return Promise.all(e.map((async e=>this.add(e,t))))}start(){if(!this._isPaused){return this}this._isPaused=false;this._processQueue();return this}pause(){this._isPaused=true}clear(){this._queue=new this._queueClass}async onEmpty(){if(this._queue.size===0){return}return new Promise((e=>{const t=this._resolveEmpty;this._resolveEmpty=()=>{t();e()}}))}async onIdle(){if(this._pendingCount===0&&this._queue.size===0){return}return new Promise((e=>{const t=this._resolveIdle;this._resolveIdle=()=>{t();e()}}))}get size(){return this._queue.size}sizeBy(e){return this._queue.filter(e).length}get pending(){return this._pendingCount}get isPaused(){return this._isPaused}get timeout(){return this._timeout}set timeout(e){this._timeout=e}}e[\"default\"]=PQueue})();module.exports=n})();","/**\n * In edge runtime, these props directly accessed from environment variables.\n *   - local: env vars will be injected through edge-runtime as runtime env vars\n *   - deployment: env vars will be replaced by edge build pipeline\n */\nexport function getEdgePreviewProps() {\n  return {\n    previewModeId: process.env.__NEXT_PREVIEW_MODE_ID || '',\n    previewModeSigningKey: process.env.__NEXT_PREVIEW_MODE_SIGNING_KEY || '',\n    previewModeEncryptionKey:\n      process.env.__NEXT_PREVIEW_MODE_ENCRYPTION_KEY || '',\n  }\n}\n","import { AsyncLocalStorage } from 'node:async_hooks'\n\nexport interface TestReqInfo {\n  url: string\n  proxyPort: number\n  testData: string\n}\n\nexport interface TestRequestReader<R> {\n  url(req: R): string\n  header(req: R, name: string): string | null\n}\n\nconst testStorage = new AsyncLocalStorage<TestReqInfo>()\n\nfunction extractTestInfoFromRequest<R>(\n  req: R,\n  reader: TestRequestReader<R>\n): TestReqInfo | undefined {\n  const proxyPortHeader = reader.header(req, 'next-test-proxy-port')\n  if (!proxyPortHeader) {\n    return undefined\n  }\n  const url = reader.url(req)\n  const proxyPort = Number(proxyPortHeader)\n  const testData = reader.header(req, 'next-test-data') || ''\n  return { url, proxyPort, testData }\n}\n\nexport function withRequest<R, T>(\n  req: R,\n  reader: TestRequestReader<R>,\n  fn: () => T\n): T {\n  const testReqInfo = extractTestInfoFromRequest(req, reader)\n  if (!testReqInfo) {\n    return fn()\n  }\n  return testStorage.run(testReqInfo, fn)\n}\n\nexport function getTestReqInfo<R>(\n  req?: R,\n  reader?: TestRequestReader<R>\n): TestReqInfo | undefined {\n  const testReqInfo = testStorage.getStore()\n  if (testReqInfo) {\n    return testReqInfo\n  }\n  if (req && reader) {\n    return extractTestInfoFromRequest(req, reader)\n  }\n  return undefined\n}\n","import type {\n  ProxyFetchRequest,\n  ProxyFetchResponse,\n  ProxyResponse,\n} from './proxy'\nimport { getTestReqInfo, type TestRequestReader } from './context'\n\ntype Fetch = typeof fetch\ntype FetchInputArg = Parameters<Fetch>[0]\ntype FetchInitArg = Parameters<Fetch>[1]\n\nexport const reader: TestRequestReader<Request> = {\n  url(req) {\n    return req.url\n  },\n  header(req, name) {\n    return req.headers.get(name)\n  },\n}\n\nfunction getTestStack(): string {\n  let stack = (new Error().stack ?? '').split('\\n')\n  // Skip the first line and find first non-empty line.\n  for (let i = 1; i < stack.length; i++) {\n    if (stack[i].length > 0) {\n      stack = stack.slice(i)\n      break\n    }\n  }\n  // Filter out franmework lines.\n  stack = stack.filter((f) => !f.includes('/next/dist/'))\n  // At most 5 lines.\n  stack = stack.slice(0, 5)\n  // Cleanup some internal info and trim.\n  stack = stack.map((s) => s.replace('webpack-internal:///(rsc)/', '').trim())\n  return stack.join('    ')\n}\n\nasync function buildProxyRequest(\n  testData: string,\n  request: Request\n): Promise<ProxyFetchRequest> {\n  const {\n    url,\n    method,\n    headers,\n    body,\n    cache,\n    credentials,\n    integrity,\n    mode,\n    redirect,\n    referrer,\n    referrerPolicy,\n  } = request\n  return {\n    testData,\n    api: 'fetch',\n    request: {\n      url,\n      method,\n      headers: [...Array.from(headers), ['next-test-stack', getTestStack()]],\n      body: body\n        ? Buffer.from(await request.arrayBuffer()).toString('base64')\n        : null,\n      cache,\n      credentials,\n      integrity,\n      mode,\n      redirect,\n      referrer,\n      referrerPolicy,\n    },\n  }\n}\n\nfunction buildResponse(proxyResponse: ProxyFetchResponse): Response {\n  const { status, headers, body } = proxyResponse.response\n  return new Response(body ? Buffer.from(body, 'base64') : null, {\n    status,\n    headers: new Headers(headers),\n  })\n}\n\nexport async function handleFetch(\n  originalFetch: Fetch,\n  request: Request\n): Promise<Response> {\n  const testInfo = getTestReqInfo(request, reader)\n  if (!testInfo) {\n    // Passthrough non-test requests.\n    return originalFetch(request)\n  }\n\n  const { testData, proxyPort } = testInfo\n  const proxyRequest = await buildProxyRequest(testData, request)\n\n  const resp = await originalFetch(`http://localhost:${proxyPort}`, {\n    method: 'POST',\n    body: JSON.stringify(proxyRequest),\n    next: {\n      // @ts-ignore\n      internal: true,\n    },\n  })\n  if (!resp.ok) {\n    throw new Error(`Proxy request failed: ${resp.status}`)\n  }\n\n  const proxyResponse = (await resp.json()) as ProxyResponse\n  const { api } = proxyResponse\n  switch (api) {\n    case 'continue':\n      return originalFetch(request)\n    case 'abort':\n    case 'unhandled':\n      throw new Error(\n        `Proxy request aborted [${request.method} ${request.url}]`\n      )\n    case 'fetch':\n      return buildResponse(proxyResponse)\n    default:\n      return api satisfies never\n  }\n}\n\nexport function interceptFetch(originalFetch: Fetch) {\n  global.fetch = function testFetch(\n    input: FetchInputArg,\n    init?: FetchInitArg\n  ): Promise<Response> {\n    // Passthrough internal requests.\n    // @ts-ignore\n    if (init?.next?.internal) {\n      return originalFetch(input, init)\n    }\n    return handleFetch(originalFetch, new Request(input, init))\n  }\n  return () => {\n    global.fetch = originalFetch\n  }\n}\n","import { withRequest as withRequestContext } from './context'\nimport { interceptFetch, reader } from './fetch'\n\nexport function interceptTestApis(): () => void {\n  return interceptFetch(global.fetch)\n}\n\nexport function wrapRequestHandler<T, TRequest extends Request>(\n  handler: (req: TRequest, fn: () => T) => T\n): (req: TRequest, fn: () => T) => T {\n  return (req, fn) => withRequestContext(req, reader, () => handler(req, fn))\n}\n","(function(){\"use strict\";var e={114:function(e){function assertPath(e){if(typeof e!==\"string\"){throw new TypeError(\"Path must be a string. Received \"+JSON.stringify(e))}}function normalizeStringPosix(e,r){var t=\"\";var i=0;var n=-1;var a=0;var f;for(var l=0;l<=e.length;++l){if(l<e.length)f=e.charCodeAt(l);else if(f===47)break;else f=47;if(f===47){if(n===l-1||a===1){}else if(n!==l-1&&a===2){if(t.length<2||i!==2||t.charCodeAt(t.length-1)!==46||t.charCodeAt(t.length-2)!==46){if(t.length>2){var s=t.lastIndexOf(\"/\");if(s!==t.length-1){if(s===-1){t=\"\";i=0}else{t=t.slice(0,s);i=t.length-1-t.lastIndexOf(\"/\")}n=l;a=0;continue}}else if(t.length===2||t.length===1){t=\"\";i=0;n=l;a=0;continue}}if(r){if(t.length>0)t+=\"/..\";else t=\"..\";i=2}}else{if(t.length>0)t+=\"/\"+e.slice(n+1,l);else t=e.slice(n+1,l);i=l-n-1}n=l;a=0}else if(f===46&&a!==-1){++a}else{a=-1}}return t}function _format(e,r){var t=r.dir||r.root;var i=r.base||(r.name||\"\")+(r.ext||\"\");if(!t){return i}if(t===r.root){return t+i}return t+e+i}var r={resolve:function resolve(){var e=\"\";var r=false;var t;for(var i=arguments.length-1;i>=-1&&!r;i--){var n;if(i>=0)n=arguments[i];else{if(t===undefined)t=\"\";n=t}assertPath(n);if(n.length===0){continue}e=n+\"/\"+e;r=n.charCodeAt(0)===47}e=normalizeStringPosix(e,!r);if(r){if(e.length>0)return\"/\"+e;else return\"/\"}else if(e.length>0){return e}else{return\".\"}},normalize:function normalize(e){assertPath(e);if(e.length===0)return\".\";var r=e.charCodeAt(0)===47;var t=e.charCodeAt(e.length-1)===47;e=normalizeStringPosix(e,!r);if(e.length===0&&!r)e=\".\";if(e.length>0&&t)e+=\"/\";if(r)return\"/\"+e;return e},isAbsolute:function isAbsolute(e){assertPath(e);return e.length>0&&e.charCodeAt(0)===47},join:function join(){if(arguments.length===0)return\".\";var e;for(var t=0;t<arguments.length;++t){var i=arguments[t];assertPath(i);if(i.length>0){if(e===undefined)e=i;else e+=\"/\"+i}}if(e===undefined)return\".\";return r.normalize(e)},relative:function relative(e,t){assertPath(e);assertPath(t);if(e===t)return\"\";e=r.resolve(e);t=r.resolve(t);if(e===t)return\"\";var i=1;for(;i<e.length;++i){if(e.charCodeAt(i)!==47)break}var n=e.length;var a=n-i;var f=1;for(;f<t.length;++f){if(t.charCodeAt(f)!==47)break}var l=t.length;var s=l-f;var o=a<s?a:s;var u=-1;var h=0;for(;h<=o;++h){if(h===o){if(s>o){if(t.charCodeAt(f+h)===47){return t.slice(f+h+1)}else if(h===0){return t.slice(f+h)}}else if(a>o){if(e.charCodeAt(i+h)===47){u=h}else if(h===0){u=0}}break}var c=e.charCodeAt(i+h);var v=t.charCodeAt(f+h);if(c!==v)break;else if(c===47)u=h}var g=\"\";for(h=i+u+1;h<=n;++h){if(h===n||e.charCodeAt(h)===47){if(g.length===0)g+=\"..\";else g+=\"/..\"}}if(g.length>0)return g+t.slice(f+u);else{f+=u;if(t.charCodeAt(f)===47)++f;return t.slice(f)}},_makeLong:function _makeLong(e){return e},dirname:function dirname(e){assertPath(e);if(e.length===0)return\".\";var r=e.charCodeAt(0);var t=r===47;var i=-1;var n=true;for(var a=e.length-1;a>=1;--a){r=e.charCodeAt(a);if(r===47){if(!n){i=a;break}}else{n=false}}if(i===-1)return t?\"/\":\".\";if(t&&i===1)return\"//\";return e.slice(0,i)},basename:function basename(e,r){if(r!==undefined&&typeof r!==\"string\")throw new TypeError('\"ext\" argument must be a string');assertPath(e);var t=0;var i=-1;var n=true;var a;if(r!==undefined&&r.length>0&&r.length<=e.length){if(r.length===e.length&&r===e)return\"\";var f=r.length-1;var l=-1;for(a=e.length-1;a>=0;--a){var s=e.charCodeAt(a);if(s===47){if(!n){t=a+1;break}}else{if(l===-1){n=false;l=a+1}if(f>=0){if(s===r.charCodeAt(f)){if(--f===-1){i=a}}else{f=-1;i=l}}}}if(t===i)i=l;else if(i===-1)i=e.length;return e.slice(t,i)}else{for(a=e.length-1;a>=0;--a){if(e.charCodeAt(a)===47){if(!n){t=a+1;break}}else if(i===-1){n=false;i=a+1}}if(i===-1)return\"\";return e.slice(t,i)}},extname:function extname(e){assertPath(e);var r=-1;var t=0;var i=-1;var n=true;var a=0;for(var f=e.length-1;f>=0;--f){var l=e.charCodeAt(f);if(l===47){if(!n){t=f+1;break}continue}if(i===-1){n=false;i=f+1}if(l===46){if(r===-1)r=f;else if(a!==1)a=1}else if(r!==-1){a=-1}}if(r===-1||i===-1||a===0||a===1&&r===i-1&&r===t+1){return\"\"}return e.slice(r,i)},format:function format(e){if(e===null||typeof e!==\"object\"){throw new TypeError('The \"pathObject\" argument must be of type Object. Received type '+typeof e)}return _format(\"/\",e)},parse:function parse(e){assertPath(e);var r={root:\"\",dir:\"\",base:\"\",ext:\"\",name:\"\"};if(e.length===0)return r;var t=e.charCodeAt(0);var i=t===47;var n;if(i){r.root=\"/\";n=1}else{n=0}var a=-1;var f=0;var l=-1;var s=true;var o=e.length-1;var u=0;for(;o>=n;--o){t=e.charCodeAt(o);if(t===47){if(!s){f=o+1;break}continue}if(l===-1){s=false;l=o+1}if(t===46){if(a===-1)a=o;else if(u!==1)u=1}else if(a!==-1){u=-1}}if(a===-1||l===-1||u===0||u===1&&a===l-1&&a===f+1){if(l!==-1){if(f===0&&i)r.base=r.name=e.slice(1,l);else r.base=r.name=e.slice(f,l)}}else{if(f===0&&i){r.name=e.slice(1,a);r.base=e.slice(1,l)}else{r.name=e.slice(f,a);r.base=e.slice(f,l)}r.ext=e.slice(a,l)}if(f>0)r.dir=e.slice(0,f-1);else if(i)r.dir=\"/\";return r},sep:\"/\",delimiter:\":\",win32:null,posix:null};r.posix=r;e.exports=r}};var r={};function __nccwpck_require__(t){var i=r[t];if(i!==undefined){return i.exports}var n=r[t]={exports:{}};var a=true;try{e[t](n,n.exports,__nccwpck_require__);a=false}finally{if(a)delete r[t]}return n.exports}if(typeof __nccwpck_require__!==\"undefined\")__nccwpck_require__.ab=__dirname+\"/\";var t=__nccwpck_require__(114);module.exports=t})();","/**\n * This module is for next.js server internal usage of path module.\n * It will use native path module for nodejs runtime.\n * It will use path-browserify polyfill for edge runtime.\n */\nlet path\n\nif (process.env.NEXT_RUNTIME === 'edge') {\n  path = require('next/dist/compiled/path-browserify')\n} else {\n  path = require('path')\n}\n\nmodule.exports = path\n","(()=>{\"use strict\";if(typeof __nccwpck_require__!==\"undefined\")__nccwpck_require__.ab=__dirname+\"/\";var e={};(()=>{var n=e;Object.defineProperty(n,\"__esModule\",{value:true});n.pathToRegexp=n.tokensToRegexp=n.regexpToFunction=n.match=n.tokensToFunction=n.compile=n.parse=void 0;function lexer(e){var n=[];var r=0;while(r<e.length){var t=e[r];if(t===\"*\"||t===\"+\"||t===\"?\"){n.push({type:\"MODIFIER\",index:r,value:e[r++]});continue}if(t===\"\\\\\"){n.push({type:\"ESCAPED_CHAR\",index:r++,value:e[r++]});continue}if(t===\"{\"){n.push({type:\"OPEN\",index:r,value:e[r++]});continue}if(t===\"}\"){n.push({type:\"CLOSE\",index:r,value:e[r++]});continue}if(t===\":\"){var a=\"\";var i=r+1;while(i<e.length){var o=e.charCodeAt(i);if(o>=48&&o<=57||o>=65&&o<=90||o>=97&&o<=122||o===95){a+=e[i++];continue}break}if(!a)throw new TypeError(\"Missing parameter name at \".concat(r));n.push({type:\"NAME\",index:r,value:a});r=i;continue}if(t===\"(\"){var c=1;var f=\"\";var i=r+1;if(e[i]===\"?\"){throw new TypeError('Pattern cannot start with \"?\" at '.concat(i))}while(i<e.length){if(e[i]===\"\\\\\"){f+=e[i++]+e[i++];continue}if(e[i]===\")\"){c--;if(c===0){i++;break}}else if(e[i]===\"(\"){c++;if(e[i+1]!==\"?\"){throw new TypeError(\"Capturing groups are not allowed at \".concat(i))}}f+=e[i++]}if(c)throw new TypeError(\"Unbalanced pattern at \".concat(r));if(!f)throw new TypeError(\"Missing pattern at \".concat(r));n.push({type:\"PATTERN\",index:r,value:f});r=i;continue}n.push({type:\"CHAR\",index:r,value:e[r++]})}n.push({type:\"END\",index:r,value:\"\"});return n}function parse(e,n){if(n===void 0){n={}}var r=lexer(e);var t=n.prefixes,a=t===void 0?\"./\":t,i=n.delimiter,o=i===void 0?\"/#?\":i;var c=[];var f=0;var u=0;var p=\"\";var tryConsume=function(e){if(u<r.length&&r[u].type===e)return r[u++].value};var mustConsume=function(e){var n=tryConsume(e);if(n!==undefined)return n;var t=r[u],a=t.type,i=t.index;throw new TypeError(\"Unexpected \".concat(a,\" at \").concat(i,\", expected \").concat(e))};var consumeText=function(){var e=\"\";var n;while(n=tryConsume(\"CHAR\")||tryConsume(\"ESCAPED_CHAR\")){e+=n}return e};var isSafe=function(e){for(var n=0,r=o;n<r.length;n++){var t=r[n];if(e.indexOf(t)>-1)return true}return false};var safePattern=function(e){var n=c[c.length-1];var r=e||(n&&typeof n===\"string\"?n:\"\");if(n&&!r){throw new TypeError('Must have text between two parameters, missing text after \"'.concat(n.name,'\"'))}if(!r||isSafe(r))return\"[^\".concat(escapeString(o),\"]+?\");return\"(?:(?!\".concat(escapeString(r),\")[^\").concat(escapeString(o),\"])+?\")};while(u<r.length){var v=tryConsume(\"CHAR\");var s=tryConsume(\"NAME\");var d=tryConsume(\"PATTERN\");if(s||d){var g=v||\"\";if(a.indexOf(g)===-1){p+=g;g=\"\"}if(p){c.push(p);p=\"\"}c.push({name:s||f++,prefix:g,suffix:\"\",pattern:d||safePattern(g),modifier:tryConsume(\"MODIFIER\")||\"\"});continue}var x=v||tryConsume(\"ESCAPED_CHAR\");if(x){p+=x;continue}if(p){c.push(p);p=\"\"}var h=tryConsume(\"OPEN\");if(h){var g=consumeText();var l=tryConsume(\"NAME\")||\"\";var m=tryConsume(\"PATTERN\")||\"\";var T=consumeText();mustConsume(\"CLOSE\");c.push({name:l||(m?f++:\"\"),pattern:l&&!m?safePattern(g):m,prefix:g,suffix:T,modifier:tryConsume(\"MODIFIER\")||\"\"});continue}mustConsume(\"END\")}return c}n.parse=parse;function compile(e,n){return tokensToFunction(parse(e,n),n)}n.compile=compile;function tokensToFunction(e,n){if(n===void 0){n={}}var r=flags(n);var t=n.encode,a=t===void 0?function(e){return e}:t,i=n.validate,o=i===void 0?true:i;var c=e.map((function(e){if(typeof e===\"object\"){return new RegExp(\"^(?:\".concat(e.pattern,\")$\"),r)}}));return function(n){var r=\"\";for(var t=0;t<e.length;t++){var i=e[t];if(typeof i===\"string\"){r+=i;continue}var f=n?n[i.name]:undefined;var u=i.modifier===\"?\"||i.modifier===\"*\";var p=i.modifier===\"*\"||i.modifier===\"+\";if(Array.isArray(f)){if(!p){throw new TypeError('Expected \"'.concat(i.name,'\" to not repeat, but got an array'))}if(f.length===0){if(u)continue;throw new TypeError('Expected \"'.concat(i.name,'\" to not be empty'))}for(var v=0;v<f.length;v++){var s=a(f[v],i);if(o&&!c[t].test(s)){throw new TypeError('Expected all \"'.concat(i.name,'\" to match \"').concat(i.pattern,'\", but got \"').concat(s,'\"'))}r+=i.prefix+s+i.suffix}continue}if(typeof f===\"string\"||typeof f===\"number\"){var s=a(String(f),i);if(o&&!c[t].test(s)){throw new TypeError('Expected \"'.concat(i.name,'\" to match \"').concat(i.pattern,'\", but got \"').concat(s,'\"'))}r+=i.prefix+s+i.suffix;continue}if(u)continue;var d=p?\"an array\":\"a string\";throw new TypeError('Expected \"'.concat(i.name,'\" to be ').concat(d))}return r}}n.tokensToFunction=tokensToFunction;function match(e,n){var r=[];var t=pathToRegexp(e,r,n);return regexpToFunction(t,r,n)}n.match=match;function regexpToFunction(e,n,r){if(r===void 0){r={}}var t=r.decode,a=t===void 0?function(e){return e}:t;return function(r){var t=e.exec(r);if(!t)return false;var i=t[0],o=t.index;var c=Object.create(null);var _loop_1=function(e){if(t[e]===undefined)return\"continue\";var r=n[e-1];if(r.modifier===\"*\"||r.modifier===\"+\"){c[r.name]=t[e].split(r.prefix+r.suffix).map((function(e){return a(e,r)}))}else{c[r.name]=a(t[e],r)}};for(var f=1;f<t.length;f++){_loop_1(f)}return{path:i,index:o,params:c}}}n.regexpToFunction=regexpToFunction;function escapeString(e){return e.replace(/([.+*?=^!:${}()[\\]|/\\\\])/g,\"\\\\$1\")}function flags(e){return e&&e.sensitive?\"\":\"i\"}function regexpToRegexp(e,n){if(!n)return e;var r=/\\((?:\\?<(.*?)>)?(?!\\?)/g;var t=0;var a=r.exec(e.source);while(a){n.push({name:a[1]||t++,prefix:\"\",suffix:\"\",modifier:\"\",pattern:\"\"});a=r.exec(e.source)}return e}function arrayToRegexp(e,n,r){var t=e.map((function(e){return pathToRegexp(e,n,r).source}));return new RegExp(\"(?:\".concat(t.join(\"|\"),\")\"),flags(r))}function stringToRegexp(e,n,r){return tokensToRegexp(parse(e,r),n,r)}function tokensToRegexp(e,n,r){if(r===void 0){r={}}var t=r.strict,a=t===void 0?false:t,i=r.start,o=i===void 0?true:i,c=r.end,f=c===void 0?true:c,u=r.encode,p=u===void 0?function(e){return e}:u,v=r.delimiter,s=v===void 0?\"/#?\":v,d=r.endsWith,g=d===void 0?\"\":d;var x=\"[\".concat(escapeString(g),\"]|$\");var h=\"[\".concat(escapeString(s),\"]\");var l=o?\"^\":\"\";for(var m=0,T=e;m<T.length;m++){var E=T[m];if(typeof E===\"string\"){l+=escapeString(p(E))}else{var w=escapeString(p(E.prefix));var y=escapeString(p(E.suffix));if(E.pattern){if(n)n.push(E);if(w||y){if(E.modifier===\"+\"||E.modifier===\"*\"){var R=E.modifier===\"*\"?\"?\":\"\";l+=\"(?:\".concat(w,\"((?:\").concat(E.pattern,\")(?:\").concat(y).concat(w,\"(?:\").concat(E.pattern,\"))*)\").concat(y,\")\").concat(R)}else{l+=\"(?:\".concat(w,\"(\").concat(E.pattern,\")\").concat(y,\")\").concat(E.modifier)}}else{if(E.modifier===\"+\"||E.modifier===\"*\"){throw new TypeError('Can not repeat \"'.concat(E.name,'\" without a prefix and suffix'))}l+=\"(\".concat(E.pattern,\")\").concat(E.modifier)}}else{l+=\"(?:\".concat(w).concat(y,\")\").concat(E.modifier)}}}if(f){if(!a)l+=\"\".concat(h,\"?\");l+=!r.endsWith?\"$\":\"(?=\".concat(x,\")\")}else{var A=e[e.length-1];var _=typeof A===\"string\"?h.indexOf(A[A.length-1])>-1:A===undefined;if(!a){l+=\"(?:\".concat(h,\"(?=\").concat(x,\"))?\")}if(!_){l+=\"(?=\".concat(h,\"|\").concat(x,\")\")}}return new RegExp(l,flags(r))}n.tokensToRegexp=tokensToRegexp;function pathToRegexp(e,n,r){if(e instanceof RegExp)return regexpToRegexp(e,n);if(Array.isArray(e))return arrayToRegexp(e,n,r);return stringToRegexp(e,n,r)}n.pathToRegexp=pathToRegexp})();module.exports=e})();","// Note: This file is JS because it's used by the taskfile-swc.js file, which is JS.\n// Keep file changes in sync with the corresponding `.d.ts` files.\n\n/**\n * These are the minimum browser versions that we consider \"modern\" and thus compile for by default.\n * This list was generated using `pnpm browserslist \"baseline widely available\"` on 2025-10-01.\n */\nconst MODERN_BROWSERSLIST_TARGET = [\n  'chrome 111',\n  'edge 111',\n  'firefox 111',\n  'safari 16.4',\n]\n\nmodule.exports = MODERN_BROWSERSLIST_TARGET\n","/**\n * @license React\n * react.react-server.production.js\n *\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\"use strict\";\nvar ReactSharedInternals = { H: null, A: null };\nfunction formatProdErrorMessage(code) {\n  var url = \"https://react.dev/errors/\" + code;\n  if (1 < arguments.length) {\n    url += \"?args[]=\" + encodeURIComponent(arguments[1]);\n    for (var i = 2; i < arguments.length; i++)\n      url += \"&args[]=\" + encodeURIComponent(arguments[i]);\n  }\n  return (\n    \"Minified React error #\" +\n    code +\n    \"; visit \" +\n    url +\n    \" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\"\n  );\n}\nvar isArrayImpl = Array.isArray;\nfunction noop() {}\nvar REACT_ELEMENT_TYPE = Symbol.for(\"react.transitional.element\"),\n  REACT_PORTAL_TYPE = Symbol.for(\"react.portal\"),\n  REACT_FRAGMENT_TYPE = Symbol.for(\"react.fragment\"),\n  REACT_STRICT_MODE_TYPE = Symbol.for(\"react.strict_mode\"),\n  REACT_PROFILER_TYPE = Symbol.for(\"react.profiler\"),\n  REACT_FORWARD_REF_TYPE = Symbol.for(\"react.forward_ref\"),\n  REACT_SUSPENSE_TYPE = Symbol.for(\"react.suspense\"),\n  REACT_MEMO_TYPE = Symbol.for(\"react.memo\"),\n  REACT_LAZY_TYPE = Symbol.for(\"react.lazy\"),\n  REACT_ACTIVITY_TYPE = Symbol.for(\"react.activity\"),\n  REACT_VIEW_TRANSITION_TYPE = Symbol.for(\"react.view_transition\"),\n  MAYBE_ITERATOR_SYMBOL = Symbol.iterator;\nfunction getIteratorFn(maybeIterable) {\n  if (null === maybeIterable || \"object\" !== typeof maybeIterable) return null;\n  maybeIterable =\n    (MAYBE_ITERATOR_SYMBOL && maybeIterable[MAYBE_ITERATOR_SYMBOL]) ||\n    maybeIterable[\"@@iterator\"];\n  return \"function\" === typeof maybeIterable ? maybeIterable : null;\n}\nvar hasOwnProperty = Object.prototype.hasOwnProperty,\n  assign = Object.assign;\nfunction ReactElement(type, key, props) {\n  var refProp = props.ref;\n  return {\n    $$typeof: REACT_ELEMENT_TYPE,\n    type: type,\n    key: key,\n    ref: void 0 !== refProp ? refProp : null,\n    props: props\n  };\n}\nfunction cloneAndReplaceKey(oldElement, newKey) {\n  return ReactElement(oldElement.type, newKey, oldElement.props);\n}\nfunction isValidElement(object) {\n  return (\n    \"object\" === typeof object &&\n    null !== object &&\n    object.$$typeof === REACT_ELEMENT_TYPE\n  );\n}\nfunction escape(key) {\n  var escaperLookup = { \"=\": \"=0\", \":\": \"=2\" };\n  return (\n    \"$\" +\n    key.replace(/[=:]/g, function (match) {\n      return escaperLookup[match];\n    })\n  );\n}\nvar userProvidedKeyEscapeRegex = /\\/+/g;\nfunction getElementKey(element, index) {\n  return \"object\" === typeof element && null !== element && null != element.key\n    ? escape(\"\" + element.key)\n    : index.toString(36);\n}\nfunction resolveThenable(thenable) {\n  switch (thenable.status) {\n    case \"fulfilled\":\n      return thenable.value;\n    case \"rejected\":\n      throw thenable.reason;\n    default:\n      switch (\n        (\"string\" === typeof thenable.status\n          ? thenable.then(noop, noop)\n          : ((thenable.status = \"pending\"),\n            thenable.then(\n              function (fulfilledValue) {\n                \"pending\" === thenable.status &&\n                  ((thenable.status = \"fulfilled\"),\n                  (thenable.value = fulfilledValue));\n              },\n              function (error) {\n                \"pending\" === thenable.status &&\n                  ((thenable.status = \"rejected\"), (thenable.reason = error));\n              }\n            )),\n        thenable.status)\n      ) {\n        case \"fulfilled\":\n          return thenable.value;\n        case \"rejected\":\n          throw thenable.reason;\n      }\n  }\n  throw thenable;\n}\nfunction mapIntoArray(children, array, escapedPrefix, nameSoFar, callback) {\n  var type = typeof children;\n  if (\"undefined\" === type || \"boolean\" === type) children = null;\n  var invokeCallback = !1;\n  if (null === children) invokeCallback = !0;\n  else\n    switch (type) {\n      case \"bigint\":\n      case \"string\":\n      case \"number\":\n        invokeCallback = !0;\n        break;\n      case \"object\":\n        switch (children.$$typeof) {\n          case REACT_ELEMENT_TYPE:\n          case REACT_PORTAL_TYPE:\n            invokeCallback = !0;\n            break;\n          case REACT_LAZY_TYPE:\n            return (\n              (invokeCallback = children._init),\n              mapIntoArray(\n                invokeCallback(children._payload),\n                array,\n                escapedPrefix,\n                nameSoFar,\n                callback\n              )\n            );\n        }\n    }\n  if (invokeCallback)\n    return (\n      (callback = callback(children)),\n      (invokeCallback =\n        \"\" === nameSoFar ? \".\" + getElementKey(children, 0) : nameSoFar),\n      isArrayImpl(callback)\n        ? ((escapedPrefix = \"\"),\n          null != invokeCallback &&\n            (escapedPrefix =\n              invokeCallback.replace(userProvidedKeyEscapeRegex, \"$&/\") + \"/\"),\n          mapIntoArray(callback, array, escapedPrefix, \"\", function (c) {\n            return c;\n          }))\n        : null != callback &&\n          (isValidElement(callback) &&\n            (callback = cloneAndReplaceKey(\n              callback,\n              escapedPrefix +\n                (null == callback.key ||\n                (children && children.key === callback.key)\n                  ? \"\"\n                  : (\"\" + callback.key).replace(\n                      userProvidedKeyEscapeRegex,\n                      \"$&/\"\n                    ) + \"/\") +\n                invokeCallback\n            )),\n          array.push(callback)),\n      1\n    );\n  invokeCallback = 0;\n  var nextNamePrefix = \"\" === nameSoFar ? \".\" : nameSoFar + \":\";\n  if (isArrayImpl(children))\n    for (var i = 0; i < children.length; i++)\n      (nameSoFar = children[i]),\n        (type = nextNamePrefix + getElementKey(nameSoFar, i)),\n        (invokeCallback += mapIntoArray(\n          nameSoFar,\n          array,\n          escapedPrefix,\n          type,\n          callback\n        ));\n  else if (((i = getIteratorFn(children)), \"function\" === typeof i))\n    for (\n      children = i.call(children), i = 0;\n      !(nameSoFar = children.next()).done;\n\n    )\n      (nameSoFar = nameSoFar.value),\n        (type = nextNamePrefix + getElementKey(nameSoFar, i++)),\n        (invokeCallback += mapIntoArray(\n          nameSoFar,\n          array,\n          escapedPrefix,\n          type,\n          callback\n        ));\n  else if (\"object\" === type) {\n    if (\"function\" === typeof children.then)\n      return mapIntoArray(\n        resolveThenable(children),\n        array,\n        escapedPrefix,\n        nameSoFar,\n        callback\n      );\n    array = String(children);\n    throw Error(\n      formatProdErrorMessage(\n        31,\n        \"[object Object]\" === array\n          ? \"object with keys {\" + Object.keys(children).join(\", \") + \"}\"\n          : array\n      )\n    );\n  }\n  return invokeCallback;\n}\nfunction mapChildren(children, func, context) {\n  if (null == children) return children;\n  var result = [],\n    count = 0;\n  mapIntoArray(children, result, \"\", \"\", function (child) {\n    return func.call(context, child, count++);\n  });\n  return result;\n}\nfunction lazyInitializer(payload) {\n  if (-1 === payload._status) {\n    var ctor = payload._result;\n    ctor = ctor();\n    ctor.then(\n      function (moduleObject) {\n        if (0 === payload._status || -1 === payload._status)\n          (payload._status = 1), (payload._result = moduleObject);\n      },\n      function (error) {\n        if (0 === payload._status || -1 === payload._status)\n          (payload._status = 2), (payload._result = error);\n      }\n    );\n    -1 === payload._status && ((payload._status = 0), (payload._result = ctor));\n  }\n  if (1 === payload._status) return payload._result.default;\n  throw payload._result;\n}\nfunction createCacheRoot() {\n  return new WeakMap();\n}\nfunction createCacheNode() {\n  return { s: 0, v: void 0, o: null, p: null };\n}\nvar Children = {\n  map: mapChildren,\n  forEach: function (children, forEachFunc, forEachContext) {\n    mapChildren(\n      children,\n      function () {\n        forEachFunc.apply(this, arguments);\n      },\n      forEachContext\n    );\n  },\n  count: function (children) {\n    var n = 0;\n    mapChildren(children, function () {\n      n++;\n    });\n    return n;\n  },\n  toArray: function (children) {\n    return (\n      mapChildren(children, function (child) {\n        return child;\n      }) || []\n    );\n  },\n  only: function (children) {\n    if (!isValidElement(children)) throw Error(formatProdErrorMessage(143));\n    return children;\n  }\n};\nexports.Activity = REACT_ACTIVITY_TYPE;\nexports.Children = Children;\nexports.Fragment = REACT_FRAGMENT_TYPE;\nexports.Profiler = REACT_PROFILER_TYPE;\nexports.StrictMode = REACT_STRICT_MODE_TYPE;\nexports.Suspense = REACT_SUSPENSE_TYPE;\nexports.ViewTransition = REACT_VIEW_TRANSITION_TYPE;\nexports.__SERVER_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE =\n  ReactSharedInternals;\nexports.cache = function (fn) {\n  return function () {\n    var dispatcher = ReactSharedInternals.A;\n    if (!dispatcher) return fn.apply(null, arguments);\n    var fnMap = dispatcher.getCacheForType(createCacheRoot);\n    dispatcher = fnMap.get(fn);\n    void 0 === dispatcher &&\n      ((dispatcher = createCacheNode()), fnMap.set(fn, dispatcher));\n    fnMap = 0;\n    for (var l = arguments.length; fnMap < l; fnMap++) {\n      var arg = arguments[fnMap];\n      if (\n        \"function\" === typeof arg ||\n        (\"object\" === typeof arg && null !== arg)\n      ) {\n        var objectCache = dispatcher.o;\n        null === objectCache && (dispatcher.o = objectCache = new WeakMap());\n        dispatcher = objectCache.get(arg);\n        void 0 === dispatcher &&\n          ((dispatcher = createCacheNode()), objectCache.set(arg, dispatcher));\n      } else\n        (objectCache = dispatcher.p),\n          null === objectCache && (dispatcher.p = objectCache = new Map()),\n          (dispatcher = objectCache.get(arg)),\n          void 0 === dispatcher &&\n            ((dispatcher = createCacheNode()),\n            objectCache.set(arg, dispatcher));\n    }\n    if (1 === dispatcher.s) return dispatcher.v;\n    if (2 === dispatcher.s) throw dispatcher.v;\n    try {\n      var result = fn.apply(null, arguments);\n      fnMap = dispatcher;\n      fnMap.s = 1;\n      return (fnMap.v = result);\n    } catch (error) {\n      throw ((result = dispatcher), (result.s = 2), (result.v = error), error);\n    }\n  };\n};\nexports.cacheSignal = function () {\n  var dispatcher = ReactSharedInternals.A;\n  return dispatcher ? dispatcher.cacheSignal() : null;\n};\nexports.captureOwnerStack = function () {\n  return null;\n};\nexports.cloneElement = function (element, config, children) {\n  if (null === element || void 0 === element)\n    throw Error(formatProdErrorMessage(267, element));\n  var props = assign({}, element.props),\n    key = element.key;\n  if (null != config)\n    for (propName in (void 0 !== config.key && (key = \"\" + config.key), config))\n      !hasOwnProperty.call(config, propName) ||\n        \"key\" === propName ||\n        \"__self\" === propName ||\n        \"__source\" === propName ||\n        (\"ref\" === propName && void 0 === config.ref) ||\n        (props[propName] = config[propName]);\n  var propName = arguments.length - 2;\n  if (1 === propName) props.children = children;\n  else if (1 < propName) {\n    for (var childArray = Array(propName), i = 0; i < propName; i++)\n      childArray[i] = arguments[i + 2];\n    props.children = childArray;\n  }\n  return ReactElement(element.type, key, props);\n};\nexports.createElement = function (type, config, children) {\n  var propName,\n    props = {},\n    key = null;\n  if (null != config)\n    for (propName in (void 0 !== config.key && (key = \"\" + config.key), config))\n      hasOwnProperty.call(config, propName) &&\n        \"key\" !== propName &&\n        \"__self\" !== propName &&\n        \"__source\" !== propName &&\n        (props[propName] = config[propName]);\n  var childrenLength = arguments.length - 2;\n  if (1 === childrenLength) props.children = children;\n  else if (1 < childrenLength) {\n    for (var childArray = Array(childrenLength), i = 0; i < childrenLength; i++)\n      childArray[i] = arguments[i + 2];\n    props.children = childArray;\n  }\n  if (type && type.defaultProps)\n    for (propName in ((childrenLength = type.defaultProps), childrenLength))\n      void 0 === props[propName] &&\n        (props[propName] = childrenLength[propName]);\n  return ReactElement(type, key, props);\n};\nexports.createRef = function () {\n  return { current: null };\n};\nexports.forwardRef = function (render) {\n  return { $$typeof: REACT_FORWARD_REF_TYPE, render: render };\n};\nexports.isValidElement = isValidElement;\nexports.lazy = function (ctor) {\n  return {\n    $$typeof: REACT_LAZY_TYPE,\n    _payload: { _status: -1, _result: ctor },\n    _init: lazyInitializer\n  };\n};\nexports.memo = function (type, compare) {\n  return {\n    $$typeof: REACT_MEMO_TYPE,\n    type: type,\n    compare: void 0 === compare ? null : compare\n  };\n};\nexports.use = function (usable) {\n  return ReactSharedInternals.H.use(usable);\n};\nexports.useCallback = function (callback, deps) {\n  return ReactSharedInternals.H.useCallback(callback, deps);\n};\nexports.useDebugValue = function () {};\nexports.useId = function () {\n  return ReactSharedInternals.H.useId();\n};\nexports.useMemo = function (create, deps) {\n  return ReactSharedInternals.H.useMemo(create, deps);\n};\nexports.version = \"19.3.0-canary-f93b9fd4-20251217\";\n","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('./cjs/react.react-server.production.js');\n} else {\n  module.exports = require('./cjs/react.react-server.development.js');\n}\n","import { createAsyncLocalStorage } from './async-local-storage';\nexport const workAsyncStorageInstance = createAsyncLocalStorage();\n\n//# sourceMappingURL=work-async-storage-instance.js.map","/**\n * A cache of lowercased locales for each list of locales. This is stored as a\n * WeakMap so if the locales are garbage collected, the cache entry will be\n * removed as well.\n */ const cache = new WeakMap();\n/**\n * For a pathname that may include a locale from a list of locales, it\n * removes the locale from the pathname returning it alongside with the\n * detected locale.\n *\n * @param pathname A pathname that may include a locale.\n * @param locales A list of locales.\n * @returns The detected locale and pathname without locale\n */ export function normalizeLocalePath(pathname, locales) {\n    // If locales is undefined, return the pathname as is.\n    if (!locales) return {\n        pathname\n    };\n    // Get the cached lowercased locales or create a new cache entry.\n    let lowercasedLocales = cache.get(locales);\n    if (!lowercasedLocales) {\n        lowercasedLocales = locales.map((locale)=>locale.toLowerCase());\n        cache.set(locales, lowercasedLocales);\n    }\n    let detectedLocale;\n    // The first segment will be empty, because it has a leading `/`. If\n    // there is no further segment, there is no locale (or it's the default).\n    const segments = pathname.split('/', 2);\n    // If there's no second segment (ie, the pathname is just `/`), there's no\n    // locale.\n    if (!segments[1]) return {\n        pathname\n    };\n    // The second segment will contain the locale part if any.\n    const segment = segments[1].toLowerCase();\n    // See if the segment matches one of the locales. If it doesn't, there is\n    // no locale (or it's the default).\n    const index = lowercasedLocales.indexOf(segment);\n    if (index < 0) return {\n        pathname\n    };\n    // Return the case-sensitive locale.\n    detectedLocale = locales[index];\n    // Remove the `/${locale}` part of the pathname.\n    pathname = pathname.slice(detectedLocale.length + 1) || '/';\n    return {\n        pathname,\n        detectedLocale\n    };\n}\n\n//# sourceMappingURL=normalize-locale-path.js.map","export { RequestCookies, ResponseCookies, stringifyCookie } from 'next/dist/compiled/@edge-runtime/cookies';\n\n//# sourceMappingURL=cookies.js.map","/**\n * Contains predefined constants for the trace span name in next/server.\n *\n * Currently, next/server/tracer is internal implementation only for tracking\n * next.js's implementation only with known span names defined here.\n **/ // eslint typescript has a bug with TS enums\nvar BaseServerSpan = /*#__PURE__*/ function(BaseServerSpan) {\n    BaseServerSpan[\"handleRequest\"] = \"BaseServer.handleRequest\";\n    BaseServerSpan[\"run\"] = \"BaseServer.run\";\n    BaseServerSpan[\"pipe\"] = \"BaseServer.pipe\";\n    BaseServerSpan[\"getStaticHTML\"] = \"BaseServer.getStaticHTML\";\n    BaseServerSpan[\"render\"] = \"BaseServer.render\";\n    BaseServerSpan[\"renderToResponseWithComponents\"] = \"BaseServer.renderToResponseWithComponents\";\n    BaseServerSpan[\"renderToResponse\"] = \"BaseServer.renderToResponse\";\n    BaseServerSpan[\"renderToHTML\"] = \"BaseServer.renderToHTML\";\n    BaseServerSpan[\"renderError\"] = \"BaseServer.renderError\";\n    BaseServerSpan[\"renderErrorToResponse\"] = \"BaseServer.renderErrorToResponse\";\n    BaseServerSpan[\"renderErrorToHTML\"] = \"BaseServer.renderErrorToHTML\";\n    BaseServerSpan[\"render404\"] = \"BaseServer.render404\";\n    return BaseServerSpan;\n}(BaseServerSpan || {});\nvar LoadComponentsSpan = /*#__PURE__*/ function(LoadComponentsSpan) {\n    LoadComponentsSpan[\"loadDefaultErrorComponents\"] = \"LoadComponents.loadDefaultErrorComponents\";\n    LoadComponentsSpan[\"loadComponents\"] = \"LoadComponents.loadComponents\";\n    return LoadComponentsSpan;\n}(LoadComponentsSpan || {});\nvar NextServerSpan = /*#__PURE__*/ function(NextServerSpan) {\n    NextServerSpan[\"getRequestHandler\"] = \"NextServer.getRequestHandler\";\n    NextServerSpan[\"getRequestHandlerWithMetadata\"] = \"NextServer.getRequestHandlerWithMetadata\";\n    NextServerSpan[\"getServer\"] = \"NextServer.getServer\";\n    NextServerSpan[\"getServerRequestHandler\"] = \"NextServer.getServerRequestHandler\";\n    NextServerSpan[\"createServer\"] = \"createServer.createServer\";\n    return NextServerSpan;\n}(NextServerSpan || {});\nvar NextNodeServerSpan = /*#__PURE__*/ function(NextNodeServerSpan) {\n    NextNodeServerSpan[\"compression\"] = \"NextNodeServer.compression\";\n    NextNodeServerSpan[\"getBuildId\"] = \"NextNodeServer.getBuildId\";\n    NextNodeServerSpan[\"createComponentTree\"] = \"NextNodeServer.createComponentTree\";\n    NextNodeServerSpan[\"clientComponentLoading\"] = \"NextNodeServer.clientComponentLoading\";\n    NextNodeServerSpan[\"getLayoutOrPageModule\"] = \"NextNodeServer.getLayoutOrPageModule\";\n    NextNodeServerSpan[\"generateStaticRoutes\"] = \"NextNodeServer.generateStaticRoutes\";\n    NextNodeServerSpan[\"generateFsStaticRoutes\"] = \"NextNodeServer.generateFsStaticRoutes\";\n    NextNodeServerSpan[\"generatePublicRoutes\"] = \"NextNodeServer.generatePublicRoutes\";\n    NextNodeServerSpan[\"generateImageRoutes\"] = \"NextNodeServer.generateImageRoutes.route\";\n    NextNodeServerSpan[\"sendRenderResult\"] = \"NextNodeServer.sendRenderResult\";\n    NextNodeServerSpan[\"proxyRequest\"] = \"NextNodeServer.proxyRequest\";\n    NextNodeServerSpan[\"runApi\"] = \"NextNodeServer.runApi\";\n    NextNodeServerSpan[\"render\"] = \"NextNodeServer.render\";\n    NextNodeServerSpan[\"renderHTML\"] = \"NextNodeServer.renderHTML\";\n    NextNodeServerSpan[\"imageOptimizer\"] = \"NextNodeServer.imageOptimizer\";\n    NextNodeServerSpan[\"getPagePath\"] = \"NextNodeServer.getPagePath\";\n    NextNodeServerSpan[\"getRoutesManifest\"] = \"NextNodeServer.getRoutesManifest\";\n    NextNodeServerSpan[\"findPageComponents\"] = \"NextNodeServer.findPageComponents\";\n    NextNodeServerSpan[\"getFontManifest\"] = \"NextNodeServer.getFontManifest\";\n    NextNodeServerSpan[\"getServerComponentManifest\"] = \"NextNodeServer.getServerComponentManifest\";\n    NextNodeServerSpan[\"getRequestHandler\"] = \"NextNodeServer.getRequestHandler\";\n    NextNodeServerSpan[\"renderToHTML\"] = \"NextNodeServer.renderToHTML\";\n    NextNodeServerSpan[\"renderError\"] = \"NextNodeServer.renderError\";\n    NextNodeServerSpan[\"renderErrorToHTML\"] = \"NextNodeServer.renderErrorToHTML\";\n    NextNodeServerSpan[\"render404\"] = \"NextNodeServer.render404\";\n    NextNodeServerSpan[\"startResponse\"] = \"NextNodeServer.startResponse\";\n    // nested inner span, does not require parent scope name\n    NextNodeServerSpan[\"route\"] = \"route\";\n    NextNodeServerSpan[\"onProxyReq\"] = \"onProxyReq\";\n    NextNodeServerSpan[\"apiResolver\"] = \"apiResolver\";\n    NextNodeServerSpan[\"internalFetch\"] = \"internalFetch\";\n    return NextNodeServerSpan;\n}(NextNodeServerSpan || {});\nvar StartServerSpan = /*#__PURE__*/ function(StartServerSpan) {\n    StartServerSpan[\"startServer\"] = \"startServer.startServer\";\n    return StartServerSpan;\n}(StartServerSpan || {});\nvar RenderSpan = /*#__PURE__*/ function(RenderSpan) {\n    RenderSpan[\"getServerSideProps\"] = \"Render.getServerSideProps\";\n    RenderSpan[\"getStaticProps\"] = \"Render.getStaticProps\";\n    RenderSpan[\"renderToString\"] = \"Render.renderToString\";\n    RenderSpan[\"renderDocument\"] = \"Render.renderDocument\";\n    RenderSpan[\"createBodyResult\"] = \"Render.createBodyResult\";\n    return RenderSpan;\n}(RenderSpan || {});\nvar AppRenderSpan = /*#__PURE__*/ function(AppRenderSpan) {\n    AppRenderSpan[\"renderToString\"] = \"AppRender.renderToString\";\n    AppRenderSpan[\"renderToReadableStream\"] = \"AppRender.renderToReadableStream\";\n    AppRenderSpan[\"getBodyResult\"] = \"AppRender.getBodyResult\";\n    AppRenderSpan[\"fetch\"] = \"AppRender.fetch\";\n    return AppRenderSpan;\n}(AppRenderSpan || {});\nvar RouterSpan = /*#__PURE__*/ function(RouterSpan) {\n    RouterSpan[\"executeRoute\"] = \"Router.executeRoute\";\n    return RouterSpan;\n}(RouterSpan || {});\nvar NodeSpan = /*#__PURE__*/ function(NodeSpan) {\n    NodeSpan[\"runHandler\"] = \"Node.runHandler\";\n    return NodeSpan;\n}(NodeSpan || {});\nvar AppRouteRouteHandlersSpan = /*#__PURE__*/ function(AppRouteRouteHandlersSpan) {\n    AppRouteRouteHandlersSpan[\"runHandler\"] = \"AppRouteRouteHandlers.runHandler\";\n    return AppRouteRouteHandlersSpan;\n}(AppRouteRouteHandlersSpan || {});\nvar ResolveMetadataSpan = /*#__PURE__*/ function(ResolveMetadataSpan) {\n    ResolveMetadataSpan[\"generateMetadata\"] = \"ResolveMetadata.generateMetadata\";\n    ResolveMetadataSpan[\"generateViewport\"] = \"ResolveMetadata.generateViewport\";\n    return ResolveMetadataSpan;\n}(ResolveMetadataSpan || {});\nvar MiddlewareSpan = /*#__PURE__*/ function(MiddlewareSpan) {\n    MiddlewareSpan[\"execute\"] = \"Middleware.execute\";\n    return MiddlewareSpan;\n}(MiddlewareSpan || {});\n// This list is used to filter out spans that are not relevant to the user\nexport const NextVanillaSpanAllowlist = new Set([\n    \"Middleware.execute\",\n    \"BaseServer.handleRequest\",\n    \"Render.getServerSideProps\",\n    \"Render.getStaticProps\",\n    \"AppRender.fetch\",\n    \"AppRender.getBodyResult\",\n    \"Render.renderDocument\",\n    \"Node.runHandler\",\n    \"AppRouteRouteHandlers.runHandler\",\n    \"ResolveMetadata.generateMetadata\",\n    \"ResolveMetadata.generateViewport\",\n    \"NextNodeServer.createComponentTree\",\n    \"NextNodeServer.findPageComponents\",\n    \"NextNodeServer.getLayoutOrPageModule\",\n    \"NextNodeServer.startResponse\",\n    \"NextNodeServer.clientComponentLoading\"\n]);\n// These Spans are allowed to be always logged\n// when the otel log prefix env is set\nexport const LogSpanAllowList = new Set([\n    \"NextNodeServer.findPageComponents\",\n    \"NextNodeServer.createComponentTree\",\n    \"NextNodeServer.clientComponentLoading\"\n]);\nexport { BaseServerSpan, LoadComponentsSpan, NextServerSpan, NextNodeServerSpan, StartServerSpan, RenderSpan, RouterSpan, AppRenderSpan, NodeSpan, AppRouteRouteHandlersSpan, ResolveMetadataSpan, MiddlewareSpan,  };\n\n//# sourceMappingURL=constants.js.map","import PromiseQueue from 'next/dist/compiled/p-queue';\nimport { InvariantError } from '../../shared/lib/invariant-error';\nimport { isThenable } from '../../shared/lib/is-thenable';\nimport { workAsyncStorage } from '../app-render/work-async-storage.external';\nimport { withExecuteRevalidates } from '../revalidation-utils';\nimport { bindSnapshot } from '../app-render/async-local-storage';\nimport { workUnitAsyncStorage } from '../app-render/work-unit-async-storage.external';\nimport { afterTaskAsyncStorage } from '../app-render/after-task-async-storage.external';\nexport class AfterContext {\n    constructor({ waitUntil, onClose, onTaskError }){\n        this.workUnitStores = new Set();\n        this.waitUntil = waitUntil;\n        this.onClose = onClose;\n        this.onTaskError = onTaskError;\n        this.callbackQueue = new PromiseQueue();\n        this.callbackQueue.pause();\n    }\n    after(task) {\n        if (isThenable(task)) {\n            if (!this.waitUntil) {\n                errorWaitUntilNotAvailable();\n            }\n            this.waitUntil(task.catch((error)=>this.reportTaskError('promise', error)));\n        } else if (typeof task === 'function') {\n            // TODO(after): implement tracing\n            this.addCallback(task);\n        } else {\n            throw Object.defineProperty(new Error('`after()`: Argument must be a promise or a function'), \"__NEXT_ERROR_CODE\", {\n                value: \"E50\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n    addCallback(callback) {\n        // if something is wrong, throw synchronously, bubbling up to the `after` callsite.\n        if (!this.waitUntil) {\n            errorWaitUntilNotAvailable();\n        }\n        const workUnitStore = workUnitAsyncStorage.getStore();\n        if (workUnitStore) {\n            this.workUnitStores.add(workUnitStore);\n        }\n        const afterTaskStore = afterTaskAsyncStorage.getStore();\n        // This is used for checking if request APIs can be called inside `after`.\n        // Note that we need to check the phase in which the *topmost* `after` was called (which should be \"action\"),\n        // not the current phase (which might be \"after\" if we're in a nested after).\n        // Otherwise, we might allow `after(() => headers())`, but not `after(() => after(() => headers()))`.\n        const rootTaskSpawnPhase = afterTaskStore ? afterTaskStore.rootTaskSpawnPhase // nested after\n         : workUnitStore == null ? void 0 : workUnitStore.phase // topmost after\n        ;\n        // this should only happen once.\n        if (!this.runCallbacksOnClosePromise) {\n            this.runCallbacksOnClosePromise = this.runCallbacksOnClose();\n            this.waitUntil(this.runCallbacksOnClosePromise);\n        }\n        // Bind the callback to the current execution context (i.e. preserve all currently available ALS-es).\n        // We do this because we want all of these to be equivalent in every regard except timing:\n        //   after(() => x())\n        //   after(x())\n        //   await x()\n        const wrappedCallback = bindSnapshot(// WARNING: Don't make this a named function. It must be anonymous.\n        // See: https://github.com/facebook/react/pull/34911\n        async ()=>{\n            try {\n                await afterTaskAsyncStorage.run({\n                    rootTaskSpawnPhase\n                }, ()=>callback());\n            } catch (error) {\n                this.reportTaskError('function', error);\n            }\n        });\n        this.callbackQueue.add(wrappedCallback);\n    }\n    async runCallbacksOnClose() {\n        await new Promise((resolve)=>this.onClose(resolve));\n        return this.runCallbacks();\n    }\n    async runCallbacks() {\n        if (this.callbackQueue.size === 0) return;\n        for (const workUnitStore of this.workUnitStores){\n            workUnitStore.phase = 'after';\n        }\n        const workStore = workAsyncStorage.getStore();\n        if (!workStore) {\n            throw Object.defineProperty(new InvariantError('Missing workStore in AfterContext.runCallbacks'), \"__NEXT_ERROR_CODE\", {\n                value: \"E547\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        return withExecuteRevalidates(workStore, ()=>{\n            this.callbackQueue.start();\n            return this.callbackQueue.onIdle();\n        });\n    }\n    reportTaskError(taskKind, error) {\n        // TODO(after): this is fine for now, but will need better intergration with our error reporting.\n        // TODO(after): should we log this if we have a onTaskError callback?\n        console.error(taskKind === 'promise' ? `A promise passed to \\`after()\\` rejected:` : `An error occurred in a function passed to \\`after()\\`:`, error);\n        if (this.onTaskError) {\n            // this is very defensive, but we really don't want anything to blow up in an error handler\n            try {\n                this.onTaskError == null ? void 0 : this.onTaskError.call(this, error);\n            } catch (handlerError) {\n                console.error(Object.defineProperty(new InvariantError('`onTaskError` threw while handling an error thrown from an `after` task', {\n                    cause: handlerError\n                }), \"__NEXT_ERROR_CODE\", {\n                    value: \"E569\",\n                    enumerable: false,\n                    configurable: true\n                }));\n            }\n        }\n    }\n}\nfunction errorWaitUntilNotAvailable() {\n    throw Object.defineProperty(new Error('`after()` will not work correctly, because `waitUntil` is not available in the current environment.'), \"__NEXT_ERROR_CODE\", {\n        value: \"E91\",\n        enumerable: false,\n        configurable: true\n    });\n}\n\n//# sourceMappingURL=after-context.js.map","/**\n * Node in the doubly-linked list used for LRU tracking.\n * Each node represents a cache entry with bidirectional pointers.\n */ class LRUNode {\n    constructor(key, data, size){\n        this.prev = null;\n        this.next = null;\n        this.key = key;\n        this.data = data;\n        this.size = size;\n    }\n}\n/**\n * Sentinel node used for head/tail boundaries.\n * These nodes don't contain actual cache data but simplify list operations.\n */ class SentinelNode {\n    constructor(){\n        this.prev = null;\n        this.next = null;\n    }\n}\n/**\n * LRU (Least Recently Used) Cache implementation using a doubly-linked list\n * and hash map for O(1) operations.\n *\n * Algorithm:\n * - Uses a doubly-linked list to maintain access order (most recent at head)\n * - Hash map provides O(1) key-to-node lookup\n * - Sentinel head/tail nodes simplify edge case handling\n * - Size-based eviction supports custom size calculation functions\n *\n * Data Structure Layout:\n * HEAD <-> [most recent] <-> ... <-> [least recent] <-> TAIL\n *\n * Operations:\n * - get(): Move accessed node to head (mark as most recent)\n * - set(): Add new node at head, evict from tail if over capacity\n * - Eviction: Remove least recent node (tail.prev) when size exceeds limit\n */ export class LRUCache {\n    constructor(maxSize, calculateSize, onEvict){\n        this.cache = new Map();\n        this.totalSize = 0;\n        this.maxSize = maxSize;\n        this.calculateSize = calculateSize;\n        this.onEvict = onEvict;\n        // Create sentinel nodes to simplify doubly-linked list operations\n        // HEAD <-> TAIL (empty list)\n        this.head = new SentinelNode();\n        this.tail = new SentinelNode();\n        this.head.next = this.tail;\n        this.tail.prev = this.head;\n    }\n    /**\n   * Adds a node immediately after the head (marks as most recently used).\n   * Used when inserting new items or when an item is accessed.\n   * PRECONDITION: node must be disconnected (prev/next should be null)\n   */ addToHead(node) {\n        node.prev = this.head;\n        node.next = this.head.next;\n        // head.next is always non-null (points to tail or another node)\n        this.head.next.prev = node;\n        this.head.next = node;\n    }\n    /**\n   * Removes a node from its current position in the doubly-linked list.\n   * Updates the prev/next pointers of adjacent nodes to maintain list integrity.\n   * PRECONDITION: node must be connected (prev/next are non-null)\n   */ removeNode(node) {\n        // Connected nodes always have non-null prev/next\n        node.prev.next = node.next;\n        node.next.prev = node.prev;\n    }\n    /**\n   * Moves an existing node to the head position (marks as most recently used).\n   * This is the core LRU operation - accessed items become most recent.\n   */ moveToHead(node) {\n        this.removeNode(node);\n        this.addToHead(node);\n    }\n    /**\n   * Removes and returns the least recently used node (the one before tail).\n   * This is called during eviction when the cache exceeds capacity.\n   * PRECONDITION: cache is not empty (ensured by caller)\n   */ removeTail() {\n        const lastNode = this.tail.prev;\n        // tail.prev is always non-null and always LRUNode when cache is not empty\n        this.removeNode(lastNode);\n        return lastNode;\n    }\n    /**\n   * Sets a key-value pair in the cache.\n   * If the key exists, updates the value and moves to head.\n   * If new, adds at head and evicts from tail if necessary.\n   *\n   * Time Complexity:\n   * - O(1) for uniform item sizes\n   * - O(k) where k is the number of items evicted (can be O(N) for variable sizes)\n   */ set(key, value) {\n        const size = (this.calculateSize == null ? void 0 : this.calculateSize.call(this, value)) ?? 1;\n        if (size > this.maxSize) {\n            console.warn('Single item size exceeds maxSize');\n            return;\n        }\n        const existing = this.cache.get(key);\n        if (existing) {\n            // Update existing node: adjust size and move to head (most recent)\n            existing.data = value;\n            this.totalSize = this.totalSize - existing.size + size;\n            existing.size = size;\n            this.moveToHead(existing);\n        } else {\n            // Add new node at head (most recent position)\n            const newNode = new LRUNode(key, value, size);\n            this.cache.set(key, newNode);\n            this.addToHead(newNode);\n            this.totalSize += size;\n        }\n        // Evict least recently used items until under capacity\n        while(this.totalSize > this.maxSize && this.cache.size > 0){\n            const tail = this.removeTail();\n            this.cache.delete(tail.key);\n            this.totalSize -= tail.size;\n            this.onEvict == null ? void 0 : this.onEvict.call(this, tail.key, tail.data);\n        }\n    }\n    /**\n   * Checks if a key exists in the cache.\n   * This is a pure query operation - does NOT update LRU order.\n   *\n   * Time Complexity: O(1)\n   */ has(key) {\n        return this.cache.has(key);\n    }\n    /**\n   * Retrieves a value by key and marks it as most recently used.\n   * Moving to head maintains the LRU property for future evictions.\n   *\n   * Time Complexity: O(1)\n   */ get(key) {\n        const node = this.cache.get(key);\n        if (!node) return undefined;\n        // Mark as most recently used by moving to head\n        this.moveToHead(node);\n        return node.data;\n    }\n    /**\n   * Returns an iterator over the cache entries. The order is outputted in the\n   * order of most recently used to least recently used.\n   */ *[Symbol.iterator]() {\n        let current = this.head.next;\n        while(current && current !== this.tail){\n            // Between head and tail, current is always LRUNode\n            const node = current;\n            yield [\n                node.key,\n                node.data\n            ];\n            current = current.next;\n        }\n    }\n    /**\n   * Removes a specific key from the cache.\n   * Updates both the hash map and doubly-linked list.\n   *\n   * Note: This is an explicit removal and does NOT trigger the `onEvict`\n   * callback. Use this for intentional deletions where eviction tracking\n   * is not needed.\n   *\n   * Time Complexity: O(1)\n   */ remove(key) {\n        const node = this.cache.get(key);\n        if (!node) return;\n        this.removeNode(node);\n        this.cache.delete(key);\n        this.totalSize -= node.size;\n    }\n    /**\n   * Returns the number of items in the cache.\n   */ get size() {\n        return this.cache.size;\n    }\n    /**\n   * Returns the current total size of all cached items.\n   * This uses the custom size calculation if provided.\n   */ get currentSize() {\n        return this.totalSize;\n    }\n}\n\n//# sourceMappingURL=lru-cache.js.map","const sharedAsyncLocalStorageNotAvailableError = Object.defineProperty(new Error('Invariant: AsyncLocalStorage accessed in runtime where it is not available'), \"__NEXT_ERROR_CODE\", {\n    value: \"E504\",\n    enumerable: false,\n    configurable: true\n});\nclass FakeAsyncLocalStorage {\n    disable() {\n        throw sharedAsyncLocalStorageNotAvailableError;\n    }\n    getStore() {\n        // This fake implementation of AsyncLocalStorage always returns `undefined`.\n        return undefined;\n    }\n    run() {\n        throw sharedAsyncLocalStorageNotAvailableError;\n    }\n    exit() {\n        throw sharedAsyncLocalStorageNotAvailableError;\n    }\n    enterWith() {\n        throw sharedAsyncLocalStorageNotAvailableError;\n    }\n    static bind(fn) {\n        return fn;\n    }\n}\nconst maybeGlobalAsyncLocalStorage = typeof globalThis !== 'undefined' && globalThis.AsyncLocalStorage;\nexport function createAsyncLocalStorage() {\n    if (maybeGlobalAsyncLocalStorage) {\n        return new maybeGlobalAsyncLocalStorage();\n    }\n    return new FakeAsyncLocalStorage();\n}\nexport function bindSnapshot(// WARNING: Don't pass a named function to this argument! See: https://github.com/facebook/react/pull/34911\nfn) {\n    if (maybeGlobalAsyncLocalStorage) {\n        return maybeGlobalAsyncLocalStorage.bind(fn);\n    }\n    return FakeAsyncLocalStorage.bind(fn);\n}\nexport function createSnapshot() {\n    if (maybeGlobalAsyncLocalStorage) {\n        return maybeGlobalAsyncLocalStorage.snapshot();\n    }\n    return function(fn, ...args) {\n        return fn(...args);\n    };\n}\n\n//# sourceMappingURL=async-local-storage.js.map","// ISC License\n// Copyright (c) 2021 Alexey Raspopov, Kostiantyn Denysov, Anton Verinov\n// Permission to use, copy, modify, and/or distribute this software for any\n// purpose with or without fee is hereby granted, provided that the above\n// copyright notice and this permission notice appear in all copies.\n// THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n// WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n// MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n// ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n// WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n// ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n// OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n//\n// https://github.com/alexeyraspopov/picocolors/blob/b6261487e7b81aaab2440e397a356732cad9e342/picocolors.js#L1\nvar _globalThis;\nconst { env, stdout } = ((_globalThis = globalThis) == null ? void 0 : _globalThis.process) ?? {};\nconst enabled = env && !env.NO_COLOR && (env.FORCE_COLOR || (stdout == null ? void 0 : stdout.isTTY) && !env.CI && env.TERM !== 'dumb');\nconst replaceClose = (str, close, replace, index)=>{\n    const start = str.substring(0, index) + replace;\n    const end = str.substring(index + close.length);\n    const nextIndex = end.indexOf(close);\n    return ~nextIndex ? start + replaceClose(end, close, replace, nextIndex) : start + end;\n};\nconst formatter = (open, close, replace = open)=>{\n    if (!enabled) return String;\n    return (input)=>{\n        const string = '' + input;\n        const index = string.indexOf(close, open.length);\n        return ~index ? open + replaceClose(string, close, replace, index) + close : open + string + close;\n    };\n};\nexport const reset = enabled ? (s)=>`\\x1b[0m${s}\\x1b[0m` : String;\nexport const bold = formatter('\\x1b[1m', '\\x1b[22m', '\\x1b[22m\\x1b[1m');\nexport const dim = formatter('\\x1b[2m', '\\x1b[22m', '\\x1b[22m\\x1b[2m');\nexport const italic = formatter('\\x1b[3m', '\\x1b[23m');\nexport const underline = formatter('\\x1b[4m', '\\x1b[24m');\nexport const inverse = formatter('\\x1b[7m', '\\x1b[27m');\nexport const hidden = formatter('\\x1b[8m', '\\x1b[28m');\nexport const strikethrough = formatter('\\x1b[9m', '\\x1b[29m');\nexport const black = formatter('\\x1b[30m', '\\x1b[39m');\nexport const red = formatter('\\x1b[31m', '\\x1b[39m');\nexport const green = formatter('\\x1b[32m', '\\x1b[39m');\nexport const yellow = formatter('\\x1b[33m', '\\x1b[39m');\nexport const blue = formatter('\\x1b[34m', '\\x1b[39m');\nexport const magenta = formatter('\\x1b[35m', '\\x1b[39m');\nexport const purple = formatter('\\x1b[38;2;173;127;168m', '\\x1b[39m');\nexport const cyan = formatter('\\x1b[36m', '\\x1b[39m');\nexport const white = formatter('\\x1b[37m', '\\x1b[39m');\nexport const gray = formatter('\\x1b[90m', '\\x1b[39m');\nexport const bgBlack = formatter('\\x1b[40m', '\\x1b[49m');\nexport const bgRed = formatter('\\x1b[41m', '\\x1b[49m');\nexport const bgGreen = formatter('\\x1b[42m', '\\x1b[49m');\nexport const bgYellow = formatter('\\x1b[43m', '\\x1b[49m');\nexport const bgBlue = formatter('\\x1b[44m', '\\x1b[49m');\nexport const bgMagenta = formatter('\\x1b[45m', '\\x1b[49m');\nexport const bgCyan = formatter('\\x1b[46m', '\\x1b[49m');\nexport const bgWhite = formatter('\\x1b[47m', '\\x1b[49m');\n\n//# sourceMappingURL=picocolors.js.map","// In output: export mode, the build id is added to the start of the HTML\n// document, directly after the doctype declaration. During a prefetch, the\n// client performs a range request to get the build id, so it can check whether\n// the target page belongs to the same build.\n//\n// The first 64 bytes of the document are requested. The exact number isn't\n// too important; it must be larger than the build id + doctype + closing and\n// ending comment markers, but it doesn't need to match the end of the\n// comment exactly.\n//\n// Build ids are 21 bytes long in the default implementation, though this\n// can be overridden in the Next.js config. For the purposes of this check,\n// it's OK to only match the start of the id, so we'll truncate it if exceeds\n// a certain length.\nconst DOCTYPE_PREFIX = '<!DOCTYPE html>' // 15 bytes\n;\nconst MAX_BUILD_ID_LENGTH = 24;\nfunction escapeBuildId(buildId) {\n    // If the build id is longer than the given limit, it's OK for our purposes\n    // to only match the beginning.\n    const truncated = buildId.slice(0, MAX_BUILD_ID_LENGTH);\n    // Replace hyphens with underscores so it doesn't break the HTML comment.\n    // (Unlikely, but if this did happen it would break the whole document.)\n    return truncated.replace(/-/g, '_');\n}\nexport function insertBuildIdComment(originalHtml, buildId) {\n    if (// Skip if the build id contains a closing comment marker.\n    buildId.includes('-->') || // React always inserts a doctype at the start of the document. Skip if it\n    // isn't present. Shouldn't happen; suggests an issue elsewhere.\n    !originalHtml.startsWith(DOCTYPE_PREFIX)) {\n        // Return the original HTML unchanged. This means the document will not\n        // be prefetched.\n        // TODO: The build id comment is currently only used during prefetches, but\n        // if we eventually use this mechanism for regular navigations, we may need\n        // to error during build if we fail to insert it for some reason.\n        return originalHtml;\n    }\n    // The comment must be inserted after the doctype.\n    return originalHtml.replace(DOCTYPE_PREFIX, DOCTYPE_PREFIX + '<!--' + escapeBuildId(buildId) + '-->');\n}\n\n//# sourceMappingURL=output-export-prefetch-encoding.js.map","// Combined load times for loading client components\nlet clientComponentLoadStart = 0;\nlet clientComponentLoadTimes = 0;\nlet clientComponentLoadCount = 0;\nexport function wrapClientComponentLoader(ComponentMod) {\n    if (!('performance' in globalThis)) {\n        return ComponentMod.__next_app__;\n    }\n    return {\n        require: (...args)=>{\n            const startTime = performance.now();\n            if (clientComponentLoadStart === 0) {\n                clientComponentLoadStart = startTime;\n            }\n            try {\n                clientComponentLoadCount += 1;\n                return ComponentMod.__next_app__.require(...args);\n            } finally{\n                clientComponentLoadTimes += performance.now() - startTime;\n            }\n        },\n        loadChunk: (...args)=>{\n            const startTime = performance.now();\n            const result = ComponentMod.__next_app__.loadChunk(...args);\n            // Avoid wrapping `loadChunk`'s result in an extra promise in case something like React depends on its identity.\n            // We only need to know when it's settled.\n            result.finally(()=>{\n                clientComponentLoadTimes += performance.now() - startTime;\n            });\n            return result;\n        }\n    };\n}\nexport function getClientComponentLoaderMetrics(options = {}) {\n    const metrics = clientComponentLoadStart === 0 ? undefined : {\n        clientComponentLoadStart,\n        clientComponentLoadTimes,\n        clientComponentLoadCount\n    };\n    if (options.reset) {\n        clientComponentLoadStart = 0;\n        clientComponentLoadTimes = 0;\n        clientComponentLoadCount = 0;\n    }\n    return metrics;\n}\n\n//# sourceMappingURL=client-component-renderer-logger.js.map","class UrlNode {\n    insert(urlPath) {\n        this._insert(urlPath.split('/').filter(Boolean), [], false);\n    }\n    smoosh() {\n        return this._smoosh();\n    }\n    _smoosh(prefix = '/') {\n        const childrenPaths = [\n            ...this.children.keys()\n        ].sort();\n        if (this.slugName !== null) {\n            childrenPaths.splice(childrenPaths.indexOf('[]'), 1);\n        }\n        if (this.restSlugName !== null) {\n            childrenPaths.splice(childrenPaths.indexOf('[...]'), 1);\n        }\n        if (this.optionalRestSlugName !== null) {\n            childrenPaths.splice(childrenPaths.indexOf('[[...]]'), 1);\n        }\n        const routes = childrenPaths.map((c)=>this.children.get(c)._smoosh(`${prefix}${c}/`)).reduce((prev, curr)=>[\n                ...prev,\n                ...curr\n            ], []);\n        if (this.slugName !== null) {\n            routes.push(...this.children.get('[]')._smoosh(`${prefix}[${this.slugName}]/`));\n        }\n        if (!this.placeholder) {\n            const r = prefix === '/' ? '/' : prefix.slice(0, -1);\n            if (this.optionalRestSlugName != null) {\n                throw Object.defineProperty(new Error(`You cannot define a route with the same specificity as a optional catch-all route (\"${r}\" and \"${r}[[...${this.optionalRestSlugName}]]\").`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E458\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            routes.unshift(r);\n        }\n        if (this.restSlugName !== null) {\n            routes.push(...this.children.get('[...]')._smoosh(`${prefix}[...${this.restSlugName}]/`));\n        }\n        if (this.optionalRestSlugName !== null) {\n            routes.push(...this.children.get('[[...]]')._smoosh(`${prefix}[[...${this.optionalRestSlugName}]]/`));\n        }\n        return routes;\n    }\n    _insert(urlPaths, slugNames, isCatchAll) {\n        if (urlPaths.length === 0) {\n            this.placeholder = false;\n            return;\n        }\n        if (isCatchAll) {\n            throw Object.defineProperty(new Error(`Catch-all must be the last part of the URL.`), \"__NEXT_ERROR_CODE\", {\n                value: \"E392\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        // The next segment in the urlPaths list\n        let nextSegment = urlPaths[0];\n        // Check if the segment matches `[something]`\n        if (nextSegment.startsWith('[') && nextSegment.endsWith(']')) {\n            // Strip `[` and `]`, leaving only `something`\n            let segmentName = nextSegment.slice(1, -1);\n            let isOptional = false;\n            if (segmentName.startsWith('[') && segmentName.endsWith(']')) {\n                // Strip optional `[` and `]`, leaving only `something`\n                segmentName = segmentName.slice(1, -1);\n                isOptional = true;\n            }\n            if (segmentName.startsWith('')) {\n                throw Object.defineProperty(new Error(`Detected a three-dot character ('') at ('${segmentName}'). Did you mean ('...')?`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E147\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            if (segmentName.startsWith('...')) {\n                // Strip `...`, leaving only `something`\n                segmentName = segmentName.substring(3);\n                isCatchAll = true;\n            }\n            if (segmentName.startsWith('[') || segmentName.endsWith(']')) {\n                throw Object.defineProperty(new Error(`Segment names may not start or end with extra brackets ('${segmentName}').`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E421\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            if (segmentName.startsWith('.')) {\n                throw Object.defineProperty(new Error(`Segment names may not start with erroneous periods ('${segmentName}').`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E288\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            function handleSlug(previousSlug, nextSlug) {\n                if (previousSlug !== null) {\n                    // If the specific segment already has a slug but the slug is not `something`\n                    // This prevents collisions like:\n                    // pages/[post]/index.js\n                    // pages/[id]/index.js\n                    // Because currently multiple dynamic params on the same segment level are not supported\n                    if (previousSlug !== nextSlug) {\n                        // TODO: This error seems to be confusing for users, needs an error link, the description can be based on above comment.\n                        throw Object.defineProperty(new Error(`You cannot use different slug names for the same dynamic path ('${previousSlug}' !== '${nextSlug}').`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E337\",\n                            enumerable: false,\n                            configurable: true\n                        });\n                    }\n                }\n                slugNames.forEach((slug)=>{\n                    if (slug === nextSlug) {\n                        throw Object.defineProperty(new Error(`You cannot have the same slug name \"${nextSlug}\" repeat within a single dynamic path`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E247\",\n                            enumerable: false,\n                            configurable: true\n                        });\n                    }\n                    if (slug.replace(/\\W/g, '') === nextSegment.replace(/\\W/g, '')) {\n                        throw Object.defineProperty(new Error(`You cannot have the slug names \"${slug}\" and \"${nextSlug}\" differ only by non-word symbols within a single dynamic path`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E499\",\n                            enumerable: false,\n                            configurable: true\n                        });\n                    }\n                });\n                slugNames.push(nextSlug);\n            }\n            if (isCatchAll) {\n                if (isOptional) {\n                    if (this.restSlugName != null) {\n                        throw Object.defineProperty(new Error(`You cannot use both an required and optional catch-all route at the same level (\"[...${this.restSlugName}]\" and \"${urlPaths[0]}\" ).`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E299\",\n                            enumerable: false,\n                            configurable: true\n                        });\n                    }\n                    handleSlug(this.optionalRestSlugName, segmentName);\n                    // slugName is kept as it can only be one particular slugName\n                    this.optionalRestSlugName = segmentName;\n                    // nextSegment is overwritten to [[...]] so that it can later be sorted specifically\n                    nextSegment = '[[...]]';\n                } else {\n                    if (this.optionalRestSlugName != null) {\n                        throw Object.defineProperty(new Error(`You cannot use both an optional and required catch-all route at the same level (\"[[...${this.optionalRestSlugName}]]\" and \"${urlPaths[0]}\").`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E300\",\n                            enumerable: false,\n                            configurable: true\n                        });\n                    }\n                    handleSlug(this.restSlugName, segmentName);\n                    // slugName is kept as it can only be one particular slugName\n                    this.restSlugName = segmentName;\n                    // nextSegment is overwritten to [...] so that it can later be sorted specifically\n                    nextSegment = '[...]';\n                }\n            } else {\n                if (isOptional) {\n                    throw Object.defineProperty(new Error(`Optional route parameters are not yet supported (\"${urlPaths[0]}\").`), \"__NEXT_ERROR_CODE\", {\n                        value: \"E435\",\n                        enumerable: false,\n                        configurable: true\n                    });\n                }\n                handleSlug(this.slugName, segmentName);\n                // slugName is kept as it can only be one particular slugName\n                this.slugName = segmentName;\n                // nextSegment is overwritten to [] so that it can later be sorted specifically\n                nextSegment = '[]';\n            }\n        }\n        // If this UrlNode doesn't have the nextSegment yet we create a new child UrlNode\n        if (!this.children.has(nextSegment)) {\n            this.children.set(nextSegment, new UrlNode());\n        }\n        this.children.get(nextSegment)._insert(urlPaths.slice(1), slugNames, isCatchAll);\n    }\n    constructor(){\n        this.placeholder = true;\n        this.children = new Map();\n        this.slugName = null;\n        this.restSlugName = null;\n        this.optionalRestSlugName = null;\n    }\n}\n/**\n * @deprecated Use `sortSortableRoutes` or `sortPages` instead.\n */ export function getSortedRoutes(normalizedPages) {\n    // First the UrlNode is created, and every UrlNode can have only 1 dynamic segment\n    // Eg you can't have pages/[post]/abc.js and pages/[hello]/something-else.js\n    // Only 1 dynamic segment per nesting level\n    // So in the case that is test/integration/dynamic-routing it'll be this:\n    // pages/[post]/comments.js\n    // pages/blog/[post]/comment/[id].js\n    // Both are fine because `pages/[post]` and `pages/blog` are on the same level\n    // So in this case `UrlNode` created here has `this.slugName === 'post'`\n    // And since your PR passed through `slugName` as an array basically it'd including it in too many possibilities\n    // Instead what has to be passed through is the upwards path's dynamic names\n    const root = new UrlNode();\n    // Here the `root` gets injected multiple paths, and insert will break them up into sublevels\n    normalizedPages.forEach((pagePath)=>root.insert(pagePath));\n    // Smoosh will then sort those sublevels up to the point where you get the correct route definition priority\n    return root.smoosh();\n}\n/**\n * @deprecated Use `sortSortableRouteObjects` or `sortPageObjects` instead.\n */ export function getSortedRouteObjects(objects, getter) {\n    // We're assuming here that all the pathnames are unique, that way we can\n    // sort the list and use the index as the key.\n    const indexes = {};\n    const pathnames = [];\n    for(let i = 0; i < objects.length; i++){\n        const pathname = getter(objects[i]);\n        indexes[pathname] = i;\n        pathnames[i] = pathname;\n    }\n    // Sort the pathnames.\n    const sorted = getSortedRoutes(pathnames);\n    // Map the sorted pathnames back to the original objects using the new sorted\n    // index.\n    return sorted.map((pathname)=>objects[indexes[pathname]]);\n}\n\n//# sourceMappingURL=sorted-routes.js.map","import { regexpToFunction } from 'next/dist/compiled/path-to-regexp';\nimport { pathToRegexp } from 'next/dist/compiled/path-to-regexp';\n/**\n * Generates a path matcher function for a given path and options based on\n * path-to-regexp. By default the match will be case insensitive, non strict\n * and delimited by `/`.\n */ export function getPathMatch(path, options) {\n    const keys = [];\n    const regexp = pathToRegexp(path, keys, {\n        delimiter: '/',\n        sensitive: typeof options?.sensitive === 'boolean' ? options.sensitive : false,\n        strict: options?.strict\n    });\n    const matcher = regexpToFunction(options?.regexModifier ? new RegExp(options.regexModifier(regexp.source), regexp.flags) : regexp, keys);\n    /**\n   * A matcher function that will check if a given pathname matches the path\n   * given in the builder function. When the path does not match it will return\n   * `false` but if it does it will return an object with the matched params\n   * merged with the params provided in the second argument.\n   */ return (pathname, params)=>{\n        // If no pathname is provided it's not a match.\n        if (typeof pathname !== 'string') return false;\n        const match = matcher(pathname);\n        // If the path did not match `false` will be returned.\n        if (!match) return false;\n        /**\n     * If unnamed params are not allowed they must be removed from\n     * the matched parameters. path-to-regexp uses \"string\" for named and\n     * \"number\" for unnamed parameters.\n     */ if (options?.removeUnnamedParams) {\n            for (const key of keys){\n                if (typeof key.name === 'number') {\n                    delete match.params[key.name];\n                }\n            }\n        }\n        return {\n            ...params,\n            ...match.params\n        };\n    };\n}\n\n//# sourceMappingURL=path-match.js.map","// regexp is based on https://github.com/sindresorhus/escape-string-regexp\nconst reHasRegExp = /[|\\\\{}()[\\]^$+*?.-]/;\nconst reReplaceRegExp = /[|\\\\{}()[\\]^$+*?.-]/g;\nexport function escapeStringRegexp(str) {\n    // see also: https://github.com/lodash/lodash/blob/2da024c3b4f9947a48517639de7560457cd4ec6c/escapeRegExp.js#L23\n    if (reHasRegExp.test(str)) {\n        return str.replace(reReplaceRegExp, '\\\\$&');\n    }\n    return str;\n}\n\n//# sourceMappingURL=escape-regexp.js.map","/**\n * The functions provided by this module are used to communicate certain properties\n * about the currently running code so that Next.js can make decisions on how to handle\n * the current execution in different rendering modes such as pre-rendering, resuming, and SSR.\n *\n * Today Next.js treats all code as potentially static. Certain APIs may only make sense when dynamically rendering.\n * Traditionally this meant deopting the entire render to dynamic however with PPR we can now deopt parts\n * of a React tree as dynamic while still keeping other parts static. There are really two different kinds of\n * Dynamic indications.\n *\n * The first is simply an intention to be dynamic. unstable_noStore is an example of this where\n * the currently executing code simply declares that the current scope is dynamic but if you use it\n * inside unstable_cache it can still be cached. This type of indication can be removed if we ever\n * make the default dynamic to begin with because the only way you would ever be static is inside\n * a cache scope which this indication does not affect.\n *\n * The second is an indication that a dynamic data source was read. This is a stronger form of dynamic\n * because it means that it is inappropriate to cache this at all. using a dynamic data source inside\n * unstable_cache should error. If you want to use some dynamic data inside unstable_cache you should\n * read that data outside the cache and pass it in as an argument to the cached function.\n */ // Once postpone is in stable we should switch to importing the postpone export directly\nimport React from 'react';\nimport { DynamicServerError } from '../../client/components/hooks-server-context';\nimport { StaticGenBailoutError } from '../../client/components/static-generation-bailout';\nimport { getRuntimeStagePromise, throwForMissingRequestStore, workUnitAsyncStorage } from './work-unit-async-storage.external';\nimport { workAsyncStorage } from '../app-render/work-async-storage.external';\nimport { makeHangingPromise } from '../dynamic-rendering-utils';\nimport { METADATA_BOUNDARY_NAME, VIEWPORT_BOUNDARY_NAME, OUTLET_BOUNDARY_NAME, ROOT_LAYOUT_BOUNDARY_NAME } from '../../lib/framework/boundary-constants';\nimport { scheduleOnNextTick } from '../../lib/scheduler';\nimport { BailoutToCSRError } from '../../shared/lib/lazy-dynamic/bailout-to-csr';\nimport { InvariantError } from '../../shared/lib/invariant-error';\nconst hasPostpone = typeof React.unstable_postpone === 'function';\nexport function createDynamicTrackingState(isDebugDynamicAccesses) {\n    return {\n        isDebugDynamicAccesses,\n        dynamicAccesses: [],\n        syncDynamicErrorWithStack: null\n    };\n}\nexport function createDynamicValidationState() {\n    return {\n        hasSuspenseAboveBody: false,\n        hasDynamicMetadata: false,\n        dynamicMetadata: null,\n        hasDynamicViewport: false,\n        hasAllowedDynamic: false,\n        dynamicErrors: []\n    };\n}\nexport function getFirstDynamicReason(trackingState) {\n    var _trackingState_dynamicAccesses_;\n    return (_trackingState_dynamicAccesses_ = trackingState.dynamicAccesses[0]) == null ? void 0 : _trackingState_dynamicAccesses_.expression;\n}\n/**\n * This function communicates that the current scope should be treated as dynamic.\n *\n * In most cases this function is a no-op but if called during\n * a PPR prerender it will postpone the current sub-tree and calling\n * it during a normal prerender will cause the entire prerender to abort\n */ export function markCurrentScopeAsDynamic(store, workUnitStore, expression) {\n    if (workUnitStore) {\n        switch(workUnitStore.type){\n            case 'cache':\n            case 'unstable-cache':\n                // Inside cache scopes, marking a scope as dynamic has no effect,\n                // because the outer cache scope creates a cache boundary. This is\n                // subtly different from reading a dynamic data source, which is\n                // forbidden inside a cache scope.\n                return;\n            case 'private-cache':\n                // A private cache scope is already dynamic by definition.\n                return;\n            case 'prerender-legacy':\n            case 'prerender-ppr':\n            case 'request':\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n    // If we're forcing dynamic rendering or we're forcing static rendering, we\n    // don't need to do anything here because the entire page is already dynamic\n    // or it's static and it should not throw or postpone here.\n    if (store.forceDynamic || store.forceStatic) return;\n    if (store.dynamicShouldError) {\n        throw Object.defineProperty(new StaticGenBailoutError(`Route ${store.route} with \\`dynamic = \"error\"\\` couldn't be rendered statically because it used \\`${expression}\\`. See more info here: https://nextjs.org/docs/app/building-your-application/rendering/static-and-dynamic#dynamic-rendering`), \"__NEXT_ERROR_CODE\", {\n            value: \"E553\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    if (workUnitStore) {\n        switch(workUnitStore.type){\n            case 'prerender-ppr':\n                return postponeWithTracking(store.route, expression, workUnitStore.dynamicTracking);\n            case 'prerender-legacy':\n                workUnitStore.revalidate = 0;\n                // We aren't prerendering, but we are generating a static page. We need\n                // to bail out of static generation.\n                const err = Object.defineProperty(new DynamicServerError(`Route ${store.route} couldn't be rendered statically because it used ${expression}. See more info here: https://nextjs.org/docs/messages/dynamic-server-error`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E550\",\n                    enumerable: false,\n                    configurable: true\n                });\n                store.dynamicUsageDescription = expression;\n                store.dynamicUsageStack = err.stack;\n                throw err;\n            case 'request':\n                if (process.env.NODE_ENV !== 'production') {\n                    workUnitStore.usedDynamic = true;\n                }\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n}\n/**\n * This function is meant to be used when prerendering without cacheComponents or PPR.\n * When called during a build it will cause Next.js to consider the route as dynamic.\n *\n * @internal\n */ export function throwToInterruptStaticGeneration(expression, store, prerenderStore) {\n    // We aren't prerendering but we are generating a static page. We need to bail out of static generation\n    const err = Object.defineProperty(new DynamicServerError(`Route ${store.route} couldn't be rendered statically because it used \\`${expression}\\`. See more info here: https://nextjs.org/docs/messages/dynamic-server-error`), \"__NEXT_ERROR_CODE\", {\n        value: \"E558\",\n        enumerable: false,\n        configurable: true\n    });\n    prerenderStore.revalidate = 0;\n    store.dynamicUsageDescription = expression;\n    store.dynamicUsageStack = err.stack;\n    throw err;\n}\n/**\n * This function should be used to track whether something dynamic happened even when\n * we are in a dynamic render. This is useful for Dev where all renders are dynamic but\n * we still track whether dynamic APIs were accessed for helpful messaging\n *\n * @internal\n */ export function trackDynamicDataInDynamicRender(workUnitStore) {\n    switch(workUnitStore.type){\n        case 'cache':\n        case 'unstable-cache':\n            // Inside cache scopes, marking a scope as dynamic has no effect,\n            // because the outer cache scope creates a cache boundary. This is\n            // subtly different from reading a dynamic data source, which is\n            // forbidden inside a cache scope.\n            return;\n        case 'private-cache':\n            // A private cache scope is already dynamic by definition.\n            return;\n        case 'prerender':\n        case 'prerender-runtime':\n        case 'prerender-legacy':\n        case 'prerender-ppr':\n        case 'prerender-client':\n            break;\n        case 'request':\n            if (process.env.NODE_ENV !== 'production') {\n                workUnitStore.usedDynamic = true;\n            }\n            break;\n        default:\n            workUnitStore;\n    }\n}\nfunction abortOnSynchronousDynamicDataAccess(route, expression, prerenderStore) {\n    const reason = `Route ${route} needs to bail out of prerendering at this point because it used ${expression}.`;\n    const error = createPrerenderInterruptedError(reason);\n    prerenderStore.controller.abort(error);\n    const dynamicTracking = prerenderStore.dynamicTracking;\n    if (dynamicTracking) {\n        dynamicTracking.dynamicAccesses.push({\n            // When we aren't debugging, we don't need to create another error for the\n            // stack trace.\n            stack: dynamicTracking.isDebugDynamicAccesses ? new Error().stack : undefined,\n            expression\n        });\n    }\n}\nexport function abortOnSynchronousPlatformIOAccess(route, expression, errorWithStack, prerenderStore) {\n    const dynamicTracking = prerenderStore.dynamicTracking;\n    abortOnSynchronousDynamicDataAccess(route, expression, prerenderStore);\n    // It is important that we set this tracking value after aborting. Aborts are executed\n    // synchronously except for the case where you abort during render itself. By setting this\n    // value late we can use it to determine if any of the aborted tasks are the task that\n    // called the sync IO expression in the first place.\n    if (dynamicTracking) {\n        if (dynamicTracking.syncDynamicErrorWithStack === null) {\n            dynamicTracking.syncDynamicErrorWithStack = errorWithStack;\n        }\n    }\n}\n/**\n * use this function when prerendering with cacheComponents. If we are doing a\n * prospective prerender we don't actually abort because we want to discover\n * all caches for the shell. If this is the actual prerender we do abort.\n *\n * This function accepts a prerenderStore but the caller should ensure we're\n * actually running in cacheComponents mode.\n *\n * @internal\n */ export function abortAndThrowOnSynchronousRequestDataAccess(route, expression, errorWithStack, prerenderStore) {\n    const prerenderSignal = prerenderStore.controller.signal;\n    if (prerenderSignal.aborted === false) {\n        // TODO it would be better to move this aborted check into the callsite so we can avoid making\n        // the error object when it isn't relevant to the aborting of the prerender however\n        // since we need the throw semantics regardless of whether we abort it is easier to land\n        // this way. See how this was handled with `abortOnSynchronousPlatformIOAccess` for a closer\n        // to ideal implementation\n        abortOnSynchronousDynamicDataAccess(route, expression, prerenderStore);\n        // It is important that we set this tracking value after aborting. Aborts are executed\n        // synchronously except for the case where you abort during render itself. By setting this\n        // value late we can use it to determine if any of the aborted tasks are the task that\n        // called the sync IO expression in the first place.\n        const dynamicTracking = prerenderStore.dynamicTracking;\n        if (dynamicTracking) {\n            if (dynamicTracking.syncDynamicErrorWithStack === null) {\n                dynamicTracking.syncDynamicErrorWithStack = errorWithStack;\n            }\n        }\n    }\n    throw createPrerenderInterruptedError(`Route ${route} needs to bail out of prerendering at this point because it used ${expression}.`);\n}\nexport function Postpone({ reason, route }) {\n    const prerenderStore = workUnitAsyncStorage.getStore();\n    const dynamicTracking = prerenderStore && prerenderStore.type === 'prerender-ppr' ? prerenderStore.dynamicTracking : null;\n    postponeWithTracking(route, reason, dynamicTracking);\n}\nexport function postponeWithTracking(route, expression, dynamicTracking) {\n    assertPostpone();\n    if (dynamicTracking) {\n        dynamicTracking.dynamicAccesses.push({\n            // When we aren't debugging, we don't need to create another error for the\n            // stack trace.\n            stack: dynamicTracking.isDebugDynamicAccesses ? new Error().stack : undefined,\n            expression\n        });\n    }\n    React.unstable_postpone(createPostponeReason(route, expression));\n}\nfunction createPostponeReason(route, expression) {\n    return `Route ${route} needs to bail out of prerendering at this point because it used ${expression}. ` + `React throws this special object to indicate where. It should not be caught by ` + `your own try/catch. Learn more: https://nextjs.org/docs/messages/ppr-caught-error`;\n}\nexport function isDynamicPostpone(err) {\n    if (typeof err === 'object' && err !== null && typeof err.message === 'string') {\n        return isDynamicPostponeReason(err.message);\n    }\n    return false;\n}\nfunction isDynamicPostponeReason(reason) {\n    return reason.includes('needs to bail out of prerendering at this point because it used') && reason.includes('Learn more: https://nextjs.org/docs/messages/ppr-caught-error');\n}\nif (isDynamicPostponeReason(createPostponeReason('%%%', '^^^')) === false) {\n    throw Object.defineProperty(new Error('Invariant: isDynamicPostpone misidentified a postpone reason. This is a bug in Next.js'), \"__NEXT_ERROR_CODE\", {\n        value: \"E296\",\n        enumerable: false,\n        configurable: true\n    });\n}\nconst NEXT_PRERENDER_INTERRUPTED = 'NEXT_PRERENDER_INTERRUPTED';\nfunction createPrerenderInterruptedError(message) {\n    const error = Object.defineProperty(new Error(message), \"__NEXT_ERROR_CODE\", {\n        value: \"E394\",\n        enumerable: false,\n        configurable: true\n    });\n    error.digest = NEXT_PRERENDER_INTERRUPTED;\n    return error;\n}\nexport function isPrerenderInterruptedError(error) {\n    return typeof error === 'object' && error !== null && error.digest === NEXT_PRERENDER_INTERRUPTED && 'name' in error && 'message' in error && error instanceof Error;\n}\nexport function accessedDynamicData(dynamicAccesses) {\n    return dynamicAccesses.length > 0;\n}\nexport function consumeDynamicAccess(serverDynamic, clientDynamic) {\n    // We mutate because we only call this once we are no longer writing\n    // to the dynamicTrackingState and it's more efficient than creating a new\n    // array.\n    serverDynamic.dynamicAccesses.push(...clientDynamic.dynamicAccesses);\n    return serverDynamic.dynamicAccesses;\n}\nexport function formatDynamicAPIAccesses(dynamicAccesses) {\n    return dynamicAccesses.filter((access)=>typeof access.stack === 'string' && access.stack.length > 0).map(({ expression, stack })=>{\n        stack = stack.split('\\n')// Remove the \"Error: \" prefix from the first line of the stack trace as\n        // well as the first 4 lines of the stack trace which is the distance\n        // from the user code and the `new Error().stack` call.\n        .slice(4).filter((line)=>{\n            // Exclude Next.js internals from the stack trace.\n            if (line.includes('node_modules/next/')) {\n                return false;\n            }\n            // Exclude anonymous functions from the stack trace.\n            if (line.includes(' (<anonymous>)')) {\n                return false;\n            }\n            // Exclude Node.js internals from the stack trace.\n            if (line.includes(' (node:')) {\n                return false;\n            }\n            return true;\n        }).join('\\n');\n        return `Dynamic API Usage Debug - ${expression}:\\n${stack}`;\n    });\n}\nfunction assertPostpone() {\n    if (!hasPostpone) {\n        throw Object.defineProperty(new Error(`Invariant: React.unstable_postpone is not defined. This suggests the wrong version of React was loaded. This is a bug in Next.js`), \"__NEXT_ERROR_CODE\", {\n            value: \"E224\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n}\n/**\n * This is a bit of a hack to allow us to abort a render using a Postpone instance instead of an Error which changes React's\n * abort semantics slightly.\n */ export function createRenderInBrowserAbortSignal() {\n    const controller = new AbortController();\n    controller.abort(Object.defineProperty(new BailoutToCSRError('Render in Browser'), \"__NEXT_ERROR_CODE\", {\n        value: \"E721\",\n        enumerable: false,\n        configurable: true\n    }));\n    return controller.signal;\n}\n/**\n * In a prerender, we may end up with hanging Promises as inputs due them\n * stalling on connection() or because they're loading dynamic data. In that\n * case we need to abort the encoding of arguments since they'll never complete.\n */ export function createHangingInputAbortSignal(workUnitStore) {\n    switch(workUnitStore.type){\n        case 'prerender':\n        case 'prerender-runtime':\n            const controller = new AbortController();\n            if (workUnitStore.cacheSignal) {\n                // If we have a cacheSignal it means we're in a prospective render. If\n                // the input we're waiting on is coming from another cache, we do want\n                // to wait for it so that we can resolve this cache entry too.\n                workUnitStore.cacheSignal.inputReady().then(()=>{\n                    controller.abort();\n                });\n            } else {\n                // Otherwise we're in the final render and we should already have all\n                // our caches filled.\n                // If the prerender uses stages, we have wait until the runtime stage,\n                // at which point all runtime inputs will be resolved.\n                // (otherwise, a runtime prerender might consider `cookies()` hanging\n                //  even though they'd resolve in the next task.)\n                //\n                // We might still be waiting on some microtasks so we\n                // wait one tick before giving up. When we give up, we still want to\n                // render the content of this cache as deeply as we can so that we can\n                // suspend as deeply as possible in the tree or not at all if we don't\n                // end up waiting for the input.\n                const runtimeStagePromise = getRuntimeStagePromise(workUnitStore);\n                if (runtimeStagePromise) {\n                    runtimeStagePromise.then(()=>scheduleOnNextTick(()=>controller.abort()));\n                } else {\n                    scheduleOnNextTick(()=>controller.abort());\n                }\n            }\n            return controller.signal;\n        case 'prerender-client':\n        case 'prerender-ppr':\n        case 'prerender-legacy':\n        case 'request':\n        case 'cache':\n        case 'private-cache':\n        case 'unstable-cache':\n            return undefined;\n        default:\n            workUnitStore;\n    }\n}\nexport function annotateDynamicAccess(expression, prerenderStore) {\n    const dynamicTracking = prerenderStore.dynamicTracking;\n    if (dynamicTracking) {\n        dynamicTracking.dynamicAccesses.push({\n            stack: dynamicTracking.isDebugDynamicAccesses ? new Error().stack : undefined,\n            expression\n        });\n    }\n}\nexport function useDynamicRouteParams(expression) {\n    const workStore = workAsyncStorage.getStore();\n    const workUnitStore = workUnitAsyncStorage.getStore();\n    if (workStore && workUnitStore) {\n        switch(workUnitStore.type){\n            case 'prerender-client':\n            case 'prerender':\n                {\n                    const fallbackParams = workUnitStore.fallbackRouteParams;\n                    if (fallbackParams && fallbackParams.size > 0) {\n                        // We are in a prerender with cacheComponents semantics. We are going to\n                        // hang here and never resolve. This will cause the currently\n                        // rendering component to effectively be a dynamic hole.\n                        React.use(makeHangingPromise(workUnitStore.renderSignal, workStore.route, expression));\n                    }\n                    break;\n                }\n            case 'prerender-ppr':\n                {\n                    const fallbackParams = workUnitStore.fallbackRouteParams;\n                    if (fallbackParams && fallbackParams.size > 0) {\n                        return postponeWithTracking(workStore.route, expression, workUnitStore.dynamicTracking);\n                    }\n                    break;\n                }\n            case 'prerender-runtime':\n                throw Object.defineProperty(new InvariantError(`\\`${expression}\\` was called during a runtime prerender. Next.js should be preventing ${expression} from being included in server components statically, but did not in this case.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E771\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'cache':\n            case 'private-cache':\n                throw Object.defineProperty(new InvariantError(`\\`${expression}\\` was called inside a cache scope. Next.js should be preventing ${expression} from being included in server components statically, but did not in this case.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E745\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender-legacy':\n            case 'request':\n            case 'unstable-cache':\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n}\nexport function useDynamicSearchParams(expression) {\n    const workStore = workAsyncStorage.getStore();\n    const workUnitStore = workUnitAsyncStorage.getStore();\n    if (!workStore) {\n        // We assume pages router context and just return\n        return;\n    }\n    if (!workUnitStore) {\n        throwForMissingRequestStore(expression);\n    }\n    switch(workUnitStore.type){\n        case 'prerender-client':\n            {\n                React.use(makeHangingPromise(workUnitStore.renderSignal, workStore.route, expression));\n                break;\n            }\n        case 'prerender-legacy':\n        case 'prerender-ppr':\n            {\n                if (workStore.forceStatic) {\n                    return;\n                }\n                throw Object.defineProperty(new BailoutToCSRError(expression), \"__NEXT_ERROR_CODE\", {\n                    value: \"E394\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n        case 'prerender':\n        case 'prerender-runtime':\n            throw Object.defineProperty(new InvariantError(`\\`${expression}\\` was called from a Server Component. Next.js should be preventing ${expression} from being included in server components statically, but did not in this case.`), \"__NEXT_ERROR_CODE\", {\n                value: \"E795\",\n                enumerable: false,\n                configurable: true\n            });\n        case 'cache':\n        case 'unstable-cache':\n        case 'private-cache':\n            throw Object.defineProperty(new InvariantError(`\\`${expression}\\` was called inside a cache scope. Next.js should be preventing ${expression} from being included in server components statically, but did not in this case.`), \"__NEXT_ERROR_CODE\", {\n                value: \"E745\",\n                enumerable: false,\n                configurable: true\n            });\n        case 'request':\n            return;\n        default:\n            workUnitStore;\n    }\n}\nconst hasSuspenseRegex = /\\n\\s+at Suspense \\(<anonymous>\\)/;\n// Common implicit body tags that React will treat as body when placed directly in html\nconst bodyAndImplicitTags = 'body|div|main|section|article|aside|header|footer|nav|form|p|span|h1|h2|h3|h4|h5|h6';\n// Detects when RootLayoutBoundary (our framework marker component) appears\n// after Suspense in the component stack, indicating the root layout is wrapped\n// within a Suspense boundary. Ensures no body/html/implicit-body components are in between.\n//\n// Example matches:\n//   at Suspense (<anonymous>)\n//   at __next_root_layout_boundary__ (<anonymous>)\n//\n// Or with other components in between (but not body/html/implicit-body):\n//   at Suspense (<anonymous>)\n//   at SomeComponent (<anonymous>)\n//   at __next_root_layout_boundary__ (<anonymous>)\nconst hasSuspenseBeforeRootLayoutWithoutBodyOrImplicitBodyRegex = new RegExp(`\\\\n\\\\s+at Suspense \\\\(<anonymous>\\\\)(?:(?!\\\\n\\\\s+at (?:${bodyAndImplicitTags}) \\\\(<anonymous>\\\\))[\\\\s\\\\S])*?\\\\n\\\\s+at ${ROOT_LAYOUT_BOUNDARY_NAME} \\\\([^\\\\n]*\\\\)`);\nconst hasMetadataRegex = new RegExp(`\\\\n\\\\s+at ${METADATA_BOUNDARY_NAME}[\\\\n\\\\s]`);\nconst hasViewportRegex = new RegExp(`\\\\n\\\\s+at ${VIEWPORT_BOUNDARY_NAME}[\\\\n\\\\s]`);\nconst hasOutletRegex = new RegExp(`\\\\n\\\\s+at ${OUTLET_BOUNDARY_NAME}[\\\\n\\\\s]`);\nexport function trackAllowedDynamicAccess(workStore, componentStack, dynamicValidation, clientDynamic) {\n    if (hasOutletRegex.test(componentStack)) {\n        // We don't need to track that this is dynamic. It is only so when something else is also dynamic.\n        return;\n    } else if (hasMetadataRegex.test(componentStack)) {\n        dynamicValidation.hasDynamicMetadata = true;\n        return;\n    } else if (hasViewportRegex.test(componentStack)) {\n        dynamicValidation.hasDynamicViewport = true;\n        return;\n    } else if (hasSuspenseBeforeRootLayoutWithoutBodyOrImplicitBodyRegex.test(componentStack)) {\n        // For Suspense within body, the prelude wouldn't be empty so it wouldn't violate the empty static shells rule.\n        // But if you have Suspense above body, the prelude is empty but we allow that because having Suspense\n        // is an explicit signal from the user that they acknowledge the empty shell and want dynamic rendering.\n        dynamicValidation.hasAllowedDynamic = true;\n        dynamicValidation.hasSuspenseAboveBody = true;\n        return;\n    } else if (hasSuspenseRegex.test(componentStack)) {\n        // this error had a Suspense boundary above it so we don't need to report it as a source\n        // of disallowed\n        dynamicValidation.hasAllowedDynamic = true;\n        return;\n    } else if (clientDynamic.syncDynamicErrorWithStack) {\n        // This task was the task that called the sync error.\n        dynamicValidation.dynamicErrors.push(clientDynamic.syncDynamicErrorWithStack);\n        return;\n    } else {\n        const message = `Route \"${workStore.route}\": Uncached data was accessed outside of ` + '<Suspense>. This delays the entire page from rendering, resulting in a ' + 'slow user experience. Learn more: ' + 'https://nextjs.org/docs/messages/blocking-route';\n        const error = createErrorWithComponentOrOwnerStack(message, componentStack);\n        dynamicValidation.dynamicErrors.push(error);\n        return;\n    }\n}\nexport function trackDynamicHoleInRuntimeShell(workStore, componentStack, dynamicValidation, clientDynamic) {\n    if (hasOutletRegex.test(componentStack)) {\n        // We don't need to track that this is dynamic. It is only so when something else is also dynamic.\n        return;\n    } else if (hasMetadataRegex.test(componentStack)) {\n        const message = `Route \"${workStore.route}\": Uncached data or \\`connection()\\` was accessed inside \\`generateMetadata\\`. Except for this instance, the page would have been entirely prerenderable which may have been the intended behavior. See more info here: https://nextjs.org/docs/messages/next-prerender-dynamic-metadata`;\n        const error = createErrorWithComponentOrOwnerStack(message, componentStack);\n        dynamicValidation.dynamicMetadata = error;\n        return;\n    } else if (hasViewportRegex.test(componentStack)) {\n        const message = `Route \"${workStore.route}\": Uncached data or \\`connection()\\` was accessed inside \\`generateViewport\\`. This delays the entire page from rendering, resulting in a slow user experience. Learn more: https://nextjs.org/docs/messages/next-prerender-dynamic-viewport`;\n        const error = createErrorWithComponentOrOwnerStack(message, componentStack);\n        dynamicValidation.dynamicErrors.push(error);\n        return;\n    } else if (hasSuspenseBeforeRootLayoutWithoutBodyOrImplicitBodyRegex.test(componentStack)) {\n        // For Suspense within body, the prelude wouldn't be empty so it wouldn't violate the empty static shells rule.\n        // But if you have Suspense above body, the prelude is empty but we allow that because having Suspense\n        // is an explicit signal from the user that they acknowledge the empty shell and want dynamic rendering.\n        dynamicValidation.hasAllowedDynamic = true;\n        dynamicValidation.hasSuspenseAboveBody = true;\n        return;\n    } else if (hasSuspenseRegex.test(componentStack)) {\n        // this error had a Suspense boundary above it so we don't need to report it as a source\n        // of disallowed\n        dynamicValidation.hasAllowedDynamic = true;\n        return;\n    } else if (clientDynamic.syncDynamicErrorWithStack) {\n        // This task was the task that called the sync error.\n        dynamicValidation.dynamicErrors.push(clientDynamic.syncDynamicErrorWithStack);\n        return;\n    } else {\n        const message = `Route \"${workStore.route}\": Uncached data or \\`connection()\\` was accessed outside of \\`<Suspense>\\`. This delays the entire page from rendering, resulting in a slow user experience. Learn more: https://nextjs.org/docs/messages/blocking-route`;\n        const error = createErrorWithComponentOrOwnerStack(message, componentStack);\n        dynamicValidation.dynamicErrors.push(error);\n        return;\n    }\n}\nexport function trackDynamicHoleInStaticShell(workStore, componentStack, dynamicValidation, clientDynamic) {\n    if (hasOutletRegex.test(componentStack)) {\n        // We don't need to track that this is dynamic. It is only so when something else is also dynamic.\n        return;\n    } else if (hasMetadataRegex.test(componentStack)) {\n        const message = `Route \"${workStore.route}\": Runtime data such as \\`cookies()\\`, \\`headers()\\`, \\`params\\`, or \\`searchParams\\` was accessed inside \\`generateMetadata\\` or you have file-based metadata such as icons that depend on dynamic params segments. Except for this instance, the page would have been entirely prerenderable which may have been the intended behavior. See more info here: https://nextjs.org/docs/messages/next-prerender-dynamic-metadata`;\n        const error = createErrorWithComponentOrOwnerStack(message, componentStack);\n        dynamicValidation.dynamicMetadata = error;\n        return;\n    } else if (hasViewportRegex.test(componentStack)) {\n        const message = `Route \"${workStore.route}\": Runtime data such as \\`cookies()\\`, \\`headers()\\`, \\`params\\`, or \\`searchParams\\` was accessed inside \\`generateViewport\\`. This delays the entire page from rendering, resulting in a slow user experience. Learn more: https://nextjs.org/docs/messages/next-prerender-dynamic-viewport`;\n        const error = createErrorWithComponentOrOwnerStack(message, componentStack);\n        dynamicValidation.dynamicErrors.push(error);\n        return;\n    } else if (hasSuspenseBeforeRootLayoutWithoutBodyOrImplicitBodyRegex.test(componentStack)) {\n        // For Suspense within body, the prelude wouldn't be empty so it wouldn't violate the empty static shells rule.\n        // But if you have Suspense above body, the prelude is empty but we allow that because having Suspense\n        // is an explicit signal from the user that they acknowledge the empty shell and want dynamic rendering.\n        dynamicValidation.hasAllowedDynamic = true;\n        dynamicValidation.hasSuspenseAboveBody = true;\n        return;\n    } else if (hasSuspenseRegex.test(componentStack)) {\n        // this error had a Suspense boundary above it so we don't need to report it as a source\n        // of disallowed\n        dynamicValidation.hasAllowedDynamic = true;\n        return;\n    } else if (clientDynamic.syncDynamicErrorWithStack) {\n        // This task was the task that called the sync error.\n        dynamicValidation.dynamicErrors.push(clientDynamic.syncDynamicErrorWithStack);\n        return;\n    } else {\n        const message = `Route \"${workStore.route}\": Runtime data such as \\`cookies()\\`, \\`headers()\\`, \\`params\\`, or \\`searchParams\\` was accessed outside of \\`<Suspense>\\`. This delays the entire page from rendering, resulting in a slow user experience. Learn more: https://nextjs.org/docs/messages/blocking-route`;\n        const error = createErrorWithComponentOrOwnerStack(message, componentStack);\n        dynamicValidation.dynamicErrors.push(error);\n        return;\n    }\n}\n/**\n * In dev mode, we prefer using the owner stack, otherwise the provided\n * component stack is used.\n */ function createErrorWithComponentOrOwnerStack(message, componentStack) {\n    const ownerStack = process.env.NODE_ENV !== 'production' && React.captureOwnerStack ? React.captureOwnerStack() : null;\n    const error = Object.defineProperty(new Error(message), \"__NEXT_ERROR_CODE\", {\n        value: \"E394\",\n        enumerable: false,\n        configurable: true\n    });\n    // TODO go back to owner stack here if available. This is temporarily using componentStack to get the right\n    //\n    error.stack = error.name + ': ' + message + (ownerStack || componentStack);\n    return error;\n}\nexport var PreludeState = /*#__PURE__*/ function(PreludeState) {\n    PreludeState[PreludeState[\"Full\"] = 0] = \"Full\";\n    PreludeState[PreludeState[\"Empty\"] = 1] = \"Empty\";\n    PreludeState[PreludeState[\"Errored\"] = 2] = \"Errored\";\n    return PreludeState;\n}({});\nexport function logDisallowedDynamicError(workStore, error) {\n    console.error(error);\n    if (!workStore.dev) {\n        if (workStore.hasReadableErrorStacks) {\n            console.error(`To get a more detailed stack trace and pinpoint the issue, start the app in development mode by running \\`next dev\\`, then open \"${workStore.route}\" in your browser to investigate the error.`);\n        } else {\n            console.error(`To get a more detailed stack trace and pinpoint the issue, try one of the following:\n  - Start the app in development mode by running \\`next dev\\`, then open \"${workStore.route}\" in your browser to investigate the error.\n  - Rerun the production build with \\`next build --debug-prerender\\` to generate better stack traces.`);\n        }\n    }\n}\nexport function throwIfDisallowedDynamic(workStore, prelude, dynamicValidation, serverDynamic) {\n    if (serverDynamic.syncDynamicErrorWithStack) {\n        logDisallowedDynamicError(workStore, serverDynamic.syncDynamicErrorWithStack);\n        throw new StaticGenBailoutError();\n    }\n    if (prelude !== 0) {\n        if (dynamicValidation.hasSuspenseAboveBody) {\n            // This route has opted into allowing fully dynamic rendering\n            // by including a Suspense boundary above the body. In this case\n            // a lack of a shell is not considered disallowed so we simply return\n            return;\n        }\n        // We didn't have any sync bailouts but there may be user code which\n        // blocked the root. We would have captured these during the prerender\n        // and can log them here and then terminate the build/validating render\n        const dynamicErrors = dynamicValidation.dynamicErrors;\n        if (dynamicErrors.length > 0) {\n            for(let i = 0; i < dynamicErrors.length; i++){\n                logDisallowedDynamicError(workStore, dynamicErrors[i]);\n            }\n            throw new StaticGenBailoutError();\n        }\n        // If we got this far then the only other thing that could be blocking\n        // the root is dynamic Viewport. If this is dynamic then\n        // you need to opt into that by adding a Suspense boundary above the body\n        // to indicate your are ok with fully dynamic rendering.\n        if (dynamicValidation.hasDynamicViewport) {\n            console.error(`Route \"${workStore.route}\" has a \\`generateViewport\\` that depends on Request data (\\`cookies()\\`, etc...) or uncached external data (\\`fetch(...)\\`, etc...) without explicitly allowing fully dynamic rendering. See more info here: https://nextjs.org/docs/messages/next-prerender-dynamic-viewport`);\n            throw new StaticGenBailoutError();\n        }\n        if (prelude === 1) {\n            // If we ever get this far then we messed up the tracking of invalid dynamic.\n            // We still adhere to the constraint that you must produce a shell but invite the\n            // user to report this as a bug in Next.js.\n            console.error(`Route \"${workStore.route}\" did not produce a static shell and Next.js was unable to determine a reason. This is a bug in Next.js.`);\n            throw new StaticGenBailoutError();\n        }\n    } else {\n        if (dynamicValidation.hasAllowedDynamic === false && dynamicValidation.hasDynamicMetadata) {\n            console.error(`Route \"${workStore.route}\" has a \\`generateMetadata\\` that depends on Request data (\\`cookies()\\`, etc...) or uncached external data (\\`fetch(...)\\`, etc...) when the rest of the route does not. See more info here: https://nextjs.org/docs/messages/next-prerender-dynamic-metadata`);\n            throw new StaticGenBailoutError();\n        }\n    }\n}\nexport function getStaticShellDisallowedDynamicReasons(workStore, prelude, dynamicValidation) {\n    if (dynamicValidation.hasSuspenseAboveBody) {\n        // This route has opted into allowing fully dynamic rendering\n        // by including a Suspense boundary above the body. In this case\n        // a lack of a shell is not considered disallowed so we simply return\n        return [];\n    }\n    if (prelude !== 0) {\n        // We didn't have any sync bailouts but there may be user code which\n        // blocked the root. We would have captured these during the prerender\n        // and can log them here and then terminate the build/validating render\n        const dynamicErrors = dynamicValidation.dynamicErrors;\n        if (dynamicErrors.length > 0) {\n            return dynamicErrors;\n        }\n        if (prelude === 1) {\n            // If we ever get this far then we messed up the tracking of invalid dynamic.\n            // We still adhere to the constraint that you must produce a shell but invite the\n            // user to report this as a bug in Next.js.\n            return [\n                Object.defineProperty(new InvariantError(`Route \"${workStore.route}\" did not produce a static shell and Next.js was unable to determine a reason.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E936\",\n                    enumerable: false,\n                    configurable: true\n                })\n            ];\n        }\n    } else {\n        // We have a prelude but we might still have dynamic metadata without any other dynamic access\n        if (dynamicValidation.hasAllowedDynamic === false && dynamicValidation.dynamicErrors.length === 0 && dynamicValidation.dynamicMetadata) {\n            return [\n                dynamicValidation.dynamicMetadata\n            ];\n        }\n    }\n    // We had a non-empty prelude and there are no dynamic holes\n    return [];\n}\nexport function delayUntilRuntimeStage(prerenderStore, result) {\n    if (prerenderStore.runtimeStagePromise) {\n        return prerenderStore.runtimeStagePromise.then(()=>result);\n    }\n    return result;\n}\n\n//# sourceMappingURL=dynamic-rendering.js.map","const DYNAMIC_ERROR_CODE = 'DYNAMIC_SERVER_USAGE';\nexport class DynamicServerError extends Error {\n    constructor(description){\n        super(`Dynamic server usage: ${description}`), this.description = description, this.digest = DYNAMIC_ERROR_CODE;\n    }\n}\nexport function isDynamicServerError(err) {\n    if (typeof err !== 'object' || err === null || !('digest' in err) || typeof err.digest !== 'string') {\n        return false;\n    }\n    return err.digest === DYNAMIC_ERROR_CODE;\n}\n\n//# sourceMappingURL=hooks-server-context.js.map","const NEXT_STATIC_GEN_BAILOUT = 'NEXT_STATIC_GEN_BAILOUT';\nexport class StaticGenBailoutError extends Error {\n    constructor(...args){\n        super(...args), this.code = NEXT_STATIC_GEN_BAILOUT;\n    }\n}\nexport function isStaticGenBailoutError(error) {\n    if (typeof error !== 'object' || error === null || !('code' in error)) {\n        return false;\n    }\n    return error.code === NEXT_STATIC_GEN_BAILOUT;\n}\n\n//# sourceMappingURL=static-generation-bailout.js.map","// This has to be a shared module which is shared between client component error boundary and dynamic component\nconst BAILOUT_TO_CSR = 'BAILOUT_TO_CLIENT_SIDE_RENDERING';\n/** An error that should be thrown when we want to bail out to client-side rendering. */ export class BailoutToCSRError extends Error {\n    constructor(reason){\n        super(`Bail out to client-side rendering: ${reason}`), this.reason = reason, this.digest = BAILOUT_TO_CSR;\n    }\n}\n/** Checks if a passed argument is an error that is thrown if we want to bail out to client-side rendering. */ export function isBailoutToCSRError(err) {\n    if (typeof err !== 'object' || err === null || !('digest' in err)) {\n        return false;\n    }\n    return err.digest === BAILOUT_TO_CSR;\n}\n\n//# sourceMappingURL=bailout-to-csr.js.map","const noop = ()=>{};\nlet registry;\nif (globalThis.FinalizationRegistry) {\n    registry = new FinalizationRegistry((weakRef)=>{\n        const stream = weakRef.deref();\n        if (stream && !stream.locked) {\n            stream.cancel('Response object has been garbage collected').then(noop);\n        }\n    });\n}\n/**\n * Clones a response by teeing the body so we can return two independent\n * ReadableStreams from it. This avoids the bug in the undici library around\n * response cloning.\n *\n * After cloning, the original response's body will be consumed and closed.\n *\n * @see https://github.com/vercel/next.js/pull/73274\n *\n * @param original - The original response to clone.\n * @returns A tuple containing two independent clones of the original response.\n */ export function cloneResponse(original) {\n    // If the response has no body, then we can just return the original response\n    // twice because it's immutable.\n    if (!original.body) {\n        return [\n            original,\n            original\n        ];\n    }\n    const [body1, body2] = original.body.tee();\n    const cloned1 = new Response(body1, {\n        status: original.status,\n        statusText: original.statusText,\n        headers: original.headers\n    });\n    Object.defineProperty(cloned1, 'url', {\n        value: original.url,\n        // How the original response.url behaves\n        configurable: true,\n        enumerable: true,\n        writable: false\n    });\n    // The Fetch Standard allows users to skip consuming the response body by\n    // relying on garbage collection to release connection resources.\n    // https://github.com/nodejs/undici?tab=readme-ov-file#garbage-collection\n    //\n    // To cancel the stream you then need to cancel both resulting branches.\n    // Teeing a stream will generally lock it for the duration, preventing other\n    // readers from locking it.\n    // https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/tee\n    // cloned2 is stored in a react cache and cloned for subsequent requests.\n    // It is the original request, and is is garbage collected by a\n    // FinalizationRegistry in Undici, but since we're tee-ing the stream\n    // ourselves, we need to cancel clone1's stream (the response returned from\n    // our dedupe fetch) when clone1 is reclaimed, otherwise we leak memory.\n    if (registry && cloned1.body) {\n        registry.register(cloned1, new WeakRef(cloned1.body));\n    }\n    const cloned2 = new Response(body2, {\n        status: original.status,\n        statusText: original.statusText,\n        headers: original.headers\n    });\n    Object.defineProperty(cloned2, 'url', {\n        value: original.url,\n        // How the original response.url behaves\n        configurable: true,\n        enumerable: true,\n        writable: false\n    });\n    return [\n        cloned1,\n        cloned2\n    ];\n}\n\n//# sourceMappingURL=clone-response.js.map","export function createPromiseWithResolvers() {\n    // Shim of Stage 4 Promise.withResolvers proposal\n    let resolve;\n    let reject;\n    const promise = new Promise((res, rej)=>{\n        resolve = res;\n        reject = rej;\n    });\n    return {\n        resolve: resolve,\n        reject: reject,\n        promise\n    };\n}\n\n//# sourceMappingURL=promise-with-resolvers.js.map","export function getSegmentValue(segment) {\n    return Array.isArray(segment) ? segment[1] : segment;\n}\nexport function isGroupSegment(segment) {\n    // Use array[0] for performant purpose\n    return segment[0] === '(' && segment.endsWith(')');\n}\nexport function isParallelRouteSegment(segment) {\n    return segment.startsWith('@') && segment !== '@children';\n}\nexport function addSearchParamsIfPageSegment(segment, searchParams) {\n    const isPageSegment = segment.includes(PAGE_SEGMENT_KEY);\n    if (isPageSegment) {\n        const stringifiedQuery = JSON.stringify(searchParams);\n        return stringifiedQuery !== '{}' ? PAGE_SEGMENT_KEY + '?' + stringifiedQuery : PAGE_SEGMENT_KEY;\n    }\n    return segment;\n}\nexport function computeSelectedLayoutSegment(segments, parallelRouteKey) {\n    if (!segments || segments.length === 0) {\n        return null;\n    }\n    // For 'children', use first segment; for other parallel routes, use last segment\n    const rawSegment = parallelRouteKey === 'children' ? segments[0] : segments[segments.length - 1];\n    // If the default slot is showing, return null since it's not technically \"selected\" (it's a fallback)\n    // Returning an internal value like `__DEFAULT__` would be confusing\n    return rawSegment === DEFAULT_SEGMENT_KEY ? null : rawSegment;\n}\n/** Get the canonical parameters from the current level to the leaf node. */ export function getSelectedLayoutSegmentPath(tree, parallelRouteKey, first = true, segmentPath = []) {\n    let node;\n    if (first) {\n        // Use the provided parallel route key on the first parallel route\n        node = tree[1][parallelRouteKey];\n    } else {\n        // After first parallel route prefer children, if there's no children pick the first parallel route.\n        const parallelRoutes = tree[1];\n        node = parallelRoutes.children ?? Object.values(parallelRoutes)[0];\n    }\n    if (!node) return segmentPath;\n    const segment = node[0];\n    let segmentValue = getSegmentValue(segment);\n    if (!segmentValue || segmentValue.startsWith(PAGE_SEGMENT_KEY)) {\n        return segmentPath;\n    }\n    segmentPath.push(segmentValue);\n    return getSelectedLayoutSegmentPath(node, parallelRouteKey, false, segmentPath);\n}\nexport const PAGE_SEGMENT_KEY = '__PAGE__';\nexport const DEFAULT_SEGMENT_KEY = '__DEFAULT__';\nexport const NOT_FOUND_SEGMENT_KEY = '/_not-found';\n\n//# sourceMappingURL=segment.js.map","export var CachedRouteKind = /*#__PURE__*/ function(CachedRouteKind) {\n    CachedRouteKind[\"APP_PAGE\"] = \"APP_PAGE\";\n    CachedRouteKind[\"APP_ROUTE\"] = \"APP_ROUTE\";\n    CachedRouteKind[\"PAGES\"] = \"PAGES\";\n    CachedRouteKind[\"FETCH\"] = \"FETCH\";\n    CachedRouteKind[\"REDIRECT\"] = \"REDIRECT\";\n    CachedRouteKind[\"IMAGE\"] = \"IMAGE\";\n    return CachedRouteKind;\n}({});\nexport var IncrementalCacheKind = /*#__PURE__*/ function(IncrementalCacheKind) {\n    IncrementalCacheKind[\"APP_PAGE\"] = \"APP_PAGE\";\n    IncrementalCacheKind[\"APP_ROUTE\"] = \"APP_ROUTE\";\n    IncrementalCacheKind[\"PAGES\"] = \"PAGES\";\n    IncrementalCacheKind[\"FETCH\"] = \"FETCH\";\n    IncrementalCacheKind[\"IMAGE\"] = \"IMAGE\";\n    return IncrementalCacheKind;\n}({});\n\n//# sourceMappingURL=types.js.map","export const ENCODED_TAGS = {\n    // opening tags do not have the closing `>` since they can contain other attributes such as `<body className=''>`\n    OPENING: {\n        // <html\n        HTML: new Uint8Array([\n            60,\n            104,\n            116,\n            109,\n            108\n        ]),\n        // <body\n        BODY: new Uint8Array([\n            60,\n            98,\n            111,\n            100,\n            121\n        ])\n    },\n    CLOSED: {\n        // </head>\n        HEAD: new Uint8Array([\n            60,\n            47,\n            104,\n            101,\n            97,\n            100,\n            62\n        ]),\n        // </body>\n        BODY: new Uint8Array([\n            60,\n            47,\n            98,\n            111,\n            100,\n            121,\n            62\n        ]),\n        // </html>\n        HTML: new Uint8Array([\n            60,\n            47,\n            104,\n            116,\n            109,\n            108,\n            62\n        ]),\n        // </body></html>\n        BODY_AND_HTML: new Uint8Array([\n            60,\n            47,\n            98,\n            111,\n            100,\n            121,\n            62,\n            60,\n            47,\n            104,\n            116,\n            109,\n            108,\n            62\n        ])\n    },\n    META: {\n        // Only the match the prefix cause the suffix can be different wether it's xml compatible or not \">\" or \"/>\"\n        // <meta name=\"nxt-icon\"\n        // This is a special mark that will be replaced by the icon insertion script tag.\n        ICON_MARK: new Uint8Array([\n            60,\n            109,\n            101,\n            116,\n            97,\n            32,\n            110,\n            97,\n            109,\n            101,\n            61,\n            34,\n            194,\n            171,\n            110,\n            120,\n            116,\n            45,\n            105,\n            99,\n            111,\n            110,\n            194,\n            187,\n            34\n        ])\n    }\n};\n\n//# sourceMappingURL=encoded-tags.js.map","export const MISSING_ROOT_TAGS_ERROR = 'NEXT_MISSING_ROOT_TAGS';\n\n//# sourceMappingURL=constants.js.map","export var RouteKind = /*#__PURE__*/ function(RouteKind) {\n    /**\n   * `PAGES` represents all the React pages that are under `pages/`.\n   */ RouteKind[\"PAGES\"] = \"PAGES\";\n    /**\n   * `PAGES_API` represents all the API routes under `pages/api/`.\n   */ RouteKind[\"PAGES_API\"] = \"PAGES_API\";\n    /**\n   * `APP_PAGE` represents all the React pages that are under `app/` with the\n   * filename of `page.{j,t}s{,x}`.\n   */ RouteKind[\"APP_PAGE\"] = \"APP_PAGE\";\n    /**\n   * `APP_ROUTE` represents all the API routes and metadata routes that are under `app/` with the\n   * filename of `route.{j,t}s{,x}`.\n   */ RouteKind[\"APP_ROUTE\"] = \"APP_ROUTE\";\n    /**\n   * `IMAGE` represents all the images that are generated by `next/image`.\n   */ RouteKind[\"IMAGE\"] = \"IMAGE\";\n    return RouteKind;\n}({});\n\n//# sourceMappingURL=route-kind.js.map","export class PageSignatureError extends Error {\n    constructor({ page }){\n        super(`The middleware \"${page}\" accepts an async API directly with the form:\n  \n  export function middleware(request, event) {\n    return NextResponse.redirect('/new-location')\n  }\n  \n  Read more: https://nextjs.org/docs/messages/middleware-new-signature\n  `);\n    }\n}\nexport class RemovedPageError extends Error {\n    constructor(){\n        super(`The request.page has been deprecated in favour of \\`URLPattern\\`.\n  Read more: https://nextjs.org/docs/messages/middleware-request-page\n  `);\n    }\n}\nexport class RemovedUAError extends Error {\n    constructor(){\n        super(`The request.ua has been removed in favour of \\`userAgent\\` function.\n  Read more: https://nextjs.org/docs/messages/middleware-parse-user-agent\n  `);\n    }\n}\n\n//# sourceMappingURL=error.js.map","export class ReflectAdapter {\n    static get(target, prop, receiver) {\n        const value = Reflect.get(target, prop, receiver);\n        if (typeof value === 'function') {\n            return value.bind(target);\n        }\n        return value;\n    }\n    static set(target, prop, value, receiver) {\n        return Reflect.set(target, prop, value, receiver);\n    }\n    static has(target, prop) {\n        return Reflect.has(target, prop);\n    }\n    static deleteProperty(target, prop) {\n        return Reflect.deleteProperty(target, prop);\n    }\n}\n\n//# sourceMappingURL=reflect.js.map","export class InvariantError extends Error {\n    constructor(message, options){\n        super(`Invariant: ${message.endsWith('.') ? message : message + '.'} This is a bug in Next.js.`, options);\n        this.name = 'InvariantError';\n    }\n}\n\n//# sourceMappingURL=invariant-error.js.map","export const RSC_HEADER = 'rsc';\nexport const ACTION_HEADER = 'next-action';\n// TODO: Instead of sending the full router state, we only need to send the\n// segment path. Saves bytes. Then we could also use this field for segment\n// prefetches, which also need to specify a particular segment.\nexport const NEXT_ROUTER_STATE_TREE_HEADER = 'next-router-state-tree';\nexport const NEXT_ROUTER_PREFETCH_HEADER = 'next-router-prefetch';\n// This contains the path to the segment being prefetched.\n// TODO: If we change next-router-state-tree to be a segment path, we can use\n// that instead. Then next-router-prefetch and next-router-segment-prefetch can\n// be merged into a single enum.\nexport const NEXT_ROUTER_SEGMENT_PREFETCH_HEADER = 'next-router-segment-prefetch';\nexport const NEXT_HMR_REFRESH_HEADER = 'next-hmr-refresh';\nexport const NEXT_HMR_REFRESH_HASH_COOKIE = '__next_hmr_refresh_hash__';\nexport const NEXT_URL = 'next-url';\nexport const RSC_CONTENT_TYPE_HEADER = 'text/x-component';\nexport const FLIGHT_HEADERS = [\n    RSC_HEADER,\n    NEXT_ROUTER_STATE_TREE_HEADER,\n    NEXT_ROUTER_PREFETCH_HEADER,\n    NEXT_HMR_REFRESH_HEADER,\n    NEXT_ROUTER_SEGMENT_PREFETCH_HEADER\n];\nexport const NEXT_RSC_UNION_QUERY = '_rsc';\nexport const NEXT_ROUTER_STALE_TIME_HEADER = 'x-nextjs-stale-time';\nexport const NEXT_DID_POSTPONE_HEADER = 'x-nextjs-postponed';\nexport const NEXT_REWRITTEN_PATH_HEADER = 'x-nextjs-rewritten-path';\nexport const NEXT_REWRITTEN_QUERY_HEADER = 'x-nextjs-rewritten-query';\nexport const NEXT_IS_PRERENDER_HEADER = 'x-nextjs-prerender';\nexport const NEXT_ACTION_NOT_FOUND_HEADER = 'x-nextjs-action-not-found';\nexport const NEXT_REQUEST_ID_HEADER = 'x-nextjs-request-id';\nexport const NEXT_HTML_REQUEST_ID_HEADER = 'x-nextjs-html-request-id';\n// TODO: Should this include nextjs in the name, like the others?\nexport const NEXT_ACTION_REVALIDATED_HEADER = 'x-action-revalidated';\n\n//# sourceMappingURL=app-router-headers.js.map","export function interceptionPrefixFromParamType(paramType) {\n    switch(paramType){\n        case 'catchall-intercepted-(..)(..)':\n        case 'dynamic-intercepted-(..)(..)':\n            return '(..)(..)';\n        case 'catchall-intercepted-(.)':\n        case 'dynamic-intercepted-(.)':\n            return '(.)';\n        case 'catchall-intercepted-(..)':\n        case 'dynamic-intercepted-(..)':\n            return '(..)';\n        case 'catchall-intercepted-(...)':\n        case 'dynamic-intercepted-(...)':\n            return '(...)';\n        case 'catchall':\n        case 'dynamic':\n        case 'optional-catchall':\n        default:\n            return null;\n    }\n}\n\n//# sourceMappingURL=interception-prefix-from-param-type.js.map","export function searchParamsToUrlQuery(searchParams) {\n    const query = {};\n    for (const [key, value] of searchParams.entries()){\n        const existing = query[key];\n        if (typeof existing === 'undefined') {\n            query[key] = value;\n        } else if (Array.isArray(existing)) {\n            existing.push(value);\n        } else {\n            query[key] = [\n                existing,\n                value\n            ];\n        }\n    }\n    return query;\n}\nfunction stringifyUrlQueryParam(param) {\n    if (typeof param === 'string') {\n        return param;\n    }\n    if (typeof param === 'number' && !isNaN(param) || typeof param === 'boolean') {\n        return String(param);\n    } else {\n        return '';\n    }\n}\nexport function urlQueryToSearchParams(query) {\n    const searchParams = new URLSearchParams();\n    for (const [key, value] of Object.entries(query)){\n        if (Array.isArray(value)) {\n            for (const item of value){\n                searchParams.append(key, stringifyUrlQueryParam(item));\n            }\n        } else {\n            searchParams.set(key, stringifyUrlQueryParam(value));\n        }\n    }\n    return searchParams;\n}\nexport function assign(target, ...searchParamsList) {\n    for (const searchParams of searchParamsList){\n        for (const key of searchParams.keys()){\n            target.delete(key);\n        }\n        for (const [key, value] of searchParams.entries()){\n            target.append(key, value);\n        }\n    }\n    return target;\n}\n\n//# sourceMappingURL=querystring.js.map","export var RedirectStatusCode = /*#__PURE__*/ function(RedirectStatusCode) {\n    RedirectStatusCode[RedirectStatusCode[\"SeeOther\"] = 303] = \"SeeOther\";\n    RedirectStatusCode[RedirectStatusCode[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    RedirectStatusCode[RedirectStatusCode[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    return RedirectStatusCode;\n}({});\n\n//# sourceMappingURL=redirect-status-code.js.map","export const ActionDidNotRevalidate = 0;\nexport const ActionDidRevalidateStaticAndDynamic = 1;\nexport const ActionDidRevalidateDynamicOnly = 2;\n\n//# sourceMappingURL=action-revalidation-kind.js.map","export function isHangingPromiseRejectionError(err) {\n    if (typeof err !== 'object' || err === null || !('digest' in err)) {\n        return false;\n    }\n    return err.digest === HANGING_PROMISE_REJECTION;\n}\nconst HANGING_PROMISE_REJECTION = 'HANGING_PROMISE_REJECTION';\nclass HangingPromiseRejectionError extends Error {\n    constructor(route, expression){\n        super(`During prerendering, ${expression} rejects when the prerender is complete. Typically these errors are handled by React but if you move ${expression} to a different context by using \\`setTimeout\\`, \\`after\\`, or similar functions you may observe this error and you should handle it in that context. This occurred at route \"${route}\".`), this.route = route, this.expression = expression, this.digest = HANGING_PROMISE_REJECTION;\n    }\n}\nconst abortListenersBySignal = new WeakMap();\n/**\n * This function constructs a promise that will never resolve. This is primarily\n * useful for cacheComponents where we use promise resolution timing to determine which\n * parts of a render can be included in a prerender.\n *\n * @internal\n */ export function makeHangingPromise(signal, route, expression) {\n    if (signal.aborted) {\n        return Promise.reject(new HangingPromiseRejectionError(route, expression));\n    } else {\n        const hangingPromise = new Promise((_, reject)=>{\n            const boundRejection = reject.bind(null, new HangingPromiseRejectionError(route, expression));\n            let currentListeners = abortListenersBySignal.get(signal);\n            if (currentListeners) {\n                currentListeners.push(boundRejection);\n            } else {\n                const listeners = [\n                    boundRejection\n                ];\n                abortListenersBySignal.set(signal, listeners);\n                signal.addEventListener('abort', ()=>{\n                    for(let i = 0; i < listeners.length; i++){\n                        listeners[i]();\n                    }\n                }, {\n                    once: true\n                });\n            }\n        });\n        // We are fine if no one actually awaits this promise. We shouldn't consider this an unhandled rejection so\n        // we attach a noop catch handler here to suppress this warning. If you actually await somewhere or construct\n        // your own promise out of it you'll need to ensure you handle the error when it rejects.\n        hangingPromise.catch(ignoreReject);\n        return hangingPromise;\n    }\n}\nfunction ignoreReject() {}\nexport function makeDevtoolsIOAwarePromise(underlying, requestStore, stage) {\n    if (requestStore.stagedRendering) {\n        // We resolve each stage in a timeout, so React DevTools will pick this up as IO.\n        return requestStore.stagedRendering.delayUntilStage(stage, undefined, underlying);\n    }\n    // in React DevTools if we resolve in a setTimeout we will observe\n    // the promise resolution as something that can suspend a boundary or root.\n    return new Promise((resolve)=>{\n        // Must use setTimeout to be considered IO React DevTools. setImmediate will not work.\n        setTimeout(()=>{\n            resolve(underlying);\n        }, 0);\n    });\n}\n\n//# sourceMappingURL=dynamic-rendering-utils.js.map","export const METADATA_BOUNDARY_NAME = '__next_metadata_boundary__';\nexport const VIEWPORT_BOUNDARY_NAME = '__next_viewport_boundary__';\nexport const OUTLET_BOUNDARY_NAME = '__next_outlet_boundary__';\nexport const ROOT_LAYOUT_BOUNDARY_NAME = '__next_root_layout_boundary__';\n\n//# sourceMappingURL=boundary-constants.js.map","export const TEXT_PLAIN_CONTENT_TYPE_HEADER = 'text/plain';\nexport const HTML_CONTENT_TYPE_HEADER = 'text/html; charset=utf-8';\nexport const JSON_CONTENT_TYPE_HEADER = 'application/json; charset=utf-8';\nexport const NEXT_QUERY_PARAM_PREFIX = 'nxtP';\nexport const NEXT_INTERCEPTION_MARKER_PREFIX = 'nxtI';\nexport const MATCHED_PATH_HEADER = 'x-matched-path';\nexport const PRERENDER_REVALIDATE_HEADER = 'x-prerender-revalidate';\nexport const PRERENDER_REVALIDATE_ONLY_GENERATED_HEADER = 'x-prerender-revalidate-if-generated';\nexport const RSC_SEGMENTS_DIR_SUFFIX = '.segments';\nexport const RSC_SEGMENT_SUFFIX = '.segment.rsc';\nexport const RSC_SUFFIX = '.rsc';\nexport const ACTION_SUFFIX = '.action';\nexport const NEXT_DATA_SUFFIX = '.json';\nexport const NEXT_META_SUFFIX = '.meta';\nexport const NEXT_BODY_SUFFIX = '.body';\nexport const NEXT_CACHE_TAGS_HEADER = 'x-next-cache-tags';\nexport const NEXT_CACHE_REVALIDATED_TAGS_HEADER = 'x-next-revalidated-tags';\nexport const NEXT_CACHE_REVALIDATE_TAG_TOKEN_HEADER = 'x-next-revalidate-tag-token';\nexport const NEXT_RESUME_HEADER = 'next-resume';\n// if these change make sure we update the related\n// documentation as well\nexport const NEXT_CACHE_TAG_MAX_ITEMS = 128;\nexport const NEXT_CACHE_TAG_MAX_LENGTH = 256;\nexport const NEXT_CACHE_SOFT_TAG_MAX_LENGTH = 1024;\nexport const NEXT_CACHE_IMPLICIT_TAG_ID = '_N_T_';\n// in seconds\nexport const CACHE_ONE_YEAR = 31536000;\n// in seconds, represents revalidate=false. I.e. never revaliate.\n// We use this value since it can be represented as a V8 SMI for optimal performance.\n// It can also be serialized as JSON if it ever leaks accidentally as an actual value.\nexport const INFINITE_CACHE = 0xfffffffe;\n// Patterns to detect middleware files\nexport const MIDDLEWARE_FILENAME = 'middleware';\nexport const MIDDLEWARE_LOCATION_REGEXP = `(?:src/)?${MIDDLEWARE_FILENAME}`;\n// Patterns to detect proxy files (replacement for middleware)\nexport const PROXY_FILENAME = 'proxy';\nexport const PROXY_LOCATION_REGEXP = `(?:src/)?${PROXY_FILENAME}`;\n// Pattern to detect instrumentation hooks file\nexport const INSTRUMENTATION_HOOK_FILENAME = 'instrumentation';\n// Because on Windows absolute paths in the generated code can break because of numbers, eg 1 in the path,\n// we have to use a private alias\nexport const PAGES_DIR_ALIAS = 'private-next-pages';\nexport const DOT_NEXT_ALIAS = 'private-dot-next';\nexport const ROOT_DIR_ALIAS = 'private-next-root-dir';\nexport const APP_DIR_ALIAS = 'private-next-app-dir';\nexport const RSC_MOD_REF_PROXY_ALIAS = 'private-next-rsc-mod-ref-proxy';\nexport const RSC_ACTION_VALIDATE_ALIAS = 'private-next-rsc-action-validate';\nexport const RSC_ACTION_PROXY_ALIAS = 'private-next-rsc-server-reference';\nexport const RSC_CACHE_WRAPPER_ALIAS = 'private-next-rsc-cache-wrapper';\nexport const RSC_DYNAMIC_IMPORT_WRAPPER_ALIAS = 'private-next-rsc-track-dynamic-import';\nexport const RSC_ACTION_ENCRYPTION_ALIAS = 'private-next-rsc-action-encryption';\nexport const RSC_ACTION_CLIENT_WRAPPER_ALIAS = 'private-next-rsc-action-client-wrapper';\nexport const PUBLIC_DIR_MIDDLEWARE_CONFLICT = `You can not have a '_next' folder inside of your public folder. This conflicts with the internal '/_next' route. https://nextjs.org/docs/messages/public-next-folder-conflict`;\nexport const SSG_GET_INITIAL_PROPS_CONFLICT = `You can not use getInitialProps with getStaticProps. To use SSG, please remove your getInitialProps`;\nexport const SERVER_PROPS_GET_INIT_PROPS_CONFLICT = `You can not use getInitialProps with getServerSideProps. Please remove getInitialProps.`;\nexport const SERVER_PROPS_SSG_CONFLICT = `You can not use getStaticProps or getStaticPaths with getServerSideProps. To use SSG, please remove getServerSideProps`;\nexport const STATIC_STATUS_PAGE_GET_INITIAL_PROPS_ERROR = `can not have getInitialProps/getServerSideProps, https://nextjs.org/docs/messages/404-get-initial-props`;\nexport const SERVER_PROPS_EXPORT_ERROR = `pages with \\`getServerSideProps\\` can not be exported. See more info here: https://nextjs.org/docs/messages/gssp-export`;\nexport const GSP_NO_RETURNED_VALUE = 'Your `getStaticProps` function did not return an object. Did you forget to add a `return`?';\nexport const GSSP_NO_RETURNED_VALUE = 'Your `getServerSideProps` function did not return an object. Did you forget to add a `return`?';\nexport const UNSTABLE_REVALIDATE_RENAME_ERROR = 'The `unstable_revalidate` property is available for general use.\\n' + 'Please use `revalidate` instead.';\nexport const GSSP_COMPONENT_MEMBER_ERROR = `can not be attached to a page's component and must be exported from the page. See more info here: https://nextjs.org/docs/messages/gssp-component-member`;\nexport const NON_STANDARD_NODE_ENV = `You are using a non-standard \"NODE_ENV\" value in your environment. This creates inconsistencies in the project and is strongly advised against. Read more: https://nextjs.org/docs/messages/non-standard-node-env`;\nexport const SSG_FALLBACK_EXPORT_ERROR = `Pages with \\`fallback\\` enabled in \\`getStaticPaths\\` can not be exported. See more info here: https://nextjs.org/docs/messages/ssg-fallback-true-export`;\nexport const ESLINT_DEFAULT_DIRS = [\n    'app',\n    'pages',\n    'components',\n    'lib',\n    'src'\n];\nexport const SERVER_RUNTIME = {\n    edge: 'edge',\n    experimentalEdge: 'experimental-edge',\n    nodejs: 'nodejs'\n};\nexport const WEB_SOCKET_MAX_RECONNECTIONS = 12;\n/**\n * The names of the webpack layers. These layers are the primitives for the\n * webpack chunks.\n */ const WEBPACK_LAYERS_NAMES = {\n    /**\n   * The layer for the shared code between the client and server bundles.\n   */ shared: 'shared',\n    /**\n   * The layer for server-only runtime and picking up `react-server` export conditions.\n   * Including app router RSC pages and app router custom routes and metadata routes.\n   */ reactServerComponents: 'rsc',\n    /**\n   * Server Side Rendering layer for app (ssr).\n   */ serverSideRendering: 'ssr',\n    /**\n   * The browser client bundle layer for actions.\n   */ actionBrowser: 'action-browser',\n    /**\n   * The Node.js bundle layer for the API routes.\n   */ apiNode: 'api-node',\n    /**\n   * The Edge Lite bundle layer for the API routes.\n   */ apiEdge: 'api-edge',\n    /**\n   * The layer for the middleware code.\n   */ middleware: 'middleware',\n    /**\n   * The layer for the instrumentation hooks.\n   */ instrument: 'instrument',\n    /**\n   * The layer for assets on the edge.\n   */ edgeAsset: 'edge-asset',\n    /**\n   * The browser client bundle layer for App directory.\n   */ appPagesBrowser: 'app-pages-browser',\n    /**\n   * The browser client bundle layer for Pages directory.\n   */ pagesDirBrowser: 'pages-dir-browser',\n    /**\n   * The Edge Lite bundle layer for Pages directory.\n   */ pagesDirEdge: 'pages-dir-edge',\n    /**\n   * The Node.js bundle layer for Pages directory.\n   */ pagesDirNode: 'pages-dir-node'\n};\nconst WEBPACK_LAYERS = {\n    ...WEBPACK_LAYERS_NAMES,\n    GROUP: {\n        builtinReact: [\n            WEBPACK_LAYERS_NAMES.reactServerComponents,\n            WEBPACK_LAYERS_NAMES.actionBrowser\n        ],\n        serverOnly: [\n            WEBPACK_LAYERS_NAMES.reactServerComponents,\n            WEBPACK_LAYERS_NAMES.actionBrowser,\n            WEBPACK_LAYERS_NAMES.instrument,\n            WEBPACK_LAYERS_NAMES.middleware\n        ],\n        neutralTarget: [\n            // pages api\n            WEBPACK_LAYERS_NAMES.apiNode,\n            WEBPACK_LAYERS_NAMES.apiEdge\n        ],\n        clientOnly: [\n            WEBPACK_LAYERS_NAMES.serverSideRendering,\n            WEBPACK_LAYERS_NAMES.appPagesBrowser\n        ],\n        bundled: [\n            WEBPACK_LAYERS_NAMES.reactServerComponents,\n            WEBPACK_LAYERS_NAMES.actionBrowser,\n            WEBPACK_LAYERS_NAMES.serverSideRendering,\n            WEBPACK_LAYERS_NAMES.appPagesBrowser,\n            WEBPACK_LAYERS_NAMES.shared,\n            WEBPACK_LAYERS_NAMES.instrument,\n            WEBPACK_LAYERS_NAMES.middleware\n        ],\n        appPages: [\n            // app router pages and layouts\n            WEBPACK_LAYERS_NAMES.reactServerComponents,\n            WEBPACK_LAYERS_NAMES.serverSideRendering,\n            WEBPACK_LAYERS_NAMES.appPagesBrowser,\n            WEBPACK_LAYERS_NAMES.actionBrowser\n        ]\n    }\n};\nconst WEBPACK_RESOURCE_QUERIES = {\n    edgeSSREntry: '__next_edge_ssr_entry__',\n    metadata: '__next_metadata__',\n    metadataRoute: '__next_metadata_route__',\n    metadataImageMeta: '__next_metadata_image_meta__'\n};\nexport { WEBPACK_LAYERS, WEBPACK_RESOURCE_QUERIES };\n\n//# sourceMappingURL=constants.js.map","export function detectDomainLocale(domainItems, hostname, detectedLocale) {\n    if (!domainItems) return;\n    if (detectedLocale) {\n        detectedLocale = detectedLocale.toLowerCase();\n    }\n    for (const item of domainItems){\n        // remove port if present\n        const domainHostname = item.domain?.split(':', 1)[0].toLowerCase();\n        if (hostname === domainHostname || detectedLocale === item.defaultLocale.toLowerCase() || item.locales?.some((locale)=>locale.toLowerCase() === detectedLocale)) {\n            return item;\n        }\n    }\n}\n\n//# sourceMappingURL=detect-domain-locale.js.map","import { NEXT_RSC_UNION_QUERY } from '../client/components/app-router-headers';\nconst DUMMY_ORIGIN = 'http://n';\nexport function isFullStringUrl(url) {\n    return /https?:\\/\\//.test(url);\n}\nexport function parseUrl(url) {\n    let parsed = undefined;\n    try {\n        parsed = new URL(url, DUMMY_ORIGIN);\n    } catch  {}\n    return parsed;\n}\nexport function parseReqUrl(url) {\n    const parsedUrl = parseUrl(url);\n    if (!parsedUrl) {\n        return;\n    }\n    const query = {};\n    for (const key of parsedUrl.searchParams.keys()){\n        const values = parsedUrl.searchParams.getAll(key);\n        query[key] = values.length > 1 ? values : values[0];\n    }\n    const legacyUrl = {\n        query,\n        hash: parsedUrl.hash,\n        search: parsedUrl.search,\n        path: parsedUrl.pathname,\n        pathname: parsedUrl.pathname,\n        href: `${parsedUrl.pathname}${parsedUrl.search}${parsedUrl.hash}`,\n        host: '',\n        hostname: '',\n        auth: '',\n        protocol: '',\n        slashes: null,\n        port: ''\n    };\n    return legacyUrl;\n}\nexport function stripNextRscUnionQuery(relativeUrl) {\n    const urlInstance = new URL(relativeUrl, DUMMY_ORIGIN);\n    urlInstance.searchParams.delete(NEXT_RSC_UNION_QUERY);\n    return urlInstance.pathname + urlInstance.search;\n}\n\n//# sourceMappingURL=url.js.map","import { CachedRouteKind, IncrementalCacheKind } from '../../response-cache';\nimport path from '../../../shared/lib/isomorphic/path';\nimport { NEXT_CACHE_TAGS_HEADER, NEXT_DATA_SUFFIX, NEXT_META_SUFFIX, RSC_SEGMENT_SUFFIX, RSC_SEGMENTS_DIR_SUFFIX, RSC_SUFFIX } from '../../../lib/constants';\nimport { areTagsExpired, tagsManifest } from './tags-manifest.external';\nimport { MultiFileWriter } from '../../../lib/multi-file-writer';\nimport { getMemoryCache } from './memory-cache.external';\nexport default class FileSystemCache {\n    static #_ = this.debug = !!process.env.NEXT_PRIVATE_DEBUG_CACHE;\n    constructor(ctx){\n        this.fs = ctx.fs;\n        this.flushToDisk = ctx.flushToDisk;\n        this.serverDistDir = ctx.serverDistDir;\n        this.revalidatedTags = ctx.revalidatedTags;\n        if (ctx.maxMemoryCacheSize) {\n            if (!FileSystemCache.memoryCache) {\n                if (FileSystemCache.debug) {\n                    console.log('FileSystemCache: using memory store for fetch cache');\n                }\n                FileSystemCache.memoryCache = getMemoryCache(ctx.maxMemoryCacheSize);\n            } else if (FileSystemCache.debug) {\n                console.log('FileSystemCache: memory store already initialized');\n            }\n        } else if (FileSystemCache.debug) {\n            console.log('FileSystemCache: not using memory store for fetch cache');\n        }\n    }\n    resetRequestCache() {}\n    async revalidateTag(tags, durations) {\n        tags = typeof tags === 'string' ? [\n            tags\n        ] : tags;\n        if (FileSystemCache.debug) {\n            console.log('FileSystemCache: revalidateTag', tags, durations);\n        }\n        if (tags.length === 0) {\n            return;\n        }\n        const now = Date.now();\n        for (const tag of tags){\n            const existingEntry = tagsManifest.get(tag) || {};\n            if (durations) {\n                // Use provided durations directly\n                const updates = {\n                    ...existingEntry\n                };\n                // mark as stale immediately\n                updates.stale = now;\n                if (durations.expire !== undefined) {\n                    updates.expired = now + durations.expire * 1000 // Convert seconds to ms\n                    ;\n                }\n                tagsManifest.set(tag, updates);\n            } else {\n                // Update expired field for immediate expiration (default behavior when no durations provided)\n                tagsManifest.set(tag, {\n                    ...existingEntry,\n                    expired: now\n                });\n            }\n        }\n    }\n    async get(...args) {\n        var _FileSystemCache_memoryCache, _data_value, _data_value1, _data_value2, _data_value3;\n        const [key, ctx] = args;\n        const { kind } = ctx;\n        let data = (_FileSystemCache_memoryCache = FileSystemCache.memoryCache) == null ? void 0 : _FileSystemCache_memoryCache.get(key);\n        if (FileSystemCache.debug) {\n            if (kind === IncrementalCacheKind.FETCH) {\n                console.log('FileSystemCache: get', key, ctx.tags, kind, !!data);\n            } else {\n                console.log('FileSystemCache: get', key, kind, !!data);\n            }\n        }\n        // let's check the disk for seed data\n        if (!data && process.env.NEXT_RUNTIME !== 'edge') {\n            try {\n                if (kind === IncrementalCacheKind.APP_ROUTE) {\n                    const filePath = this.getFilePath(`${key}.body`, IncrementalCacheKind.APP_ROUTE);\n                    const fileData = await this.fs.readFile(filePath);\n                    const { mtime } = await this.fs.stat(filePath);\n                    const meta = JSON.parse(await this.fs.readFile(filePath.replace(/\\.body$/, NEXT_META_SUFFIX), 'utf8'));\n                    data = {\n                        lastModified: mtime.getTime(),\n                        value: {\n                            kind: CachedRouteKind.APP_ROUTE,\n                            body: fileData,\n                            headers: meta.headers,\n                            status: meta.status\n                        }\n                    };\n                } else {\n                    const filePath = this.getFilePath(kind === IncrementalCacheKind.FETCH ? key : `${key}.html`, kind);\n                    const fileData = await this.fs.readFile(filePath, 'utf8');\n                    const { mtime } = await this.fs.stat(filePath);\n                    if (kind === IncrementalCacheKind.FETCH) {\n                        var _data_value4;\n                        const { tags, fetchIdx, fetchUrl } = ctx;\n                        if (!this.flushToDisk) return null;\n                        const lastModified = mtime.getTime();\n                        const parsedData = JSON.parse(fileData);\n                        data = {\n                            lastModified,\n                            value: parsedData\n                        };\n                        if (((_data_value4 = data.value) == null ? void 0 : _data_value4.kind) === CachedRouteKind.FETCH) {\n                            var _data_value5;\n                            const storedTags = (_data_value5 = data.value) == null ? void 0 : _data_value5.tags;\n                            // update stored tags if a new one is being added\n                            // TODO: remove this when we can send the tags\n                            // via header on GET same as SET\n                            if (!(tags == null ? void 0 : tags.every((tag)=>storedTags == null ? void 0 : storedTags.includes(tag)))) {\n                                if (FileSystemCache.debug) {\n                                    console.log('FileSystemCache: tags vs storedTags mismatch', tags, storedTags);\n                                }\n                                await this.set(key, data.value, {\n                                    fetchCache: true,\n                                    tags,\n                                    fetchIdx,\n                                    fetchUrl\n                                });\n                            }\n                        }\n                    } else if (kind === IncrementalCacheKind.APP_PAGE) {\n                        // We try to load the metadata file, but if it fails, we don't\n                        // error. We also don't load it if this is a fallback.\n                        let meta;\n                        try {\n                            meta = JSON.parse(await this.fs.readFile(filePath.replace(/\\.html$/, NEXT_META_SUFFIX), 'utf8'));\n                        } catch  {}\n                        let maybeSegmentData;\n                        if (meta == null ? void 0 : meta.segmentPaths) {\n                            // Collect all the segment data for this page.\n                            // TODO: To optimize file system reads, we should consider creating\n                            // separate cache entries for each segment, rather than storing them\n                            // all on the page's entry. Though the behavior is\n                            // identical regardless.\n                            const segmentData = new Map();\n                            maybeSegmentData = segmentData;\n                            const segmentsDir = key + RSC_SEGMENTS_DIR_SUFFIX;\n                            await Promise.all(meta.segmentPaths.map(async (segmentPath)=>{\n                                const segmentDataFilePath = this.getFilePath(segmentsDir + segmentPath + RSC_SEGMENT_SUFFIX, IncrementalCacheKind.APP_PAGE);\n                                try {\n                                    segmentData.set(segmentPath, await this.fs.readFile(segmentDataFilePath));\n                                } catch  {\n                                // This shouldn't happen, but if for some reason we fail to\n                                // load a segment from the filesystem, treat it the same as if\n                                // the segment is dynamic and does not have a prefetch.\n                                }\n                            }));\n                        }\n                        let rscData;\n                        if (!ctx.isFallback && !ctx.isRoutePPREnabled) {\n                            rscData = await this.fs.readFile(this.getFilePath(`${key}${RSC_SUFFIX}`, IncrementalCacheKind.APP_PAGE));\n                        }\n                        data = {\n                            lastModified: mtime.getTime(),\n                            value: {\n                                kind: CachedRouteKind.APP_PAGE,\n                                html: fileData,\n                                rscData,\n                                postponed: meta == null ? void 0 : meta.postponed,\n                                headers: meta == null ? void 0 : meta.headers,\n                                status: meta == null ? void 0 : meta.status,\n                                segmentData: maybeSegmentData\n                            }\n                        };\n                    } else if (kind === IncrementalCacheKind.PAGES) {\n                        let meta;\n                        let pageData = {};\n                        if (!ctx.isFallback) {\n                            pageData = JSON.parse(await this.fs.readFile(this.getFilePath(`${key}${NEXT_DATA_SUFFIX}`, IncrementalCacheKind.PAGES), 'utf8'));\n                        }\n                        data = {\n                            lastModified: mtime.getTime(),\n                            value: {\n                                kind: CachedRouteKind.PAGES,\n                                html: fileData,\n                                pageData,\n                                headers: meta == null ? void 0 : meta.headers,\n                                status: meta == null ? void 0 : meta.status\n                            }\n                        };\n                    } else {\n                        throw Object.defineProperty(new Error(`Invariant: Unexpected route kind ${kind} in file system cache.`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E445\",\n                            enumerable: false,\n                            configurable: true\n                        });\n                    }\n                }\n                if (data) {\n                    var _FileSystemCache_memoryCache1;\n                    (_FileSystemCache_memoryCache1 = FileSystemCache.memoryCache) == null ? void 0 : _FileSystemCache_memoryCache1.set(key, data);\n                }\n            } catch  {\n                return null;\n            }\n        }\n        if ((data == null ? void 0 : (_data_value = data.value) == null ? void 0 : _data_value.kind) === CachedRouteKind.APP_PAGE || (data == null ? void 0 : (_data_value1 = data.value) == null ? void 0 : _data_value1.kind) === CachedRouteKind.APP_ROUTE || (data == null ? void 0 : (_data_value2 = data.value) == null ? void 0 : _data_value2.kind) === CachedRouteKind.PAGES) {\n            var _data_value_headers;\n            const tagsHeader = (_data_value_headers = data.value.headers) == null ? void 0 : _data_value_headers[NEXT_CACHE_TAGS_HEADER];\n            if (typeof tagsHeader === 'string') {\n                const cacheTags = tagsHeader.split(',');\n                // we trigger a blocking validation if an ISR page\n                // had a tag revalidated, if we want to be a background\n                // revalidation instead we return data.lastModified = -1\n                if (cacheTags.length > 0 && areTagsExpired(cacheTags, data.lastModified)) {\n                    if (FileSystemCache.debug) {\n                        console.log('FileSystemCache: expired tags', cacheTags);\n                    }\n                    return null;\n                }\n            }\n        } else if ((data == null ? void 0 : (_data_value3 = data.value) == null ? void 0 : _data_value3.kind) === CachedRouteKind.FETCH) {\n            const combinedTags = ctx.kind === IncrementalCacheKind.FETCH ? [\n                ...ctx.tags || [],\n                ...ctx.softTags || []\n            ] : [];\n            // When revalidate tag is called we don't return stale data so it's\n            // updated right away.\n            if (combinedTags.some((tag)=>this.revalidatedTags.includes(tag))) {\n                if (FileSystemCache.debug) {\n                    console.log('FileSystemCache: was revalidated', combinedTags);\n                }\n                return null;\n            }\n            if (areTagsExpired(combinedTags, data.lastModified)) {\n                if (FileSystemCache.debug) {\n                    console.log('FileSystemCache: expired tags', combinedTags);\n                }\n                return null;\n            }\n        }\n        return data ?? null;\n    }\n    async set(key, data, ctx) {\n        var _FileSystemCache_memoryCache;\n        (_FileSystemCache_memoryCache = FileSystemCache.memoryCache) == null ? void 0 : _FileSystemCache_memoryCache.set(key, {\n            value: data,\n            lastModified: Date.now()\n        });\n        if (FileSystemCache.debug) {\n            console.log('FileSystemCache: set', key);\n        }\n        if (!this.flushToDisk || !data) return;\n        // Create a new writer that will prepare to write all the files to disk\n        // after their containing directory is created.\n        const writer = new MultiFileWriter(this.fs);\n        if (data.kind === CachedRouteKind.APP_ROUTE) {\n            const filePath = this.getFilePath(`${key}.body`, IncrementalCacheKind.APP_ROUTE);\n            writer.append(filePath, data.body);\n            const meta = {\n                headers: data.headers,\n                status: data.status,\n                postponed: undefined,\n                segmentPaths: undefined\n            };\n            writer.append(filePath.replace(/\\.body$/, NEXT_META_SUFFIX), JSON.stringify(meta, null, 2));\n        } else if (data.kind === CachedRouteKind.PAGES || data.kind === CachedRouteKind.APP_PAGE) {\n            const isAppPath = data.kind === CachedRouteKind.APP_PAGE;\n            const htmlPath = this.getFilePath(`${key}.html`, isAppPath ? IncrementalCacheKind.APP_PAGE : IncrementalCacheKind.PAGES);\n            writer.append(htmlPath, data.html);\n            // Fallbacks don't generate a data file.\n            if (!ctx.fetchCache && !ctx.isFallback && !ctx.isRoutePPREnabled) {\n                writer.append(this.getFilePath(`${key}${isAppPath ? RSC_SUFFIX : NEXT_DATA_SUFFIX}`, isAppPath ? IncrementalCacheKind.APP_PAGE : IncrementalCacheKind.PAGES), isAppPath ? data.rscData : JSON.stringify(data.pageData));\n            }\n            if ((data == null ? void 0 : data.kind) === CachedRouteKind.APP_PAGE) {\n                let segmentPaths;\n                if (data.segmentData) {\n                    segmentPaths = [];\n                    const segmentsDir = htmlPath.replace(/\\.html$/, RSC_SEGMENTS_DIR_SUFFIX);\n                    for (const [segmentPath, buffer] of data.segmentData){\n                        segmentPaths.push(segmentPath);\n                        const segmentDataFilePath = segmentsDir + segmentPath + RSC_SEGMENT_SUFFIX;\n                        writer.append(segmentDataFilePath, buffer);\n                    }\n                }\n                const meta = {\n                    headers: data.headers,\n                    status: data.status,\n                    postponed: data.postponed,\n                    segmentPaths\n                };\n                writer.append(htmlPath.replace(/\\.html$/, NEXT_META_SUFFIX), JSON.stringify(meta));\n            }\n        } else if (data.kind === CachedRouteKind.FETCH) {\n            const filePath = this.getFilePath(key, IncrementalCacheKind.FETCH);\n            writer.append(filePath, JSON.stringify({\n                ...data,\n                tags: ctx.fetchCache ? ctx.tags : []\n            }));\n        }\n        // Wait for all FS operations to complete.\n        await writer.wait();\n    }\n    getFilePath(pathname, kind) {\n        switch(kind){\n            case IncrementalCacheKind.FETCH:\n                // we store in .next/cache/fetch-cache so it can be persisted\n                // across deploys\n                return path.join(this.serverDistDir, '..', 'cache', 'fetch-cache', pathname);\n            case IncrementalCacheKind.PAGES:\n                return path.join(this.serverDistDir, 'pages', pathname);\n            case IncrementalCacheKind.IMAGE:\n            case IncrementalCacheKind.APP_PAGE:\n            case IncrementalCacheKind.APP_ROUTE:\n                return path.join(this.serverDistDir, 'app', pathname);\n            default:\n                throw Object.defineProperty(new Error(`Unexpected file path kind: ${kind}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E479\",\n                    enumerable: false,\n                    configurable: true\n                });\n        }\n    }\n}\n\n//# sourceMappingURL=file-system-cache.js.map","import { extractInterceptionRouteInformation, isInterceptionRouteAppPath } from './interception-routes';\n// Identify /.*[param].*/ in route string\nconst TEST_ROUTE = /\\/[^/]*\\[[^/]+\\][^/]*(?=\\/|$)/;\n// Identify /[param]/ in route string\nconst TEST_STRICT_ROUTE = /\\/\\[[^/]+\\](?=\\/|$)/;\n/**\n * Check if a route is dynamic.\n *\n * @param route - The route to check.\n * @param strict - Whether to use strict mode which prohibits segments with prefixes/suffixes (default: true).\n * @returns Whether the route is dynamic.\n */ export function isDynamicRoute(route, strict = true) {\n    if (isInterceptionRouteAppPath(route)) {\n        route = extractInterceptionRouteInformation(route).interceptedRoute;\n    }\n    if (strict) {\n        return TEST_STRICT_ROUTE.test(route);\n    }\n    return TEST_ROUTE.test(route);\n}\n\n//# sourceMappingURL=is-dynamic.js.map","import { createDefaultCacheHandler } from '../lib/cache-handlers/default';\nconst debug = process.env.NEXT_PRIVATE_DEBUG_CACHE ? (message, ...args)=>{\n    console.log(`use-cache: ${message}`, ...args);\n} : undefined;\nconst handlersSymbol = Symbol.for('@next/cache-handlers');\nconst handlersMapSymbol = Symbol.for('@next/cache-handlers-map');\nconst handlersSetSymbol = Symbol.for('@next/cache-handlers-set');\n/**\n * The reference to the cache handlers. We store the cache handlers on the\n * global object so that we can access the same instance across different\n * boundaries (such as different copies of the same module).\n */ const reference = globalThis;\n/**\n * Initialize the cache handlers.\n * @param cacheMaxMemorySize - The maximum memory size of the cache in bytes, if\n *  not provided, the default memory size will be used.\n * @returns `true` if the cache handlers were initialized, `false` if they were already initialized.\n */ export function initializeCacheHandlers(cacheMaxMemorySize) {\n    // If the cache handlers have already been initialized, don't do it again.\n    if (reference[handlersMapSymbol]) {\n        debug == null ? void 0 : debug('cache handlers already initialized');\n        return false;\n    }\n    debug == null ? void 0 : debug('initializing cache handlers');\n    reference[handlersMapSymbol] = new Map();\n    // Initialize the cache from the symbol contents first.\n    if (reference[handlersSymbol]) {\n        let fallback;\n        if (reference[handlersSymbol].DefaultCache) {\n            debug == null ? void 0 : debug('setting \"default\" cache handler from symbol');\n            fallback = reference[handlersSymbol].DefaultCache;\n        } else {\n            debug == null ? void 0 : debug('setting \"default\" cache handler from default');\n            fallback = createDefaultCacheHandler(cacheMaxMemorySize);\n        }\n        reference[handlersMapSymbol].set('default', fallback);\n        if (reference[handlersSymbol].RemoteCache) {\n            debug == null ? void 0 : debug('setting \"remote\" cache handler from symbol');\n            reference[handlersMapSymbol].set('remote', reference[handlersSymbol].RemoteCache);\n        } else {\n            debug == null ? void 0 : debug('setting \"remote\" cache handler from default');\n            reference[handlersMapSymbol].set('remote', fallback);\n        }\n    } else {\n        const handler = createDefaultCacheHandler(cacheMaxMemorySize);\n        debug == null ? void 0 : debug('setting \"default\" cache handler from default');\n        reference[handlersMapSymbol].set('default', handler);\n        debug == null ? void 0 : debug('setting \"remote\" cache handler from default');\n        reference[handlersMapSymbol].set('remote', handler);\n    }\n    // Create a set of the cache handlers.\n    reference[handlersSetSymbol] = new Set(reference[handlersMapSymbol].values());\n    return true;\n}\n/**\n * Get a cache handler by kind.\n * @param kind - The kind of cache handler to get.\n * @returns The cache handler, or `undefined` if it does not exist.\n * @throws If the cache handlers are not initialized.\n */ export function getCacheHandler(kind) {\n    // This should never be called before initializeCacheHandlers.\n    if (!reference[handlersMapSymbol]) {\n        throw Object.defineProperty(new Error('Cache handlers not initialized'), \"__NEXT_ERROR_CODE\", {\n            value: \"E649\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    return reference[handlersMapSymbol].get(kind);\n}\n/**\n * Get a set iterator over the cache handlers.\n * @returns An iterator over the cache handlers, or `undefined` if they are not\n * initialized.\n */ export function getCacheHandlers() {\n    if (!reference[handlersSetSymbol]) {\n        return undefined;\n    }\n    return reference[handlersSetSymbol].values();\n}\n/**\n * Get a map iterator over the cache handlers (keyed by kind).\n * @returns An iterator over the cache handler entries, or `undefined` if they\n * are not initialized.\n * @throws If the cache handlers are not initialized.\n */ export function getCacheHandlerEntries() {\n    if (!reference[handlersMapSymbol]) {\n        return undefined;\n    }\n    return reference[handlersMapSymbol].entries();\n}\n/**\n * Set a cache handler by kind.\n * @param kind - The kind of cache handler to set.\n * @param cacheHandler - The cache handler to set.\n */ export function setCacheHandler(kind, cacheHandler) {\n    // This should never be called before initializeCacheHandlers.\n    if (!reference[handlersMapSymbol] || !reference[handlersSetSymbol]) {\n        throw Object.defineProperty(new Error('Cache handlers not initialized'), \"__NEXT_ERROR_CODE\", {\n            value: \"E649\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    debug == null ? void 0 : debug('setting cache handler for \"%s\"', kind);\n    reference[handlersMapSymbol].set(kind, cacheHandler);\n    reference[handlersSetSymbol].add(cacheHandler);\n}\n\n//# sourceMappingURL=handlers.js.map","import { createAsyncLocalStorage } from './async-local-storage';\nexport const afterTaskAsyncStorageInstance = createAsyncLocalStorage();\n\n//# sourceMappingURL=after-task-async-storage-instance.js.map","import { createAsyncLocalStorage } from './async-local-storage';\nexport const workUnitAsyncStorageInstance = createAsyncLocalStorage();\n\n//# sourceMappingURL=work-unit-async-storage-instance.js.map","import { hexHash } from '../../hash';\nexport function computeCacheBustingSearchParam(prefetchHeader, segmentPrefetchHeader, stateTreeHeader, nextUrlHeader) {\n    if ((prefetchHeader === undefined || prefetchHeader === '0') && segmentPrefetchHeader === undefined && stateTreeHeader === undefined && nextUrlHeader === undefined) {\n        return '';\n    }\n    return hexHash([\n        prefetchHeader || '0',\n        segmentPrefetchHeader || '0',\n        stateTreeHeader || '0',\n        nextUrlHeader || '0'\n    ].join(','));\n}\n\n//# sourceMappingURL=cache-busting-search-param.js.map","// FIXME: (wyattjoh) this is a temporary solution to allow us to pass data between bundled modules\nexport const NEXT_REQUEST_META = Symbol.for('NextInternalRequestMeta');\nexport function getRequestMeta(req, key) {\n    const meta = req[NEXT_REQUEST_META] || {};\n    return typeof key === 'string' ? meta[key] : meta;\n}\n/**\n * Sets the request metadata.\n *\n * @param req the request to set the metadata on\n * @param meta the metadata to set\n * @returns the mutated request metadata\n */ export function setRequestMeta(req, meta) {\n    req[NEXT_REQUEST_META] = meta;\n    return meta;\n}\n/**\n * Adds a value to the request metadata.\n *\n * @param request the request to mutate\n * @param key the key to set\n * @param value the value to set\n * @returns the mutated request metadata\n */ export function addRequestMeta(request, key, value) {\n    const meta = getRequestMeta(request);\n    meta[key] = value;\n    return setRequestMeta(request, meta);\n}\n/**\n * Removes a key from the request metadata.\n *\n * @param request the request to mutate\n * @param key the key to remove\n * @returns the mutated request metadata\n */ export function removeRequestMeta(request, key) {\n    const meta = getRequestMeta(request);\n    delete meta[key];\n    return setRequestMeta(request, meta);\n}\n\n//# sourceMappingURL=request-meta.js.map","import { DEFAULT_SEGMENT_KEY } from '../../segment';\nexport function parseLoaderTree(tree) {\n    const [segment, parallelRoutes, modules] = tree;\n    const { layout, template } = modules;\n    let { page } = modules;\n    // a __DEFAULT__ segment means that this route didn't match any of the\n    // segments in the route, so we should use the default page\n    page = segment === DEFAULT_SEGMENT_KEY ? modules.defaultPage : page;\n    const conventionPath = layout?.[1] || template?.[1] || page?.[1];\n    return {\n        page,\n        segment,\n        modules,\n        /* it can be either layout / template / page */ conventionPath,\n        parallelRoutes\n    };\n}\n\n//# sourceMappingURL=parse-loader-tree.js.map","import { COOKIE_NAME_PRERENDER_BYPASS, checkIsOnDemandRevalidate } from '../api-utils';\nexport class DraftModeProvider {\n    constructor(previewProps, req, cookies, mutableCookies){\n        var _cookies_get;\n        // The logic for draftMode() is very similar to tryGetPreviewData()\n        // but Draft Mode does not have any data associated with it.\n        const isOnDemandRevalidate = previewProps && checkIsOnDemandRevalidate(req, previewProps).isOnDemandRevalidate;\n        const cookieValue = (_cookies_get = cookies.get(COOKIE_NAME_PRERENDER_BYPASS)) == null ? void 0 : _cookies_get.value;\n        this._isEnabled = Boolean(!isOnDemandRevalidate && cookieValue && previewProps && (cookieValue === previewProps.previewModeId || // In dev mode, the cookie can be actual hash value preview id but the preview props can still be `development-id`.\n        process.env.NODE_ENV !== 'production' && previewProps.previewModeId === 'development-id'));\n        this._previewModeId = previewProps == null ? void 0 : previewProps.previewModeId;\n        this._mutableCookies = mutableCookies;\n    }\n    get isEnabled() {\n        return this._isEnabled;\n    }\n    enable() {\n        if (!this._previewModeId) {\n            throw Object.defineProperty(new Error('Invariant: previewProps missing previewModeId this should never happen'), \"__NEXT_ERROR_CODE\", {\n                value: \"E93\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        this._mutableCookies.set({\n            name: COOKIE_NAME_PRERENDER_BYPASS,\n            value: this._previewModeId,\n            httpOnly: true,\n            sameSite: process.env.NODE_ENV !== 'development' ? 'none' : 'lax',\n            secure: process.env.NODE_ENV !== 'development',\n            path: '/'\n        });\n        this._isEnabled = true;\n    }\n    disable() {\n        // To delete a cookie, set `expires` to a date in the past:\n        // https://tools.ietf.org/html/rfc6265#section-4.1.1\n        // `Max-Age: 0` is not valid, thus ignored, and the cookie is persisted.\n        this._mutableCookies.set({\n            name: COOKIE_NAME_PRERENDER_BYPASS,\n            value: '',\n            httpOnly: true,\n            sameSite: process.env.NODE_ENV !== 'development' ? 'none' : 'lax',\n            secure: process.env.NODE_ENV !== 'development',\n            path: '/',\n            expires: new Date(0)\n        });\n        this._isEnabled = false;\n    }\n}\n\n//# sourceMappingURL=draft-mode-provider.js.map","import { getCacheHandlers } from './use-cache/handlers';\n/** Run a callback, and execute any *new* revalidations added during its runtime. */ export async function withExecuteRevalidates(store, callback) {\n    if (!store) {\n        return callback();\n    }\n    // If we executed any revalidates during the request, then we don't want to execute them again.\n    // save the state so we can check if anything changed after we're done running callbacks.\n    const savedRevalidationState = cloneRevalidationState(store);\n    try {\n        return await callback();\n    } finally{\n        // Check if we have any new revalidates, and if so, wait until they are all resolved.\n        const newRevalidates = diffRevalidationState(savedRevalidationState, cloneRevalidationState(store));\n        await executeRevalidates(store, newRevalidates);\n    }\n}\nfunction cloneRevalidationState(store) {\n    return {\n        pendingRevalidatedTags: store.pendingRevalidatedTags ? [\n            ...store.pendingRevalidatedTags\n        ] : [],\n        pendingRevalidates: {\n            ...store.pendingRevalidates\n        },\n        pendingRevalidateWrites: store.pendingRevalidateWrites ? [\n            ...store.pendingRevalidateWrites\n        ] : []\n    };\n}\nfunction diffRevalidationState(prev, curr) {\n    const prevTagsWithProfile = new Set(prev.pendingRevalidatedTags.map((item)=>{\n        const profileKey = typeof item.profile === 'object' ? JSON.stringify(item.profile) : item.profile || '';\n        return `${item.tag}:${profileKey}`;\n    }));\n    const prevRevalidateWrites = new Set(prev.pendingRevalidateWrites);\n    return {\n        pendingRevalidatedTags: curr.pendingRevalidatedTags.filter((item)=>{\n            const profileKey = typeof item.profile === 'object' ? JSON.stringify(item.profile) : item.profile || '';\n            return !prevTagsWithProfile.has(`${item.tag}:${profileKey}`);\n        }),\n        pendingRevalidates: Object.fromEntries(Object.entries(curr.pendingRevalidates).filter(([key])=>!(key in prev.pendingRevalidates))),\n        pendingRevalidateWrites: curr.pendingRevalidateWrites.filter((promise)=>!prevRevalidateWrites.has(promise))\n    };\n}\nasync function revalidateTags(tagsWithProfile, incrementalCache, workStore) {\n    if (tagsWithProfile.length === 0) {\n        return;\n    }\n    const handlers = getCacheHandlers();\n    const promises = [];\n    // Group tags by profile for batch processing\n    const tagsByProfile = new Map();\n    for (const item of tagsWithProfile){\n        const profile = item.profile;\n        // Find existing profile by comparing values\n        let existingKey = undefined;\n        for (const [key] of tagsByProfile){\n            if (typeof key === 'string' && typeof profile === 'string' && key === profile) {\n                existingKey = key;\n                break;\n            }\n            if (typeof key === 'object' && typeof profile === 'object' && JSON.stringify(key) === JSON.stringify(profile)) {\n                existingKey = key;\n                break;\n            }\n            if (key === profile) {\n                existingKey = key;\n                break;\n            }\n        }\n        const profileKey = existingKey || profile;\n        if (!tagsByProfile.has(profileKey)) {\n            tagsByProfile.set(profileKey, []);\n        }\n        tagsByProfile.get(profileKey).push(item.tag);\n    }\n    // Process each profile group\n    for (const [profile, tagsForProfile] of tagsByProfile){\n        // Look up the cache profile from workStore if available\n        let durations;\n        if (profile) {\n            let cacheLife;\n            if (typeof profile === 'object') {\n                // Profile is already a cacheLife configuration object\n                cacheLife = profile;\n            } else if (typeof profile === 'string') {\n                var _workStore_cacheLifeProfiles;\n                // Profile is a string key, look it up in workStore\n                cacheLife = workStore == null ? void 0 : (_workStore_cacheLifeProfiles = workStore.cacheLifeProfiles) == null ? void 0 : _workStore_cacheLifeProfiles[profile];\n                if (!cacheLife) {\n                    throw Object.defineProperty(new Error(`Invalid profile provided \"${profile}\" must be configured under cacheLife in next.config or be \"max\"`), \"__NEXT_ERROR_CODE\", {\n                        value: \"E873\",\n                        enumerable: false,\n                        configurable: true\n                    });\n                }\n            }\n            if (cacheLife) {\n                durations = {\n                    expire: cacheLife.expire\n                };\n            }\n        }\n        // If profile is not found and not 'max', durations will be undefined\n        // which will trigger immediate expiration in the cache handler\n        for (const handler of handlers || []){\n            if (profile) {\n                promises.push(handler.updateTags == null ? void 0 : handler.updateTags.call(handler, tagsForProfile, durations));\n            } else {\n                promises.push(handler.updateTags == null ? void 0 : handler.updateTags.call(handler, tagsForProfile));\n            }\n        }\n        if (incrementalCache) {\n            promises.push(incrementalCache.revalidateTag(tagsForProfile, durations));\n        }\n    }\n    await Promise.all(promises);\n}\nexport async function executeRevalidates(workStore, state) {\n    const pendingRevalidatedTags = (state == null ? void 0 : state.pendingRevalidatedTags) ?? workStore.pendingRevalidatedTags ?? [];\n    const pendingRevalidates = (state == null ? void 0 : state.pendingRevalidates) ?? workStore.pendingRevalidates ?? {};\n    const pendingRevalidateWrites = (state == null ? void 0 : state.pendingRevalidateWrites) ?? workStore.pendingRevalidateWrites ?? [];\n    return Promise.all([\n        revalidateTags(pendingRevalidatedTags, workStore.incrementalCache, workStore),\n        ...Object.values(pendingRevalidates),\n        ...pendingRevalidateWrites\n    ]);\n}\n\n//# sourceMappingURL=revalidation-utils.js.map","import { CachedRouteKind } from '../../response-cache/types';\nimport { LRUCache } from '../lru-cache';\nlet memoryCache;\nexport function getMemoryCache(maxMemoryCacheSize) {\n    if (!memoryCache) {\n        memoryCache = new LRUCache(maxMemoryCacheSize, function length({ value }) {\n            var _JSON_stringify;\n            if (!value) {\n                return 25;\n            } else if (value.kind === CachedRouteKind.REDIRECT) {\n                return JSON.stringify(value.props).length;\n            } else if (value.kind === CachedRouteKind.IMAGE) {\n                throw Object.defineProperty(new Error('invariant image should not be incremental-cache'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E501\",\n                    enumerable: false,\n                    configurable: true\n                });\n            } else if (value.kind === CachedRouteKind.FETCH) {\n                return JSON.stringify(value.data || '').length;\n            } else if (value.kind === CachedRouteKind.APP_ROUTE) {\n                return value.body.length;\n            }\n            // rough estimate of size of cache value\n            return value.html.length + (((_JSON_stringify = JSON.stringify(value.kind === CachedRouteKind.APP_PAGE ? value.rscData : value.pageData)) == null ? void 0 : _JSON_stringify.length) || 0);\n        });\n    }\n    return memoryCache;\n}\n\n//# sourceMappingURL=memory-cache.external.js.map","import { InvariantError } from '../../invariant-error';\nimport { interceptionPrefixFromParamType } from './interception-prefix-from-param-type';\n/**\n * Extracts the param value from a path segment, handling interception markers\n * based on the expected param type.\n *\n * @param pathSegment - The path segment to extract the value from\n * @param params - The current params object for resolving dynamic param references\n * @param paramType - The expected param type which may include interception marker info\n * @returns The extracted param value\n */ function getParamValueFromSegment(pathSegment, params, paramType) {\n    // If the segment is dynamic, resolve it from the params object\n    if (pathSegment.type === 'dynamic') {\n        return params[pathSegment.param.paramName];\n    }\n    // If the paramType indicates this is an intercepted param, strip the marker\n    // that matches the interception marker in the param type\n    const interceptionPrefix = interceptionPrefixFromParamType(paramType);\n    if (interceptionPrefix === pathSegment.interceptionMarker) {\n        return pathSegment.name.replace(pathSegment.interceptionMarker, '');\n    }\n    // For static segments, use the name\n    return pathSegment.name;\n}\n/**\n * Resolves a route parameter value from the route segments at the given depth.\n * This shared logic is used by both extractPathnameRouteParamSegmentsFromLoaderTree\n * and resolveRouteParamsFromTree.\n *\n * @param paramName - The parameter name to resolve\n * @param paramType - The parameter type (dynamic, catchall, etc.)\n * @param depth - The current depth in the route tree\n * @param route - The normalized route containing segments\n * @param params - The current params object (used to resolve embedded param references)\n * @param options - Configuration options\n * @returns The resolved parameter value, or undefined if it cannot be resolved\n */ export function resolveParamValue(paramName, paramType, depth, route, params) {\n    switch(paramType){\n        case 'catchall':\n        case 'optional-catchall':\n        case 'catchall-intercepted-(..)(..)':\n        case 'catchall-intercepted-(.)':\n        case 'catchall-intercepted-(..)':\n        case 'catchall-intercepted-(...)':\n            // For catchall routes, derive from pathname using depth to determine\n            // which segments to use\n            const processedSegments = [];\n            // Process segments to handle any embedded dynamic params\n            for(let index = depth; index < route.segments.length; index++){\n                const pathSegment = route.segments[index];\n                if (pathSegment.type === 'static') {\n                    let value = pathSegment.name;\n                    // For intercepted catch-all params, strip the marker from the first segment\n                    const interceptionPrefix = interceptionPrefixFromParamType(paramType);\n                    if (interceptionPrefix && index === depth && interceptionPrefix === pathSegment.interceptionMarker) {\n                        // Strip the interception marker from the value\n                        value = value.replace(pathSegment.interceptionMarker, '');\n                    }\n                    processedSegments.push(value);\n                } else {\n                    // If the segment is a param placeholder, check if we have its value\n                    if (!params.hasOwnProperty(pathSegment.param.paramName)) {\n                        // If the segment is an optional catchall, we can break out of the\n                        // loop because it's optional!\n                        if (pathSegment.param.paramType === 'optional-catchall') {\n                            break;\n                        }\n                        // Unknown param placeholder in pathname - can't derive full value\n                        return undefined;\n                    }\n                    // If the segment matches a param, use the param value\n                    // We don't encode values here as that's handled during retrieval.\n                    const paramValue = params[pathSegment.param.paramName];\n                    if (Array.isArray(paramValue)) {\n                        processedSegments.push(...paramValue);\n                    } else {\n                        processedSegments.push(paramValue);\n                    }\n                }\n            }\n            if (processedSegments.length > 0) {\n                return processedSegments;\n            } else if (paramType === 'optional-catchall') {\n                return undefined;\n            } else {\n                // We shouldn't be able to match a catchall segment without any path\n                // segments if it's not an optional catchall\n                throw Object.defineProperty(new InvariantError(`Unexpected empty path segments match for a route \"${route.pathname}\" with param \"${paramName}\" of type \"${paramType}\"`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E931\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n        case 'dynamic':\n        case 'dynamic-intercepted-(..)(..)':\n        case 'dynamic-intercepted-(.)':\n        case 'dynamic-intercepted-(..)':\n        case 'dynamic-intercepted-(...)':\n            // For regular dynamic parameters, take the segment at this depth\n            if (depth < route.segments.length) {\n                const pathSegment = route.segments[depth];\n                // Check if the segment at this depth is a placeholder for an unknown param\n                if (pathSegment.type === 'dynamic' && !params.hasOwnProperty(pathSegment.param.paramName)) {\n                    // The segment is a placeholder like [category] and we don't have the value\n                    return undefined;\n                }\n                // If the segment matches a param, use the param value from params object\n                // Otherwise it's a static segment, just use it directly\n                // We don't encode values here as that's handled during retrieval\n                return getParamValueFromSegment(pathSegment, params, paramType);\n            }\n            return undefined;\n        default:\n            paramType;\n    }\n}\n\n//# sourceMappingURL=resolve-param-value.js.map","import { LogSpanAllowList, NextVanillaSpanAllowlist } from './constants';\nimport { isThenable } from '../../../shared/lib/is-thenable';\nconst NEXT_OTEL_PERFORMANCE_PREFIX = process.env.NEXT_OTEL_PERFORMANCE_PREFIX;\nlet api;\n// we want to allow users to use their own version of @opentelemetry/api if they\n// want to, so we try to require it first, and if it fails we fall back to the\n// version that is bundled with Next.js\n// this is because @opentelemetry/api has to be synced with the version of\n// @opentelemetry/tracing that is used, and we don't want to force users to use\n// the version that is bundled with Next.js.\n// the API is ~stable, so this should be fine\nif (process.env.NEXT_RUNTIME === 'edge') {\n    api = require('@opentelemetry/api');\n} else {\n    try {\n        api = require('@opentelemetry/api');\n    } catch (err) {\n        api = require('next/dist/compiled/@opentelemetry/api');\n    }\n}\nconst { context, propagation, trace, SpanStatusCode, SpanKind, ROOT_CONTEXT } = api;\nexport class BubbledError extends Error {\n    constructor(bubble, result){\n        super(), this.bubble = bubble, this.result = result;\n    }\n}\nexport function isBubbledError(error) {\n    if (typeof error !== 'object' || error === null) return false;\n    return error instanceof BubbledError;\n}\nconst closeSpanWithError = (span, error)=>{\n    if (isBubbledError(error) && error.bubble) {\n        span.setAttribute('next.bubble', true);\n    } else {\n        if (error) {\n            span.recordException(error);\n            span.setAttribute('error.type', error.name);\n        }\n        span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: error == null ? void 0 : error.message\n        });\n    }\n    span.end();\n};\n/** we use this map to propagate attributes from nested spans to the top span */ const rootSpanAttributesStore = new Map();\nconst rootSpanIdKey = api.createContextKey('next.rootSpanId');\nlet lastSpanId = 0;\nconst getSpanId = ()=>lastSpanId++;\nconst clientTraceDataSetter = {\n    set (carrier, key, value) {\n        carrier.push({\n            key,\n            value\n        });\n    }\n};\nclass NextTracerImpl {\n    /**\n   * Returns an instance to the trace with configured name.\n   * Since wrap / trace can be defined in any place prior to actual trace subscriber initialization,\n   * This should be lazily evaluated.\n   */ getTracerInstance() {\n        return trace.getTracer('next.js', '0.0.1');\n    }\n    getContext() {\n        return context;\n    }\n    getTracePropagationData() {\n        const activeContext = context.active();\n        const entries = [];\n        propagation.inject(activeContext, entries, clientTraceDataSetter);\n        return entries;\n    }\n    getActiveScopeSpan() {\n        return trace.getSpan(context == null ? void 0 : context.active());\n    }\n    withPropagatedContext(carrier, fn, getter) {\n        const activeContext = context.active();\n        if (trace.getSpanContext(activeContext)) {\n            // Active span is already set, too late to propagate.\n            return fn();\n        }\n        const remoteContext = propagation.extract(activeContext, carrier, getter);\n        return context.with(remoteContext, fn);\n    }\n    trace(...args) {\n        const [type, fnOrOptions, fnOrEmpty] = args;\n        // coerce options form overload\n        const { fn, options } = typeof fnOrOptions === 'function' ? {\n            fn: fnOrOptions,\n            options: {}\n        } : {\n            fn: fnOrEmpty,\n            options: {\n                ...fnOrOptions\n            }\n        };\n        const spanName = options.spanName ?? type;\n        if (!NextVanillaSpanAllowlist.has(type) && process.env.NEXT_OTEL_VERBOSE !== '1' || options.hideSpan) {\n            return fn();\n        }\n        // Trying to get active scoped span to assign parent. If option specifies parent span manually, will try to use it.\n        let spanContext = this.getSpanContext((options == null ? void 0 : options.parentSpan) ?? this.getActiveScopeSpan());\n        if (!spanContext) {\n            spanContext = (context == null ? void 0 : context.active()) ?? ROOT_CONTEXT;\n        }\n        // Check if there's already a root span in the store for this trace\n        // We are intentionally not checking whether there is an active context\n        // from outside of nextjs to ensure that we can provide the same level\n        // of telemetry when using a custom server\n        const existingRootSpanId = spanContext.getValue(rootSpanIdKey);\n        const isRootSpan = typeof existingRootSpanId !== 'number' || !rootSpanAttributesStore.has(existingRootSpanId);\n        const spanId = getSpanId();\n        options.attributes = {\n            'next.span_name': spanName,\n            'next.span_type': type,\n            ...options.attributes\n        };\n        return context.with(spanContext.setValue(rootSpanIdKey, spanId), ()=>this.getTracerInstance().startActiveSpan(spanName, options, (span)=>{\n                let startTime;\n                if (NEXT_OTEL_PERFORMANCE_PREFIX && type && LogSpanAllowList.has(type)) {\n                    startTime = 'performance' in globalThis && 'measure' in performance ? globalThis.performance.now() : undefined;\n                }\n                let cleanedUp = false;\n                const onCleanup = ()=>{\n                    if (cleanedUp) return;\n                    cleanedUp = true;\n                    rootSpanAttributesStore.delete(spanId);\n                    if (startTime) {\n                        performance.measure(`${NEXT_OTEL_PERFORMANCE_PREFIX}:next-${(type.split('.').pop() || '').replace(/[A-Z]/g, (match)=>'-' + match.toLowerCase())}`, {\n                            start: startTime,\n                            end: performance.now()\n                        });\n                    }\n                };\n                if (isRootSpan) {\n                    rootSpanAttributesStore.set(spanId, new Map(Object.entries(options.attributes ?? {})));\n                }\n                if (fn.length > 1) {\n                    try {\n                        return fn(span, (err)=>closeSpanWithError(span, err));\n                    } catch (err) {\n                        closeSpanWithError(span, err);\n                        throw err;\n                    } finally{\n                        onCleanup();\n                    }\n                }\n                try {\n                    const result = fn(span);\n                    if (isThenable(result)) {\n                        // If there's error make sure it throws\n                        return result.then((res)=>{\n                            span.end();\n                            // Need to pass down the promise result,\n                            // it could be react stream response with error { error, stream }\n                            return res;\n                        }).catch((err)=>{\n                            closeSpanWithError(span, err);\n                            throw err;\n                        }).finally(onCleanup);\n                    } else {\n                        span.end();\n                        onCleanup();\n                    }\n                    return result;\n                } catch (err) {\n                    closeSpanWithError(span, err);\n                    onCleanup();\n                    throw err;\n                }\n            }));\n    }\n    wrap(...args) {\n        const tracer = this;\n        const [name, options, fn] = args.length === 3 ? args : [\n            args[0],\n            {},\n            args[1]\n        ];\n        if (!NextVanillaSpanAllowlist.has(name) && process.env.NEXT_OTEL_VERBOSE !== '1') {\n            return fn;\n        }\n        return function() {\n            let optionsObj = options;\n            if (typeof optionsObj === 'function' && typeof fn === 'function') {\n                optionsObj = optionsObj.apply(this, arguments);\n            }\n            const lastArgId = arguments.length - 1;\n            const cb = arguments[lastArgId];\n            if (typeof cb === 'function') {\n                const scopeBoundCb = tracer.getContext().bind(context.active(), cb);\n                return tracer.trace(name, optionsObj, (_span, done)=>{\n                    arguments[lastArgId] = function(err) {\n                        done == null ? void 0 : done(err);\n                        return scopeBoundCb.apply(this, arguments);\n                    };\n                    return fn.apply(this, arguments);\n                });\n            } else {\n                return tracer.trace(name, optionsObj, ()=>fn.apply(this, arguments));\n            }\n        };\n    }\n    startSpan(...args) {\n        const [type, options] = args;\n        const spanContext = this.getSpanContext((options == null ? void 0 : options.parentSpan) ?? this.getActiveScopeSpan());\n        return this.getTracerInstance().startSpan(type, options, spanContext);\n    }\n    getSpanContext(parentSpan) {\n        const spanContext = parentSpan ? trace.setSpan(context.active(), parentSpan) : undefined;\n        return spanContext;\n    }\n    getRootSpanAttributes() {\n        const spanId = context.active().getValue(rootSpanIdKey);\n        return rootSpanAttributesStore.get(spanId);\n    }\n    setRootSpanAttribute(key, value) {\n        const spanId = context.active().getValue(rootSpanIdKey);\n        const attributes = rootSpanAttributesStore.get(spanId);\n        if (attributes && !attributes.has(key)) {\n            attributes.set(key, value);\n        }\n    }\n    withSpan(span, fn) {\n        const spanContext = trace.setSpan(context.active(), span);\n        return context.with(spanContext, fn);\n    }\n}\nconst getTracer = (()=>{\n    const tracer = new NextTracerImpl();\n    return ()=>tracer;\n})();\nexport { getTracer, SpanStatusCode, SpanKind };\n\n//# sourceMappingURL=tracer.js.map","import { normalizeAppPath } from './app-paths';\n// order matters here, the first match will be used\nexport const INTERCEPTION_ROUTE_MARKERS = [\n    '(..)(..)',\n    '(.)',\n    '(..)',\n    '(...)'\n];\nexport function isInterceptionRouteAppPath(path) {\n    // TODO-APP: add more serious validation\n    return path.split('/').find((segment)=>INTERCEPTION_ROUTE_MARKERS.find((m)=>segment.startsWith(m))) !== undefined;\n}\nexport function extractInterceptionRouteInformation(path) {\n    let interceptingRoute;\n    let marker;\n    let interceptedRoute;\n    for (const segment of path.split('/')){\n        marker = INTERCEPTION_ROUTE_MARKERS.find((m)=>segment.startsWith(m));\n        if (marker) {\n            ;\n            [interceptingRoute, interceptedRoute] = path.split(marker, 2);\n            break;\n        }\n    }\n    if (!interceptingRoute || !marker || !interceptedRoute) {\n        throw Object.defineProperty(new Error(`Invalid interception route: ${path}. Must be in the format /<intercepting route>/(..|...|..)(..)/<intercepted route>`), \"__NEXT_ERROR_CODE\", {\n            value: \"E269\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    interceptingRoute = normalizeAppPath(interceptingRoute) // normalize the path, e.g. /(blog)/feed -> /feed\n    ;\n    switch(marker){\n        case '(.)':\n            // (.) indicates that we should match with sibling routes, so we just need to append the intercepted route to the intercepting route\n            if (interceptingRoute === '/') {\n                interceptedRoute = `/${interceptedRoute}`;\n            } else {\n                interceptedRoute = interceptingRoute + '/' + interceptedRoute;\n            }\n            break;\n        case '(..)':\n            // (..) indicates that we should match at one level up, so we need to remove the last segment of the intercepting route\n            if (interceptingRoute === '/') {\n                throw Object.defineProperty(new Error(`Invalid interception route: ${path}. Cannot use (..) marker at the root level, use (.) instead.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E207\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            interceptedRoute = interceptingRoute.split('/').slice(0, -1).concat(interceptedRoute).join('/');\n            break;\n        case '(...)':\n            // (...) will match the route segment in the root directory, so we need to use the root directory to prepend the intercepted route\n            interceptedRoute = '/' + interceptedRoute;\n            break;\n        case '(..)(..)':\n            // (..)(..) indicates that we should match at two levels up, so we need to remove the last two segments of the intercepting route\n            const splitInterceptingRoute = interceptingRoute.split('/');\n            if (splitInterceptingRoute.length <= 2) {\n                throw Object.defineProperty(new Error(`Invalid interception route: ${path}. Cannot use (..)(..) marker at the root level or one level up.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E486\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            interceptedRoute = splitInterceptingRoute.slice(0, -2).concat(interceptedRoute).join('/');\n            break;\n        default:\n            throw Object.defineProperty(new Error('Invariant: unexpected marker'), \"__NEXT_ERROR_CODE\", {\n                value: \"E112\",\n                enumerable: false,\n                configurable: true\n            });\n    }\n    return {\n        interceptingRoute,\n        interceptedRoute\n    };\n}\n\n//# sourceMappingURL=interception-routes.js.map","import { getLocationOrigin } from '../../utils';\nimport { searchParamsToUrlQuery } from './querystring';\nexport function parseRelativeUrl(url, base, parseQuery = true) {\n    const globalBase = new URL(typeof window === 'undefined' ? 'http://n' : getLocationOrigin());\n    const resolvedBase = base ? new URL(base, globalBase) : url.startsWith('.') ? new URL(typeof window === 'undefined' ? 'http://n' : window.location.href) : globalBase;\n    const { pathname, searchParams, search, hash, href, origin } = new URL(url, resolvedBase);\n    if (origin !== globalBase.origin) {\n        throw Object.defineProperty(new Error(`invariant: invalid relative URL, router received ${url}`), \"__NEXT_ERROR_CODE\", {\n            value: \"E159\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    return {\n        pathname,\n        query: parseQuery ? searchParamsToUrlQuery(searchParams) : undefined,\n        search,\n        hash,\n        href: href.slice(origin.length),\n        // We don't know for relative URLs at this point since we set a custom, internal\n        // base that isn't surfaced to users.\n        slashes: undefined\n    };\n}\n\n//# sourceMappingURL=parse-relative-url.js.map","import { searchParamsToUrlQuery } from './querystring';\nimport { parseRelativeUrl } from './parse-relative-url';\nexport function parseUrl(url) {\n    if (url.startsWith('/')) {\n        return parseRelativeUrl(url);\n    }\n    const parsedURL = new URL(url);\n    return {\n        hash: parsedURL.hash,\n        hostname: parsedURL.hostname,\n        href: parsedURL.href,\n        pathname: parsedURL.pathname,\n        port: parsedURL.port,\n        protocol: parsedURL.protocol,\n        query: searchParamsToUrlQuery(parsedURL.searchParams),\n        search: parsedURL.search,\n        origin: parsedURL.origin,\n        slashes: parsedURL.href.slice(parsedURL.protocol.length, parsedURL.protocol.length + 2) === '//'\n    };\n}\n\n//# sourceMappingURL=parse-url.js.map","import { DecodeError } from '../../utils';\nimport { safeRouteMatcher } from './route-match-utils';\nexport function getRouteMatcher({ re, groups }) {\n    const rawMatcher = (pathname)=>{\n        const routeMatch = re.exec(pathname);\n        if (!routeMatch) return false;\n        const decode = (param)=>{\n            try {\n                return decodeURIComponent(param);\n            } catch  {\n                throw Object.defineProperty(new DecodeError('failed to decode param'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E528\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n        };\n        const params = {};\n        for (const [key, group] of Object.entries(groups)){\n            const match = routeMatch[group.pos];\n            if (match !== undefined) {\n                if (group.repeat) {\n                    params[key] = match.split('/').map((entry)=>decode(entry));\n                } else {\n                    params[key] = decode(match);\n                }\n            }\n        }\n        return params;\n    };\n    // Wrap with safe matcher to handle parameter cleaning\n    return safeRouteMatcher(rawMatcher);\n}\n\n//# sourceMappingURL=route-matcher.js.map","import { bold, green, magenta, red, yellow, white } from '../../lib/picocolors';\nimport { LRUCache } from '../../server/lib/lru-cache';\nexport const prefixes = {\n    wait: white(bold('')),\n    error: red(bold('')),\n    warn: yellow(bold('')),\n    ready: '',\n    info: white(bold(' ')),\n    event: green(bold('')),\n    trace: magenta(bold(''))\n};\nconst LOGGING_METHOD = {\n    log: 'log',\n    warn: 'warn',\n    error: 'error'\n};\nfunction prefixedLog(prefixType, ...message) {\n    if ((message[0] === '' || message[0] === undefined) && message.length === 1) {\n        message.shift();\n    }\n    const consoleMethod = prefixType in LOGGING_METHOD ? LOGGING_METHOD[prefixType] : 'log';\n    const prefix = prefixes[prefixType];\n    // If there's no message, don't print the prefix but a new line\n    if (message.length === 0) {\n        console[consoleMethod]('');\n    } else {\n        // Ensure if there's ANSI escape codes it's concatenated into one string.\n        // Chrome DevTool can only handle color if it's in one string.\n        if (message.length === 1 && typeof message[0] === 'string') {\n            console[consoleMethod](prefix + ' ' + message[0]);\n        } else {\n            console[consoleMethod](prefix, ...message);\n        }\n    }\n}\nexport function bootstrap(message) {\n    console.log(message);\n}\nexport function wait(...message) {\n    prefixedLog('wait', ...message);\n}\nexport function error(...message) {\n    prefixedLog('error', ...message);\n}\nexport function warn(...message) {\n    prefixedLog('warn', ...message);\n}\nexport function ready(...message) {\n    prefixedLog('ready', ...message);\n}\nexport function info(...message) {\n    prefixedLog('info', ...message);\n}\nexport function event(...message) {\n    prefixedLog('event', ...message);\n}\nexport function trace(...message) {\n    prefixedLog('trace', ...message);\n}\nconst warnOnceCache = new LRUCache(10000, (value)=>value.length);\nexport function warnOnce(...message) {\n    const key = message.join(' ');\n    if (!warnOnceCache.has(key)) {\n        warnOnceCache.set(key, key);\n        warn(...message);\n    }\n}\nconst errorOnceCache = new LRUCache(10000, (value)=>value.length);\nexport function errorOnce(...message) {\n    const key = message.join(' ');\n    if (!errorOnceCache.has(key)) {\n        errorOnceCache.set(key, key);\n        error(...message);\n    }\n}\n\n//# sourceMappingURL=log.js.map","// We share the tags manifest between the \"use cache\" handlers and the previous\n// file-system cache.\nexport const tagsManifest = new Map();\nexport const areTagsExpired = (tags, timestamp)=>{\n    for (const tag of tags){\n        const entry = tagsManifest.get(tag);\n        const expiredAt = entry == null ? void 0 : entry.expired;\n        if (typeof expiredAt === 'number') {\n            const now = Date.now();\n            // For immediate expiration (expiredAt <= now) and tag was invalidated after entry was created\n            // OR for future expiration that has now passed (expiredAt > timestamp && expiredAt <= now)\n            const isImmediatelyExpired = expiredAt <= now && expiredAt > timestamp;\n            if (isImmediatelyExpired) {\n                return true;\n            }\n        }\n    }\n    return false;\n};\nexport const areTagsStale = (tags, timestamp)=>{\n    for (const tag of tags){\n        const entry = tagsManifest.get(tag);\n        const staleAt = (entry == null ? void 0 : entry.stale) ?? 0;\n        if (typeof staleAt === 'number' && staleAt > timestamp) {\n            return true;\n        }\n    }\n    return false;\n};\n\n//# sourceMappingURL=tags-manifest.external.js.map","import { InvariantError } from '../../shared/lib/invariant-error';\nimport { createPromiseWithResolvers } from '../../shared/lib/promise-with-resolvers';\nexport var RenderStage = /*#__PURE__*/ function(RenderStage) {\n    RenderStage[RenderStage[\"Before\"] = 1] = \"Before\";\n    RenderStage[RenderStage[\"Static\"] = 2] = \"Static\";\n    RenderStage[RenderStage[\"Runtime\"] = 3] = \"Runtime\";\n    RenderStage[RenderStage[\"Dynamic\"] = 4] = \"Dynamic\";\n    RenderStage[RenderStage[\"Abandoned\"] = 5] = \"Abandoned\";\n    return RenderStage;\n}({});\nexport class StagedRenderingController {\n    constructor(abortSignal = null, hasRuntimePrefetch){\n        this.abortSignal = abortSignal;\n        this.hasRuntimePrefetch = hasRuntimePrefetch;\n        this.currentStage = 1;\n        this.staticInterruptReason = null;\n        this.runtimeInterruptReason = null;\n        this.staticStageEndTime = Infinity;\n        this.runtimeStageEndTime = Infinity;\n        this.runtimeStageListeners = [];\n        this.dynamicStageListeners = [];\n        this.runtimeStagePromise = createPromiseWithResolvers();\n        this.dynamicStagePromise = createPromiseWithResolvers();\n        this.mayAbandon = false;\n        if (abortSignal) {\n            abortSignal.addEventListener('abort', ()=>{\n                const { reason } = abortSignal;\n                if (this.currentStage < 3) {\n                    this.runtimeStagePromise.promise.catch(ignoreReject) // avoid unhandled rejections\n                    ;\n                    this.runtimeStagePromise.reject(reason);\n                }\n                if (this.currentStage < 4 || this.currentStage === 5) {\n                    this.dynamicStagePromise.promise.catch(ignoreReject) // avoid unhandled rejections\n                    ;\n                    this.dynamicStagePromise.reject(reason);\n                }\n            }, {\n                once: true\n            });\n            this.mayAbandon = true;\n        }\n    }\n    onStage(stage, callback) {\n        if (this.currentStage >= stage) {\n            callback();\n        } else if (stage === 3) {\n            this.runtimeStageListeners.push(callback);\n        } else if (stage === 4) {\n            this.dynamicStageListeners.push(callback);\n        } else {\n            // This should never happen\n            throw Object.defineProperty(new InvariantError(`Invalid render stage: ${stage}`), \"__NEXT_ERROR_CODE\", {\n                value: \"E881\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n    canSyncInterrupt() {\n        // If we haven't started the render yet, it can't be interrupted.\n        if (this.currentStage === 1) {\n            return false;\n        }\n        const boundaryStage = this.hasRuntimePrefetch ? 4 : 3;\n        return this.currentStage < boundaryStage;\n    }\n    syncInterruptCurrentStageWithReason(reason) {\n        if (this.currentStage === 1) {\n            return;\n        }\n        // If Sync IO occurs during the initial (abandonable) render, we'll retry it,\n        // so we want a slightly different flow.\n        // See the implementation of `abandonRenderImpl` for more explanation.\n        if (this.mayAbandon) {\n            return this.abandonRenderImpl();\n        }\n        // If we're in the final render, we cannot abandon it. We need to advance to the Dynamic stage\n        // and capture the interruption reason.\n        switch(this.currentStage){\n            case 2:\n                {\n                    this.staticInterruptReason = reason;\n                    this.advanceStage(4);\n                    return;\n                }\n            case 3:\n                {\n                    // We only error for Sync IO in the runtime stage if the route\n                    // is configured to use runtime prefetching.\n                    // We do this to reflect the fact that during a runtime prefetch,\n                    // Sync IO aborts aborts the render.\n                    // Note that `canSyncInterrupt` should prevent us from getting here at all\n                    // if runtime prefetching isn't enabled.\n                    if (this.hasRuntimePrefetch) {\n                        this.runtimeInterruptReason = reason;\n                        this.advanceStage(4);\n                    }\n                    return;\n                }\n            case 4:\n            case 5:\n            default:\n        }\n    }\n    getStaticInterruptReason() {\n        return this.staticInterruptReason;\n    }\n    getRuntimeInterruptReason() {\n        return this.runtimeInterruptReason;\n    }\n    getStaticStageEndTime() {\n        return this.staticStageEndTime;\n    }\n    getRuntimeStageEndTime() {\n        return this.runtimeStageEndTime;\n    }\n    abandonRender() {\n        if (!this.mayAbandon) {\n            throw Object.defineProperty(new InvariantError('`abandonRender` called on a stage controller that cannot be abandoned.'), \"__NEXT_ERROR_CODE\", {\n                value: \"E938\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        this.abandonRenderImpl();\n    }\n    abandonRenderImpl() {\n        // In staged rendering, only the initial render is abandonable.\n        // We can abandon the initial render if\n        //   1. We notice a cache miss, and need to wait for caches to fill\n        //   2. A sync IO error occurs, and the render should be interrupted\n        //      (this might be a lazy intitialization of a module,\n        //       so we still want to restart in this case and see if it still occurs)\n        // In either case, we'll be doing another render after this one,\n        // so we only want to unblock the Runtime stage, not Dynamic, because\n        // unblocking the dynamic stage would likely lead to wasted (uncached) IO.\n        const { currentStage } = this;\n        switch(currentStage){\n            case 2:\n                {\n                    this.currentStage = 5;\n                    this.resolveRuntimeStage();\n                    return;\n                }\n            case 3:\n                {\n                    this.currentStage = 5;\n                    return;\n                }\n            case 4:\n            case 1:\n            case 5:\n                break;\n            default:\n                {\n                    currentStage;\n                }\n        }\n    }\n    advanceStage(stage) {\n        // If we're already at the target stage or beyond, do nothing.\n        // (this can happen e.g. if sync IO advanced us to the dynamic stage)\n        if (stage <= this.currentStage) {\n            return;\n        }\n        let currentStage = this.currentStage;\n        this.currentStage = stage;\n        if (currentStage < 3 && stage >= 3) {\n            this.staticStageEndTime = performance.now() + performance.timeOrigin;\n            this.resolveRuntimeStage();\n        }\n        if (currentStage < 4 && stage >= 4) {\n            this.runtimeStageEndTime = performance.now() + performance.timeOrigin;\n            this.resolveDynamicStage();\n            return;\n        }\n    }\n    /** Fire the `onStage` listeners for the runtime stage and unblock any promises waiting for it. */ resolveRuntimeStage() {\n        const runtimeListeners = this.runtimeStageListeners;\n        for(let i = 0; i < runtimeListeners.length; i++){\n            runtimeListeners[i]();\n        }\n        runtimeListeners.length = 0;\n        this.runtimeStagePromise.resolve();\n    }\n    /** Fire the `onStage` listeners for the dynamic stage and unblock any promises waiting for it. */ resolveDynamicStage() {\n        const dynamicListeners = this.dynamicStageListeners;\n        for(let i = 0; i < dynamicListeners.length; i++){\n            dynamicListeners[i]();\n        }\n        dynamicListeners.length = 0;\n        this.dynamicStagePromise.resolve();\n    }\n    getStagePromise(stage) {\n        switch(stage){\n            case 3:\n                {\n                    return this.runtimeStagePromise.promise;\n                }\n            case 4:\n                {\n                    return this.dynamicStagePromise.promise;\n                }\n            default:\n                {\n                    stage;\n                    throw Object.defineProperty(new InvariantError(`Invalid render stage: ${stage}`), \"__NEXT_ERROR_CODE\", {\n                        value: \"E881\",\n                        enumerable: false,\n                        configurable: true\n                    });\n                }\n        }\n    }\n    waitForStage(stage) {\n        return this.getStagePromise(stage);\n    }\n    delayUntilStage(stage, displayName, resolvedValue) {\n        const ioTriggerPromise = this.getStagePromise(stage);\n        const promise = makeDevtoolsIOPromiseFromIOTrigger(ioTriggerPromise, displayName, resolvedValue);\n        // Analogously to `makeHangingPromise`, we might reject this promise if the signal is invoked.\n        // (e.g. in the case where we don't want want the render to proceed to the dynamic stage and abort it).\n        // We shouldn't consider this an unhandled rejection, so we attach a noop catch handler here to suppress this warning.\n        if (this.abortSignal) {\n            promise.catch(ignoreReject);\n        }\n        return promise;\n    }\n}\nfunction ignoreReject() {}\n// TODO(restart-on-cache-miss): the layering of `delayUntilStage`,\n// `makeDevtoolsIOPromiseFromIOTrigger` and and `makeDevtoolsIOAwarePromise`\n// is confusing, we should clean it up.\nfunction makeDevtoolsIOPromiseFromIOTrigger(ioTrigger, displayName, resolvedValue) {\n    // If we create a `new Promise` and give it a displayName\n    // (with no userspace code above us in the stack)\n    // React Devtools will use it as the IO cause when determining \"suspended by\".\n    // In particular, it should shadow any inner IO that resolved/rejected the promise\n    // (in case of staged rendering, this will be the `setTimeout` that triggers the relevant stage)\n    const promise = new Promise((resolve, reject)=>{\n        ioTrigger.then(resolve.bind(null, resolvedValue), reject);\n    });\n    if (displayName !== undefined) {\n        // @ts-expect-error\n        promise.displayName = displayName;\n    }\n    return promise;\n}\n\n//# sourceMappingURL=staged-rendering.js.map","/**\n * Find the starting index of Uint8Array `b` within Uint8Array `a`.\n */ export function indexOfUint8Array(a, b) {\n    if (b.length === 0) return 0;\n    if (a.length === 0 || b.length > a.length) return -1;\n    // start iterating through `a`\n    for(let i = 0; i <= a.length - b.length; i++){\n        let completeMatch = true;\n        // from index `i`, iterate through `b` and check for mismatch\n        for(let j = 0; j < b.length; j++){\n            // if the values do not match, then this isn't a complete match, exit `b` iteration early and iterate to next index of `a`.\n            if (a[i + j] !== b[j]) {\n                completeMatch = false;\n                break;\n            }\n        }\n        if (completeMatch) {\n            return i;\n        }\n    }\n    return -1;\n}\n/**\n * Check if two Uint8Arrays are strictly equivalent.\n */ export function isEquivalentUint8Arrays(a, b) {\n    if (a.length !== b.length) return false;\n    for(let i = 0; i < a.length; i++){\n        if (a[i] !== b[i]) return false;\n    }\n    return true;\n}\n/**\n * Remove Uint8Array `b` from Uint8Array `a`.\n *\n * If `b` is not in `a`, `a` is returned unchanged.\n *\n * Otherwise, the function returns a new Uint8Array instance with size `a.length - b.length`\n */ export function removeFromUint8Array(a, b) {\n    const tagIndex = indexOfUint8Array(a, b);\n    if (tagIndex === 0) return a.subarray(b.length);\n    if (tagIndex > -1) {\n        const removed = new Uint8Array(a.length - b.length);\n        removed.set(a.slice(0, tagIndex));\n        removed.set(a.slice(tagIndex + b.length), tagIndex);\n        return removed;\n    } else {\n        return a;\n    }\n}\n\n//# sourceMappingURL=uint8array-helpers.js.map","import { NEXT_CACHE_IMPLICIT_TAG_ID } from '../../lib/constants';\nimport { getCacheHandlerEntries } from '../use-cache/handlers';\nimport { createLazyResult } from './lazy-result';\nconst getDerivedTags = (pathname)=>{\n    const derivedTags = [\n        `/layout`\n    ];\n    // we automatically add the current path segments as tags\n    // for revalidatePath handling\n    if (pathname.startsWith('/')) {\n        const pathnameParts = pathname.split('/');\n        for(let i = 1; i < pathnameParts.length + 1; i++){\n            let curPathname = pathnameParts.slice(0, i).join('/');\n            if (curPathname) {\n                // all derived tags other than the page are layout tags\n                if (!curPathname.endsWith('/page') && !curPathname.endsWith('/route')) {\n                    curPathname = `${curPathname}${!curPathname.endsWith('/') ? '/' : ''}layout`;\n                }\n                derivedTags.push(curPathname);\n            }\n        }\n    }\n    return derivedTags;\n};\n/**\n * Creates a map with lazy results that fetch the expiration value for the given\n * tags and respective cache kind when they're awaited for the first time.\n */ function createTagsExpirationsByCacheKind(tags) {\n    const expirationsByCacheKind = new Map();\n    const cacheHandlers = getCacheHandlerEntries();\n    if (cacheHandlers) {\n        for (const [kind, cacheHandler] of cacheHandlers){\n            if ('getExpiration' in cacheHandler) {\n                expirationsByCacheKind.set(kind, createLazyResult(async ()=>cacheHandler.getExpiration(tags)));\n            }\n        }\n    }\n    return expirationsByCacheKind;\n}\nexport async function getImplicitTags(page, url, fallbackRouteParams) {\n    const tags = new Set();\n    // Add the derived tags from the page.\n    const derivedTags = getDerivedTags(page);\n    for (let tag of derivedTags){\n        tag = `${NEXT_CACHE_IMPLICIT_TAG_ID}${tag}`;\n        tags.add(tag);\n    }\n    // Add the tags from the pathname. If the route has unknown params, we don't\n    // want to add the pathname as a tag, as it will be invalid.\n    if (url.pathname && (!fallbackRouteParams || fallbackRouteParams.size === 0)) {\n        const tag = `${NEXT_CACHE_IMPLICIT_TAG_ID}${url.pathname}`;\n        tags.add(tag);\n    }\n    if (tags.has(`${NEXT_CACHE_IMPLICIT_TAG_ID}/`)) {\n        tags.add(`${NEXT_CACHE_IMPLICIT_TAG_ID}/index`);\n    }\n    if (tags.has(`${NEXT_CACHE_IMPLICIT_TAG_ID}/index`)) {\n        tags.add(`${NEXT_CACHE_IMPLICIT_TAG_ID}/`);\n    }\n    const tagsArray = Array.from(tags);\n    return {\n        tags: tagsArray,\n        expirationsByCacheKind: createTagsExpirationsByCacheKind(tagsArray)\n    };\n}\n\n//# sourceMappingURL=implicit-tags.js.map","import { normalizeLocalePath } from '../../i18n/normalize-locale-path';\nimport { removePathPrefix } from './remove-path-prefix';\nimport { pathHasPrefix } from './path-has-prefix';\nexport function getNextPathnameInfo(pathname, options) {\n    const { basePath, i18n, trailingSlash } = options.nextConfig ?? {};\n    const info = {\n        pathname,\n        trailingSlash: pathname !== '/' ? pathname.endsWith('/') : trailingSlash\n    };\n    if (basePath && pathHasPrefix(info.pathname, basePath)) {\n        info.pathname = removePathPrefix(info.pathname, basePath);\n        info.basePath = basePath;\n    }\n    let pathnameNoDataPrefix = info.pathname;\n    if (info.pathname.startsWith('/_next/data/') && info.pathname.endsWith('.json')) {\n        const paths = info.pathname.replace(/^\\/_next\\/data\\//, '').replace(/\\.json$/, '').split('/');\n        const buildId = paths[0];\n        info.buildId = buildId;\n        pathnameNoDataPrefix = paths[1] !== 'index' ? `/${paths.slice(1).join('/')}` : '/';\n        // update pathname with normalized if enabled although\n        // we use normalized to populate locale info still\n        if (options.parseData === true) {\n            info.pathname = pathnameNoDataPrefix;\n        }\n    }\n    // If provided, use the locale route normalizer to detect the locale instead\n    // of the function below.\n    if (i18n) {\n        let result = options.i18nProvider ? options.i18nProvider.analyze(info.pathname) : normalizeLocalePath(info.pathname, i18n.locales);\n        info.locale = result.detectedLocale;\n        info.pathname = result.pathname ?? info.pathname;\n        if (!result.detectedLocale && info.buildId) {\n            result = options.i18nProvider ? options.i18nProvider.analyze(pathnameNoDataPrefix) : normalizeLocalePath(pathnameNoDataPrefix, i18n.locales);\n            if (result.detectedLocale) {\n                info.locale = result.detectedLocale;\n            }\n        }\n    }\n    return info;\n}\n\n//# sourceMappingURL=get-next-pathname-info.js.map","import { InvariantError } from '../../invariant-error';\nimport { getSegmentParam } from '../utils/get-segment-param';\nimport { INTERCEPTION_ROUTE_MARKERS } from '../utils/interception-routes';\nexport function parseAppRouteSegment(segment) {\n    if (segment === '') {\n        return null;\n    }\n    // Check if the segment starts with an interception marker\n    const interceptionMarker = INTERCEPTION_ROUTE_MARKERS.find((m)=>segment.startsWith(m));\n    const param = getSegmentParam(segment);\n    if (param) {\n        return {\n            type: 'dynamic',\n            name: segment,\n            param,\n            interceptionMarker\n        };\n    } else if (segment.startsWith('(') && segment.endsWith(')')) {\n        return {\n            type: 'route-group',\n            name: segment,\n            interceptionMarker\n        };\n    } else if (segment.startsWith('@')) {\n        return {\n            type: 'parallel-route',\n            name: segment,\n            interceptionMarker\n        };\n    } else {\n        return {\n            type: 'static',\n            name: segment,\n            interceptionMarker\n        };\n    }\n}\nexport function isNormalizedAppRoute(route) {\n    return route.normalized;\n}\nexport function isInterceptionAppRoute(route) {\n    return route.interceptionMarker !== undefined && route.interceptingRoute !== undefined && route.interceptedRoute !== undefined;\n}\nexport function parseAppRoute(pathname, normalized) {\n    const pathnameSegments = pathname.split('/').filter(Boolean);\n    // Build segments array with static and dynamic segments\n    const segments = [];\n    // Parse if this is an interception route.\n    let interceptionMarker;\n    let interceptingRoute;\n    let interceptedRoute;\n    for (const segment of pathnameSegments){\n        // Parse the segment into an AppSegment.\n        const appSegment = parseAppRouteSegment(segment);\n        if (!appSegment) {\n            continue;\n        }\n        if (normalized && (appSegment.type === 'route-group' || appSegment.type === 'parallel-route')) {\n            throw Object.defineProperty(new InvariantError(`${pathname} is being parsed as a normalized route, but it has a route group or parallel route segment.`), \"__NEXT_ERROR_CODE\", {\n                value: \"E923\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        segments.push(appSegment);\n        if (appSegment.interceptionMarker) {\n            const parts = pathname.split(appSegment.interceptionMarker);\n            if (parts.length !== 2) {\n                throw Object.defineProperty(new Error(`Invalid interception route: ${pathname}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E924\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            interceptingRoute = normalized ? parseAppRoute(parts[0], true) : parseAppRoute(parts[0], false);\n            interceptedRoute = normalized ? parseAppRoute(parts[1], true) : parseAppRoute(parts[1], false);\n            interceptionMarker = appSegment.interceptionMarker;\n        }\n    }\n    const dynamicSegments = segments.filter((segment)=>segment.type === 'dynamic');\n    return {\n        normalized,\n        pathname,\n        segments,\n        dynamicSegments,\n        interceptionMarker,\n        interceptingRoute,\n        interceptedRoute\n    };\n}\n\n//# sourceMappingURL=app.js.map","/**\n * For a given page path, this function ensures that there is a leading slash.\n * If there is not a leading slash, one is added, otherwise it is noop.\n */ export function ensureLeadingSlash(path) {\n    return path.startsWith('/') ? path : `/${path}`;\n}\n\n//# sourceMappingURL=ensure-leading-slash.js.map","/**\n * Parse cookies from the `headers` of request\n * @param req request object\n */ export function getCookieParser(headers) {\n    return function parseCookie() {\n        const { cookie } = headers;\n        if (!cookie) {\n            return {};\n        }\n        const { parse: parseCookieFn } = require('next/dist/compiled/cookie');\n        return parseCookieFn(Array.isArray(cookie) ? cookie.join('; ') : cookie);\n    };\n}\n\n//# sourceMappingURL=get-cookie-parser.js.map","/**\n * Web vitals provided to _app.reportWebVitals by Core Web Vitals plugin developed by Google Chrome team.\n * https://nextjs.org/blog/next-9-4#integrated-web-vitals-reporting\n */ export const WEB_VITALS = [\n    'CLS',\n    'FCP',\n    'FID',\n    'INP',\n    'LCP',\n    'TTFB'\n];\n/**\n * Utils\n */ export function execOnce(fn) {\n    let used = false;\n    let result;\n    return (...args)=>{\n        if (!used) {\n            used = true;\n            result = fn(...args);\n        }\n        return result;\n    };\n}\n// Scheme: https://tools.ietf.org/html/rfc3986#section-3.1\n// Absolute URL: https://tools.ietf.org/html/rfc3986#section-4.3\nconst ABSOLUTE_URL_REGEX = /^[a-zA-Z][a-zA-Z\\d+\\-.]*?:/;\nexport const isAbsoluteUrl = (url)=>ABSOLUTE_URL_REGEX.test(url);\nexport function getLocationOrigin() {\n    const { protocol, hostname, port } = window.location;\n    return `${protocol}//${hostname}${port ? ':' + port : ''}`;\n}\nexport function getURL() {\n    const { href } = window.location;\n    const origin = getLocationOrigin();\n    return href.substring(origin.length);\n}\nexport function getDisplayName(Component) {\n    return typeof Component === 'string' ? Component : Component.displayName || Component.name || 'Unknown';\n}\nexport function isResSent(res) {\n    return res.finished || res.headersSent;\n}\nexport function normalizeRepeatedSlashes(url) {\n    const urlParts = url.split('?');\n    const urlNoQuery = urlParts[0];\n    return urlNoQuery// first we replace any non-encoded backslashes with forward\n    // then normalize repeated forward slashes\n    .replace(/\\\\/g, '/').replace(/\\/\\/+/g, '/') + (urlParts[1] ? `?${urlParts.slice(1).join('?')}` : '');\n}\nexport async function loadGetInitialProps(App, ctx) {\n    if (process.env.NODE_ENV !== 'production') {\n        if (App.prototype?.getInitialProps) {\n            const message = `\"${getDisplayName(App)}.getInitialProps()\" is defined as an instance method - visit https://nextjs.org/docs/messages/get-initial-props-as-an-instance-method for more information.`;\n            throw Object.defineProperty(new Error(message), \"__NEXT_ERROR_CODE\", {\n                value: \"E394\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n    // when called from _app `ctx` is nested in `ctx`\n    const res = ctx.res || ctx.ctx && ctx.ctx.res;\n    if (!App.getInitialProps) {\n        if (ctx.ctx && ctx.Component) {\n            // @ts-ignore pageProps default\n            return {\n                pageProps: await loadGetInitialProps(ctx.Component, ctx.ctx)\n            };\n        }\n        return {};\n    }\n    const props = await App.getInitialProps(ctx);\n    if (res && isResSent(res)) {\n        return props;\n    }\n    if (!props) {\n        const message = `\"${getDisplayName(App)}.getInitialProps()\" should resolve to an object. But found \"${props}\" instead.`;\n        throw Object.defineProperty(new Error(message), \"__NEXT_ERROR_CODE\", {\n            value: \"E394\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    if (process.env.NODE_ENV !== 'production') {\n        if (Object.keys(props).length === 0 && !ctx.ctx) {\n            console.warn(`${getDisplayName(App)} returned an empty object from \\`getInitialProps\\`. This de-optimizes and prevents automatic static optimization. https://nextjs.org/docs/messages/empty-object-getInitialProps`);\n        }\n    }\n    return props;\n}\nexport const SP = typeof performance !== 'undefined';\nexport const ST = SP && [\n    'mark',\n    'measure',\n    'getEntriesByName'\n].every((method)=>typeof performance[method] === 'function');\nexport class DecodeError extends Error {\n}\nexport class NormalizeError extends Error {\n}\nexport class PageNotFoundError extends Error {\n    constructor(page){\n        super();\n        this.code = 'ENOENT';\n        this.name = 'PageNotFoundError';\n        this.message = `Cannot find module for page: ${page}`;\n    }\n}\nexport class MissingStaticPage extends Error {\n    constructor(page, message){\n        super();\n        this.message = `Failed to load static file for page: ${page} ${message}`;\n    }\n}\nexport class MiddlewareNotFoundError extends Error {\n    constructor(){\n        super();\n        this.code = 'ENOENT';\n        this.message = `Cannot find the middleware module`;\n    }\n}\nexport function stringifyError(error) {\n    return JSON.stringify({\n        message: error.message,\n        stack: error.stack\n    });\n}\n\n//# sourceMappingURL=utils.js.map","import { INTERCEPTION_ROUTE_MARKERS } from './interception-routes';\n/**\n * Parse dynamic route segment to type of parameter\n */ export function getSegmentParam(segment) {\n    const interceptionMarker = INTERCEPTION_ROUTE_MARKERS.find((marker)=>segment.startsWith(marker));\n    // if an interception marker is part of the path segment, we need to jump ahead\n    // to the relevant portion for param parsing\n    if (interceptionMarker) {\n        segment = segment.slice(interceptionMarker.length);\n    }\n    if (segment.startsWith('[[...') && segment.endsWith(']]')) {\n        return {\n            // TODO-APP: Optional catchall does not currently work with parallel routes,\n            // so for now aren't handling a potential interception marker.\n            paramType: 'optional-catchall',\n            paramName: segment.slice(5, -2)\n        };\n    }\n    if (segment.startsWith('[...') && segment.endsWith(']')) {\n        return {\n            paramType: interceptionMarker ? `catchall-intercepted-${interceptionMarker}` : 'catchall',\n            paramName: segment.slice(4, -1)\n        };\n    }\n    if (segment.startsWith('[') && segment.endsWith(']')) {\n        return {\n            paramType: interceptionMarker ? `dynamic-intercepted-${interceptionMarker}` : 'dynamic',\n            paramName: segment.slice(1, -1)\n        };\n    }\n    return null;\n}\nexport function isCatchAll(type) {\n    return type === 'catchall' || type === 'catchall-intercepted-(..)(..)' || type === 'catchall-intercepted-(.)' || type === 'catchall-intercepted-(..)' || type === 'catchall-intercepted-(...)' || type === 'optional-catchall';\n}\nexport function getParamProperties(paramType) {\n    let repeat = false;\n    let optional = false;\n    switch(paramType){\n        case 'catchall':\n        case 'catchall-intercepted-(..)(..)':\n        case 'catchall-intercepted-(.)':\n        case 'catchall-intercepted-(..)':\n        case 'catchall-intercepted-(...)':\n            repeat = true;\n            break;\n        case 'optional-catchall':\n            repeat = true;\n            optional = true;\n            break;\n        case 'dynamic':\n        case 'dynamic-intercepted-(..)(..)':\n        case 'dynamic-intercepted-(.)':\n        case 'dynamic-intercepted-(..)':\n        case 'dynamic-intercepted-(...)':\n            break;\n        default:\n            paramType;\n    }\n    return {\n        repeat,\n        optional\n    };\n}\n\n//# sourceMappingURL=get-segment-param.js.map","import { ReflectAdapter } from './reflect';\n/**\n * @internal\n */ export class ReadonlyHeadersError extends Error {\n    constructor(){\n        super('Headers cannot be modified. Read more: https://nextjs.org/docs/app/api-reference/functions/headers');\n    }\n    static callable() {\n        throw new ReadonlyHeadersError();\n    }\n}\nexport class HeadersAdapter extends Headers {\n    constructor(headers){\n        // We've already overridden the methods that would be called, so we're just\n        // calling the super constructor to ensure that the instanceof check works.\n        super();\n        this.headers = new Proxy(headers, {\n            get (target, prop, receiver) {\n                // Because this is just an object, we expect that all \"get\" operations\n                // are for properties. If it's a \"get\" for a symbol, we'll just return\n                // the symbol.\n                if (typeof prop === 'symbol') {\n                    return ReflectAdapter.get(target, prop, receiver);\n                }\n                const lowercased = prop.toLowerCase();\n                // Let's find the original casing of the key. This assumes that there is\n                // no mixed case keys (e.g. \"Content-Type\" and \"content-type\") in the\n                // headers object.\n                const original = Object.keys(headers).find((o)=>o.toLowerCase() === lowercased);\n                // If the original casing doesn't exist, return undefined.\n                if (typeof original === 'undefined') return;\n                // If the original casing exists, return the value.\n                return ReflectAdapter.get(target, original, receiver);\n            },\n            set (target, prop, value, receiver) {\n                if (typeof prop === 'symbol') {\n                    return ReflectAdapter.set(target, prop, value, receiver);\n                }\n                const lowercased = prop.toLowerCase();\n                // Let's find the original casing of the key. This assumes that there is\n                // no mixed case keys (e.g. \"Content-Type\" and \"content-type\") in the\n                // headers object.\n                const original = Object.keys(headers).find((o)=>o.toLowerCase() === lowercased);\n                // If the original casing doesn't exist, use the prop as the key.\n                return ReflectAdapter.set(target, original ?? prop, value, receiver);\n            },\n            has (target, prop) {\n                if (typeof prop === 'symbol') return ReflectAdapter.has(target, prop);\n                const lowercased = prop.toLowerCase();\n                // Let's find the original casing of the key. This assumes that there is\n                // no mixed case keys (e.g. \"Content-Type\" and \"content-type\") in the\n                // headers object.\n                const original = Object.keys(headers).find((o)=>o.toLowerCase() === lowercased);\n                // If the original casing doesn't exist, return false.\n                if (typeof original === 'undefined') return false;\n                // If the original casing exists, return true.\n                return ReflectAdapter.has(target, original);\n            },\n            deleteProperty (target, prop) {\n                if (typeof prop === 'symbol') return ReflectAdapter.deleteProperty(target, prop);\n                const lowercased = prop.toLowerCase();\n                // Let's find the original casing of the key. This assumes that there is\n                // no mixed case keys (e.g. \"Content-Type\" and \"content-type\") in the\n                // headers object.\n                const original = Object.keys(headers).find((o)=>o.toLowerCase() === lowercased);\n                // If the original casing doesn't exist, return true.\n                if (typeof original === 'undefined') return true;\n                // If the original casing exists, delete the property.\n                return ReflectAdapter.deleteProperty(target, original);\n            }\n        });\n    }\n    /**\n   * Seals a Headers instance to prevent modification by throwing an error when\n   * any mutating method is called.\n   */ static seal(headers) {\n        return new Proxy(headers, {\n            get (target, prop, receiver) {\n                switch(prop){\n                    case 'append':\n                    case 'delete':\n                    case 'set':\n                        return ReadonlyHeadersError.callable;\n                    default:\n                        return ReflectAdapter.get(target, prop, receiver);\n                }\n            }\n        });\n    }\n    /**\n   * Merges a header value into a string. This stores multiple values as an\n   * array, so we need to merge them into a string.\n   *\n   * @param value a header value\n   * @returns a merged header value (a string)\n   */ merge(value) {\n        if (Array.isArray(value)) return value.join(', ');\n        return value;\n    }\n    /**\n   * Creates a Headers instance from a plain object or a Headers instance.\n   *\n   * @param headers a plain object or a Headers instance\n   * @returns a headers instance\n   */ static from(headers) {\n        if (headers instanceof Headers) return headers;\n        return new HeadersAdapter(headers);\n    }\n    append(name, value) {\n        const existing = this.headers[name];\n        if (typeof existing === 'string') {\n            this.headers[name] = [\n                existing,\n                value\n            ];\n        } else if (Array.isArray(existing)) {\n            existing.push(value);\n        } else {\n            this.headers[name] = value;\n        }\n    }\n    delete(name) {\n        delete this.headers[name];\n    }\n    get(name) {\n        const value = this.headers[name];\n        if (typeof value !== 'undefined') return this.merge(value);\n        return null;\n    }\n    has(name) {\n        return typeof this.headers[name] !== 'undefined';\n    }\n    set(name, value) {\n        this.headers[name] = value;\n    }\n    forEach(callbackfn, thisArg) {\n        for (const [name, value] of this.entries()){\n            callbackfn.call(thisArg, value, name, this);\n        }\n    }\n    *entries() {\n        for (const key of Object.keys(this.headers)){\n            const name = key.toLowerCase();\n            // We assert here that this is a string because we got it from the\n            // Object.keys() call above.\n            const value = this.get(name);\n            yield [\n                name,\n                value\n            ];\n        }\n    }\n    *keys() {\n        for (const key of Object.keys(this.headers)){\n            const name = key.toLowerCase();\n            yield name;\n        }\n    }\n    *values() {\n        for (const key of Object.keys(this.headers)){\n            // We assert here that this is a string because we got it from the\n            // Object.keys() call above.\n            const value = this.get(key);\n            yield value;\n        }\n    }\n    [Symbol.iterator]() {\n        return this.entries();\n    }\n}\n\n//# sourceMappingURL=headers.js.map","import { chainStreams, streamFromBuffer, streamFromString, streamToString } from './stream-utils/node-web-streams-helper';\nimport { isAbortError, pipeToNodeResponse } from './pipe-readable';\nimport { InvariantError } from '../shared/lib/invariant-error';\nexport default class RenderResult {\n    static #_ = /**\n   * A render result that represents an empty response. This is used to\n   * represent a response that was not found or was already sent.\n   */ this.EMPTY = new RenderResult(null, {\n        metadata: {},\n        contentType: null\n    });\n    /**\n   * Creates a new RenderResult instance from a static response.\n   *\n   * @param value the static response value\n   * @param contentType the content type of the response\n   * @returns a new RenderResult instance\n   */ static fromStatic(value, contentType) {\n        return new RenderResult(value, {\n            metadata: {},\n            contentType\n        });\n    }\n    constructor(response, { contentType, waitUntil, metadata }){\n        this.response = response;\n        this.contentType = contentType;\n        this.metadata = metadata;\n        this.waitUntil = waitUntil;\n    }\n    assignMetadata(metadata) {\n        Object.assign(this.metadata, metadata);\n    }\n    /**\n   * Returns true if the response is null. It can be null if the response was\n   * not found or was already sent.\n   */ get isNull() {\n        return this.response === null;\n    }\n    /**\n   * Returns false if the response is a string. It can be a string if the page\n   * was prerendered. If it's not, then it was generated dynamically.\n   */ get isDynamic() {\n        return typeof this.response !== 'string';\n    }\n    toUnchunkedString(stream = false) {\n        if (this.response === null) {\n            // If the response is null, return an empty string. This behavior is\n            // intentional as we're now providing the `RenderResult.EMPTY` value.\n            return '';\n        }\n        if (typeof this.response !== 'string') {\n            if (!stream) {\n                throw Object.defineProperty(new InvariantError('dynamic responses cannot be unchunked. This is a bug in Next.js'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E732\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            return streamToString(this.readable);\n        }\n        return this.response;\n    }\n    /**\n   * Returns a readable stream of the response.\n   */ get readable() {\n        if (this.response === null) {\n            // If the response is null, return an empty stream. This behavior is\n            // intentional as we're now providing the `RenderResult.EMPTY` value.\n            return new ReadableStream({\n                start (controller) {\n                    controller.close();\n                }\n            });\n        }\n        if (typeof this.response === 'string') {\n            return streamFromString(this.response);\n        }\n        if (Buffer.isBuffer(this.response)) {\n            return streamFromBuffer(this.response);\n        }\n        // If the response is an array of streams, then chain them together.\n        if (Array.isArray(this.response)) {\n            return chainStreams(...this.response);\n        }\n        return this.response;\n    }\n    /**\n   * Coerces the response to an array of streams. This will convert the response\n   * to an array of streams if it is not already one.\n   *\n   * @returns An array of streams\n   */ coerce() {\n        if (this.response === null) {\n            // If the response is null, return an empty stream. This behavior is\n            // intentional as we're now providing the `RenderResult.EMPTY` value.\n            return [];\n        }\n        if (typeof this.response === 'string') {\n            return [\n                streamFromString(this.response)\n            ];\n        } else if (Array.isArray(this.response)) {\n            return this.response;\n        } else if (Buffer.isBuffer(this.response)) {\n            return [\n                streamFromBuffer(this.response)\n            ];\n        } else {\n            return [\n                this.response\n            ];\n        }\n    }\n    /**\n   * Unshifts a new stream to the response. This will convert the response to an\n   * array of streams if it is not already one and will add the new stream to\n   * the start of the array. When this response is piped, all of the streams\n   * will be piped one after the other.\n   *\n   * @param readable The new stream to unshift\n   */ unshift(readable) {\n        // Coerce the response to an array of streams.\n        this.response = this.coerce();\n        // Add the new stream to the start of the array.\n        this.response.unshift(readable);\n    }\n    /**\n   * Chains a new stream to the response. This will convert the response to an\n   * array of streams if it is not already one and will add the new stream to\n   * the end. When this response is piped, all of the streams will be piped\n   * one after the other.\n   *\n   * @param readable The new stream to chain\n   */ push(readable) {\n        // Coerce the response to an array of streams.\n        this.response = this.coerce();\n        // Add the new stream to the end of the array.\n        this.response.push(readable);\n    }\n    /**\n   * Pipes the response to a writable stream. This will close/cancel the\n   * writable stream if an error is encountered. If this doesn't throw, then\n   * the writable stream will be closed or aborted.\n   *\n   * @param writable Writable stream to pipe the response to\n   */ async pipeTo(writable) {\n        try {\n            await this.readable.pipeTo(writable, {\n                // We want to close the writable stream ourselves so that we can wait\n                // for the waitUntil promise to resolve before closing it. If an error\n                // is encountered, we'll abort the writable stream if we swallowed the\n                // error.\n                preventClose: true\n            });\n            // If there is a waitUntil promise, wait for it to resolve before\n            // closing the writable stream.\n            if (this.waitUntil) await this.waitUntil;\n            // Close the writable stream.\n            await writable.close();\n        } catch (err) {\n            // If this is an abort error, we should abort the writable stream (as we\n            // took ownership of it when we started piping). We don't need to re-throw\n            // because we handled the error.\n            if (isAbortError(err)) {\n                // Abort the writable stream if an error is encountered.\n                await writable.abort(err);\n                return;\n            }\n            // We're not aborting the writer here as when this method throws it's not\n            // clear as to how so the caller should assume it's their responsibility\n            // to clean up the writer.\n            throw err;\n        }\n    }\n    /**\n   * Pipes the response to a node response. This will close/cancel the node\n   * response if an error is encountered.\n   *\n   * @param res\n   */ async pipeToNodeResponse(res) {\n        await pipeToNodeResponse(this.readable, res, this.waitUntil);\n    }\n}\n\n//# sourceMappingURL=render-result.js.map","import { InvariantError } from '../../invariant-error';\nimport { parseLoaderTree } from './parse-loader-tree';\nimport { parseAppRoute, parseAppRouteSegment } from '../routes/app';\nimport { resolveParamValue } from './resolve-param-value';\n/**\n * Gets the value of a param from the params object. This correctly handles the\n * case where the param is a fallback route param and encodes the resulting\n * value.\n *\n * @param interpolatedParams - The params object.\n * @param segmentKey - The key of the segment.\n * @param fallbackRouteParams - The fallback route params.\n * @returns The value of the param.\n */ function getParamValue(interpolatedParams, segmentKey, fallbackRouteParams) {\n    let value = interpolatedParams[segmentKey];\n    if (fallbackRouteParams?.has(segmentKey)) {\n        // We know that the fallback route params has the segment key because we\n        // checked that above.\n        const [searchValue] = fallbackRouteParams.get(segmentKey);\n        value = searchValue;\n    } else if (Array.isArray(value)) {\n        value = value.map((i)=>encodeURIComponent(i));\n    } else if (typeof value === 'string') {\n        value = encodeURIComponent(value);\n    }\n    return value;\n}\nexport function interpolateParallelRouteParams(loaderTree, params, pagePath, fallbackRouteParams) {\n    const interpolated = structuredClone(params);\n    // Stack-based traversal with depth tracking\n    const stack = [\n        {\n            tree: loaderTree,\n            depth: 0\n        }\n    ];\n    // Parse the route from the provided page path.\n    const route = parseAppRoute(pagePath, true);\n    while(stack.length > 0){\n        const { tree, depth } = stack.pop();\n        const { segment, parallelRoutes } = parseLoaderTree(tree);\n        const appSegment = parseAppRouteSegment(segment);\n        if (appSegment?.type === 'dynamic' && !interpolated.hasOwnProperty(appSegment.param.paramName) && // If the param is in the fallback route params, we don't need to\n        // interpolate it because it's already marked as being unknown.\n        !fallbackRouteParams?.has(appSegment.param.paramName)) {\n            const { paramName, paramType } = appSegment.param;\n            const paramValue = resolveParamValue(paramName, paramType, depth, route, interpolated);\n            if (paramValue !== undefined) {\n                interpolated[paramName] = paramValue;\n            } else if (paramType !== 'optional-catchall') {\n                throw Object.defineProperty(new InvariantError(`Could not resolve param value for segment: ${paramName}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E932\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n        }\n        // Calculate next depth - increment if this is not a route group and not empty\n        let nextDepth = depth;\n        if (appSegment && appSegment.type !== 'route-group' && appSegment.type !== 'parallel-route') {\n            nextDepth++;\n        }\n        // Add all parallel routes to the stack for processing\n        for (const parallelRoute of Object.values(parallelRoutes)){\n            stack.push({\n                tree: parallelRoute,\n                depth: nextDepth\n            });\n        }\n    }\n    return interpolated;\n}\n/**\n *\n * Shared logic on client and server for creating a dynamic param value.\n *\n * This code needs to be shared with the client so it can extract dynamic route\n * params from the URL without a server request.\n *\n * Because everything in this module is sent to the client, we should aim to\n * keep this code as simple as possible. The special case handling for catchall\n * and optional is, alas, unfortunate.\n */ export function getDynamicParam(interpolatedParams, segmentKey, dynamicParamType, fallbackRouteParams) {\n    let value = getParamValue(interpolatedParams, segmentKey, fallbackRouteParams);\n    // handle the case where an optional catchall does not have a value,\n    // e.g. `/dashboard/[[...slug]]` when requesting `/dashboard`\n    if (!value || value.length === 0) {\n        if (dynamicParamType === 'oc') {\n            return {\n                param: segmentKey,\n                value: null,\n                type: dynamicParamType,\n                treeSegment: [\n                    segmentKey,\n                    '',\n                    dynamicParamType\n                ]\n            };\n        }\n        throw Object.defineProperty(new InvariantError(`Missing value for segment key: \"${segmentKey}\" with dynamic param type: ${dynamicParamType}`), \"__NEXT_ERROR_CODE\", {\n            value: \"E864\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    return {\n        param: segmentKey,\n        // The value that is passed to user code.\n        value,\n        // The value that is rendered in the router tree.\n        treeSegment: [\n            segmentKey,\n            Array.isArray(value) ? value.join('/') : value,\n            dynamicParamType\n        ],\n        type: dynamicParamType\n    };\n}\n/**\n * Regular expression pattern used to match route parameters.\n * Matches both single parameters and parameter groups.\n * Examples:\n *   - `[[...slug]]` matches parameter group with key 'slug', repeat: true, optional: true\n *   - `[...slug]` matches parameter group with key 'slug', repeat: true, optional: false\n *   - `[[foo]]` matches parameter with key 'foo', repeat: false, optional: true\n *   - `[bar]` matches parameter with key 'bar', repeat: false, optional: false\n */ export const PARAMETER_PATTERN = /^([^[]*)\\[((?:\\[[^\\]]*\\])|[^\\]]+)\\](.*)$/;\n/**\n * Parses a given parameter from a route to a data structure that can be used\n * to generate the parametrized route.\n * Examples:\n *   - `[[...slug]]` -> `{ key: 'slug', repeat: true, optional: true }`\n *   - `[...slug]` -> `{ key: 'slug', repeat: true, optional: false }`\n *   - `[[foo]]` -> `{ key: 'foo', repeat: false, optional: true }`\n *   - `[bar]` -> `{ key: 'bar', repeat: false, optional: false }`\n *   - `fizz` -> `{ key: 'fizz', repeat: false, optional: false }`\n * @param param - The parameter to parse.\n * @returns The parsed parameter as a data structure.\n */ export function parseParameter(param) {\n    const match = param.match(PARAMETER_PATTERN);\n    if (!match) {\n        return parseMatchedParameter(param);\n    }\n    return parseMatchedParameter(match[2]);\n}\n/**\n * Parses a matched parameter from the PARAMETER_PATTERN regex to a data structure that can be used\n * to generate the parametrized route.\n * Examples:\n *   - `[...slug]` -> `{ key: 'slug', repeat: true, optional: true }`\n *   - `...slug` -> `{ key: 'slug', repeat: true, optional: false }`\n *   - `[foo]` -> `{ key: 'foo', repeat: false, optional: true }`\n *   - `bar` -> `{ key: 'bar', repeat: false, optional: false }`\n * @param param - The matched parameter to parse.\n * @returns The parsed parameter as a data structure.\n */ export function parseMatchedParameter(param) {\n    const optional = param.startsWith('[') && param.endsWith(']');\n    if (optional) {\n        param = param.slice(1, -1);\n    }\n    const repeat = param.startsWith('...');\n    if (repeat) {\n        param = param.slice(3);\n    }\n    return {\n        key: param,\n        repeat,\n        optional\n    };\n}\n\n//# sourceMappingURL=get-dynamic-param.js.map","import { detectDomainLocale } from '../../shared/lib/i18n/detect-domain-locale';\nimport { formatNextPathnameInfo } from '../../shared/lib/router/utils/format-next-pathname-info';\nimport { getHostname } from '../../shared/lib/get-hostname';\nimport { getNextPathnameInfo } from '../../shared/lib/router/utils/get-next-pathname-info';\nconst REGEX_LOCALHOST_HOSTNAME = /(?!^https?:\\/\\/)(127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}|\\[::1\\]|localhost)/;\nfunction parseURL(url, base) {\n    return new URL(String(url).replace(REGEX_LOCALHOST_HOSTNAME, 'localhost'), base && String(base).replace(REGEX_LOCALHOST_HOSTNAME, 'localhost'));\n}\nconst Internal = Symbol('NextURLInternal');\nexport class NextURL {\n    constructor(input, baseOrOpts, opts){\n        let base;\n        let options;\n        if (typeof baseOrOpts === 'object' && 'pathname' in baseOrOpts || typeof baseOrOpts === 'string') {\n            base = baseOrOpts;\n            options = opts || {};\n        } else {\n            options = opts || baseOrOpts || {};\n        }\n        this[Internal] = {\n            url: parseURL(input, base ?? options.base),\n            options: options,\n            basePath: ''\n        };\n        this.analyze();\n    }\n    analyze() {\n        var _this_Internal_options_nextConfig_i18n, _this_Internal_options_nextConfig, _this_Internal_domainLocale, _this_Internal_options_nextConfig_i18n1, _this_Internal_options_nextConfig1;\n        const info = getNextPathnameInfo(this[Internal].url.pathname, {\n            nextConfig: this[Internal].options.nextConfig,\n            parseData: !process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE,\n            i18nProvider: this[Internal].options.i18nProvider\n        });\n        const hostname = getHostname(this[Internal].url, this[Internal].options.headers);\n        this[Internal].domainLocale = this[Internal].options.i18nProvider ? this[Internal].options.i18nProvider.detectDomainLocale(hostname) : detectDomainLocale((_this_Internal_options_nextConfig = this[Internal].options.nextConfig) == null ? void 0 : (_this_Internal_options_nextConfig_i18n = _this_Internal_options_nextConfig.i18n) == null ? void 0 : _this_Internal_options_nextConfig_i18n.domains, hostname);\n        const defaultLocale = ((_this_Internal_domainLocale = this[Internal].domainLocale) == null ? void 0 : _this_Internal_domainLocale.defaultLocale) || ((_this_Internal_options_nextConfig1 = this[Internal].options.nextConfig) == null ? void 0 : (_this_Internal_options_nextConfig_i18n1 = _this_Internal_options_nextConfig1.i18n) == null ? void 0 : _this_Internal_options_nextConfig_i18n1.defaultLocale);\n        this[Internal].url.pathname = info.pathname;\n        this[Internal].defaultLocale = defaultLocale;\n        this[Internal].basePath = info.basePath ?? '';\n        this[Internal].buildId = info.buildId;\n        this[Internal].locale = info.locale ?? defaultLocale;\n        this[Internal].trailingSlash = info.trailingSlash;\n    }\n    formatPathname() {\n        return formatNextPathnameInfo({\n            basePath: this[Internal].basePath,\n            buildId: this[Internal].buildId,\n            defaultLocale: !this[Internal].options.forceLocale ? this[Internal].defaultLocale : undefined,\n            locale: this[Internal].locale,\n            pathname: this[Internal].url.pathname,\n            trailingSlash: this[Internal].trailingSlash\n        });\n    }\n    formatSearch() {\n        return this[Internal].url.search;\n    }\n    get buildId() {\n        return this[Internal].buildId;\n    }\n    set buildId(buildId) {\n        this[Internal].buildId = buildId;\n    }\n    get locale() {\n        return this[Internal].locale ?? '';\n    }\n    set locale(locale) {\n        var _this_Internal_options_nextConfig_i18n, _this_Internal_options_nextConfig;\n        if (!this[Internal].locale || !((_this_Internal_options_nextConfig = this[Internal].options.nextConfig) == null ? void 0 : (_this_Internal_options_nextConfig_i18n = _this_Internal_options_nextConfig.i18n) == null ? void 0 : _this_Internal_options_nextConfig_i18n.locales.includes(locale))) {\n            throw Object.defineProperty(new TypeError(`The NextURL configuration includes no locale \"${locale}\"`), \"__NEXT_ERROR_CODE\", {\n                value: \"E597\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        this[Internal].locale = locale;\n    }\n    get defaultLocale() {\n        return this[Internal].defaultLocale;\n    }\n    get domainLocale() {\n        return this[Internal].domainLocale;\n    }\n    get searchParams() {\n        return this[Internal].url.searchParams;\n    }\n    get host() {\n        return this[Internal].url.host;\n    }\n    set host(value) {\n        this[Internal].url.host = value;\n    }\n    get hostname() {\n        return this[Internal].url.hostname;\n    }\n    set hostname(value) {\n        this[Internal].url.hostname = value;\n    }\n    get port() {\n        return this[Internal].url.port;\n    }\n    set port(value) {\n        this[Internal].url.port = value;\n    }\n    get protocol() {\n        return this[Internal].url.protocol;\n    }\n    set protocol(value) {\n        this[Internal].url.protocol = value;\n    }\n    get href() {\n        const pathname = this.formatPathname();\n        const search = this.formatSearch();\n        return `${this.protocol}//${this.host}${pathname}${search}${this.hash}`;\n    }\n    set href(url) {\n        this[Internal].url = parseURL(url);\n        this.analyze();\n    }\n    get origin() {\n        return this[Internal].url.origin;\n    }\n    get pathname() {\n        return this[Internal].url.pathname;\n    }\n    set pathname(value) {\n        this[Internal].url.pathname = value;\n    }\n    get hash() {\n        return this[Internal].url.hash;\n    }\n    set hash(value) {\n        this[Internal].url.hash = value;\n    }\n    get search() {\n        return this[Internal].url.search;\n    }\n    set search(value) {\n        this[Internal].url.search = value;\n    }\n    get password() {\n        return this[Internal].url.password;\n    }\n    set password(value) {\n        this[Internal].url.password = value;\n    }\n    get username() {\n        return this[Internal].url.username;\n    }\n    set username(value) {\n        this[Internal].url.username = value;\n    }\n    get basePath() {\n        return this[Internal].basePath;\n    }\n    set basePath(value) {\n        this[Internal].basePath = value.startsWith('/') ? value : `/${value}`;\n    }\n    toString() {\n        return this.href;\n    }\n    toJSON() {\n        return this.href;\n    }\n    [Symbol.for('edge-runtime.inspect.custom')]() {\n        return {\n            href: this.href,\n            origin: this.origin,\n            protocol: this.protocol,\n            username: this.username,\n            password: this.password,\n            host: this.host,\n            hostname: this.hostname,\n            port: this.port,\n            pathname: this.pathname,\n            search: this.search,\n            searchParams: this.searchParams,\n            hash: this.hash\n        };\n    }\n    clone() {\n        return new NextURL(String(this), this[Internal].options);\n    }\n}\n\n//# sourceMappingURL=next-url.js.map","import { CachedRouteKind, IncrementalCacheKind } from './types';\nimport RenderResult from '../render-result';\nimport { RouteKind } from '../route-kind';\nimport { HTML_CONTENT_TYPE_HEADER } from '../../lib/constants';\nexport async function fromResponseCacheEntry(cacheEntry) {\n    var _cacheEntry_value, _cacheEntry_value1;\n    return {\n        ...cacheEntry,\n        value: ((_cacheEntry_value = cacheEntry.value) == null ? void 0 : _cacheEntry_value.kind) === CachedRouteKind.PAGES ? {\n            kind: CachedRouteKind.PAGES,\n            html: await cacheEntry.value.html.toUnchunkedString(true),\n            pageData: cacheEntry.value.pageData,\n            headers: cacheEntry.value.headers,\n            status: cacheEntry.value.status\n        } : ((_cacheEntry_value1 = cacheEntry.value) == null ? void 0 : _cacheEntry_value1.kind) === CachedRouteKind.APP_PAGE ? {\n            kind: CachedRouteKind.APP_PAGE,\n            html: await cacheEntry.value.html.toUnchunkedString(true),\n            postponed: cacheEntry.value.postponed,\n            rscData: cacheEntry.value.rscData,\n            headers: cacheEntry.value.headers,\n            status: cacheEntry.value.status,\n            segmentData: cacheEntry.value.segmentData\n        } : cacheEntry.value\n    };\n}\nexport async function toResponseCacheEntry(response) {\n    var _response_value, _response_value1;\n    if (!response) return null;\n    return {\n        isMiss: response.isMiss,\n        isStale: response.isStale,\n        cacheControl: response.cacheControl,\n        value: ((_response_value = response.value) == null ? void 0 : _response_value.kind) === CachedRouteKind.PAGES ? {\n            kind: CachedRouteKind.PAGES,\n            html: RenderResult.fromStatic(response.value.html, HTML_CONTENT_TYPE_HEADER),\n            pageData: response.value.pageData,\n            headers: response.value.headers,\n            status: response.value.status\n        } : ((_response_value1 = response.value) == null ? void 0 : _response_value1.kind) === CachedRouteKind.APP_PAGE ? {\n            kind: CachedRouteKind.APP_PAGE,\n            html: RenderResult.fromStatic(response.value.html, HTML_CONTENT_TYPE_HEADER),\n            rscData: response.value.rscData,\n            headers: response.value.headers,\n            status: response.value.status,\n            postponed: response.value.postponed,\n            segmentData: response.value.segmentData\n        } : response.value\n    };\n}\nexport function routeKindToIncrementalCacheKind(routeKind) {\n    switch(routeKind){\n        case RouteKind.PAGES:\n            return IncrementalCacheKind.PAGES;\n        case RouteKind.APP_PAGE:\n            return IncrementalCacheKind.APP_PAGE;\n        case RouteKind.IMAGE:\n            return IncrementalCacheKind.IMAGE;\n        case RouteKind.APP_ROUTE:\n            return IncrementalCacheKind.APP_ROUTE;\n        case RouteKind.PAGES_API:\n            // Pages Router API routes are not cached in the incremental cache.\n            throw Object.defineProperty(new Error(`Unexpected route kind ${routeKind}`), \"__NEXT_ERROR_CODE\", {\n                value: \"E64\",\n                enumerable: false,\n                configurable: true\n            });\n        default:\n            return routeKind;\n    }\n}\n\n//# sourceMappingURL=utils.js.map","import { removeTrailingSlash } from './remove-trailing-slash';\nimport { addPathPrefix } from './add-path-prefix';\nimport { addPathSuffix } from './add-path-suffix';\nimport { addLocale } from './add-locale';\nexport function formatNextPathnameInfo(info) {\n    let pathname = addLocale(info.pathname, info.locale, info.buildId ? undefined : info.defaultLocale, info.ignorePrefix);\n    if (info.buildId || !info.trailingSlash) {\n        pathname = removeTrailingSlash(pathname);\n    }\n    if (info.buildId) {\n        pathname = addPathSuffix(addPathPrefix(pathname, `/_next/data/${info.buildId}`), info.pathname === '/' ? 'index.json' : '.json');\n    }\n    pathname = addPathPrefix(pathname, info.basePath);\n    return !info.buildId && info.trailingSlash ? !pathname.endsWith('/') ? addPathSuffix(pathname, '/') : pathname : removeTrailingSlash(pathname);\n}\n\n//# sourceMappingURL=format-next-pathname-info.js.map","import { NextURL } from '../next-url';\nimport { toNodeOutgoingHttpHeaders, validateURL } from '../utils';\nimport { RemovedUAError, RemovedPageError } from '../error';\nimport { RequestCookies } from './cookies';\nexport const INTERNALS = Symbol('internal request');\n/**\n * This class extends the [Web `Request` API](https://developer.mozilla.org/docs/Web/API/Request) with additional convenience methods.\n *\n * Read more: [Next.js Docs: `NextRequest`](https://nextjs.org/docs/app/api-reference/functions/next-request)\n */ export class NextRequest extends Request {\n    constructor(input, init = {}){\n        const url = typeof input !== 'string' && 'url' in input ? input.url : String(input);\n        validateURL(url);\n        // node Request instance requires duplex option when a body\n        // is present or it errors, we don't handle this for\n        // Request being passed in since it would have already\n        // errored if this wasn't configured\n        if (process.env.NEXT_RUNTIME !== 'edge') {\n            if (init.body && init.duplex !== 'half') {\n                init.duplex = 'half';\n            }\n        }\n        if (input instanceof Request) super(input, init);\n        else super(url, init);\n        const nextUrl = new NextURL(url, {\n            headers: toNodeOutgoingHttpHeaders(this.headers),\n            nextConfig: init.nextConfig\n        });\n        this[INTERNALS] = {\n            cookies: new RequestCookies(this.headers),\n            nextUrl,\n            url: process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE ? url : nextUrl.toString()\n        };\n    }\n    [Symbol.for('edge-runtime.inspect.custom')]() {\n        return {\n            cookies: this.cookies,\n            nextUrl: this.nextUrl,\n            url: this.url,\n            // rest of props come from Request\n            bodyUsed: this.bodyUsed,\n            cache: this.cache,\n            credentials: this.credentials,\n            destination: this.destination,\n            headers: Object.fromEntries(this.headers),\n            integrity: this.integrity,\n            keepalive: this.keepalive,\n            method: this.method,\n            mode: this.mode,\n            redirect: this.redirect,\n            referrer: this.referrer,\n            referrerPolicy: this.referrerPolicy,\n            signal: this.signal\n        };\n    }\n    get cookies() {\n        return this[INTERNALS].cookies;\n    }\n    get nextUrl() {\n        return this[INTERNALS].nextUrl;\n    }\n    /**\n   * @deprecated\n   * `page` has been deprecated in favour of `URLPattern`.\n   * Read more: https://nextjs.org/docs/messages/middleware-request-page\n   */ get page() {\n        throw new RemovedPageError();\n    }\n    /**\n   * @deprecated\n   * `ua` has been removed in favour of \\`userAgent\\` function.\n   * Read more: https://nextjs.org/docs/messages/middleware-parse-user-agent\n   */ get ua() {\n        throw new RemovedUAError();\n    }\n    get url() {\n        return this[INTERNALS].url;\n    }\n}\n\n//# sourceMappingURL=request.js.map","import { HeadersAdapter } from '../web/spec-extension/adapters/headers';\nimport { PRERENDER_REVALIDATE_HEADER, PRERENDER_REVALIDATE_ONLY_GENERATED_HEADER } from '../../lib/constants';\nimport { getTracer } from '../lib/trace/tracer';\nimport { NodeSpan } from '../lib/trace/constants';\nexport function wrapApiHandler(page, handler) {\n    return (...args)=>{\n        getTracer().setRootSpanAttribute('next.route', page);\n        // Call API route method\n        return getTracer().trace(NodeSpan.runHandler, {\n            spanName: `executing api route (pages) ${page}`\n        }, ()=>handler(...args));\n    };\n}\n/**\n *\n * @param res response object\n * @param statusCode `HTTP` status code of response\n */ export function sendStatusCode(res, statusCode) {\n    res.statusCode = statusCode;\n    return res;\n}\n/**\n *\n * @param res response object\n * @param [statusOrUrl] `HTTP` status code of redirect\n * @param url URL of redirect\n */ export function redirect(res, statusOrUrl, url) {\n    if (typeof statusOrUrl === 'string') {\n        url = statusOrUrl;\n        statusOrUrl = 307;\n    }\n    if (typeof statusOrUrl !== 'number' || typeof url !== 'string') {\n        throw Object.defineProperty(new Error(`Invalid redirect arguments. Please use a single argument URL, e.g. res.redirect('/destination') or use a status code and URL, e.g. res.redirect(307, '/destination').`), \"__NEXT_ERROR_CODE\", {\n            value: \"E389\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    res.writeHead(statusOrUrl, {\n        Location: url\n    });\n    res.write(url);\n    res.end();\n    return res;\n}\nexport function checkIsOnDemandRevalidate(req, previewProps) {\n    const headers = HeadersAdapter.from(req.headers);\n    const previewModeId = headers.get(PRERENDER_REVALIDATE_HEADER);\n    const isOnDemandRevalidate = previewModeId === previewProps.previewModeId;\n    const revalidateOnlyGenerated = headers.has(PRERENDER_REVALIDATE_ONLY_GENERATED_HEADER);\n    return {\n        isOnDemandRevalidate,\n        revalidateOnlyGenerated\n    };\n}\nexport const COOKIE_NAME_PRERENDER_BYPASS = `__prerender_bypass`;\nexport const COOKIE_NAME_PRERENDER_DATA = `__next_preview_data`;\nexport const RESPONSE_LIMIT_DEFAULT = 4 * 1024 * 1024;\nexport const SYMBOL_PREVIEW_DATA = Symbol(COOKIE_NAME_PRERENDER_DATA);\nexport const SYMBOL_CLEARED_COOKIES = Symbol(COOKIE_NAME_PRERENDER_BYPASS);\nexport function clearPreviewData(res, options = {}) {\n    if (SYMBOL_CLEARED_COOKIES in res) {\n        return res;\n    }\n    const { serialize } = require('next/dist/compiled/cookie');\n    const previous = res.getHeader('Set-Cookie');\n    res.setHeader(`Set-Cookie`, [\n        ...typeof previous === 'string' ? [\n            previous\n        ] : Array.isArray(previous) ? previous : [],\n        serialize(COOKIE_NAME_PRERENDER_BYPASS, '', {\n            // To delete a cookie, set `expires` to a date in the past:\n            // https://tools.ietf.org/html/rfc6265#section-4.1.1\n            // `Max-Age: 0` is not valid, thus ignored, and the cookie is persisted.\n            expires: new Date(0),\n            httpOnly: true,\n            sameSite: process.env.NODE_ENV !== 'development' ? 'none' : 'lax',\n            secure: process.env.NODE_ENV !== 'development',\n            path: '/',\n            ...options.path !== undefined ? {\n                path: options.path\n            } : undefined\n        }),\n        serialize(COOKIE_NAME_PRERENDER_DATA, '', {\n            // To delete a cookie, set `expires` to a date in the past:\n            // https://tools.ietf.org/html/rfc6265#section-4.1.1\n            // `Max-Age: 0` is not valid, thus ignored, and the cookie is persisted.\n            expires: new Date(0),\n            httpOnly: true,\n            sameSite: process.env.NODE_ENV !== 'development' ? 'none' : 'lax',\n            secure: process.env.NODE_ENV !== 'development',\n            path: '/',\n            ...options.path !== undefined ? {\n                path: options.path\n            } : undefined\n        })\n    ]);\n    Object.defineProperty(res, SYMBOL_CLEARED_COOKIES, {\n        value: true,\n        enumerable: false\n    });\n    return res;\n}\n/**\n * Custom error class\n */ export class ApiError extends Error {\n    constructor(statusCode, message){\n        super(message);\n        this.statusCode = statusCode;\n    }\n}\n/**\n * Sends error in `response`\n * @param res response object\n * @param statusCode of response\n * @param message of response\n */ export function sendError(res, statusCode, message) {\n    res.statusCode = statusCode;\n    res.statusMessage = message;\n    res.end(message);\n}\n/**\n * Execute getter function only if its needed\n * @param LazyProps `req` and `params` for lazyProp\n * @param prop name of property\n * @param getter function to get data\n */ export function setLazyProp({ req }, prop, getter) {\n    const opts = {\n        configurable: true,\n        enumerable: true\n    };\n    const optsReset = {\n        ...opts,\n        writable: true\n    };\n    Object.defineProperty(req, prop, {\n        ...opts,\n        get: ()=>{\n            const value = getter();\n            // we set the property on the object to avoid recalculating it\n            Object.defineProperty(req, prop, {\n                ...optsReset,\n                value\n            });\n            return value;\n        },\n        set: (value)=>{\n            Object.defineProperty(req, prop, {\n                ...optsReset,\n                value\n            });\n        }\n    });\n}\n\n//# sourceMappingURL=index.js.map","import { getRequestMeta } from '../../../request-meta';\nimport { fromNodeOutgoingHttpHeaders } from '../../utils';\nimport { NextRequest } from '../request';\nimport { isNodeNextRequest, isWebNextRequest } from '../../../base-http/helpers';\nexport const ResponseAbortedName = 'ResponseAborted';\nexport class ResponseAborted extends Error {\n    constructor(...args){\n        super(...args), this.name = ResponseAbortedName;\n    }\n}\n/**\n * Creates an AbortController tied to the closing of a ServerResponse (or other\n * appropriate Writable).\n *\n * If the `close` event is fired before the `finish` event, then we'll send the\n * `abort` signal.\n */ export function createAbortController(response) {\n    const controller = new AbortController();\n    // If `finish` fires first, then `res.end()` has been called and the close is\n    // just us finishing the stream on our side. If `close` fires first, then we\n    // know the client disconnected before we finished.\n    response.once('close', ()=>{\n        if (response.writableFinished) return;\n        controller.abort(new ResponseAborted());\n    });\n    return controller;\n}\n/**\n * Creates an AbortSignal tied to the closing of a ServerResponse (or other\n * appropriate Writable).\n *\n * This cannot be done with the request (IncomingMessage or Readable) because\n * the `abort` event will not fire if to data has been fully read (because that\n * will \"close\" the readable stream and nothing fires after that).\n */ export function signalFromNodeResponse(response) {\n    const { errored, destroyed } = response;\n    if (errored || destroyed) {\n        return AbortSignal.abort(errored ?? new ResponseAborted());\n    }\n    const { signal } = createAbortController(response);\n    return signal;\n}\nexport class NextRequestAdapter {\n    static fromBaseNextRequest(request, signal) {\n        if (// The type check here ensures that `req` is correctly typed, and the\n        // environment variable check provides dead code elimination.\n        process.env.NEXT_RUNTIME === 'edge' && isWebNextRequest(request)) {\n            return NextRequestAdapter.fromWebNextRequest(request);\n        } else if (// The type check here ensures that `req` is correctly typed, and the\n        // environment variable check provides dead code elimination.\n        process.env.NEXT_RUNTIME !== 'edge' && isNodeNextRequest(request)) {\n            return NextRequestAdapter.fromNodeNextRequest(request, signal);\n        } else {\n            throw Object.defineProperty(new Error('Invariant: Unsupported NextRequest type'), \"__NEXT_ERROR_CODE\", {\n                value: \"E345\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n    static fromNodeNextRequest(request, signal) {\n        // HEAD and GET requests can not have a body.\n        let body = null;\n        if (request.method !== 'GET' && request.method !== 'HEAD' && request.body) {\n            // @ts-expect-error - this is handled by undici, when streams/web land use it instead\n            body = request.body;\n        }\n        let url;\n        if (request.url.startsWith('http')) {\n            url = new URL(request.url);\n        } else {\n            // Grab the full URL from the request metadata.\n            const base = getRequestMeta(request, 'initURL');\n            if (!base || !base.startsWith('http')) {\n                // Because the URL construction relies on the fact that the URL provided\n                // is absolute, we need to provide a base URL. We can't use the request\n                // URL because it's relative, so we use a dummy URL instead.\n                url = new URL(request.url, 'http://n');\n            } else {\n                url = new URL(request.url, base);\n            }\n        }\n        return new NextRequest(url, {\n            method: request.method,\n            headers: fromNodeOutgoingHttpHeaders(request.headers),\n            duplex: 'half',\n            signal,\n            // geo\n            // ip\n            // nextConfig\n            // body can not be passed if request was aborted\n            // or we get a Request body was disturbed error\n            ...signal.aborted ? {} : {\n                body\n            }\n        });\n    }\n    static fromWebNextRequest(request) {\n        // HEAD and GET requests can not have a body.\n        let body = null;\n        if (request.method !== 'GET' && request.method !== 'HEAD') {\n            body = request.body;\n        }\n        return new NextRequest(request.url, {\n            method: request.method,\n            headers: fromNodeOutgoingHttpHeaders(request.headers),\n            duplex: 'half',\n            signal: request.request.signal,\n            // geo\n            // ip\n            // nextConfig\n            // body can not be passed if request was aborted\n            // or we get a Request body was disturbed error\n            ...request.request.signal.aborted ? {} : {\n                body\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=next-request.js.map","/**\n * A shared cache of cache controls for routes. This cache is used so we don't\n * have to modify the prerender manifest when we want to update the cache\n * control for a route.\n */ export class SharedCacheControls {\n    static #_ = /**\n   * The in-memory cache of cache lives for routes. This cache is populated when\n   * the cache is updated with new cache lives.\n   */ this.cacheControls = new Map();\n    constructor(/**\n     * The prerender manifest that contains the initial cache controls for\n     * routes.\n     */ prerenderManifest){\n        this.prerenderManifest = prerenderManifest;\n    }\n    /**\n   * Try to get the cache control value for a route. This will first try to get\n   * the value from the in-memory cache. If the value is not present in the\n   * in-memory cache, it will be sourced from the prerender manifest.\n   *\n   * @param route the route to get the cache control for\n   * @returns the cache control for the route, or undefined if the values\n   *          are not present in the in-memory cache or the prerender manifest\n   */ get(route) {\n        // This is a copy on write cache that is updated when the cache is updated.\n        // If the cache is never written to, then the values will be sourced from\n        // the prerender manifest.\n        let cacheControl = SharedCacheControls.cacheControls.get(route);\n        if (cacheControl) return cacheControl;\n        let prerenderData = this.prerenderManifest.routes[route];\n        if (prerenderData) {\n            const { initialRevalidateSeconds, initialExpireSeconds } = prerenderData;\n            if (typeof initialRevalidateSeconds !== 'undefined') {\n                return {\n                    revalidate: initialRevalidateSeconds,\n                    expire: initialExpireSeconds\n                };\n            }\n        }\n        const dynamicPrerenderData = this.prerenderManifest.dynamicRoutes[route];\n        if (dynamicPrerenderData) {\n            const { fallbackRevalidate, fallbackExpire } = dynamicPrerenderData;\n            if (typeof fallbackRevalidate !== 'undefined') {\n                return {\n                    revalidate: fallbackRevalidate,\n                    expire: fallbackExpire\n                };\n            }\n        }\n        return undefined;\n    }\n    /**\n   * Set the cache control for a route.\n   *\n   * @param route the route to set the cache control for\n   * @param cacheControl the cache control for the route\n   */ set(route, cacheControl) {\n        SharedCacheControls.cacheControls.set(route, cacheControl);\n    }\n    /**\n   * Clear the in-memory cache of cache controls for routes.\n   */ clear() {\n        SharedCacheControls.cacheControls.clear();\n    }\n}\n\n//# sourceMappingURL=shared-cache-controls.external.js.map","/**\n * Calls the given function only when the returned promise-like object is\n * awaited. Afterwards, it provides the resolved value synchronously as `value`\n * property.\n */ export function createLazyResult(fn) {\n    let pendingResult;\n    const result = {\n        then (onfulfilled, onrejected) {\n            if (!pendingResult) {\n                pendingResult = Promise.resolve(fn());\n            }\n            pendingResult.then((value)=>{\n                result.value = value;\n            }).catch(()=>{\n            // The externally awaited result will be rejected via `onrejected`. We\n            // don't need to handle it here. But we do want to avoid an unhandled\n            // rejection.\n            });\n            return pendingResult.then(onfulfilled, onrejected);\n        }\n    };\n    return result;\n}\nexport function isResolvedLazyResult(result) {\n    return result.hasOwnProperty('value');\n}\n\n//# sourceMappingURL=lazy-result.js.map","import { parsePath } from './parse-path';\n/**\n * Adds the provided prefix to the given path. It first ensures that the path\n * is indeed starting with a slash.\n */ export function addPathPrefix(path, prefix) {\n    if (!path.startsWith('/') || !prefix) {\n        return path;\n    }\n    const { pathname, query, hash } = parsePath(path);\n    return `${prefix}${pathname}${query}${hash}`;\n}\n\n//# sourceMappingURL=add-path-prefix.js.map","import { DetachedPromise } from './detached-promise';\n/**\n * A wrapper for a function that will only allow one call to the function to\n * execute at a time.\n */ export class Batcher {\n    constructor(cacheKeyFn, /**\n     * A function that will be called to schedule the wrapped function to be\n     * executed. This defaults to a function that will execute the function\n     * immediately.\n     */ schedulerFn = (fn)=>fn()){\n        this.cacheKeyFn = cacheKeyFn;\n        this.schedulerFn = schedulerFn;\n        this.pending = new Map();\n    }\n    static create(options) {\n        return new Batcher(options == null ? void 0 : options.cacheKeyFn, options == null ? void 0 : options.schedulerFn);\n    }\n    /**\n   * Wraps a function in a promise that will be resolved or rejected only once\n   * for a given key. This will allow multiple calls to the function to be\n   * made, but only one will be executed at a time. The result of the first\n   * call will be returned to all callers.\n   *\n   * @param key the key to use for the cache\n   * @param fn the function to wrap\n   * @returns a promise that resolves to the result of the function\n   */ async batch(key, fn) {\n        const cacheKey = this.cacheKeyFn ? await this.cacheKeyFn(key) : key;\n        if (cacheKey === null) {\n            return fn({\n                resolve: (value)=>Promise.resolve(value),\n                key\n            });\n        }\n        const pending = this.pending.get(cacheKey);\n        if (pending) return pending;\n        const { promise, resolve, reject } = new DetachedPromise();\n        this.pending.set(cacheKey, promise);\n        this.schedulerFn(async ()=>{\n            try {\n                const result = await fn({\n                    resolve,\n                    key\n                });\n                // Resolving a promise multiple times is a no-op, so we can safely\n                // resolve all pending promises with the same result.\n                resolve(result);\n            } catch (err) {\n                reject(err);\n            } finally{\n                this.pending.delete(cacheKey);\n            }\n        });\n        return promise;\n    }\n}\n\n//# sourceMappingURL=batcher.js.map","/**\n * Given a path this function will find the pathname, query and hash and return\n * them. This is useful to parse full paths on the client side.\n * @param path A path to parse e.g. /foo/bar?id=1#hash\n */ export function parsePath(path) {\n    const hashIndex = path.indexOf('#');\n    const queryIndex = path.indexOf('?');\n    const hasQuery = queryIndex > -1 && (hashIndex < 0 || queryIndex < hashIndex);\n    if (hasQuery || hashIndex > -1) {\n        return {\n            pathname: path.substring(0, hasQuery ? queryIndex : hashIndex),\n            query: hasQuery ? path.substring(queryIndex, hashIndex > -1 ? hashIndex : undefined) : '',\n            hash: hashIndex > -1 ? path.slice(hashIndex) : ''\n        };\n    }\n    return {\n        pathname: path,\n        query: '',\n        hash: ''\n    };\n}\n\n//# sourceMappingURL=parse-path.js.map","import { NEXT_INTERCEPTION_MARKER_PREFIX, NEXT_QUERY_PARAM_PREFIX } from '../../../../lib/constants';\nimport { INTERCEPTION_ROUTE_MARKERS } from './interception-routes';\nimport { escapeStringRegexp } from '../../escape-regexp';\nimport { removeTrailingSlash } from './remove-trailing-slash';\nimport { PARAMETER_PATTERN, parseMatchedParameter } from './get-dynamic-param';\nfunction getParametrizedRoute(route, includeSuffix, includePrefix) {\n    const groups = {};\n    let groupIndex = 1;\n    const segments = [];\n    for (const segment of removeTrailingSlash(route).slice(1).split('/')){\n        const markerMatch = INTERCEPTION_ROUTE_MARKERS.find((m)=>segment.startsWith(m));\n        const paramMatches = segment.match(PARAMETER_PATTERN) // Check for parameters\n        ;\n        if (markerMatch && paramMatches && paramMatches[2]) {\n            const { key, optional, repeat } = parseMatchedParameter(paramMatches[2]);\n            groups[key] = {\n                pos: groupIndex++,\n                repeat,\n                optional\n            };\n            segments.push(`/${escapeStringRegexp(markerMatch)}([^/]+?)`);\n        } else if (paramMatches && paramMatches[2]) {\n            const { key, repeat, optional } = parseMatchedParameter(paramMatches[2]);\n            groups[key] = {\n                pos: groupIndex++,\n                repeat,\n                optional\n            };\n            if (includePrefix && paramMatches[1]) {\n                segments.push(`/${escapeStringRegexp(paramMatches[1])}`);\n            }\n            let s = repeat ? optional ? '(?:/(.+?))?' : '/(.+?)' : '/([^/]+?)';\n            // Remove the leading slash if includePrefix already added it.\n            if (includePrefix && paramMatches[1]) {\n                s = s.substring(1);\n            }\n            segments.push(s);\n        } else {\n            segments.push(`/${escapeStringRegexp(segment)}`);\n        }\n        // If there's a suffix, add it to the segments if it's enabled.\n        if (includeSuffix && paramMatches && paramMatches[3]) {\n            segments.push(escapeStringRegexp(paramMatches[3]));\n        }\n    }\n    return {\n        parameterizedRoute: segments.join(''),\n        groups\n    };\n}\n/**\n * From a normalized route this function generates a regular expression and\n * a corresponding groups object intended to be used to store matching groups\n * from the regular expression.\n */ export function getRouteRegex(normalizedRoute, { includeSuffix = false, includePrefix = false, excludeOptionalTrailingSlash = false } = {}) {\n    const { parameterizedRoute, groups } = getParametrizedRoute(normalizedRoute, includeSuffix, includePrefix);\n    let re = parameterizedRoute;\n    if (!excludeOptionalTrailingSlash) {\n        re += '(?:/)?';\n    }\n    return {\n        re: new RegExp(`^${re}$`),\n        groups: groups\n    };\n}\n/**\n * Builds a function to generate a minimal routeKey using only a-z and minimal\n * number of characters.\n */ function buildGetSafeRouteKey() {\n    let i = 0;\n    return ()=>{\n        let routeKey = '';\n        let j = ++i;\n        while(j > 0){\n            routeKey += String.fromCharCode(97 + (j - 1) % 26);\n            j = Math.floor((j - 1) / 26);\n        }\n        return routeKey;\n    };\n}\nfunction getSafeKeyFromSegment({ interceptionMarker, getSafeRouteKey, segment, routeKeys, keyPrefix, backreferenceDuplicateKeys }) {\n    const { key, optional, repeat } = parseMatchedParameter(segment);\n    // replace any non-word characters since they can break\n    // the named regex\n    let cleanedKey = key.replace(/\\W/g, '');\n    if (keyPrefix) {\n        cleanedKey = `${keyPrefix}${cleanedKey}`;\n    }\n    let invalidKey = false;\n    // check if the key is still invalid and fallback to using a known\n    // safe key\n    if (cleanedKey.length === 0 || cleanedKey.length > 30) {\n        invalidKey = true;\n    }\n    if (!isNaN(parseInt(cleanedKey.slice(0, 1)))) {\n        invalidKey = true;\n    }\n    if (invalidKey) {\n        cleanedKey = getSafeRouteKey();\n    }\n    const duplicateKey = cleanedKey in routeKeys;\n    if (keyPrefix) {\n        routeKeys[cleanedKey] = `${keyPrefix}${key}`;\n    } else {\n        routeKeys[cleanedKey] = key;\n    }\n    // if the segment has an interception marker, make sure that's part of the regex pattern\n    // this is to ensure that the route with the interception marker doesn't incorrectly match\n    // the non-intercepted route (ie /app/(.)[username] should not match /app/[username])\n    const interceptionPrefix = interceptionMarker ? escapeStringRegexp(interceptionMarker) : '';\n    let pattern;\n    if (duplicateKey && backreferenceDuplicateKeys) {\n        // Use a backreference to the key to ensure that the key is the same value\n        // in each of the placeholders.\n        pattern = `\\\\k<${cleanedKey}>`;\n    } else if (repeat) {\n        pattern = `(?<${cleanedKey}>.+?)`;\n    } else {\n        pattern = `(?<${cleanedKey}>[^/]+?)`;\n    }\n    return {\n        key,\n        pattern: optional ? `(?:/${interceptionPrefix}${pattern})?` : `/${interceptionPrefix}${pattern}`,\n        cleanedKey: cleanedKey,\n        optional,\n        repeat\n    };\n}\nfunction getNamedParametrizedRoute(route, prefixRouteKeys, includeSuffix, includePrefix, backreferenceDuplicateKeys, reference = {\n    names: {},\n    intercepted: {}\n}) {\n    const getSafeRouteKey = buildGetSafeRouteKey();\n    const routeKeys = {};\n    const segments = [];\n    const inverseParts = [];\n    // Ensure we don't mutate the original reference object.\n    reference = structuredClone(reference);\n    for (const segment of removeTrailingSlash(route).slice(1).split('/')){\n        const hasInterceptionMarker = INTERCEPTION_ROUTE_MARKERS.some((m)=>segment.startsWith(m));\n        const paramMatches = segment.match(PARAMETER_PATTERN) // Check for parameters\n        ;\n        const interceptionMarker = hasInterceptionMarker ? paramMatches?.[1] : undefined;\n        let keyPrefix;\n        if (interceptionMarker && paramMatches?.[2]) {\n            keyPrefix = prefixRouteKeys ? NEXT_INTERCEPTION_MARKER_PREFIX : undefined;\n            reference.intercepted[paramMatches[2]] = interceptionMarker;\n        } else if (paramMatches?.[2] && reference.intercepted[paramMatches[2]]) {\n            keyPrefix = prefixRouteKeys ? NEXT_INTERCEPTION_MARKER_PREFIX : undefined;\n        } else {\n            keyPrefix = prefixRouteKeys ? NEXT_QUERY_PARAM_PREFIX : undefined;\n        }\n        if (interceptionMarker && paramMatches && paramMatches[2]) {\n            // If there's an interception marker, add it to the segments.\n            const { key, pattern, cleanedKey, repeat, optional } = getSafeKeyFromSegment({\n                getSafeRouteKey,\n                interceptionMarker,\n                segment: paramMatches[2],\n                routeKeys,\n                keyPrefix,\n                backreferenceDuplicateKeys\n            });\n            segments.push(pattern);\n            inverseParts.push(`/${paramMatches[1]}:${reference.names[key] ?? cleanedKey}${repeat ? optional ? '*' : '+' : ''}`);\n            reference.names[key] ??= cleanedKey;\n        } else if (paramMatches && paramMatches[2]) {\n            // If there's a prefix, add it to the segments if it's enabled.\n            if (includePrefix && paramMatches[1]) {\n                segments.push(`/${escapeStringRegexp(paramMatches[1])}`);\n                inverseParts.push(`/${paramMatches[1]}`);\n            }\n            const { key, pattern, cleanedKey, repeat, optional } = getSafeKeyFromSegment({\n                getSafeRouteKey,\n                segment: paramMatches[2],\n                routeKeys,\n                keyPrefix,\n                backreferenceDuplicateKeys\n            });\n            // Remove the leading slash if includePrefix already added it.\n            let s = pattern;\n            if (includePrefix && paramMatches[1]) {\n                s = s.substring(1);\n            }\n            segments.push(s);\n            inverseParts.push(`/:${reference.names[key] ?? cleanedKey}${repeat ? optional ? '*' : '+' : ''}`);\n            reference.names[key] ??= cleanedKey;\n        } else {\n            segments.push(`/${escapeStringRegexp(segment)}`);\n            inverseParts.push(`/${segment}`);\n        }\n        // If there's a suffix, add it to the segments if it's enabled.\n        if (includeSuffix && paramMatches && paramMatches[3]) {\n            segments.push(escapeStringRegexp(paramMatches[3]));\n            inverseParts.push(paramMatches[3]);\n        }\n    }\n    return {\n        namedParameterizedRoute: segments.join(''),\n        routeKeys,\n        pathToRegexpPattern: inverseParts.join(''),\n        reference\n    };\n}\n/**\n * This function extends `getRouteRegex` generating also a named regexp where\n * each group is named along with a routeKeys object that indexes the assigned\n * named group with its corresponding key. When the routeKeys need to be\n * prefixed to uniquely identify internally the \"prefixRouteKey\" arg should\n * be \"true\" currently this is only the case when creating the routes-manifest\n * during the build\n */ export function getNamedRouteRegex(normalizedRoute, options) {\n    const result = getNamedParametrizedRoute(normalizedRoute, options.prefixRouteKeys, options.includeSuffix ?? false, options.includePrefix ?? false, options.backreferenceDuplicateKeys ?? false, options.reference);\n    let namedRegex = result.namedParameterizedRoute;\n    if (!options.excludeOptionalTrailingSlash) {\n        namedRegex += '(?:/)?';\n    }\n    return {\n        ...getRouteRegex(normalizedRoute, options),\n        namedRegex: `^${namedRegex}$`,\n        routeKeys: result.routeKeys,\n        pathToRegexpPattern: result.pathToRegexpPattern,\n        reference: result.reference\n    };\n}\n/**\n * Generates a named regexp.\n * This is intended to be using for build time only.\n */ export function getNamedMiddlewareRegex(normalizedRoute, options) {\n    const { parameterizedRoute } = getParametrizedRoute(normalizedRoute, false, false);\n    const { catchAll = true } = options;\n    if (parameterizedRoute === '/') {\n        let catchAllRegex = catchAll ? '.*' : '';\n        return {\n            namedRegex: `^/${catchAllRegex}$`\n        };\n    }\n    const { namedParameterizedRoute } = getNamedParametrizedRoute(normalizedRoute, false, false, false, false, undefined);\n    let catchAllGroupedRegex = catchAll ? '(?:(/.*)?)' : '';\n    return {\n        namedRegex: `^${namedParameterizedRoute}${catchAllGroupedRegex}$`\n    };\n}\n\n//# sourceMappingURL=route-regex.js.map","import { escapeStringRegexp } from '../../escape-regexp';\nimport { parseUrl } from './parse-url';\nimport { INTERCEPTION_ROUTE_MARKERS, isInterceptionRouteAppPath } from './interception-routes';\nimport { getCookieParser } from '../../../../server/api-utils/get-cookie-parser';\nimport { safePathToRegexp, safeCompile } from './route-match-utils';\n/**\n * Ensure only a-zA-Z are used for param names for proper interpolating\n * with path-to-regexp\n */ function getSafeParamName(paramName) {\n    let newParamName = '';\n    for(let i = 0; i < paramName.length; i++){\n        const charCode = paramName.charCodeAt(i);\n        if (charCode > 64 && charCode < 91 || // A-Z\n        charCode > 96 && charCode < 123 // a-z\n        ) {\n            newParamName += paramName[i];\n        }\n    }\n    return newParamName;\n}\nfunction escapeSegment(str, segmentName) {\n    return str.replace(new RegExp(`:${escapeStringRegexp(segmentName)}`, 'g'), `__ESC_COLON_${segmentName}`);\n}\nfunction unescapeSegments(str) {\n    return str.replace(/__ESC_COLON_/gi, ':');\n}\nexport function matchHas(req, query, has = [], missing = []) {\n    const params = {};\n    const hasMatch = (hasItem)=>{\n        let value;\n        let key = hasItem.key;\n        switch(hasItem.type){\n            case 'header':\n                {\n                    key = key.toLowerCase();\n                    value = req.headers[key];\n                    break;\n                }\n            case 'cookie':\n                {\n                    if ('cookies' in req) {\n                        value = req.cookies[hasItem.key];\n                    } else {\n                        const cookies = getCookieParser(req.headers)();\n                        value = cookies[hasItem.key];\n                    }\n                    break;\n                }\n            case 'query':\n                {\n                    value = query[key];\n                    break;\n                }\n            case 'host':\n                {\n                    const { host } = req?.headers || {};\n                    // remove port from host if present\n                    const hostname = host?.split(':', 1)[0].toLowerCase();\n                    value = hostname;\n                    break;\n                }\n            default:\n                {\n                    break;\n                }\n        }\n        if (!hasItem.value && value) {\n            params[getSafeParamName(key)] = value;\n            return true;\n        } else if (value) {\n            const matcher = new RegExp(`^${hasItem.value}$`);\n            const matches = Array.isArray(value) ? value.slice(-1)[0].match(matcher) : value.match(matcher);\n            if (matches) {\n                if (Array.isArray(matches)) {\n                    if (matches.groups) {\n                        Object.keys(matches.groups).forEach((groupKey)=>{\n                            params[groupKey] = matches.groups[groupKey];\n                        });\n                    } else if (hasItem.type === 'host' && matches[0]) {\n                        params.host = matches[0];\n                    }\n                }\n                return true;\n            }\n        }\n        return false;\n    };\n    const allMatch = has.every((item)=>hasMatch(item)) && !missing.some((item)=>hasMatch(item));\n    if (allMatch) {\n        return params;\n    }\n    return false;\n}\nexport function compileNonPath(value, params) {\n    if (!value.includes(':')) {\n        return value;\n    }\n    for (const key of Object.keys(params)){\n        if (value.includes(`:${key}`)) {\n            value = value.replace(new RegExp(`:${key}\\\\*`, 'g'), `:${key}--ESCAPED_PARAM_ASTERISKS`).replace(new RegExp(`:${key}\\\\?`, 'g'), `:${key}--ESCAPED_PARAM_QUESTION`).replace(new RegExp(`:${key}\\\\+`, 'g'), `:${key}--ESCAPED_PARAM_PLUS`).replace(new RegExp(`:${key}(?!\\\\w)`, 'g'), `--ESCAPED_PARAM_COLON${key}`);\n        }\n    }\n    value = value.replace(/(:|\\*|\\?|\\+|\\(|\\)|\\{|\\})/g, '\\\\$1').replace(/--ESCAPED_PARAM_PLUS/g, '+').replace(/--ESCAPED_PARAM_COLON/g, ':').replace(/--ESCAPED_PARAM_QUESTION/g, '?').replace(/--ESCAPED_PARAM_ASTERISKS/g, '*');\n    // the value needs to start with a forward-slash to be compiled\n    // correctly\n    return safeCompile(`/${value}`, {\n        validate: false\n    })(params).slice(1);\n}\nexport function parseDestination(args) {\n    let escaped = args.destination;\n    for (const param of Object.keys({\n        ...args.params,\n        ...args.query\n    })){\n        if (!param) continue;\n        escaped = escapeSegment(escaped, param);\n    }\n    const parsed = parseUrl(escaped);\n    let pathname = parsed.pathname;\n    if (pathname) {\n        pathname = unescapeSegments(pathname);\n    }\n    let href = parsed.href;\n    if (href) {\n        href = unescapeSegments(href);\n    }\n    let hostname = parsed.hostname;\n    if (hostname) {\n        hostname = unescapeSegments(hostname);\n    }\n    let hash = parsed.hash;\n    if (hash) {\n        hash = unescapeSegments(hash);\n    }\n    let search = parsed.search;\n    if (search) {\n        search = unescapeSegments(search);\n    }\n    let origin = parsed.origin;\n    if (origin) {\n        origin = unescapeSegments(origin);\n    }\n    return {\n        ...parsed,\n        pathname,\n        hostname,\n        href,\n        hash,\n        search,\n        origin\n    };\n}\nexport function prepareDestination(args) {\n    const parsedDestination = parseDestination(args);\n    const { hostname: destHostname, query: destQuery, search: destSearch } = parsedDestination;\n    // The following code assumes that the pathname here includes the hash if it's\n    // present.\n    let destPath = parsedDestination.pathname;\n    if (parsedDestination.hash) {\n        destPath = `${destPath}${parsedDestination.hash}`;\n    }\n    const destParams = [];\n    const destPathParamKeys = [];\n    safePathToRegexp(destPath, destPathParamKeys);\n    for (const key of destPathParamKeys){\n        destParams.push(key.name);\n    }\n    if (destHostname) {\n        const destHostnameParamKeys = [];\n        safePathToRegexp(destHostname, destHostnameParamKeys);\n        for (const key of destHostnameParamKeys){\n            destParams.push(key.name);\n        }\n    }\n    const destPathCompiler = safeCompile(destPath, // we don't validate while compiling the destination since we should\n    // have already validated before we got to this point and validating\n    // breaks compiling destinations with named pattern params from the source\n    // e.g. /something:hello(.*) -> /another/:hello is broken with validation\n    // since compile validation is meant for reversing and not for inserting\n    // params from a separate path-regex into another\n    {\n        validate: false\n    });\n    let destHostnameCompiler;\n    if (destHostname) {\n        destHostnameCompiler = safeCompile(destHostname, {\n            validate: false\n        });\n    }\n    // update any params in query values\n    for (const [key, strOrArray] of Object.entries(destQuery)){\n        // the value needs to start with a forward-slash to be compiled\n        // correctly\n        if (Array.isArray(strOrArray)) {\n            destQuery[key] = strOrArray.map((value)=>compileNonPath(unescapeSegments(value), args.params));\n        } else if (typeof strOrArray === 'string') {\n            destQuery[key] = compileNonPath(unescapeSegments(strOrArray), args.params);\n        }\n    }\n    // add path params to query if it's not a redirect and not\n    // already defined in destination query or path\n    let paramKeys = Object.keys(args.params).filter((name)=>name !== 'nextInternalLocale');\n    if (args.appendParamsToQuery && !paramKeys.some((key)=>destParams.includes(key))) {\n        for (const key of paramKeys){\n            if (!(key in destQuery)) {\n                destQuery[key] = args.params[key];\n            }\n        }\n    }\n    let newUrl;\n    // The compiler also that the interception route marker is an unnamed param, hence '0',\n    // so we need to add it to the params object.\n    if (isInterceptionRouteAppPath(destPath)) {\n        for (const segment of destPath.split('/')){\n            const marker = INTERCEPTION_ROUTE_MARKERS.find((m)=>segment.startsWith(m));\n            if (marker) {\n                if (marker === '(..)(..)') {\n                    args.params['0'] = '(..)';\n                    args.params['1'] = '(..)';\n                } else {\n                    args.params['0'] = marker;\n                }\n                break;\n            }\n        }\n    }\n    try {\n        newUrl = destPathCompiler(args.params);\n        const [pathname, hash] = newUrl.split('#', 2);\n        if (destHostnameCompiler) {\n            parsedDestination.hostname = destHostnameCompiler(args.params);\n        }\n        parsedDestination.pathname = pathname;\n        parsedDestination.hash = `${hash ? '#' : ''}${hash || ''}`;\n        parsedDestination.search = destSearch ? compileNonPath(destSearch, args.params) : '';\n    } catch (err) {\n        if (err.message.match(/Expected .*? to not repeat, but got an array/)) {\n            throw Object.defineProperty(new Error(`To use a multi-match in the destination you must add \\`*\\` at the end of the param name to signify it should repeat. https://nextjs.org/docs/messages/invalid-multi-match`), \"__NEXT_ERROR_CODE\", {\n                value: \"E329\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        throw err;\n    }\n    // Query merge order lowest priority to highest\n    // 1. initial URL query values\n    // 2. path segment values\n    // 3. destination specified query values\n    parsedDestination.query = {\n        ...args.query,\n        ...parsedDestination.query\n    };\n    return {\n        newUrl,\n        destQuery,\n        parsedDestination\n    };\n}\n\n//# sourceMappingURL=prepare-destination.js.map","/**\n * Based on https://github.com/facebook/react/blob/d4e78c42a94be027b4dc7ed2659a5fddfbf9bd4e/packages/react/src/ReactFetch.js\n */ import * as React from 'react';\nimport { cloneResponse } from './clone-response';\nimport { InvariantError } from '../../shared/lib/invariant-error';\nconst simpleCacheKey = '[\"GET\",[],null,\"follow\",null,null,null,null]' // generateCacheKey(new Request('https://blank'));\n;\n// Headers that should not affect deduplication\n// traceparent and tracestate are used for distributed tracing and should not affect cache keys\nconst headersToExcludeInCacheKey = new Set([\n    'traceparent',\n    'tracestate'\n]);\nfunction generateCacheKey(request) {\n    // We pick the fields that goes into the key used to dedupe requests.\n    // We don't include the `cache` field, because we end up using whatever\n    // caching resulted from the first request.\n    // Notably we currently don't consider non-standard (or future) options.\n    // This might not be safe. TODO: warn for non-standard extensions differing.\n    // IF YOU CHANGE THIS UPDATE THE simpleCacheKey ABOVE.\n    const filteredHeaders = Array.from(request.headers.entries()).filter(([key])=>!headersToExcludeInCacheKey.has(key.toLowerCase()));\n    return JSON.stringify([\n        request.method,\n        filteredHeaders,\n        request.mode,\n        request.redirect,\n        request.credentials,\n        request.referrer,\n        request.referrerPolicy,\n        request.integrity\n    ]);\n}\nexport function createDedupeFetch(originalFetch) {\n    const getCacheEntries = React.cache(// eslint-disable-next-line @typescript-eslint/no-unused-vars -- url is the cache key\n    (url)=>[]);\n    return function dedupeFetch(resource, options) {\n        if (options && options.signal) {\n            // If we're passed a signal, then we assume that\n            // someone else controls the lifetime of this object and opts out of\n            // caching. It's effectively the opt-out mechanism.\n            // Ideally we should be able to check this on the Request but\n            // it always gets initialized with its own signal so we don't\n            // know if it's supposed to override - unless we also override the\n            // Request constructor.\n            return originalFetch(resource, options);\n        }\n        // Normalize the Request\n        let url;\n        let cacheKey;\n        if (typeof resource === 'string' && !options) {\n            // Fast path.\n            cacheKey = simpleCacheKey;\n            url = resource;\n        } else {\n            // Normalize the request.\n            // if resource is not a string or a URL (its an instance of Request)\n            // then do not instantiate a new Request but instead\n            // reuse the request as to not disturb the body in the event it's a ReadableStream.\n            const request = typeof resource === 'string' || resource instanceof URL ? new Request(resource, options) : resource;\n            if (request.method !== 'GET' && request.method !== 'HEAD' || request.keepalive) {\n                // We currently don't dedupe requests that might have side-effects. Those\n                // have to be explicitly cached. We assume that the request doesn't have a\n                // body if it's GET or HEAD.\n                // keepalive gets treated the same as if you passed a custom cache signal.\n                return originalFetch(resource, options);\n            }\n            cacheKey = generateCacheKey(request);\n            url = request.url;\n        }\n        const cacheEntries = getCacheEntries(url);\n        for(let i = 0, j = cacheEntries.length; i < j; i += 1){\n            const [key, promise] = cacheEntries[i];\n            if (key === cacheKey) {\n                return promise.then(()=>{\n                    const response = cacheEntries[i][2];\n                    if (!response) throw Object.defineProperty(new InvariantError('No cached response'), \"__NEXT_ERROR_CODE\", {\n                        value: \"E579\",\n                        enumerable: false,\n                        configurable: true\n                    });\n                    // We're cloning the response using this utility because there exists\n                    // a bug in the undici library around response cloning. See the\n                    // following pull request for more details:\n                    // https://github.com/vercel/next.js/pull/73274\n                    const [cloned1, cloned2] = cloneResponse(response);\n                    cacheEntries[i][2] = cloned2;\n                    return cloned1;\n                });\n            }\n        }\n        // We pass the original arguments here in case normalizing the Request\n        // doesn't include all the options in this environment.\n        const promise = originalFetch(resource, options);\n        const entry = [\n            cacheKey,\n            promise,\n            null\n        ];\n        cacheEntries.push(entry);\n        return promise.then((response)=>{\n            // We're cloning the response using this utility because there exists\n            // a bug in the undici library around response cloning. See the\n            // following pull request for more details:\n            // https://github.com/vercel/next.js/pull/73274\n            const [cloned1, cloned2] = cloneResponse(response);\n            entry[2] = cloned2;\n            return cloned1;\n        });\n    };\n}\n\n//# sourceMappingURL=dedupe-fetch.js.map","import { InvariantError } from '../../shared/lib/invariant-error';\nimport { normalizeAppPath } from '../../shared/lib/router/utils/app-paths';\nimport { pathHasPrefix } from '../../shared/lib/router/utils/path-has-prefix';\nimport { removePathPrefix } from '../../shared/lib/router/utils/remove-path-prefix';\nimport { workAsyncStorage } from './work-async-storage.external';\n// This is a global singleton that is, among other things, also used to\n// encode/decode bound args of server function closures. This can't be using a\n// AsyncLocalStorage as it might happen at the module level.\nconst MANIFESTS_SINGLETON = Symbol.for('next.server.manifests');\nconst globalThisWithManifests = globalThis;\nfunction createProxiedClientReferenceManifest(clientReferenceManifestsPerRoute) {\n    const createMappingProxy = (prop)=>{\n        return new Proxy({}, {\n            get (_, id) {\n                const workStore = workAsyncStorage.getStore();\n                if (workStore) {\n                    const currentManifest = clientReferenceManifestsPerRoute.get(workStore.route);\n                    if (currentManifest == null ? void 0 : currentManifest[prop][id]) {\n                        return currentManifest[prop][id];\n                    }\n                    // In development, we also check all other manifests to see if the\n                    // module exists there. This is to support a scenario where React's\n                    // I/O tracking (dev-only) creates a connection from one page to\n                    // another through an emitted async I/O node that references client\n                    // components from the other page, e.g. in owner props.\n                    // TODO: Maybe we need to add a `debugBundlerConfig` option to React\n                    // to avoid this workaround. The current workaround has the\n                    // disadvantage that one might accidentally or intentionally share\n                    // client references across pages (e.g. by storing them in a global\n                    // variable), which would then only be caught in production.\n                    if (process.env.NODE_ENV !== 'production') {\n                        for (const [route, manifest] of clientReferenceManifestsPerRoute){\n                            if (route === workStore.route) {\n                                continue;\n                            }\n                            const entry = manifest[prop][id];\n                            if (entry !== undefined) {\n                                return entry;\n                            }\n                        }\n                    }\n                } else {\n                    // If there's no work store defined, we can assume that a client\n                    // reference manifest is needed during module evaluation, e.g. to\n                    // create a server function using a higher-order function. This\n                    // might also use client components which need to be serialized by\n                    // Flight, and therefore client references need to be resolvable. In\n                    // that case we search all page manifests to find the module.\n                    for (const manifest of clientReferenceManifestsPerRoute.values()){\n                        const entry = manifest[prop][id];\n                        if (entry !== undefined) {\n                            return entry;\n                        }\n                    }\n                }\n                return undefined;\n            }\n        });\n    };\n    const mappingProxies = new Map();\n    return new Proxy({}, {\n        get (_, prop) {\n            const workStore = workAsyncStorage.getStore();\n            switch(prop){\n                case 'moduleLoading':\n                case 'entryCSSFiles':\n                case 'entryJSFiles':\n                    {\n                        if (!workStore) {\n                            throw Object.defineProperty(new InvariantError(`Cannot access \"${prop}\" without a work store.`), \"__NEXT_ERROR_CODE\", {\n                                value: \"E952\",\n                                enumerable: false,\n                                configurable: true\n                            });\n                        }\n                        const currentManifest = clientReferenceManifestsPerRoute.get(workStore.route);\n                        if (!currentManifest) {\n                            throw Object.defineProperty(new InvariantError(`The client reference manifest for route \"${workStore.route}\" does not exist.`), \"__NEXT_ERROR_CODE\", {\n                                value: \"E951\",\n                                enumerable: false,\n                                configurable: true\n                            });\n                        }\n                        return currentManifest[prop];\n                    }\n                case 'clientModules':\n                case 'rscModuleMapping':\n                case 'edgeRscModuleMapping':\n                case 'ssrModuleMapping':\n                case 'edgeSSRModuleMapping':\n                    {\n                        let proxy = mappingProxies.get(prop);\n                        if (!proxy) {\n                            proxy = createMappingProxy(prop);\n                            mappingProxies.set(prop, proxy);\n                        }\n                        return proxy;\n                    }\n                default:\n                    {\n                        throw Object.defineProperty(new InvariantError(`This is a proxied client reference manifest. The property \"${String(prop)}\" is not handled.`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E953\",\n                            enumerable: false,\n                            configurable: true\n                        });\n                    }\n            }\n        }\n    });\n}\n/**\n * This function creates a Flight-acceptable server module map proxy from our\n * Server Reference Manifest similar to our client module map. This is because\n * our manifest contains a lot of internal Next.js data that are relevant to the\n * runtime, workers, etc. that React doesn't need to know.\n */ function createServerModuleMap() {\n    return new Proxy({}, {\n        get: (_, id)=>{\n            var _getServerActionsManifest__id, _getServerActionsManifest_;\n            const workers = (_getServerActionsManifest_ = getServerActionsManifest()[process.env.NEXT_RUNTIME === 'edge' ? 'edge' : 'node']) == null ? void 0 : (_getServerActionsManifest__id = _getServerActionsManifest_[id]) == null ? void 0 : _getServerActionsManifest__id.workers;\n            if (!workers) {\n                return undefined;\n            }\n            const workStore = workAsyncStorage.getStore();\n            let workerEntry;\n            if (workStore) {\n                workerEntry = workers[normalizeWorkerPageName(workStore.page)];\n            } else {\n                // If there's no work store defined, we can assume that a server\n                // module map is needed during module evaluation, e.g. to create a\n                // server action using a higher-order function. Therefore it should be\n                // safe to return any entry from the manifest that matches the action\n                // ID. They all refer to the same module ID, which must also exist in\n                // the current page bundle. TODO: This is currently not guaranteed in\n                // Turbopack, and needs to be fixed.\n                workerEntry = Object.values(workers).at(0);\n            }\n            if (!workerEntry) {\n                return undefined;\n            }\n            const { moduleId, async } = workerEntry;\n            return {\n                id: moduleId,\n                name: id,\n                chunks: [],\n                async\n            };\n        }\n    });\n}\n/**\n * The flight entry loader keys actions by bundlePath. bundlePath corresponds\n * with the relative path (including 'app') to the page entrypoint.\n */ function normalizeWorkerPageName(pageName) {\n    if (pathHasPrefix(pageName, 'app')) {\n        return pageName;\n    }\n    return 'app' + pageName;\n}\n/**\n * Converts a bundlePath (relative path to the entrypoint) to a routable page\n * name.\n */ function denormalizeWorkerPageName(bundlePath) {\n    return normalizeAppPath(removePathPrefix(bundlePath, 'app'));\n}\n/**\n * Checks if the requested action has a worker for the current page.\n * If not, it returns the first worker that has a handler for the action.\n */ export function selectWorkerForForwarding(actionId, pageName) {\n    var _serverActionsManifest__actionId;\n    const serverActionsManifest = getServerActionsManifest();\n    const workers = (_serverActionsManifest__actionId = serverActionsManifest[process.env.NEXT_RUNTIME === 'edge' ? 'edge' : 'node'][actionId]) == null ? void 0 : _serverActionsManifest__actionId.workers;\n    // There are no workers to handle this action, nothing to forward to.\n    if (!workers) {\n        return;\n    }\n    // If there is an entry for the current page, we don't need to forward.\n    if (workers[normalizeWorkerPageName(pageName)]) {\n        return;\n    }\n    // Otherwise, grab the first worker that has a handler for this action id.\n    return denormalizeWorkerPageName(Object.keys(workers)[0]);\n}\nexport function setManifestsSingleton({ page, clientReferenceManifest, serverActionsManifest }) {\n    const existingSingleton = globalThisWithManifests[MANIFESTS_SINGLETON];\n    if (existingSingleton) {\n        existingSingleton.clientReferenceManifestsPerRoute.set(normalizeAppPath(page), clientReferenceManifest);\n        existingSingleton.serverActionsManifest = serverActionsManifest;\n    } else {\n        const clientReferenceManifestsPerRoute = new Map([\n            [\n                normalizeAppPath(page),\n                clientReferenceManifest\n            ]\n        ]);\n        const proxiedClientReferenceManifest = createProxiedClientReferenceManifest(clientReferenceManifestsPerRoute);\n        globalThisWithManifests[MANIFESTS_SINGLETON] = {\n            clientReferenceManifestsPerRoute,\n            proxiedClientReferenceManifest,\n            serverActionsManifest,\n            serverModuleMap: createServerModuleMap()\n        };\n    }\n}\nfunction getManifestsSingleton() {\n    const manifestSingleton = globalThisWithManifests[MANIFESTS_SINGLETON];\n    if (!manifestSingleton) {\n        throw Object.defineProperty(new InvariantError('The manifests singleton was not initialized.'), \"__NEXT_ERROR_CODE\", {\n            value: \"E950\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    return manifestSingleton;\n}\nexport function getClientReferenceManifest() {\n    return getManifestsSingleton().proxiedClientReferenceManifest;\n}\nexport function getServerActionsManifest() {\n    return getManifestsSingleton().serverActionsManifest;\n}\nexport function getServerModuleMap() {\n    return getManifestsSingleton().serverModuleMap;\n}\n\n//# sourceMappingURL=manifests-singleton.js.map","import { Batcher } from '../../lib/batcher';\nimport { LRUCache } from '../lib/lru-cache';\nimport { warnOnce } from '../../build/output/log';\nimport { scheduleOnNextTick } from '../../lib/scheduler';\nimport { fromResponseCacheEntry, routeKindToIncrementalCacheKind, toResponseCacheEntry } from './utils';\n/**\n * Parses an environment variable as a positive integer, returning the fallback\n * if the value is missing, not a number, or not positive.\n */ function parsePositiveInt(envValue, fallback) {\n    if (!envValue) return fallback;\n    const parsed = parseInt(envValue, 10);\n    return Number.isFinite(parsed) && parsed > 0 ? parsed : fallback;\n}\n/**\n * Default TTL (in milliseconds) for minimal mode response cache entries.\n * Used for cache hit validation as a fallback for providers that don't\n * send the x-invocation-id header yet.\n *\n * 10 seconds chosen because:\n * - Long enough to dedupe rapid successive requests (e.g., page + data)\n * - Short enough to not serve stale data across unrelated requests\n *\n * Can be configured via `NEXT_PRIVATE_RESPONSE_CACHE_TTL` environment variable.\n */ const DEFAULT_TTL_MS = parsePositiveInt(process.env.NEXT_PRIVATE_RESPONSE_CACHE_TTL, 10000);\n/**\n * Default maximum number of entries in the response cache.\n * Can be configured via `NEXT_PRIVATE_RESPONSE_CACHE_MAX_SIZE` environment variable.\n */ const DEFAULT_MAX_SIZE = parsePositiveInt(process.env.NEXT_PRIVATE_RESPONSE_CACHE_MAX_SIZE, 150);\n/**\n * Separator used in compound cache keys to join pathname and invocationID.\n * Using null byte (\\0) since it cannot appear in valid URL paths or UUIDs.\n */ const KEY_SEPARATOR = '\\0';\n/**\n * Sentinel value used for TTL-based cache entries (when invocationID is undefined).\n * Chosen to be a clearly reserved marker for internal cache keys.\n */ const TTL_SENTINEL = '__ttl_sentinel__';\n/**\n * Creates a compound cache key from pathname and invocationID.\n */ function createCacheKey(pathname, invocationID) {\n    return `${pathname}${KEY_SEPARATOR}${invocationID ?? TTL_SENTINEL}`;\n}\n/**\n * Extracts the invocationID from a compound cache key.\n * Returns undefined if the key used TTL_SENTINEL.\n */ function extractInvocationID(compoundKey) {\n    const separatorIndex = compoundKey.lastIndexOf(KEY_SEPARATOR);\n    if (separatorIndex === -1) return undefined;\n    const invocationID = compoundKey.slice(separatorIndex + 1);\n    return invocationID === TTL_SENTINEL ? undefined : invocationID;\n}\nexport * from './types';\nexport default class ResponseCache {\n    constructor(minimal_mode, maxSize = DEFAULT_MAX_SIZE, ttl = DEFAULT_TTL_MS){\n        this.getBatcher = Batcher.create({\n            // Ensure on-demand revalidate doesn't block normal requests, it should be\n            // safe to run an on-demand revalidate for the same key as a normal request.\n            cacheKeyFn: ({ key, isOnDemandRevalidate })=>`${key}-${isOnDemandRevalidate ? '1' : '0'}`,\n            // We wait to do any async work until after we've added our promise to\n            // `pendingResponses` to ensure that any any other calls will reuse the\n            // same promise until we've fully finished our work.\n            schedulerFn: scheduleOnNextTick\n        });\n        this.revalidateBatcher = Batcher.create({\n            // We wait to do any async work until after we've added our promise to\n            // `pendingResponses` to ensure that any any other calls will reuse the\n            // same promise until we've fully finished our work.\n            schedulerFn: scheduleOnNextTick\n        });\n        /**\n   * Set of invocation IDs that have had cache entries evicted.\n   * Used to detect when the cache size may be too small.\n   * Bounded to prevent memory growth.\n   */ this.evictedInvocationIDs = new Set();\n        this.minimal_mode = minimal_mode;\n        this.maxSize = maxSize;\n        this.ttl = ttl;\n        // Create the LRU cache with eviction tracking\n        this.cache = new LRUCache(maxSize, undefined, (compoundKey)=>{\n            const invocationID = extractInvocationID(compoundKey);\n            if (invocationID) {\n                // Bound to 100 entries to prevent unbounded memory growth.\n                // FIFO eviction is acceptable here because:\n                // 1. Invocations are short-lived (single request lifecycle), so older\n                //    invocations are unlikely to still be active after 100 newer ones\n                // 2. This warning mechanism is best-effort for developer guidance\n                //    missing occasional eviction warnings doesn't affect correctness\n                // 3. If a long-running invocation is somehow evicted and then has\n                //    another cache entry evicted, it will simply be re-added\n                if (this.evictedInvocationIDs.size >= 100) {\n                    const first = this.evictedInvocationIDs.values().next().value;\n                    if (first) this.evictedInvocationIDs.delete(first);\n                }\n                this.evictedInvocationIDs.add(invocationID);\n            }\n        });\n    }\n    /**\n   * Gets the response cache entry for the given key.\n   *\n   * @param key - The key to get the response cache entry for.\n   * @param responseGenerator - The response generator to use to generate the response cache entry.\n   * @param context - The context for the get request.\n   * @returns The response cache entry.\n   */ async get(key, responseGenerator, context) {\n        // If there is no key for the cache, we can't possibly look this up in the\n        // cache so just return the result of the response generator.\n        if (!key) {\n            return responseGenerator({\n                hasResolved: false,\n                previousCacheEntry: null\n            });\n        }\n        // Check minimal mode cache before doing any other work.\n        if (this.minimal_mode) {\n            const cacheKey = createCacheKey(key, context.invocationID);\n            const cachedItem = this.cache.get(cacheKey);\n            if (cachedItem) {\n                // With invocationID: exact match found - always a hit\n                // With TTL mode: must check expiration\n                if (context.invocationID !== undefined) {\n                    return toResponseCacheEntry(cachedItem.entry);\n                }\n                // TTL mode: check expiration\n                const now = Date.now();\n                if (cachedItem.expiresAt > now) {\n                    return toResponseCacheEntry(cachedItem.entry);\n                }\n                // TTL expired - clean up\n                this.cache.remove(cacheKey);\n            }\n            // Warn if this invocation had entries evicted - indicates cache may be too small.\n            if (context.invocationID && this.evictedInvocationIDs.has(context.invocationID)) {\n                warnOnce(`Response cache entry was evicted for invocation ${context.invocationID}. ` + `Consider increasing NEXT_PRIVATE_RESPONSE_CACHE_MAX_SIZE (current: ${this.maxSize}).`);\n            }\n        }\n        const { incrementalCache, isOnDemandRevalidate = false, isFallback = false, isRoutePPREnabled = false, isPrefetch = false, waitUntil, routeKind, invocationID } = context;\n        const response = await this.getBatcher.batch({\n            key,\n            isOnDemandRevalidate\n        }, ({ resolve })=>{\n            const promise = this.handleGet(key, responseGenerator, {\n                incrementalCache,\n                isOnDemandRevalidate,\n                isFallback,\n                isRoutePPREnabled,\n                isPrefetch,\n                routeKind,\n                invocationID\n            }, resolve);\n            // We need to ensure background revalidates are passed to waitUntil.\n            if (waitUntil) waitUntil(promise);\n            return promise;\n        });\n        return toResponseCacheEntry(response);\n    }\n    /**\n   * Handles the get request for the response cache.\n   *\n   * @param key - The key to get the response cache entry for.\n   * @param responseGenerator - The response generator to use to generate the response cache entry.\n   * @param context - The context for the get request.\n   * @param resolve - The resolve function to use to resolve the response cache entry.\n   * @returns The response cache entry.\n   */ async handleGet(key, responseGenerator, context, resolve) {\n        let previousIncrementalCacheEntry = null;\n        let resolved = false;\n        try {\n            // Get the previous cache entry if not in minimal mode\n            previousIncrementalCacheEntry = !this.minimal_mode ? await context.incrementalCache.get(key, {\n                kind: routeKindToIncrementalCacheKind(context.routeKind),\n                isRoutePPREnabled: context.isRoutePPREnabled,\n                isFallback: context.isFallback\n            }) : null;\n            if (previousIncrementalCacheEntry && !context.isOnDemandRevalidate) {\n                resolve(previousIncrementalCacheEntry);\n                resolved = true;\n                if (!previousIncrementalCacheEntry.isStale || context.isPrefetch) {\n                    // The cached value is still valid, so we don't need to update it yet.\n                    return previousIncrementalCacheEntry;\n                }\n            }\n            // Revalidate the cache entry\n            const incrementalResponseCacheEntry = await this.revalidate(key, context.incrementalCache, context.isRoutePPREnabled, context.isFallback, responseGenerator, previousIncrementalCacheEntry, previousIncrementalCacheEntry !== null && !context.isOnDemandRevalidate, undefined, context.invocationID);\n            // Handle null response\n            if (!incrementalResponseCacheEntry) {\n                // Remove the cache item if it was set so we don't use it again.\n                if (this.minimal_mode) {\n                    const cacheKey = createCacheKey(key, context.invocationID);\n                    this.cache.remove(cacheKey);\n                }\n                return null;\n            }\n            // Resolve for on-demand revalidation or if not already resolved\n            if (context.isOnDemandRevalidate && !resolved) {\n                return incrementalResponseCacheEntry;\n            }\n            return incrementalResponseCacheEntry;\n        } catch (err) {\n            // If we've already resolved the cache entry, we can't reject as we\n            // already resolved the cache entry so log the error here.\n            if (resolved) {\n                console.error(err);\n                return null;\n            }\n            throw err;\n        }\n    }\n    /**\n   * Revalidates the cache entry for the given key.\n   *\n   * @param key - The key to revalidate the cache entry for.\n   * @param incrementalCache - The incremental cache to use to revalidate the cache entry.\n   * @param isRoutePPREnabled - Whether the route is PPR enabled.\n   * @param isFallback - Whether the route is a fallback.\n   * @param responseGenerator - The response generator to use to generate the response cache entry.\n   * @param previousIncrementalCacheEntry - The previous cache entry to use to revalidate the cache entry.\n   * @param hasResolved - Whether the response has been resolved.\n   * @param waitUntil - Optional function to register background work.\n   * @param invocationID - The invocation ID for cache key scoping.\n   * @returns The revalidated cache entry.\n   */ async revalidate(key, incrementalCache, isRoutePPREnabled, isFallback, responseGenerator, previousIncrementalCacheEntry, hasResolved, waitUntil, invocationID) {\n        return this.revalidateBatcher.batch(key, ()=>{\n            const promise = this.handleRevalidate(key, incrementalCache, isRoutePPREnabled, isFallback, responseGenerator, previousIncrementalCacheEntry, hasResolved, invocationID);\n            // We need to ensure background revalidates are passed to waitUntil.\n            if (waitUntil) waitUntil(promise);\n            return promise;\n        });\n    }\n    async handleRevalidate(key, incrementalCache, isRoutePPREnabled, isFallback, responseGenerator, previousIncrementalCacheEntry, hasResolved, invocationID) {\n        try {\n            // Generate the response cache entry using the response generator.\n            const responseCacheEntry = await responseGenerator({\n                hasResolved,\n                previousCacheEntry: previousIncrementalCacheEntry,\n                isRevalidating: true\n            });\n            if (!responseCacheEntry) {\n                return null;\n            }\n            // Convert the response cache entry to an incremental response cache entry.\n            const incrementalResponseCacheEntry = await fromResponseCacheEntry({\n                ...responseCacheEntry,\n                isMiss: !previousIncrementalCacheEntry\n            });\n            // We want to persist the result only if it has a cache control value\n            // defined.\n            if (incrementalResponseCacheEntry.cacheControl) {\n                if (this.minimal_mode) {\n                    // Set TTL expiration for cache hit validation. Entries are validated\n                    // by invocationID when available, with TTL as a fallback for providers\n                    // that don't send x-invocation-id. Memory is managed by LRU eviction.\n                    const cacheKey = createCacheKey(key, invocationID);\n                    this.cache.set(cacheKey, {\n                        entry: incrementalResponseCacheEntry,\n                        expiresAt: Date.now() + this.ttl\n                    });\n                } else {\n                    await incrementalCache.set(key, incrementalResponseCacheEntry.value, {\n                        cacheControl: incrementalResponseCacheEntry.cacheControl,\n                        isRoutePPREnabled,\n                        isFallback\n                    });\n                }\n            }\n            return incrementalResponseCacheEntry;\n        } catch (err) {\n            // When a path is erroring we automatically re-set the existing cache\n            // with new revalidate and expire times to prevent non-stop retrying.\n            if (previousIncrementalCacheEntry == null ? void 0 : previousIncrementalCacheEntry.cacheControl) {\n                const revalidate = Math.min(Math.max(previousIncrementalCacheEntry.cacheControl.revalidate || 3, 3), 30);\n                const expire = previousIncrementalCacheEntry.cacheControl.expire === undefined ? undefined : Math.max(revalidate + 3, previousIncrementalCacheEntry.cacheControl.expire);\n                await incrementalCache.set(key, previousIncrementalCacheEntry.value, {\n                    cacheControl: {\n                        revalidate: revalidate,\n                        expire: expire\n                    },\n                    isRoutePPREnabled,\n                    isFallback\n                });\n            }\n            // We haven't resolved yet, so let's throw to indicate an error.\n            throw err;\n        }\n    }\n}\n\n//# sourceMappingURL=index.js.map","import { AfterContext } from '../after/after-context';\nimport { normalizeAppPath } from '../../shared/lib/router/utils/app-paths';\nimport { createLazyResult } from '../lib/lazy-result';\nimport { getCacheHandlerEntries } from '../use-cache/handlers';\nimport { createSnapshot } from '../app-render/async-local-storage';\nexport function createWorkStore({ page, renderOpts, isPrefetchRequest, buildId, previouslyRevalidatedTags, nonce }) {\n    /**\n   * Rules of Static & Dynamic HTML:\n   *\n   *    1.) We must generate static HTML unless the caller explicitly opts\n   *        in to dynamic HTML support.\n   *\n   *    2.) If dynamic HTML support is requested, we must honor that request\n   *        or throw an error. It is the sole responsibility of the caller to\n   *        ensure they aren't e.g. requesting dynamic HTML for a static page.\n   *\n   *    3.) If the request is in draft mode, we must generate dynamic HTML.\n   *\n   *    4.) If the request is a server action, we must generate dynamic HTML.\n   *\n   * These rules help ensure that other existing features like request caching,\n   * coalescing, and ISR continue working as intended.\n   */ const isStaticGeneration = !renderOpts.shouldWaitOnAllReady && !renderOpts.supportsDynamicResponse && !renderOpts.isDraftMode && !renderOpts.isPossibleServerAction;\n    const isDevelopment = renderOpts.dev ?? false;\n    const shouldTrackFetchMetrics = isDevelopment || // The only times we want to track fetch metrics outside of development is\n    // when we are performing a static generation and we either are in debug\n    // mode, or tracking fetch metrics was specifically opted into.\n    isStaticGeneration && (!!process.env.NEXT_DEBUG_BUILD || process.env.NEXT_SSG_FETCH_METRICS === '1');\n    const store = {\n        isStaticGeneration,\n        page,\n        route: normalizeAppPath(page),\n        incrementalCache: // we fallback to a global incremental cache for edge-runtime locally\n        // so that it can access the fs cache without mocks\n        renderOpts.incrementalCache || globalThis.__incrementalCache,\n        cacheLifeProfiles: renderOpts.cacheLifeProfiles,\n        isBuildTimePrerendering: renderOpts.nextExport,\n        hasReadableErrorStacks: renderOpts.hasReadableErrorStacks,\n        fetchCache: renderOpts.fetchCache,\n        isOnDemandRevalidate: renderOpts.isOnDemandRevalidate,\n        isDraftMode: renderOpts.isDraftMode,\n        isPrefetchRequest,\n        buildId,\n        reactLoadableManifest: (renderOpts == null ? void 0 : renderOpts.reactLoadableManifest) || {},\n        assetPrefix: (renderOpts == null ? void 0 : renderOpts.assetPrefix) || '',\n        nonce,\n        afterContext: createAfterContext(renderOpts),\n        cacheComponentsEnabled: renderOpts.cacheComponents,\n        dev: isDevelopment,\n        previouslyRevalidatedTags,\n        refreshTagsByCacheKind: createRefreshTagsByCacheKind(),\n        runInCleanSnapshot: createSnapshot(),\n        shouldTrackFetchMetrics,\n        reactServerErrorsByDigest: new Map()\n    };\n    // TODO: remove this when we resolve accessing the store outside the execution context\n    renderOpts.store = store;\n    return store;\n}\nfunction createAfterContext(renderOpts) {\n    const { waitUntil, onClose, onAfterTaskError } = renderOpts;\n    return new AfterContext({\n        waitUntil,\n        onClose,\n        onTaskError: onAfterTaskError\n    });\n}\n/**\n * Creates a map with lazy results that refresh tags for the respective cache\n * kind when they're awaited for the first time.\n */ function createRefreshTagsByCacheKind() {\n    const refreshTagsByCacheKind = new Map();\n    const cacheHandlers = getCacheHandlerEntries();\n    if (cacheHandlers) {\n        for (const [kind, cacheHandler] of cacheHandlers){\n            if ('refreshTags' in cacheHandler) {\n                refreshTagsByCacheKind.set(kind, createLazyResult(async ()=>cacheHandler.refreshTags()));\n            }\n        }\n    }\n    return refreshTagsByCacheKind;\n}\n\n//# sourceMappingURL=work-store.js.map","import { ResponseAbortedName, createAbortController } from './web/spec-extension/adapters/next-request';\nimport { DetachedPromise } from '../lib/detached-promise';\nimport { getTracer } from './lib/trace/tracer';\nimport { NextNodeServerSpan } from './lib/trace/constants';\nimport { getClientComponentLoaderMetrics } from './client-component-renderer-logger';\nexport function isAbortError(e) {\n    return (e == null ? void 0 : e.name) === 'AbortError' || (e == null ? void 0 : e.name) === ResponseAbortedName;\n}\nfunction createWriterFromResponse(res, waitUntilForEnd) {\n    let started = false;\n    // Create a promise that will resolve once the response has drained. See\n    // https://nodejs.org/api/stream.html#stream_event_drain\n    let drained = new DetachedPromise();\n    function onDrain() {\n        drained.resolve();\n    }\n    res.on('drain', onDrain);\n    // If the finish event fires, it means we shouldn't block and wait for the\n    // drain event.\n    res.once('close', ()=>{\n        res.off('drain', onDrain);\n        drained.resolve();\n    });\n    // Create a promise that will resolve once the response has finished. See\n    // https://nodejs.org/api/http.html#event-finish_1\n    const finished = new DetachedPromise();\n    res.once('finish', ()=>{\n        finished.resolve();\n    });\n    // Create a writable stream that will write to the response.\n    return new WritableStream({\n        write: async (chunk)=>{\n            // You'd think we'd want to use `start` instead of placing this in `write`\n            // but this ensures that we don't actually flush the headers until we've\n            // started writing chunks.\n            if (!started) {\n                started = true;\n                if ('performance' in globalThis && process.env.NEXT_OTEL_PERFORMANCE_PREFIX) {\n                    const metrics = getClientComponentLoaderMetrics();\n                    if (metrics) {\n                        performance.measure(`${process.env.NEXT_OTEL_PERFORMANCE_PREFIX}:next-client-component-loading`, {\n                            start: metrics.clientComponentLoadStart,\n                            end: metrics.clientComponentLoadStart + metrics.clientComponentLoadTimes\n                        });\n                    }\n                }\n                res.flushHeaders();\n                getTracer().trace(NextNodeServerSpan.startResponse, {\n                    spanName: 'start response'\n                }, ()=>undefined);\n            }\n            try {\n                const ok = res.write(chunk);\n                // Added by the `compression` middleware, this is a function that will\n                // flush the partially-compressed response to the client.\n                if ('flush' in res && typeof res.flush === 'function') {\n                    res.flush();\n                }\n                // If the write returns false, it means there's some backpressure, so\n                // wait until it's streamed before continuing.\n                if (!ok) {\n                    await drained.promise;\n                    // Reset the drained promise so that we can wait for the next drain event.\n                    drained = new DetachedPromise();\n                }\n            } catch (err) {\n                res.end();\n                throw Object.defineProperty(new Error('failed to write chunk to response', {\n                    cause: err\n                }), \"__NEXT_ERROR_CODE\", {\n                    value: \"E321\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n        },\n        abort: (err)=>{\n            if (res.writableFinished) return;\n            res.destroy(err);\n        },\n        close: async ()=>{\n            // if a waitUntil promise was passed, wait for it to resolve before\n            // ending the response.\n            if (waitUntilForEnd) {\n                await waitUntilForEnd;\n            }\n            if (res.writableFinished) return;\n            res.end();\n            return finished.promise;\n        }\n    });\n}\nexport async function pipeToNodeResponse(readable, res, waitUntilForEnd) {\n    try {\n        // If the response has already errored, then just return now.\n        const { errored, destroyed } = res;\n        if (errored || destroyed) return;\n        // Create a new AbortController so that we can abort the readable if the\n        // client disconnects.\n        const controller = createAbortController(res);\n        const writer = createWriterFromResponse(res, waitUntilForEnd);\n        await readable.pipeTo(writer, {\n            signal: controller.signal\n        });\n    } catch (err) {\n        // If this isn't related to an abort error, re-throw it.\n        if (isAbortError(err)) return;\n        throw Object.defineProperty(new Error('failed to pipe response', {\n            cause: err\n        }), \"__NEXT_ERROR_CODE\", {\n            value: \"E180\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n}\n\n//# sourceMappingURL=pipe-readable.js.map","/**\n * Check to see if a value is Thenable.\n *\n * @param promise the maybe-thenable value\n * @returns true if the value is thenable\n */ export function isThenable(promise) {\n    return promise !== null && typeof promise === 'object' && 'then' in promise && typeof promise.then === 'function';\n}\n\n//# sourceMappingURL=is-thenable.js.map","import path from '../shared/lib/isomorphic/path';\n/**\n * MultiFileWriter is a utility for writing multiple files in parallel that\n * guarantees that all files will be written after their containing directory\n * is created, and that the directory will only be created once.\n */ export class MultiFileWriter {\n    constructor(/**\n     * The file system methods to use.\n     */ fs){\n        this.fs = fs;\n        this.tasks = [];\n    }\n    /**\n   * Finds or creates a task for a directory.\n   *\n   * @param directory - The directory to find or create a task for.\n   * @returns The task for the directory.\n   */ findOrCreateTask(directory) {\n        // See if this directory already has a task to create it.\n        for (const task of this.tasks){\n            if (task[0] === directory) {\n                return task;\n            }\n        }\n        const promise = this.fs.mkdir(directory);\n        // Attach a catch handler so that it doesn't throw an unhandled promise\n        // rejection warning.\n        promise.catch(()=>{});\n        // Otherwise, create a new task for this directory.\n        const task = [\n            directory,\n            promise,\n            []\n        ];\n        this.tasks.push(task);\n        return task;\n    }\n    /**\n   * Appends a file to the writer to be written after its containing directory\n   * is created. The file writer should be awaited after all the files have been\n   * appended. Any async operation that occurs between appending and awaiting\n   * may cause an unhandled promise rejection warning and potentially crash the\n   * process.\n   *\n   * @param filePath - The path to the file to write.\n   * @param data - The data to write to the file.\n   */ append(filePath, data) {\n        // Find or create a task for the directory that contains the file.\n        const task = this.findOrCreateTask(path.dirname(filePath));\n        const promise = task[1].then(()=>this.fs.writeFile(filePath, data));\n        // Attach a catch handler so that it doesn't throw an unhandled promise\n        // rejection warning.\n        promise.catch(()=>{});\n        // Add the file write to the task AFTER the directory promise has resolved.\n        task[2].push(promise);\n    }\n    /**\n   * Returns a promise that resolves when all the files have been written.\n   */ wait() {\n        return Promise.all(this.tasks.flatMap((task)=>task[2]));\n    }\n}\n\n//# sourceMappingURL=multi-file-writer.js.map","/**\n * Decodes a query path parameter.\n *\n * @param value - The value to decode.\n * @returns The decoded value.\n */ export function decodeQueryPathParameter(value) {\n    // When deployed to Vercel, the value may be encoded, so this attempts to\n    // decode it and returns the original value if it fails.\n    try {\n        return decodeURIComponent(value);\n    } catch  {\n        return value;\n    }\n}\n\n//# sourceMappingURL=decode-query-path-parameter.js.map","/**\n * Takes an object with a hostname property (like a parsed URL) and some\n * headers that may contain Host and returns the preferred hostname.\n * @param parsed An object containing a hostname property.\n * @param headers A dictionary with headers containing a `host`.\n */ export function getHostname(parsed, headers) {\n    // Get the hostname from the headers if it exists, otherwise use the parsed\n    // hostname.\n    let hostname;\n    if (headers?.host && !Array.isArray(headers.host)) {\n        hostname = headers.host.toString().split(':', 1)[0];\n    } else if (parsed.hostname) {\n        hostname = parsed.hostname;\n    } else return;\n    return hostname.toLowerCase();\n}\n\n//# sourceMappingURL=get-hostname.js.map","/**\n * A `Promise.withResolvers` implementation that exposes the `resolve` and\n * `reject` functions on a `Promise`.\n *\n * @see https://tc39.es/proposal-promise-with-resolvers/\n */ export class DetachedPromise {\n    constructor(){\n        let resolve;\n        let reject;\n        // Create the promise and assign the resolvers to the object.\n        this.promise = new Promise((res, rej)=>{\n            resolve = res;\n            reject = rej;\n        });\n        // We know that resolvers is defined because the Promise constructor runs\n        // synchronously.\n        this.resolve = resolve;\n        this.reject = reject;\n    }\n}\n\n//# sourceMappingURL=detached-promise.js.map","/**\n * Schedules a function to be called on the next tick after the other promises\n * have been resolved.\n *\n * @param cb the function to schedule\n */ export const scheduleOnNextTick = (cb)=>{\n    // We use Promise.resolve().then() here so that the operation is scheduled at\n    // the end of the promise job queue, we then add it to the next process tick\n    // to ensure it's evaluated afterwards.\n    //\n    // This was inspired by the implementation of the DataLoader interface: https://github.com/graphql/dataloader/blob/d336bd15282664e0be4b4a657cb796f09bafbc6b/src/index.js#L213-L255\n    //\n    Promise.resolve().then(()=>{\n        if (process.env.NEXT_RUNTIME === 'edge') {\n            setTimeout(cb, 0);\n        } else {\n            process.nextTick(cb);\n        }\n    });\n};\n/**\n * Schedules a function to be called using `setImmediate` or `setTimeout` if\n * `setImmediate` is not available (like in the Edge runtime).\n *\n * @param cb the function to schedule\n */ export const scheduleImmediate = (cb)=>{\n    if (process.env.NEXT_RUNTIME === 'edge') {\n        setTimeout(cb, 0);\n    } else {\n        setImmediate(cb);\n    }\n};\n/**\n * returns a promise than resolves in a future task. There is no guarantee that the task it resolves in\n * will be the next task but if you await it you can at least be sure that the current task is over and\n * most usefully that the entire microtask queue of the current task has been emptied.\n */ export function atLeastOneTask() {\n    return new Promise((resolve)=>scheduleImmediate(resolve));\n}\n/**\n * This utility function is extracted to make it easier to find places where we are doing\n * specific timing tricks to try to schedule work after React has rendered. This is especially\n * important at the moment because Next.js uses the edge builds of React which use setTimeout to\n * schedule work when you might expect that something like setImmediate would do the trick.\n *\n * Long term we should switch to the node versions of React rendering when possible and then\n * update this to use setImmediate rather than setTimeout\n */ export function waitAtLeastOneReactRenderTask() {\n    if (process.env.NEXT_RUNTIME === 'edge') {\n        return new Promise((r)=>setTimeout(r, 0));\n    } else {\n        return new Promise((r)=>setImmediate(r));\n    }\n}\n\n//# sourceMappingURL=scheduler.js.map","import { parsePath } from './parse-path';\n/**\n * Similarly to `addPathPrefix`, this function adds a suffix at the end on the\n * provided path. It also works only for paths ensuring the argument starts\n * with a slash.\n */ export function addPathSuffix(path, suffix) {\n    if (!path.startsWith('/') || !suffix) {\n        return path;\n    }\n    const { pathname, query, hash } = parsePath(path);\n    return `${pathname}${suffix}${query}${hash}`;\n}\n\n//# sourceMappingURL=add-path-suffix.js.map","import { FLIGHT_HEADERS } from '../../client/components/app-router-headers';\nimport { HeadersAdapter } from '../web/spec-extension/adapters/headers';\nimport { MutableRequestCookiesAdapter, RequestCookiesAdapter, responseCookiesToRequestCookies, createCookiesWithMutableAccessCheck } from '../web/spec-extension/adapters/request-cookies';\nimport { ResponseCookies, RequestCookies } from '../web/spec-extension/cookies';\nimport { DraftModeProvider } from './draft-mode-provider';\nimport { splitCookiesString } from '../web/utils';\nfunction getHeaders(headers) {\n    const cleaned = HeadersAdapter.from(headers);\n    for (const header of FLIGHT_HEADERS){\n        cleaned.delete(header);\n    }\n    return HeadersAdapter.seal(cleaned);\n}\nfunction getMutableCookies(headers, onUpdateCookies) {\n    const cookies = new RequestCookies(HeadersAdapter.from(headers));\n    return MutableRequestCookiesAdapter.wrap(cookies, onUpdateCookies);\n}\n/**\n * If middleware set cookies in this request (indicated by `x-middleware-set-cookie`),\n * then merge those into the existing cookie object, so that when `cookies()` is accessed\n * it's able to read the newly set cookies.\n */ function mergeMiddlewareCookies(req, existingCookies) {\n    if ('x-middleware-set-cookie' in req.headers && typeof req.headers['x-middleware-set-cookie'] === 'string') {\n        const setCookieValue = req.headers['x-middleware-set-cookie'];\n        const responseHeaders = new Headers();\n        for (const cookie of splitCookiesString(setCookieValue)){\n            responseHeaders.append('set-cookie', cookie);\n        }\n        const responseCookies = new ResponseCookies(responseHeaders);\n        // Transfer cookies from ResponseCookies to RequestCookies\n        for (const cookie of responseCookies.getAll()){\n            existingCookies.set(cookie);\n        }\n    }\n}\nexport function createRequestStoreForRender(req, res, url, rootParams, implicitTags, onUpdateCookies, previewProps, isHmrRefresh, serverComponentsHmrCache, renderResumeDataCache, devFallbackParams) {\n    return createRequestStoreImpl(// Pages start in render phase by default\n    'render', req, res, url, rootParams, implicitTags, onUpdateCookies, renderResumeDataCache, previewProps, isHmrRefresh, serverComponentsHmrCache, devFallbackParams);\n}\nexport function createRequestStoreForAPI(req, url, implicitTags, onUpdateCookies, previewProps) {\n    return createRequestStoreImpl(// API routes start in action phase by default\n    'action', req, undefined, url, {}, implicitTags, onUpdateCookies, null, previewProps, false, undefined, null);\n}\nfunction createRequestStoreImpl(phase, req, res, url, rootParams, implicitTags, onUpdateCookies, renderResumeDataCache, previewProps, isHmrRefresh, serverComponentsHmrCache, devFallbackParams) {\n    function defaultOnUpdateCookies(cookies) {\n        if (res) {\n            res.setHeader('Set-Cookie', cookies);\n        }\n    }\n    const cache = {};\n    return {\n        type: 'request',\n        phase,\n        implicitTags,\n        // Rather than just using the whole `url` here, we pull the parts we want\n        // to ensure we don't use parts of the URL that we shouldn't. This also\n        // lets us avoid requiring an empty string for `search` in the type.\n        url: {\n            pathname: url.pathname,\n            search: url.search ?? ''\n        },\n        rootParams,\n        get headers () {\n            if (!cache.headers) {\n                // Seal the headers object that'll freeze out any methods that could\n                // mutate the underlying data.\n                cache.headers = getHeaders(req.headers);\n            }\n            return cache.headers;\n        },\n        get cookies () {\n            if (!cache.cookies) {\n                // if middleware is setting cookie(s), then include those in\n                // the initial cached cookies so they can be read in render\n                const requestCookies = new RequestCookies(HeadersAdapter.from(req.headers));\n                mergeMiddlewareCookies(req, requestCookies);\n                // Seal the cookies object that'll freeze out any methods that could\n                // mutate the underlying data.\n                cache.cookies = RequestCookiesAdapter.seal(requestCookies);\n            }\n            return cache.cookies;\n        },\n        set cookies (value){\n            cache.cookies = value;\n        },\n        get mutableCookies () {\n            if (!cache.mutableCookies) {\n                const mutableCookies = getMutableCookies(req.headers, onUpdateCookies || (res ? defaultOnUpdateCookies : undefined));\n                mergeMiddlewareCookies(req, mutableCookies);\n                cache.mutableCookies = mutableCookies;\n            }\n            return cache.mutableCookies;\n        },\n        get userspaceMutableCookies () {\n            if (!cache.userspaceMutableCookies) {\n                const userspaceMutableCookies = createCookiesWithMutableAccessCheck(this);\n                cache.userspaceMutableCookies = userspaceMutableCookies;\n            }\n            return cache.userspaceMutableCookies;\n        },\n        get draftMode () {\n            if (!cache.draftMode) {\n                cache.draftMode = new DraftModeProvider(previewProps, req, this.cookies, this.mutableCookies);\n            }\n            return cache.draftMode;\n        },\n        renderResumeDataCache: renderResumeDataCache ?? null,\n        isHmrRefresh,\n        serverComponentsHmrCache: serverComponentsHmrCache || globalThis.__serverComponentsHmrCache,\n        devFallbackParams\n    };\n}\nexport function synchronizeMutableCookies(store) {\n    // TODO: does this need to update headers as well?\n    store.cookies = RequestCookiesAdapter.seal(responseCookiesToRequestCookies(store.mutableCookies));\n}\n\n//# sourceMappingURL=request-store.js.map","import { addPathPrefix } from './add-path-prefix';\nimport { pathHasPrefix } from './path-has-prefix';\n/**\n * For a given path and a locale, if the locale is given, it will prefix the\n * locale. The path shouldn't be an API path. If a default locale is given the\n * prefix will be omitted if the locale is already the default locale.\n */ export function addLocale(path, locale, defaultLocale, ignorePrefix) {\n    // If no locale was given or the locale is the default locale, we don't need\n    // to prefix the path.\n    if (!locale || locale === defaultLocale) return path;\n    const lower = path.toLowerCase();\n    // If the path is an API path or the path already has the locale prefix, we\n    // don't need to prefix the path.\n    if (!ignorePrefix) {\n        if (pathHasPrefix(lower, '/api')) return path;\n        if (pathHasPrefix(lower, `/${locale.toLowerCase()}`)) return path;\n    }\n    // Add the locale prefix to the path.\n    return addPathPrefix(path, `/${locale}`);\n}\n\n//# sourceMappingURL=add-locale.js.map","/**\n * Removes the trailing slash for a given route or page path. Preserves the\n * root page. Examples:\n *   - `/foo/bar/` -> `/foo/bar`\n *   - `/foo/bar` -> `/foo/bar`\n *   - `/` -> `/`\n */ export function removeTrailingSlash(route) {\n    return route.replace(/\\/$/, '') || '/';\n}\n\n//# sourceMappingURL=remove-trailing-slash.js.map","// http://www.cse.yorku.ca/~oz/hash.html\n// More specifically, 32-bit hash via djbxor\n// (ref: https://gist.github.com/eplawless/52813b1d8ad9af510d85?permalink_comment_id=3367765#gistcomment-3367765)\n// This is due to number type differences between rust for turbopack to js number types,\n// where rust does not have easy way to repreesnt js's 53-bit float number type for the matching\n// overflow behavior. This is more `correct` in terms of having canonical hash across different runtime / implementation\n// as can gaurantee determinstic output from 32bit hash.\nexport function djb2Hash(str) {\n    let hash = 5381;\n    for(let i = 0; i < str.length; i++){\n        const char = str.charCodeAt(i);\n        hash = (hash << 5) + hash + char & 0xffffffff;\n    }\n    return hash >>> 0;\n}\nexport function hexHash(str) {\n    return djb2Hash(str).toString(36).slice(0, 5);\n}\n\n//# sourceMappingURL=hash.js.map","// Share the instance module in the next-shared layer\nimport { workUnitAsyncStorageInstance } from './work-unit-async-storage-instance' with {\n    'turbopack-transition': 'next-shared'\n};\nimport { NEXT_HMR_REFRESH_HASH_COOKIE } from '../../client/components/app-router-headers';\nimport { InvariantError } from '../../shared/lib/invariant-error';\nexport { workUnitAsyncStorageInstance as workUnitAsyncStorage };\nexport function throwForMissingRequestStore(callingExpression) {\n    throw Object.defineProperty(new Error(`\\`${callingExpression}\\` was called outside a request scope. Read more: https://nextjs.org/docs/messages/next-dynamic-api-wrong-context`), \"__NEXT_ERROR_CODE\", {\n        value: \"E251\",\n        enumerable: false,\n        configurable: true\n    });\n}\nexport function throwInvariantForMissingStore() {\n    throw Object.defineProperty(new InvariantError('Expected workUnitAsyncStorage to have a store.'), \"__NEXT_ERROR_CODE\", {\n        value: \"E696\",\n        enumerable: false,\n        configurable: true\n    });\n}\nexport function getPrerenderResumeDataCache(workUnitStore) {\n    switch(workUnitStore.type){\n        case 'prerender':\n        case 'prerender-runtime':\n        case 'prerender-ppr':\n            return workUnitStore.prerenderResumeDataCache;\n        case 'prerender-client':\n            // TODO eliminate fetch caching in client scope and stop exposing this data\n            // cache during SSR.\n            return workUnitStore.prerenderResumeDataCache;\n        case 'request':\n            {\n                // In dev, we might fill caches even during a dynamic request.\n                if (workUnitStore.prerenderResumeDataCache) {\n                    return workUnitStore.prerenderResumeDataCache;\n                }\n            // fallthrough\n            }\n        case 'prerender-legacy':\n        case 'cache':\n        case 'private-cache':\n        case 'unstable-cache':\n            return null;\n        default:\n            return workUnitStore;\n    }\n}\nexport function getRenderResumeDataCache(workUnitStore) {\n    switch(workUnitStore.type){\n        case 'request':\n        case 'prerender':\n        case 'prerender-runtime':\n        case 'prerender-client':\n            if (workUnitStore.renderResumeDataCache) {\n                // If we are in a prerender, we might have a render resume data cache\n                // that is used to read from prefilled caches.\n                return workUnitStore.renderResumeDataCache;\n            }\n        // fallthrough\n        case 'prerender-ppr':\n            // Otherwise we return the mutable resume data cache here as an immutable\n            // version of the cache as it can also be used for reading.\n            return workUnitStore.prerenderResumeDataCache ?? null;\n        case 'cache':\n        case 'private-cache':\n        case 'unstable-cache':\n        case 'prerender-legacy':\n            return null;\n        default:\n            return workUnitStore;\n    }\n}\nexport function getHmrRefreshHash(workStore, workUnitStore) {\n    if (workStore.dev) {\n        switch(workUnitStore.type){\n            case 'cache':\n            case 'private-cache':\n            case 'prerender':\n            case 'prerender-runtime':\n                return workUnitStore.hmrRefreshHash;\n            case 'request':\n                var _workUnitStore_cookies_get;\n                return (_workUnitStore_cookies_get = workUnitStore.cookies.get(NEXT_HMR_REFRESH_HASH_COOKIE)) == null ? void 0 : _workUnitStore_cookies_get.value;\n            case 'prerender-client':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'unstable-cache':\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n    return undefined;\n}\nexport function isHmrRefresh(workStore, workUnitStore) {\n    if (workStore.dev) {\n        switch(workUnitStore.type){\n            case 'cache':\n            case 'private-cache':\n            case 'request':\n                return workUnitStore.isHmrRefresh ?? false;\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-runtime':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'unstable-cache':\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n    return false;\n}\nexport function getServerComponentsHmrCache(workStore, workUnitStore) {\n    if (workStore.dev) {\n        switch(workUnitStore.type){\n            case 'cache':\n            case 'private-cache':\n            case 'request':\n                return workUnitStore.serverComponentsHmrCache;\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-runtime':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'unstable-cache':\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n    return undefined;\n}\n/**\n * Returns a draft mode provider only if draft mode is enabled.\n */ export function getDraftModeProviderForCacheScope(workStore, workUnitStore) {\n    if (workStore.isDraftMode) {\n        switch(workUnitStore.type){\n            case 'cache':\n            case 'private-cache':\n            case 'unstable-cache':\n            case 'prerender-runtime':\n            case 'request':\n                return workUnitStore.draftMode;\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n    return undefined;\n}\nexport function getCacheSignal(workUnitStore) {\n    switch(workUnitStore.type){\n        case 'prerender':\n        case 'prerender-client':\n        case 'prerender-runtime':\n            return workUnitStore.cacheSignal;\n        case 'request':\n            {\n                // In dev, we might fill caches even during a dynamic request.\n                if (workUnitStore.cacheSignal) {\n                    return workUnitStore.cacheSignal;\n                }\n            // fallthrough\n            }\n        case 'prerender-ppr':\n        case 'prerender-legacy':\n        case 'cache':\n        case 'private-cache':\n        case 'unstable-cache':\n            return null;\n        default:\n            return workUnitStore;\n    }\n}\nexport function getRuntimeStagePromise(workUnitStore) {\n    switch(workUnitStore.type){\n        case 'prerender-runtime':\n        case 'private-cache':\n            return workUnitStore.runtimeStagePromise;\n        case 'prerender':\n        case 'prerender-client':\n        case 'prerender-ppr':\n        case 'prerender-legacy':\n        case 'request':\n        case 'cache':\n        case 'unstable-cache':\n            return null;\n        default:\n            return workUnitStore;\n    }\n}\n\n//# sourceMappingURL=work-unit-async-storage.external.js.map","import { RequestCookies } from '../cookies';\nimport { ResponseCookies } from '../cookies';\nimport { ReflectAdapter } from './reflect';\nimport { workAsyncStorage } from '../../../app-render/work-async-storage.external';\nimport { ActionDidRevalidateStaticAndDynamic } from '../../../../shared/lib/action-revalidation-kind';\n/**\n * @internal\n */ export class ReadonlyRequestCookiesError extends Error {\n    constructor(){\n        super('Cookies can only be modified in a Server Action or Route Handler. Read more: https://nextjs.org/docs/app/api-reference/functions/cookies#options');\n    }\n    static callable() {\n        throw new ReadonlyRequestCookiesError();\n    }\n}\nexport class RequestCookiesAdapter {\n    static seal(cookies) {\n        return new Proxy(cookies, {\n            get (target, prop, receiver) {\n                switch(prop){\n                    case 'clear':\n                    case 'delete':\n                    case 'set':\n                        return ReadonlyRequestCookiesError.callable;\n                    default:\n                        return ReflectAdapter.get(target, prop, receiver);\n                }\n            }\n        });\n    }\n}\nconst SYMBOL_MODIFY_COOKIE_VALUES = Symbol.for('next.mutated.cookies');\nexport function getModifiedCookieValues(cookies) {\n    const modified = cookies[SYMBOL_MODIFY_COOKIE_VALUES];\n    if (!modified || !Array.isArray(modified) || modified.length === 0) {\n        return [];\n    }\n    return modified;\n}\nexport function appendMutableCookies(headers, mutableCookies) {\n    const modifiedCookieValues = getModifiedCookieValues(mutableCookies);\n    if (modifiedCookieValues.length === 0) {\n        return false;\n    }\n    // Return a new response that extends the response with\n    // the modified cookies as fallbacks. `res` cookies\n    // will still take precedence.\n    const resCookies = new ResponseCookies(headers);\n    const returnedCookies = resCookies.getAll();\n    // Set the modified cookies as fallbacks.\n    for (const cookie of modifiedCookieValues){\n        resCookies.set(cookie);\n    }\n    // Set the original cookies as the final values.\n    for (const cookie of returnedCookies){\n        resCookies.set(cookie);\n    }\n    return true;\n}\nexport class MutableRequestCookiesAdapter {\n    static wrap(cookies, onUpdateCookies) {\n        const responseCookies = new ResponseCookies(new Headers());\n        for (const cookie of cookies.getAll()){\n            responseCookies.set(cookie);\n        }\n        let modifiedValues = [];\n        const modifiedCookies = new Set();\n        const updateResponseCookies = ()=>{\n            // TODO-APP: change method of getting workStore\n            const workStore = workAsyncStorage.getStore();\n            if (workStore) {\n                workStore.pathWasRevalidated = ActionDidRevalidateStaticAndDynamic;\n            }\n            const allCookies = responseCookies.getAll();\n            modifiedValues = allCookies.filter((c)=>modifiedCookies.has(c.name));\n            if (onUpdateCookies) {\n                const serializedCookies = [];\n                for (const cookie of modifiedValues){\n                    const tempCookies = new ResponseCookies(new Headers());\n                    tempCookies.set(cookie);\n                    serializedCookies.push(tempCookies.toString());\n                }\n                onUpdateCookies(serializedCookies);\n            }\n        };\n        const wrappedCookies = new Proxy(responseCookies, {\n            get (target, prop, receiver) {\n                switch(prop){\n                    // A special symbol to get the modified cookie values\n                    case SYMBOL_MODIFY_COOKIE_VALUES:\n                        return modifiedValues;\n                    // TODO: Throw error if trying to set a cookie after the response\n                    // headers have been set.\n                    case 'delete':\n                        return function(...args) {\n                            modifiedCookies.add(typeof args[0] === 'string' ? args[0] : args[0].name);\n                            try {\n                                target.delete(...args);\n                                return wrappedCookies;\n                            } finally{\n                                updateResponseCookies();\n                            }\n                        };\n                    case 'set':\n                        return function(...args) {\n                            modifiedCookies.add(typeof args[0] === 'string' ? args[0] : args[0].name);\n                            try {\n                                target.set(...args);\n                                return wrappedCookies;\n                            } finally{\n                                updateResponseCookies();\n                            }\n                        };\n                    default:\n                        return ReflectAdapter.get(target, prop, receiver);\n                }\n            }\n        });\n        return wrappedCookies;\n    }\n}\nexport function createCookiesWithMutableAccessCheck(requestStore) {\n    const wrappedCookies = new Proxy(requestStore.mutableCookies, {\n        get (target, prop, receiver) {\n            switch(prop){\n                case 'delete':\n                    return function(...args) {\n                        ensureCookiesAreStillMutable(requestStore, 'cookies().delete');\n                        target.delete(...args);\n                        return wrappedCookies;\n                    };\n                case 'set':\n                    return function(...args) {\n                        ensureCookiesAreStillMutable(requestStore, 'cookies().set');\n                        target.set(...args);\n                        return wrappedCookies;\n                    };\n                default:\n                    return ReflectAdapter.get(target, prop, receiver);\n            }\n        }\n    });\n    return wrappedCookies;\n}\nexport function areCookiesMutableInCurrentPhase(requestStore) {\n    return requestStore.phase === 'action';\n}\n/** Ensure that cookies() starts throwing on mutation\n * if we changed phases and can no longer mutate.\n *\n * This can happen when going:\n *   'render' -> 'after'\n *   'action' -> 'render'\n * */ function ensureCookiesAreStillMutable(requestStore, _callingExpression) {\n    if (!areCookiesMutableInCurrentPhase(requestStore)) {\n        // TODO: maybe we can give a more precise error message based on callingExpression?\n        throw new ReadonlyRequestCookiesError();\n    }\n}\nexport function responseCookiesToRequestCookies(responseCookies) {\n    const requestCookies = new RequestCookies(new Headers());\n    for (const cookie of responseCookies.getAll()){\n        requestCookies.set(cookie);\n    }\n    return requestCookies;\n}\n\n//# sourceMappingURL=request-cookies.js.map","import { parsePath } from './parse-path';\n/**\n * Checks if a given path starts with a given prefix. It ensures it matches\n * exactly without containing extra chars. e.g. prefix /docs should replace\n * for /docs, /docs/, /docs/a but not /docsss\n * @param path The path to check.\n * @param prefix The prefix to check against.\n */ export function pathHasPrefix(path, prefix) {\n    if (typeof path !== 'string') {\n        return false;\n    }\n    const { pathname } = parsePath(path);\n    return pathname === prefix || pathname.startsWith(prefix + '/');\n}\n\n//# sourceMappingURL=path-has-prefix.js.map","import { pathHasPrefix } from './path-has-prefix';\n/**\n * Given a path and a prefix it will remove the prefix when it exists in the\n * given path. It ensures it matches exactly without containing extra chars\n * and if the prefix is not there it will be noop.\n *\n * @param path The path to remove the prefix from.\n * @param prefix The prefix to be removed.\n */ export function removePathPrefix(path, prefix) {\n    // If the path doesn't start with the prefix we can return it as is. This\n    // protects us from situations where the prefix is a substring of the path\n    // prefix such as:\n    //\n    // For prefix: /blog\n    //\n    //   /blog -> true\n    //   /blog/ -> true\n    //   /blog/1 -> true\n    //   /blogging -> false\n    //   /blogging/ -> false\n    //   /blogging/1 -> false\n    if (!pathHasPrefix(path, prefix)) {\n        return path;\n    }\n    // Remove the prefix from the path via slicing.\n    const withoutPrefix = path.slice(prefix.length);\n    // If the path without the prefix starts with a `/` we can return it as is.\n    if (withoutPrefix.startsWith('/')) {\n        return withoutPrefix;\n    }\n    // If the path without the prefix doesn't start with a `/` we need to add it\n    // back to the path to make sure it's a valid path.\n    return `/${withoutPrefix}`;\n}\n\n//# sourceMappingURL=remove-path-prefix.js.map","/**\n * Client-safe utilities for route matching that don't import server-side\n * utilities to avoid bundling issues with Turbopack\n */ import { pathToRegexp, compile, regexpToFunction } from 'next/dist/compiled/path-to-regexp';\nimport { hasAdjacentParameterIssues, normalizeAdjacentParameters, stripParameterSeparators, stripNormalizedSeparators } from '../../../../lib/route-pattern-normalizer';\n/**\n * Client-safe wrapper around pathToRegexp that handles path-to-regexp 6.3.0+ validation errors.\n * This includes both \"Can not repeat without prefix/suffix\" and \"Must have text between parameters\" errors.\n */ export function safePathToRegexp(route, keys, options) {\n    if (typeof route !== 'string') {\n        return pathToRegexp(route, keys, options);\n    }\n    // Check if normalization is needed and cache the result\n    const needsNormalization = hasAdjacentParameterIssues(route);\n    const routeToUse = needsNormalization ? normalizeAdjacentParameters(route) : route;\n    try {\n        return pathToRegexp(routeToUse, keys, options);\n    } catch (error) {\n        // Only try normalization if we haven't already normalized\n        if (!needsNormalization) {\n            try {\n                const normalizedRoute = normalizeAdjacentParameters(route);\n                return pathToRegexp(normalizedRoute, keys, options);\n            } catch (retryError) {\n                // If that doesn't work, fall back to original error\n                throw error;\n            }\n        }\n        throw error;\n    }\n}\n/**\n * Client-safe wrapper around compile that handles path-to-regexp 6.3.0+ validation errors.\n * No server-side error reporting to avoid bundling issues.\n * When normalization is applied, the returned compiler function automatically strips\n * the internal separator from the output URL.\n */ export function safeCompile(route, options) {\n    // Check if normalization is needed and cache the result\n    const needsNormalization = hasAdjacentParameterIssues(route);\n    const routeToUse = needsNormalization ? normalizeAdjacentParameters(route) : route;\n    try {\n        const compiler = compile(routeToUse, options);\n        // If we normalized the route, wrap the compiler to strip separators from output\n        // The normalization inserts _NEXTSEP_ as a literal string in the pattern to satisfy\n        // path-to-regexp validation, but we don't want it in the final compiled URL\n        if (needsNormalization) {\n            return (params)=>{\n                return stripNormalizedSeparators(compiler(params));\n            };\n        }\n        return compiler;\n    } catch (error) {\n        // Only try normalization if we haven't already normalized\n        if (!needsNormalization) {\n            try {\n                const normalizedRoute = normalizeAdjacentParameters(route);\n                const compiler = compile(normalizedRoute, options);\n                // Wrap the compiler to strip separators from output\n                return (params)=>{\n                    return stripNormalizedSeparators(compiler(params));\n                };\n            } catch (retryError) {\n                // If that doesn't work, fall back to original error\n                throw error;\n            }\n        }\n        throw error;\n    }\n}\n/**\n * Client-safe wrapper around regexpToFunction that automatically cleans parameters.\n */ export function safeRegexpToFunction(regexp, keys) {\n    const originalMatcher = regexpToFunction(regexp, keys || []);\n    return (pathname)=>{\n        const result = originalMatcher(pathname);\n        if (!result) return false;\n        // Clean parameters before returning\n        return {\n            ...result,\n            params: stripParameterSeparators(result.params)\n        };\n    };\n}\n/**\n * Safe wrapper for route matcher functions that automatically cleans parameters.\n * This is client-safe and doesn't import path-to-regexp.\n */ export function safeRouteMatcher(matcherFn) {\n    return (pathname)=>{\n        const result = matcherFn(pathname);\n        if (!result) return false;\n        // Clean parameters before returning\n        return stripParameterSeparators(result);\n    };\n}\n\n//# sourceMappingURL=route-match-utils.js.map","/**\n * This is the default \"use cache\" handler it defaults to an in-memory store.\n * In-memory caches are fragile and should not use stale-while-revalidate\n * semantics on the caches because it's not worth warming up an entry that's\n * likely going to get evicted before we get to use it anyway. However, we also\n * don't want to reuse a stale entry for too long so stale entries should be\n * considered expired/missing in such cache handlers.\n */ import { LRUCache } from '../lru-cache';\nimport { areTagsExpired, areTagsStale, tagsManifest } from '../incremental-cache/tags-manifest.external';\nexport function createDefaultCacheHandler(maxSize) {\n    // If the max size is 0, return a cache handler that doesn't cache anything,\n    // this avoids an unnecessary LRUCache instance and potential memory\n    // allocation.\n    if (maxSize === 0) {\n        return {\n            get: ()=>Promise.resolve(undefined),\n            set: ()=>Promise.resolve(),\n            refreshTags: ()=>Promise.resolve(),\n            getExpiration: ()=>Promise.resolve(0),\n            updateTags: ()=>Promise.resolve()\n        };\n    }\n    const memoryCache = new LRUCache(maxSize, (entry)=>entry.size);\n    const pendingSets = new Map();\n    const debug = process.env.NEXT_PRIVATE_DEBUG_CACHE ? console.debug.bind(console, 'DefaultCacheHandler:') : undefined;\n    return {\n        async get (cacheKey) {\n            const pendingPromise = pendingSets.get(cacheKey);\n            if (pendingPromise) {\n                debug == null ? void 0 : debug('get', cacheKey, 'pending');\n                await pendingPromise;\n            }\n            const privateEntry = memoryCache.get(cacheKey);\n            if (!privateEntry) {\n                debug == null ? void 0 : debug('get', cacheKey, 'not found');\n                return undefined;\n            }\n            const entry = privateEntry.entry;\n            if (performance.timeOrigin + performance.now() > entry.timestamp + entry.revalidate * 1000) {\n                // In-memory caches should expire after revalidate time because it is\n                // unlikely that a new entry will be able to be used before it is dropped\n                // from the cache.\n                debug == null ? void 0 : debug('get', cacheKey, 'expired');\n                return undefined;\n            }\n            let revalidate = entry.revalidate;\n            if (areTagsExpired(entry.tags, entry.timestamp)) {\n                debug == null ? void 0 : debug('get', cacheKey, 'had expired tag');\n                return undefined;\n            }\n            if (areTagsStale(entry.tags, entry.timestamp)) {\n                debug == null ? void 0 : debug('get', cacheKey, 'had stale tag');\n                revalidate = -1;\n            }\n            const [returnStream, newSaved] = entry.value.tee();\n            entry.value = newSaved;\n            debug == null ? void 0 : debug('get', cacheKey, 'found', {\n                tags: entry.tags,\n                timestamp: entry.timestamp,\n                expire: entry.expire,\n                revalidate\n            });\n            return {\n                ...entry,\n                revalidate,\n                value: returnStream\n            };\n        },\n        async set (cacheKey, pendingEntry) {\n            debug == null ? void 0 : debug('set', cacheKey, 'start');\n            let resolvePending = ()=>{};\n            const pendingPromise = new Promise((resolve)=>{\n                resolvePending = resolve;\n            });\n            pendingSets.set(cacheKey, pendingPromise);\n            const entry = await pendingEntry;\n            let size = 0;\n            try {\n                const [value, clonedValue] = entry.value.tee();\n                entry.value = value;\n                const reader = clonedValue.getReader();\n                for(let chunk; !(chunk = await reader.read()).done;){\n                    size += Buffer.from(chunk.value).byteLength;\n                }\n                memoryCache.set(cacheKey, {\n                    entry,\n                    isErrored: false,\n                    errorRetryCount: 0,\n                    size\n                });\n                debug == null ? void 0 : debug('set', cacheKey, 'done');\n            } catch (err) {\n                // TODO: store partial buffer with error after we retry 3 times\n                debug == null ? void 0 : debug('set', cacheKey, 'failed', err);\n            } finally{\n                resolvePending();\n                pendingSets.delete(cacheKey);\n            }\n        },\n        async refreshTags () {\n        // Nothing to do for an in-memory cache handler.\n        },\n        async getExpiration (tags) {\n            const expirations = tags.map((tag)=>{\n                const entry = tagsManifest.get(tag);\n                if (!entry) return 0;\n                // Return the most recent timestamp (either expired or stale)\n                return entry.expired || 0;\n            });\n            const expiration = Math.max(...expirations, 0);\n            debug == null ? void 0 : debug('getExpiration', {\n                tags,\n                expiration\n            });\n            return expiration;\n        },\n        async updateTags (tags, durations) {\n            const now = Math.round(performance.timeOrigin + performance.now());\n            debug == null ? void 0 : debug('updateTags', {\n                tags,\n                timestamp: now\n            });\n            for (const tag of tags){\n                // TODO: update file-system-cache?\n                const existingEntry = tagsManifest.get(tag) || {};\n                if (durations) {\n                    // Use provided durations directly\n                    const updates = {\n                        ...existingEntry\n                    };\n                    // mark as stale immediately\n                    updates.stale = now;\n                    if (durations.expire !== undefined) {\n                        updates.expired = now + durations.expire * 1000 // Convert seconds to ms\n                        ;\n                    }\n                    tagsManifest.set(tag, updates);\n                } else {\n                    // Update expired field for immediate expiration (default behavior when no durations provided)\n                    tagsManifest.set(tag, {\n                        ...existingEntry,\n                        expired: now\n                    });\n                }\n            }\n        }\n    };\n}\n\n//# sourceMappingURL=default.js.map","import { NEXT_INTERCEPTION_MARKER_PREFIX, NEXT_QUERY_PARAM_PREFIX } from '../../lib/constants';\n/**\n * Converts a Node.js IncomingHttpHeaders object to a Headers object. Any\n * headers with multiple values will be joined with a comma and space. Any\n * headers that have an undefined value will be ignored and others will be\n * coerced to strings.\n *\n * @param nodeHeaders the headers object to convert\n * @returns the converted headers object\n */ export function fromNodeOutgoingHttpHeaders(nodeHeaders) {\n    const headers = new Headers();\n    for (let [key, value] of Object.entries(nodeHeaders)){\n        const values = Array.isArray(value) ? value : [\n            value\n        ];\n        for (let v of values){\n            if (typeof v === 'undefined') continue;\n            if (typeof v === 'number') {\n                v = v.toString();\n            }\n            headers.append(key, v);\n        }\n    }\n    return headers;\n}\n/*\n  Set-Cookie header field-values are sometimes comma joined in one string. This splits them without choking on commas\n  that are within a single set-cookie field-value, such as in the Expires portion.\n  This is uncommon, but explicitly allowed - see https://tools.ietf.org/html/rfc2616#section-4.2\n  Node.js does this for every header *except* set-cookie - see https://github.com/nodejs/node/blob/d5e363b77ebaf1caf67cd7528224b651c86815c1/lib/_http_incoming.js#L128\n  React Native's fetch does this for *every* header, including set-cookie.\n  \n  Based on: https://github.com/google/j2objc/commit/16820fdbc8f76ca0c33472810ce0cb03d20efe25\n  Credits to: https://github.com/tomball for original and https://github.com/chrusart for JavaScript implementation\n*/ export function splitCookiesString(cookiesString) {\n    var cookiesStrings = [];\n    var pos = 0;\n    var start;\n    var ch;\n    var lastComma;\n    var nextStart;\n    var cookiesSeparatorFound;\n    function skipWhitespace() {\n        while(pos < cookiesString.length && /\\s/.test(cookiesString.charAt(pos))){\n            pos += 1;\n        }\n        return pos < cookiesString.length;\n    }\n    function notSpecialChar() {\n        ch = cookiesString.charAt(pos);\n        return ch !== '=' && ch !== ';' && ch !== ',';\n    }\n    while(pos < cookiesString.length){\n        start = pos;\n        cookiesSeparatorFound = false;\n        while(skipWhitespace()){\n            ch = cookiesString.charAt(pos);\n            if (ch === ',') {\n                // ',' is a cookie separator if we have later first '=', not ';' or ','\n                lastComma = pos;\n                pos += 1;\n                skipWhitespace();\n                nextStart = pos;\n                while(pos < cookiesString.length && notSpecialChar()){\n                    pos += 1;\n                }\n                // currently special character\n                if (pos < cookiesString.length && cookiesString.charAt(pos) === '=') {\n                    // we found cookies separator\n                    cookiesSeparatorFound = true;\n                    // pos is inside the next cookie, so back up and return it.\n                    pos = nextStart;\n                    cookiesStrings.push(cookiesString.substring(start, lastComma));\n                    start = pos;\n                } else {\n                    // in param ',' or param separator ';',\n                    // we continue from that comma\n                    pos = lastComma + 1;\n                }\n            } else {\n                pos += 1;\n            }\n        }\n        if (!cookiesSeparatorFound || pos >= cookiesString.length) {\n            cookiesStrings.push(cookiesString.substring(start, cookiesString.length));\n        }\n    }\n    return cookiesStrings;\n}\n/**\n * Converts a Headers object to a Node.js OutgoingHttpHeaders object. This is\n * required to support the set-cookie header, which may have multiple values.\n *\n * @param headers the headers object to convert\n * @returns the converted headers object\n */ export function toNodeOutgoingHttpHeaders(headers) {\n    const nodeHeaders = {};\n    const cookies = [];\n    if (headers) {\n        for (const [key, value] of headers.entries()){\n            if (key.toLowerCase() === 'set-cookie') {\n                // We may have gotten a comma joined string of cookies, or multiple\n                // set-cookie headers. We need to merge them into one header array\n                // to represent all the cookies.\n                cookies.push(...splitCookiesString(value));\n                nodeHeaders[key] = cookies.length === 1 ? cookies[0] : cookies;\n            } else {\n                nodeHeaders[key] = value;\n            }\n        }\n    }\n    return nodeHeaders;\n}\n/**\n * Validate the correctness of a user-provided URL.\n */ export function validateURL(url) {\n    try {\n        return String(new URL(String(url)));\n    } catch (error) {\n        throw Object.defineProperty(new Error(`URL is malformed \"${String(url)}\". Please use only absolute URLs - https://nextjs.org/docs/messages/middleware-relative-urls`, {\n            cause: error\n        }), \"__NEXT_ERROR_CODE\", {\n            value: \"E61\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n}\n/**\n * Normalizes `nxtP` and `nxtI` query param values to remove the prefix.\n * This function does not mutate the input key.\n */ export function normalizeNextQueryParam(key) {\n    const prefixes = [\n        NEXT_QUERY_PARAM_PREFIX,\n        NEXT_INTERCEPTION_MARKER_PREFIX\n    ];\n    for (const prefix of prefixes){\n        if (key !== prefix && key.startsWith(prefix)) {\n            return key.substring(prefix.length);\n        }\n    }\n    return null;\n}\n\n//# sourceMappingURL=utils.js.map","import { getTracer } from '../lib/trace/tracer';\nimport { AppRenderSpan } from '../lib/trace/constants';\nimport { DetachedPromise } from '../../lib/detached-promise';\nimport { scheduleImmediate, atLeastOneTask, waitAtLeastOneReactRenderTask } from '../../lib/scheduler';\nimport { ENCODED_TAGS } from './encoded-tags';\nimport { indexOfUint8Array, isEquivalentUint8Arrays, removeFromUint8Array } from './uint8array-helpers';\nimport { MISSING_ROOT_TAGS_ERROR } from '../../shared/lib/errors/constants';\nimport { insertBuildIdComment } from '../../shared/lib/segment-cache/output-export-prefetch-encoding';\nimport { RSC_HEADER, NEXT_ROUTER_PREFETCH_HEADER, NEXT_ROUTER_SEGMENT_PREFETCH_HEADER, NEXT_RSC_UNION_QUERY } from '../../client/components/app-router-headers';\nimport { computeCacheBustingSearchParam } from '../../shared/lib/router/utils/cache-busting-search-param';\nfunction voidCatch() {\n// this catcher is designed to be used with pipeTo where we expect the underlying\n// pipe implementation to forward errors but we don't want the pipeTo promise to reject\n// and be unhandled\n}\n// We can share the same encoder instance everywhere\n// Notably we cannot do the same for TextDecoder because it is stateful\n// when handling streaming data\nconst encoder = new TextEncoder();\nexport function chainStreams(...streams) {\n    // If we have no streams, return an empty stream. This behavior is\n    // intentional as we're now providing the `RenderResult.EMPTY` value.\n    if (streams.length === 0) {\n        return new ReadableStream({\n            start (controller) {\n                controller.close();\n            }\n        });\n    }\n    // If we only have 1 stream we fast path it by returning just this stream\n    if (streams.length === 1) {\n        return streams[0];\n    }\n    const { readable, writable } = new TransformStream();\n    // We always initiate pipeTo immediately. We know we have at least 2 streams\n    // so we need to avoid closing the writable when this one finishes.\n    let promise = streams[0].pipeTo(writable, {\n        preventClose: true\n    });\n    let i = 1;\n    for(; i < streams.length - 1; i++){\n        const nextStream = streams[i];\n        promise = promise.then(()=>nextStream.pipeTo(writable, {\n                preventClose: true\n            }));\n    }\n    // We can omit the length check because we halted before the last stream and there\n    // is at least two streams so the lastStream here will always be defined\n    const lastStream = streams[i];\n    promise = promise.then(()=>lastStream.pipeTo(writable));\n    // Catch any errors from the streams and ignore them, they will be handled\n    // by whatever is consuming the readable stream.\n    promise.catch(voidCatch);\n    return readable;\n}\nexport function streamFromString(str) {\n    return new ReadableStream({\n        start (controller) {\n            controller.enqueue(encoder.encode(str));\n            controller.close();\n        }\n    });\n}\nexport function streamFromBuffer(chunk) {\n    return new ReadableStream({\n        start (controller) {\n            controller.enqueue(chunk);\n            controller.close();\n        }\n    });\n}\nasync function streamToChunks(stream) {\n    const reader = stream.getReader();\n    const chunks = [];\n    while(true){\n        const { done, value } = await reader.read();\n        if (done) {\n            break;\n        }\n        chunks.push(value);\n    }\n    return chunks;\n}\nfunction concatUint8Arrays(chunks) {\n    const totalLength = chunks.reduce((sum, chunk)=>sum + chunk.length, 0);\n    const result = new Uint8Array(totalLength);\n    let offset = 0;\n    for (const chunk of chunks){\n        result.set(chunk, offset);\n        offset += chunk.length;\n    }\n    return result;\n}\nexport async function streamToUint8Array(stream) {\n    return concatUint8Arrays(await streamToChunks(stream));\n}\nexport async function streamToBuffer(stream) {\n    return Buffer.concat(await streamToChunks(stream));\n}\nexport async function streamToString(stream, signal) {\n    const decoder = new TextDecoder('utf-8', {\n        fatal: true\n    });\n    let string = '';\n    for await (const chunk of stream){\n        if (signal == null ? void 0 : signal.aborted) {\n            return string;\n        }\n        string += decoder.decode(chunk, {\n            stream: true\n        });\n    }\n    string += decoder.decode();\n    return string;\n}\nexport function createBufferedTransformStream(options = {}) {\n    const { maxBufferByteLength = Infinity } = options;\n    let bufferedChunks = [];\n    let bufferByteLength = 0;\n    let pending;\n    const flush = (controller)=>{\n        try {\n            if (bufferedChunks.length === 0) {\n                return;\n            }\n            const chunk = new Uint8Array(bufferByteLength);\n            let copiedBytes = 0;\n            for(let i = 0; i < bufferedChunks.length; i++){\n                const bufferedChunk = bufferedChunks[i];\n                chunk.set(bufferedChunk, copiedBytes);\n                copiedBytes += bufferedChunk.byteLength;\n            }\n            // We just wrote all the buffered chunks so we need to reset the bufferedChunks array\n            // and our bufferByteLength to prepare for the next round of buffered chunks\n            bufferedChunks.length = 0;\n            bufferByteLength = 0;\n            controller.enqueue(chunk);\n        } catch  {\n        // If an error occurs while enqueuing, it can't be due to this\n        // transformer. It's most likely caused by the controller having been\n        // errored (for example, if the stream was cancelled).\n        }\n    };\n    const scheduleFlush = (controller)=>{\n        if (pending) {\n            return;\n        }\n        const detached = new DetachedPromise();\n        pending = detached;\n        scheduleImmediate(()=>{\n            try {\n                flush(controller);\n            } finally{\n                pending = undefined;\n                detached.resolve();\n            }\n        });\n    };\n    return new TransformStream({\n        transform (chunk, controller) {\n            // Combine the previous buffer with the new chunk.\n            bufferedChunks.push(chunk);\n            bufferByteLength += chunk.byteLength;\n            if (bufferByteLength >= maxBufferByteLength) {\n                flush(controller);\n            } else {\n                scheduleFlush(controller);\n            }\n        },\n        flush () {\n            return pending == null ? void 0 : pending.promise;\n        }\n    });\n}\nfunction createPrefetchCommentStream(isBuildTimePrerendering, buildId) {\n    // Insert an extra comment at the beginning of the HTML document. This must\n    // come after the DOCTYPE, which is inserted by React.\n    //\n    // The first chunk sent by React will contain the doctype. After that, we can\n    // pass through the rest of the chunks as-is.\n    let didTransformFirstChunk = false;\n    return new TransformStream({\n        transform (chunk, controller) {\n            if (isBuildTimePrerendering && !didTransformFirstChunk) {\n                didTransformFirstChunk = true;\n                const decoder = new TextDecoder('utf-8', {\n                    fatal: true\n                });\n                const chunkStr = decoder.decode(chunk, {\n                    stream: true\n                });\n                const updatedChunkStr = insertBuildIdComment(chunkStr, buildId);\n                controller.enqueue(encoder.encode(updatedChunkStr));\n                return;\n            }\n            controller.enqueue(chunk);\n        }\n    });\n}\nexport function renderToInitialFizzStream({ ReactDOMServer, element, streamOptions }) {\n    return getTracer().trace(AppRenderSpan.renderToReadableStream, async ()=>ReactDOMServer.renderToReadableStream(element, streamOptions));\n}\nfunction createMetadataTransformStream(insert) {\n    let chunkIndex = -1;\n    let isMarkRemoved = false;\n    return new TransformStream({\n        async transform (chunk, controller) {\n            let iconMarkIndex = -1;\n            let closedHeadIndex = -1;\n            chunkIndex++;\n            if (isMarkRemoved) {\n                controller.enqueue(chunk);\n                return;\n            }\n            let iconMarkLength = 0;\n            // Only search for the closed head tag once\n            if (iconMarkIndex === -1) {\n                iconMarkIndex = indexOfUint8Array(chunk, ENCODED_TAGS.META.ICON_MARK);\n                if (iconMarkIndex === -1) {\n                    controller.enqueue(chunk);\n                    return;\n                } else {\n                    // When we found the `<meta name=\"nxt-icon\"` tag prefix, we will remove it from the chunk.\n                    // Its close tag could either be `/>` or `>`, checking the next char to ensure we cover both cases.\n                    iconMarkLength = ENCODED_TAGS.META.ICON_MARK.length;\n                    // Check if next char is /, this is for xml mode.\n                    if (chunk[iconMarkIndex + iconMarkLength] === 47) {\n                        iconMarkLength += 2;\n                    } else {\n                        // The last char is `>`\n                        iconMarkLength++;\n                    }\n                }\n            }\n            // Check if icon mark is inside <head> tag in the first chunk.\n            if (chunkIndex === 0) {\n                closedHeadIndex = indexOfUint8Array(chunk, ENCODED_TAGS.CLOSED.HEAD);\n                if (iconMarkIndex !== -1) {\n                    // The mark icon is located in the 1st chunk before the head tag.\n                    // We do not need to insert the script tag in this case because it's in the head.\n                    // Just remove the icon mark from the chunk.\n                    if (iconMarkIndex < closedHeadIndex) {\n                        const replaced = new Uint8Array(chunk.length - iconMarkLength);\n                        // Remove the icon mark from the chunk.\n                        replaced.set(chunk.subarray(0, iconMarkIndex));\n                        replaced.set(chunk.subarray(iconMarkIndex + iconMarkLength), iconMarkIndex);\n                        chunk = replaced;\n                    } else {\n                        // The icon mark is after the head tag, replace and insert the script tag at that position.\n                        const insertion = await insert();\n                        const encodedInsertion = encoder.encode(insertion);\n                        const insertionLength = encodedInsertion.length;\n                        const replaced = new Uint8Array(chunk.length - iconMarkLength + insertionLength);\n                        replaced.set(chunk.subarray(0, iconMarkIndex));\n                        replaced.set(encodedInsertion, iconMarkIndex);\n                        replaced.set(chunk.subarray(iconMarkIndex + iconMarkLength), iconMarkIndex + insertionLength);\n                        chunk = replaced;\n                    }\n                    isMarkRemoved = true;\n                }\n            // If there's no icon mark located, it will be handled later when if present in the following chunks.\n            } else {\n                // When it's appeared in the following chunks, we'll need to\n                // remove the mark and then insert the script tag at that position.\n                const insertion = await insert();\n                const encodedInsertion = encoder.encode(insertion);\n                const insertionLength = encodedInsertion.length;\n                // Replace the icon mark with the hoist script or empty string.\n                const replaced = new Uint8Array(chunk.length - iconMarkLength + insertionLength);\n                // Set the first part of the chunk, before the icon mark.\n                replaced.set(chunk.subarray(0, iconMarkIndex));\n                // Set the insertion after the icon mark.\n                replaced.set(encodedInsertion, iconMarkIndex);\n                // Set the rest of the chunk after the icon mark.\n                replaced.set(chunk.subarray(iconMarkIndex + iconMarkLength), iconMarkIndex + insertionLength);\n                chunk = replaced;\n                isMarkRemoved = true;\n            }\n            controller.enqueue(chunk);\n        }\n    });\n}\nfunction createHeadInsertionTransformStream(insert) {\n    let inserted = false;\n    // We need to track if this transform saw any bytes because if it didn't\n    // we won't want to insert any server HTML at all\n    let hasBytes = false;\n    return new TransformStream({\n        async transform (chunk, controller) {\n            hasBytes = true;\n            const insertion = await insert();\n            if (inserted) {\n                if (insertion) {\n                    const encodedInsertion = encoder.encode(insertion);\n                    controller.enqueue(encodedInsertion);\n                }\n                controller.enqueue(chunk);\n            } else {\n                // TODO (@Ethan-Arrowood): Replace the generic `indexOfUint8Array` method with something finely tuned for the subset of things actually being checked for.\n                const index = indexOfUint8Array(chunk, ENCODED_TAGS.CLOSED.HEAD);\n                // In fully static rendering or non PPR rendering cases:\n                // `/head>` will always be found in the chunk in first chunk rendering.\n                if (index !== -1) {\n                    if (insertion) {\n                        const encodedInsertion = encoder.encode(insertion);\n                        // Get the total count of the bytes in the chunk and the insertion\n                        // e.g.\n                        // chunk = <head><meta charset=\"utf-8\"></head>\n                        // insertion = <script>...</script>\n                        // output = <head><meta charset=\"utf-8\"> [ <script>...</script> ] </head>\n                        const insertedHeadContent = new Uint8Array(chunk.length + encodedInsertion.length);\n                        // Append the first part of the chunk, before the head tag\n                        insertedHeadContent.set(chunk.slice(0, index));\n                        // Append the server inserted content\n                        insertedHeadContent.set(encodedInsertion, index);\n                        // Append the rest of the chunk\n                        insertedHeadContent.set(chunk.slice(index), index + encodedInsertion.length);\n                        controller.enqueue(insertedHeadContent);\n                    } else {\n                        controller.enqueue(chunk);\n                    }\n                    inserted = true;\n                } else {\n                    // This will happens in PPR rendering during next start, when the page is partially rendered.\n                    // When the page resumes, the head tag will be found in the middle of the chunk.\n                    // Where we just need to append the insertion and chunk to the current stream.\n                    // e.g.\n                    // PPR-static: <head>...</head><body> [ resume content ] </body>\n                    // PPR-resume: [ insertion ] [ rest content ]\n                    if (insertion) {\n                        controller.enqueue(encoder.encode(insertion));\n                    }\n                    controller.enqueue(chunk);\n                    inserted = true;\n                }\n            }\n        },\n        async flush (controller) {\n            // Check before closing if there's anything remaining to insert.\n            if (hasBytes) {\n                const insertion = await insert();\n                if (insertion) {\n                    controller.enqueue(encoder.encode(insertion));\n                }\n            }\n        }\n    });\n}\nfunction createClientResumeScriptInsertionTransformStream() {\n    const segmentPath = '/_full';\n    const cacheBustingHeader = computeCacheBustingSearchParam('1', '/_full', undefined, undefined //       headers[NEXT_URL]\n    );\n    const searchStr = `${NEXT_RSC_UNION_QUERY}=${cacheBustingHeader}`;\n    const NEXT_CLIENT_RESUME_SCRIPT = `<script>__NEXT_CLIENT_RESUME=fetch(location.pathname+'?${searchStr}',{credentials:'same-origin',headers:{'${RSC_HEADER}': '1','${NEXT_ROUTER_PREFETCH_HEADER}': '1','${NEXT_ROUTER_SEGMENT_PREFETCH_HEADER}': '${segmentPath}'}})</script>`;\n    let didAlreadyInsert = false;\n    return new TransformStream({\n        transform (chunk, controller) {\n            if (didAlreadyInsert) {\n                // Already inserted the script into the head. Pass through.\n                controller.enqueue(chunk);\n                return;\n            }\n            // TODO (@Ethan-Arrowood): Replace the generic `indexOfUint8Array` method with something finely tuned for the subset of things actually being checked for.\n            const headClosingTagIndex = indexOfUint8Array(chunk, ENCODED_TAGS.CLOSED.HEAD);\n            if (headClosingTagIndex === -1) {\n                // In fully static rendering or non PPR rendering cases:\n                // `/head>` will always be found in the chunk in first chunk rendering.\n                controller.enqueue(chunk);\n                return;\n            }\n            const encodedInsertion = encoder.encode(NEXT_CLIENT_RESUME_SCRIPT);\n            // Get the total count of the bytes in the chunk and the insertion\n            // e.g.\n            // chunk = <head><meta charset=\"utf-8\"></head>\n            // insertion = <script>...</script>\n            // output = <head><meta charset=\"utf-8\"> [ <script>...</script> ] </head>\n            const insertedHeadContent = new Uint8Array(chunk.length + encodedInsertion.length);\n            // Append the first part of the chunk, before the head tag\n            insertedHeadContent.set(chunk.slice(0, headClosingTagIndex));\n            // Append the server inserted content\n            insertedHeadContent.set(encodedInsertion, headClosingTagIndex);\n            // Append the rest of the chunk\n            insertedHeadContent.set(chunk.slice(headClosingTagIndex), headClosingTagIndex + encodedInsertion.length);\n            controller.enqueue(insertedHeadContent);\n            didAlreadyInsert = true;\n        }\n    });\n}\n// Suffix after main body content - scripts before </body>,\n// but wait for the major chunks to be enqueued.\nfunction createDeferredSuffixStream(suffix) {\n    let flushed = false;\n    let pending;\n    const flush = (controller)=>{\n        const detached = new DetachedPromise();\n        pending = detached;\n        scheduleImmediate(()=>{\n            try {\n                controller.enqueue(encoder.encode(suffix));\n            } catch  {\n            // If an error occurs while enqueuing it can't be due to this\n            // transformers fault. It's likely due to the controller being\n            // errored due to the stream being cancelled.\n            } finally{\n                pending = undefined;\n                detached.resolve();\n            }\n        });\n    };\n    return new TransformStream({\n        transform (chunk, controller) {\n            controller.enqueue(chunk);\n            // If we've already flushed, we're done.\n            if (flushed) return;\n            // Schedule the flush to happen.\n            flushed = true;\n            flush(controller);\n        },\n        flush (controller) {\n            if (pending) return pending.promise;\n            if (flushed) return;\n            // Flush now.\n            controller.enqueue(encoder.encode(suffix));\n        }\n    });\n}\nfunction createFlightDataInjectionTransformStream(stream, delayDataUntilFirstHtmlChunk) {\n    let htmlStreamFinished = false;\n    let pull = null;\n    let donePulling = false;\n    function startOrContinuePulling(controller) {\n        if (!pull) {\n            pull = startPulling(controller);\n        }\n        return pull;\n    }\n    async function startPulling(controller) {\n        const reader = stream.getReader();\n        if (delayDataUntilFirstHtmlChunk) {\n            // NOTE: streaming flush\n            // We are buffering here for the inlined data stream because the\n            // \"shell\" stream might be chunkenized again by the underlying stream\n            // implementation, e.g. with a specific high-water mark. To ensure it's\n            // the safe timing to pipe the data stream, this extra tick is\n            // necessary.\n            // We don't start reading until we've left the current Task to ensure\n            // that it's inserted after flushing the shell. Note that this implementation\n            // might get stale if impl details of Fizz change in the future.\n            await atLeastOneTask();\n        }\n        try {\n            while(true){\n                const { done, value } = await reader.read();\n                if (done) {\n                    donePulling = true;\n                    return;\n                }\n                // We want to prioritize HTML over RSC data.\n                // The SSR render is based on the same RSC stream, so when we get a new RSC chunk,\n                // we're likely to produce an HTML chunk as well, so give it a chance to flush first.\n                if (!delayDataUntilFirstHtmlChunk && !htmlStreamFinished) {\n                    await atLeastOneTask();\n                }\n                controller.enqueue(value);\n            }\n        } catch (err) {\n            controller.error(err);\n        }\n    }\n    return new TransformStream({\n        start (controller) {\n            if (!delayDataUntilFirstHtmlChunk) {\n                startOrContinuePulling(controller);\n            }\n        },\n        transform (chunk, controller) {\n            controller.enqueue(chunk);\n            // Start the streaming if it hasn't already been started yet.\n            if (delayDataUntilFirstHtmlChunk) {\n                startOrContinuePulling(controller);\n            }\n        },\n        flush (controller) {\n            htmlStreamFinished = true;\n            if (donePulling) {\n                return;\n            }\n            return startOrContinuePulling(controller);\n        }\n    });\n}\nconst CLOSE_TAG = '</body></html>';\n/**\n * This transform stream moves the suffix to the end of the stream, so results\n * like `</body></html><script>...</script>` will be transformed to\n * `<script>...</script></body></html>`.\n */ function createMoveSuffixStream() {\n    let foundSuffix = false;\n    return new TransformStream({\n        transform (chunk, controller) {\n            if (foundSuffix) {\n                return controller.enqueue(chunk);\n            }\n            const index = indexOfUint8Array(chunk, ENCODED_TAGS.CLOSED.BODY_AND_HTML);\n            if (index > -1) {\n                foundSuffix = true;\n                // If the whole chunk is the suffix, then don't write anything, it will\n                // be written in the flush.\n                if (chunk.length === ENCODED_TAGS.CLOSED.BODY_AND_HTML.length) {\n                    return;\n                }\n                // Write out the part before the suffix.\n                const before = chunk.slice(0, index);\n                controller.enqueue(before);\n                // In the case where the suffix is in the middle of the chunk, we need\n                // to split the chunk into two parts.\n                if (chunk.length > ENCODED_TAGS.CLOSED.BODY_AND_HTML.length + index) {\n                    // Write out the part after the suffix.\n                    const after = chunk.slice(index + ENCODED_TAGS.CLOSED.BODY_AND_HTML.length);\n                    controller.enqueue(after);\n                }\n            } else {\n                controller.enqueue(chunk);\n            }\n        },\n        flush (controller) {\n            // Even if we didn't find the suffix, the HTML is not valid if we don't\n            // add it, so insert it at the end.\n            controller.enqueue(ENCODED_TAGS.CLOSED.BODY_AND_HTML);\n        }\n    });\n}\nfunction createStripDocumentClosingTagsTransform() {\n    return new TransformStream({\n        transform (chunk, controller) {\n            // We rely on the assumption that chunks will never break across a code unit.\n            // This is reasonable because we currently concat all of React's output from a single\n            // flush into one chunk before streaming it forward which means the chunk will represent\n            // a single coherent utf-8 string. This is not safe to use if we change our streaming to no\n            // longer do this large buffered chunk\n            if (isEquivalentUint8Arrays(chunk, ENCODED_TAGS.CLOSED.BODY_AND_HTML) || isEquivalentUint8Arrays(chunk, ENCODED_TAGS.CLOSED.BODY) || isEquivalentUint8Arrays(chunk, ENCODED_TAGS.CLOSED.HTML)) {\n                // the entire chunk is the closing tags; return without enqueueing anything.\n                return;\n            }\n            // We assume these tags will go at together at the end of the document and that\n            // they won't appear anywhere else in the document. This is not really a safe assumption\n            // but until we revamp our streaming infra this is a performant way to string the tags\n            chunk = removeFromUint8Array(chunk, ENCODED_TAGS.CLOSED.BODY);\n            chunk = removeFromUint8Array(chunk, ENCODED_TAGS.CLOSED.HTML);\n            controller.enqueue(chunk);\n        }\n    });\n}\n/*\n * Checks if the root layout is missing the html or body tags\n * and if so, it will inject a script tag to throw an error in the browser, showing the user\n * the error message in the error overlay.\n */ export function createRootLayoutValidatorStream() {\n    let foundHtml = false;\n    let foundBody = false;\n    return new TransformStream({\n        async transform (chunk, controller) {\n            // Peek into the streamed chunk to see if the tags are present.\n            if (!foundHtml && indexOfUint8Array(chunk, ENCODED_TAGS.OPENING.HTML) > -1) {\n                foundHtml = true;\n            }\n            if (!foundBody && indexOfUint8Array(chunk, ENCODED_TAGS.OPENING.BODY) > -1) {\n                foundBody = true;\n            }\n            controller.enqueue(chunk);\n        },\n        flush (controller) {\n            const missingTags = [];\n            if (!foundHtml) missingTags.push('html');\n            if (!foundBody) missingTags.push('body');\n            if (!missingTags.length) return;\n            controller.enqueue(encoder.encode(`<html id=\"__next_error__\">\n            <template\n              data-next-error-message=\"Missing ${missingTags.map((c)=>`<${c}>`).join(missingTags.length > 1 ? ' and ' : '')} tags in the root layout.\\nRead more at https://nextjs.org/docs/messages/missing-root-layout-tags\"\n              data-next-error-digest=\"${MISSING_ROOT_TAGS_ERROR}\"\n              data-next-error-stack=\"\"\n            ></template>\n          `));\n        }\n    });\n}\nfunction chainTransformers(readable, transformers) {\n    let stream = readable;\n    for (const transformer of transformers){\n        if (!transformer) continue;\n        stream = stream.pipeThrough(transformer);\n    }\n    return stream;\n}\nexport async function continueFizzStream(renderStream, { suffix, inlinedDataStream, isStaticGeneration, isBuildTimePrerendering, buildId, getServerInsertedHTML, getServerInsertedMetadata, validateRootLayout }) {\n    // Suffix itself might contain close tags at the end, so we need to split it.\n    const suffixUnclosed = suffix ? suffix.split(CLOSE_TAG, 1)[0] : null;\n    if (isStaticGeneration) {\n        // If we're generating static HTML we need to wait for it to resolve before continuing.\n        await renderStream.allReady;\n    } else {\n        // Otherwise, we want to make sure Fizz is done with all microtasky work\n        // before we start pulling the stream and cause a flush.\n        await waitAtLeastOneReactRenderTask();\n    }\n    return chainTransformers(renderStream, [\n        // Buffer everything to avoid flushing too frequently\n        createBufferedTransformStream(),\n        // Add build id comment to start of the HTML document (in export mode)\n        createPrefetchCommentStream(isBuildTimePrerendering, buildId),\n        // Transform metadata\n        createMetadataTransformStream(getServerInsertedMetadata),\n        // Insert suffix content\n        suffixUnclosed != null && suffixUnclosed.length > 0 ? createDeferredSuffixStream(suffixUnclosed) : null,\n        // Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n        inlinedDataStream ? createFlightDataInjectionTransformStream(inlinedDataStream, true) : null,\n        // Validate the root layout for missing html or body tags\n        validateRootLayout ? createRootLayoutValidatorStream() : null,\n        // Close tags should always be deferred to the end\n        createMoveSuffixStream(),\n        // Special head insertions\n        // TODO-APP: Insert server side html to end of head in app layout rendering, to avoid\n        // hydration errors. Remove this once it's ready to be handled by react itself.\n        createHeadInsertionTransformStream(getServerInsertedHTML)\n    ]);\n}\nexport async function continueDynamicPrerender(prerenderStream, { getServerInsertedHTML, getServerInsertedMetadata }) {\n    return prerenderStream// Buffer everything to avoid flushing too frequently\n    .pipeThrough(createBufferedTransformStream()).pipeThrough(createStripDocumentClosingTagsTransform())// Insert generated tags to head\n    .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))// Transform metadata\n    .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata));\n}\nexport async function continueStaticPrerender(prerenderStream, { inlinedDataStream, getServerInsertedHTML, getServerInsertedMetadata, isBuildTimePrerendering, buildId }) {\n    return prerenderStream// Buffer everything to avoid flushing too frequently\n    .pipeThrough(createBufferedTransformStream())// Add build id comment to start of the HTML document (in export mode)\n    .pipeThrough(createPrefetchCommentStream(isBuildTimePrerendering, buildId))// Insert generated tags to head\n    .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))// Transform metadata\n    .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata))// Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n    .pipeThrough(createFlightDataInjectionTransformStream(inlinedDataStream, true))// Close tags should always be deferred to the end\n    .pipeThrough(createMoveSuffixStream());\n}\nexport async function continueStaticFallbackPrerender(prerenderStream, { inlinedDataStream, getServerInsertedHTML, getServerInsertedMetadata, isBuildTimePrerendering, buildId }) {\n    // Same as `continueStaticPrerender`, but also inserts an additional script\n    // to instruct the client to start fetching the hydration data as early\n    // as possible.\n    return prerenderStream// Buffer everything to avoid flushing too frequently\n    .pipeThrough(createBufferedTransformStream())// Add build id comment to start of the HTML document (in export mode)\n    .pipeThrough(createPrefetchCommentStream(isBuildTimePrerendering, buildId))// Insert generated tags to head\n    .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))// Insert the client resume script into the head\n    .pipeThrough(createClientResumeScriptInsertionTransformStream())// Transform metadata\n    .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata))// Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n    .pipeThrough(createFlightDataInjectionTransformStream(inlinedDataStream, true))// Close tags should always be deferred to the end\n    .pipeThrough(createMoveSuffixStream());\n}\nexport async function continueDynamicHTMLResume(renderStream, { delayDataUntilFirstHtmlChunk, inlinedDataStream, getServerInsertedHTML, getServerInsertedMetadata }) {\n    return renderStream// Buffer everything to avoid flushing too frequently\n    .pipeThrough(createBufferedTransformStream())// Insert generated tags to head\n    .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))// Transform metadata\n    .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata))// Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n    .pipeThrough(createFlightDataInjectionTransformStream(inlinedDataStream, delayDataUntilFirstHtmlChunk))// Close tags should always be deferred to the end\n    .pipeThrough(createMoveSuffixStream());\n}\nexport function createDocumentClosingStream() {\n    return streamFromString(CLOSE_TAG);\n}\n\n//# sourceMappingURL=node-web-streams-helper.js.map","import { AppRenderSpan, NextNodeServerSpan } from './trace/constants';\nimport { getTracer, SpanKind } from './trace/tracer';\nimport { CACHE_ONE_YEAR, INFINITE_CACHE, NEXT_CACHE_TAG_MAX_ITEMS, NEXT_CACHE_TAG_MAX_LENGTH } from '../../lib/constants';\nimport { markCurrentScopeAsDynamic } from '../app-render/dynamic-rendering';\nimport { makeHangingPromise } from '../dynamic-rendering-utils';\nimport { createDedupeFetch } from './dedupe-fetch';\nimport { getCacheSignal } from '../app-render/work-unit-async-storage.external';\nimport { CachedRouteKind, IncrementalCacheKind } from '../response-cache';\nimport { cloneResponse } from './clone-response';\nimport { RenderStage } from '../app-render/staged-rendering';\nconst isEdgeRuntime = process.env.NEXT_RUNTIME === 'edge';\nexport const NEXT_PATCH_SYMBOL = Symbol.for('next-patch');\nfunction isFetchPatched() {\n    return globalThis[NEXT_PATCH_SYMBOL] === true;\n}\nexport function validateRevalidate(revalidateVal, route) {\n    try {\n        let normalizedRevalidate = undefined;\n        if (revalidateVal === false) {\n            normalizedRevalidate = INFINITE_CACHE;\n        } else if (typeof revalidateVal === 'number' && !isNaN(revalidateVal) && revalidateVal > -1) {\n            normalizedRevalidate = revalidateVal;\n        } else if (typeof revalidateVal !== 'undefined') {\n            throw Object.defineProperty(new Error(`Invalid revalidate value \"${revalidateVal}\" on \"${route}\", must be a non-negative number or false`), \"__NEXT_ERROR_CODE\", {\n                value: \"E179\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        return normalizedRevalidate;\n    } catch (err) {\n        // handle client component error from attempting to check revalidate value\n        if (err instanceof Error && err.message.includes('Invalid revalidate')) {\n            throw err;\n        }\n        return undefined;\n    }\n}\nexport function validateTags(tags, description) {\n    const validTags = [];\n    const invalidTags = [];\n    for(let i = 0; i < tags.length; i++){\n        const tag = tags[i];\n        if (typeof tag !== 'string') {\n            invalidTags.push({\n                tag,\n                reason: 'invalid type, must be a string'\n            });\n        } else if (tag.length > NEXT_CACHE_TAG_MAX_LENGTH) {\n            invalidTags.push({\n                tag,\n                reason: `exceeded max length of ${NEXT_CACHE_TAG_MAX_LENGTH}`\n            });\n        } else {\n            validTags.push(tag);\n        }\n        if (validTags.length > NEXT_CACHE_TAG_MAX_ITEMS) {\n            console.warn(`Warning: exceeded max tag count for ${description}, dropped tags:`, tags.slice(i).join(', '));\n            break;\n        }\n    }\n    if (invalidTags.length > 0) {\n        console.warn(`Warning: invalid tags passed to ${description}: `);\n        for (const { tag, reason } of invalidTags){\n            console.log(`tag: \"${tag}\" ${reason}`);\n        }\n    }\n    return validTags;\n}\nfunction trackFetchMetric(workStore, ctx) {\n    if (!workStore.shouldTrackFetchMetrics) {\n        return;\n    }\n    workStore.fetchMetrics ??= [];\n    workStore.fetchMetrics.push({\n        ...ctx,\n        end: performance.timeOrigin + performance.now(),\n        idx: workStore.nextFetchId || 0\n    });\n}\nasync function createCachedPrerenderResponse(res, cacheKey, incrementalCacheContext, incrementalCache, revalidate, handleUnlock) {\n    // We are prerendering at build time or revalidate time with cacheComponents so we\n    // need to buffer the response so we can guarantee it can be read in a\n    // microtask.\n    const bodyBuffer = await res.arrayBuffer();\n    const fetchedData = {\n        headers: Object.fromEntries(res.headers.entries()),\n        body: Buffer.from(bodyBuffer).toString('base64'),\n        status: res.status,\n        url: res.url\n    };\n    // We can skip setting the serverComponentsHmrCache because we aren't in dev\n    // mode.\n    if (incrementalCacheContext) {\n        await incrementalCache.set(cacheKey, {\n            kind: CachedRouteKind.FETCH,\n            data: fetchedData,\n            revalidate\n        }, incrementalCacheContext);\n    }\n    await handleUnlock();\n    // We return a new Response to the caller.\n    return new Response(bodyBuffer, {\n        headers: res.headers,\n        status: res.status,\n        statusText: res.statusText\n    });\n}\nasync function createCachedDynamicResponse(workStore, res, cacheKey, incrementalCacheContext, incrementalCache, serverComponentsHmrCache, revalidate, input, handleUnlock) {\n    // We're cloning the response using this utility because there exists a bug in\n    // the undici library around response cloning. See the following pull request\n    // for more details: https://github.com/vercel/next.js/pull/73274\n    const [cloned1, cloned2] = cloneResponse(res);\n    // We are dynamically rendering including dev mode. We want to return the\n    // response to the caller as soon as possible because it might stream over a\n    // very long time.\n    const cacheSetPromise = cloned1.arrayBuffer().then(async (arrayBuffer)=>{\n        const bodyBuffer = Buffer.from(arrayBuffer);\n        const fetchedData = {\n            headers: Object.fromEntries(cloned1.headers.entries()),\n            body: bodyBuffer.toString('base64'),\n            status: cloned1.status,\n            url: cloned1.url\n        };\n        serverComponentsHmrCache == null ? void 0 : serverComponentsHmrCache.set(cacheKey, fetchedData);\n        if (incrementalCacheContext) {\n            await incrementalCache.set(cacheKey, {\n                kind: CachedRouteKind.FETCH,\n                data: fetchedData,\n                revalidate\n            }, incrementalCacheContext);\n        }\n    }).catch((error)=>console.warn(`Failed to set fetch cache`, input, error)).finally(handleUnlock);\n    const pendingRevalidateKey = `cache-set-${cacheKey}`;\n    const pendingRevalidates = workStore.pendingRevalidates ??= {};\n    let pendingRevalidatePromise = Promise.resolve();\n    if (pendingRevalidateKey in pendingRevalidates) {\n        // There is already a pending revalidate entry that we need to await to\n        // avoid race conditions.\n        pendingRevalidatePromise = pendingRevalidates[pendingRevalidateKey];\n    }\n    pendingRevalidates[pendingRevalidateKey] = pendingRevalidatePromise.then(()=>cacheSetPromise).finally(()=>{\n        // If the pending revalidate is not present in the store, then we have\n        // nothing to delete.\n        if (!(pendingRevalidates == null ? void 0 : pendingRevalidates[pendingRevalidateKey])) {\n            return;\n        }\n        delete pendingRevalidates[pendingRevalidateKey];\n    });\n    return cloned2;\n}\nexport function createPatchedFetcher(originFetch, { workAsyncStorage, workUnitAsyncStorage }) {\n    // Create the patched fetch function.\n    const patched = async function fetch(input, init) {\n        var _init_method, _init_next;\n        let url;\n        try {\n            url = new URL(input instanceof Request ? input.url : input);\n            url.username = '';\n            url.password = '';\n        } catch  {\n            // Error caused by malformed URL should be handled by native fetch\n            url = undefined;\n        }\n        const fetchUrl = (url == null ? void 0 : url.href) ?? '';\n        const method = (init == null ? void 0 : (_init_method = init.method) == null ? void 0 : _init_method.toUpperCase()) || 'GET';\n        // Do create a new span trace for internal fetches in the\n        // non-verbose mode.\n        const isInternal = (init == null ? void 0 : (_init_next = init.next) == null ? void 0 : _init_next.internal) === true;\n        const hideSpan = process.env.NEXT_OTEL_FETCH_DISABLED === '1';\n        // We don't track fetch metrics for internal fetches\n        // so it's not critical that we have a start time, as it won't be recorded.\n        // This is to workaround a flaky issue where performance APIs might\n        // not be available and will require follow-up investigation.\n        const fetchStart = isInternal ? undefined : performance.timeOrigin + performance.now();\n        const workStore = workAsyncStorage.getStore();\n        const workUnitStore = workUnitAsyncStorage.getStore();\n        let cacheSignal = workUnitStore ? getCacheSignal(workUnitStore) : null;\n        if (cacheSignal) {\n            cacheSignal.beginRead();\n        }\n        const result = getTracer().trace(isInternal ? NextNodeServerSpan.internalFetch : AppRenderSpan.fetch, {\n            hideSpan,\n            kind: SpanKind.CLIENT,\n            spanName: [\n                'fetch',\n                method,\n                fetchUrl\n            ].filter(Boolean).join(' '),\n            attributes: {\n                'http.url': fetchUrl,\n                'http.method': method,\n                'net.peer.name': url == null ? void 0 : url.hostname,\n                'net.peer.port': (url == null ? void 0 : url.port) || undefined\n            }\n        }, async ()=>{\n            var _getRequestMeta;\n            // If this is an internal fetch, we should not do any special treatment.\n            if (isInternal) {\n                return originFetch(input, init);\n            }\n            // If the workStore is not available, we can't do any\n            // special treatment of fetch, therefore fallback to the original\n            // fetch implementation.\n            if (!workStore) {\n                return originFetch(input, init);\n            }\n            // We should also fallback to the original fetch implementation if we\n            // are in draft mode, it does not constitute a static generation.\n            if (workStore.isDraftMode) {\n                return originFetch(input, init);\n            }\n            const isRequestInput = input && typeof input === 'object' && typeof input.method === 'string';\n            const getRequestMeta = (field)=>{\n                // If request input is present but init is not, retrieve from input first.\n                const value = init == null ? void 0 : init[field];\n                return value || (isRequestInput ? input[field] : null);\n            };\n            let finalRevalidate = undefined;\n            const getNextField = (field)=>{\n                var _init_next, _init_next1, _input_next;\n                return typeof (init == null ? void 0 : (_init_next = init.next) == null ? void 0 : _init_next[field]) !== 'undefined' ? init == null ? void 0 : (_init_next1 = init.next) == null ? void 0 : _init_next1[field] : isRequestInput ? (_input_next = input.next) == null ? void 0 : _input_next[field] : undefined;\n            };\n            // RequestInit doesn't keep extra fields e.g. next so it's\n            // only available if init is used separate\n            const originalFetchRevalidate = getNextField('revalidate');\n            let currentFetchRevalidate = originalFetchRevalidate;\n            const tags = validateTags(getNextField('tags') || [], `fetch ${input.toString()}`);\n            let revalidateStore;\n            if (workUnitStore) {\n                switch(workUnitStore.type){\n                    case 'prerender':\n                    case 'prerender-runtime':\n                    // TODO: Stop accumulating tags in client prerender. (fallthrough)\n                    case 'prerender-client':\n                    case 'prerender-ppr':\n                    case 'prerender-legacy':\n                    case 'cache':\n                    case 'private-cache':\n                        revalidateStore = workUnitStore;\n                        break;\n                    case 'request':\n                    case 'unstable-cache':\n                        break;\n                    default:\n                        workUnitStore;\n                }\n            }\n            if (revalidateStore) {\n                if (Array.isArray(tags)) {\n                    // Collect tags onto parent caches or parent prerenders.\n                    const collectedTags = revalidateStore.tags ?? (revalidateStore.tags = []);\n                    for (const tag of tags){\n                        if (!collectedTags.includes(tag)) {\n                            collectedTags.push(tag);\n                        }\n                    }\n                }\n            }\n            const implicitTags = workUnitStore == null ? void 0 : workUnitStore.implicitTags;\n            let pageFetchCacheMode = workStore.fetchCache;\n            if (workUnitStore) {\n                switch(workUnitStore.type){\n                    case 'unstable-cache':\n                        // Inside unstable-cache we treat it the same as force-no-store on\n                        // the page.\n                        pageFetchCacheMode = 'force-no-store';\n                        break;\n                    case 'prerender':\n                    case 'prerender-client':\n                    case 'prerender-runtime':\n                    case 'prerender-ppr':\n                    case 'prerender-legacy':\n                    case 'request':\n                    case 'cache':\n                    case 'private-cache':\n                        break;\n                    default:\n                        workUnitStore;\n                }\n            }\n            const isUsingNoStore = !!workStore.isUnstableNoStore;\n            let currentFetchCacheConfig = getRequestMeta('cache');\n            let cacheReason = '';\n            let cacheWarning;\n            if (typeof currentFetchCacheConfig === 'string' && typeof currentFetchRevalidate !== 'undefined') {\n                // If the revalidate value conflicts with the cache value, we should warn the user and unset the conflicting values.\n                const isConflictingRevalidate = // revalidate: 0 and cache: force-cache\n                currentFetchCacheConfig === 'force-cache' && currentFetchRevalidate === 0 || // revalidate: >0 or revalidate: false and cache: no-store\n                currentFetchCacheConfig === 'no-store' && (currentFetchRevalidate > 0 || currentFetchRevalidate === false);\n                if (isConflictingRevalidate) {\n                    cacheWarning = `Specified \"cache: ${currentFetchCacheConfig}\" and \"revalidate: ${currentFetchRevalidate}\", only one should be specified.`;\n                    currentFetchCacheConfig = undefined;\n                    currentFetchRevalidate = undefined;\n                }\n            }\n            const hasExplicitFetchCacheOptOut = // fetch config itself signals not to cache\n            currentFetchCacheConfig === 'no-cache' || currentFetchCacheConfig === 'no-store' || // the fetch isn't explicitly caching and the segment level cache config signals not to cache\n            // note: `pageFetchCacheMode` is also set by being in an unstable_cache context.\n            pageFetchCacheMode === 'force-no-store' || pageFetchCacheMode === 'only-no-store';\n            // If no explicit fetch cache mode is set, but dynamic = `force-dynamic` is set,\n            // we shouldn't consider caching the fetch. This is because the `dynamic` cache\n            // is considered a \"top-level\" cache mode, whereas something like `fetchCache` is more\n            // fine-grained. Top-level modes are responsible for setting reasonable defaults for the\n            // other configurations.\n            const noFetchConfigAndForceDynamic = !pageFetchCacheMode && !currentFetchCacheConfig && !currentFetchRevalidate && workStore.forceDynamic;\n            if (// force-cache was specified without a revalidate value. We set the revalidate value to false\n            // which will signal the cache to not revalidate\n            currentFetchCacheConfig === 'force-cache' && typeof currentFetchRevalidate === 'undefined') {\n                currentFetchRevalidate = false;\n            } else if (hasExplicitFetchCacheOptOut || noFetchConfigAndForceDynamic) {\n                currentFetchRevalidate = 0;\n            }\n            if (currentFetchCacheConfig === 'no-cache' || currentFetchCacheConfig === 'no-store') {\n                cacheReason = `cache: ${currentFetchCacheConfig}`;\n            }\n            finalRevalidate = validateRevalidate(currentFetchRevalidate, workStore.route);\n            const _headers = getRequestMeta('headers');\n            const initHeaders = typeof (_headers == null ? void 0 : _headers.get) === 'function' ? _headers : new Headers(_headers || {});\n            const hasUnCacheableHeader = initHeaders.get('authorization') || initHeaders.get('cookie');\n            const isUnCacheableMethod = ![\n                'get',\n                'head'\n            ].includes(((_getRequestMeta = getRequestMeta('method')) == null ? void 0 : _getRequestMeta.toLowerCase()) || 'get');\n            /**\n         * We automatically disable fetch caching under the following conditions:\n         * - Fetch cache configs are not set. Specifically:\n         *    - A page fetch cache mode is not set (export const fetchCache=...)\n         *    - A fetch cache mode is not set in the fetch call (fetch(url, { cache: ... }))\n         *      or the fetch cache mode is set to 'default'\n         *    - A fetch revalidate value is not set in the fetch call (fetch(url, { revalidate: ... }))\n         * - OR the fetch comes after a configuration that triggered dynamic rendering (e.g., reading cookies())\n         *   and the fetch was considered uncacheable (e.g., POST method or has authorization headers)\n         */ const hasNoExplicitCacheConfig = // eslint-disable-next-line eqeqeq\n            pageFetchCacheMode == undefined && // eslint-disable-next-line eqeqeq\n            (currentFetchCacheConfig == undefined || // when considering whether to opt into the default \"no-cache\" fetch semantics,\n            // a \"default\" cache config should be treated the same as no cache config\n            currentFetchCacheConfig === 'default') && // eslint-disable-next-line eqeqeq\n            currentFetchRevalidate == undefined;\n            let autoNoCache = Boolean((hasUnCacheableHeader || isUnCacheableMethod) && (revalidateStore == null ? void 0 : revalidateStore.revalidate) === 0);\n            let isImplicitBuildTimeCache = false;\n            if (!autoNoCache && hasNoExplicitCacheConfig) {\n                // We don't enable automatic no-cache behavior during build-time\n                // prerendering so that we can still leverage the fetch cache between\n                // export workers.\n                if (workStore.isBuildTimePrerendering) {\n                    isImplicitBuildTimeCache = true;\n                } else {\n                    autoNoCache = true;\n                }\n            }\n            // If we have no cache config, and we're in Dynamic I/O prerendering,\n            // it'll be a dynamic call. We don't have to issue that dynamic call.\n            if (hasNoExplicitCacheConfig && workUnitStore !== undefined) {\n                switch(workUnitStore.type){\n                    case 'prerender':\n                    case 'prerender-runtime':\n                    // While we don't want to do caching in the client scope we know the\n                    // fetch will be dynamic for cacheComponents so we may as well avoid the\n                    // call here. (fallthrough)\n                    case 'prerender-client':\n                        if (cacheSignal) {\n                            cacheSignal.endRead();\n                            cacheSignal = null;\n                        }\n                        return makeHangingPromise(workUnitStore.renderSignal, workStore.route, 'fetch()');\n                    case 'request':\n                        if (process.env.NODE_ENV === 'development' && workUnitStore.stagedRendering) {\n                            if (cacheSignal) {\n                                cacheSignal.endRead();\n                                cacheSignal = null;\n                            }\n                            await workUnitStore.stagedRendering.waitForStage(RenderStage.Dynamic);\n                        }\n                        break;\n                    case 'prerender-ppr':\n                    case 'prerender-legacy':\n                    case 'cache':\n                    case 'private-cache':\n                    case 'unstable-cache':\n                        break;\n                    default:\n                        workUnitStore;\n                }\n            }\n            switch(pageFetchCacheMode){\n                case 'force-no-store':\n                    {\n                        cacheReason = 'fetchCache = force-no-store';\n                        break;\n                    }\n                case 'only-no-store':\n                    {\n                        if (currentFetchCacheConfig === 'force-cache' || typeof finalRevalidate !== 'undefined' && finalRevalidate > 0) {\n                            throw Object.defineProperty(new Error(`cache: 'force-cache' used on fetch for ${fetchUrl} with 'export const fetchCache = 'only-no-store'`), \"__NEXT_ERROR_CODE\", {\n                                value: \"E448\",\n                                enumerable: false,\n                                configurable: true\n                            });\n                        }\n                        cacheReason = 'fetchCache = only-no-store';\n                        break;\n                    }\n                case 'only-cache':\n                    {\n                        if (currentFetchCacheConfig === 'no-store') {\n                            throw Object.defineProperty(new Error(`cache: 'no-store' used on fetch for ${fetchUrl} with 'export const fetchCache = 'only-cache'`), \"__NEXT_ERROR_CODE\", {\n                                value: \"E521\",\n                                enumerable: false,\n                                configurable: true\n                            });\n                        }\n                        break;\n                    }\n                case 'force-cache':\n                    {\n                        if (typeof currentFetchRevalidate === 'undefined' || currentFetchRevalidate === 0) {\n                            cacheReason = 'fetchCache = force-cache';\n                            finalRevalidate = INFINITE_CACHE;\n                        }\n                        break;\n                    }\n                case 'default-cache':\n                case 'default-no-store':\n                case 'auto':\n                case undefined:\n                    break;\n                default:\n                    pageFetchCacheMode;\n            }\n            if (typeof finalRevalidate === 'undefined') {\n                if (pageFetchCacheMode === 'default-cache' && !isUsingNoStore) {\n                    finalRevalidate = INFINITE_CACHE;\n                    cacheReason = 'fetchCache = default-cache';\n                } else if (pageFetchCacheMode === 'default-no-store') {\n                    finalRevalidate = 0;\n                    cacheReason = 'fetchCache = default-no-store';\n                } else if (isUsingNoStore) {\n                    finalRevalidate = 0;\n                    cacheReason = 'noStore call';\n                } else if (autoNoCache) {\n                    finalRevalidate = 0;\n                    cacheReason = 'auto no cache';\n                } else {\n                    // TODO: should we consider this case an invariant?\n                    cacheReason = 'auto cache';\n                    finalRevalidate = revalidateStore ? revalidateStore.revalidate : INFINITE_CACHE;\n                }\n            } else if (!cacheReason) {\n                cacheReason = `revalidate: ${finalRevalidate}`;\n            }\n            if (// when force static is configured we don't bail from\n            // `revalidate: 0` values\n            !(workStore.forceStatic && finalRevalidate === 0) && // we don't consider autoNoCache to switch to dynamic for ISR\n            !autoNoCache && // If the revalidate value isn't currently set or the value is less\n            // than the current revalidate value, we should update the revalidate\n            // value.\n            revalidateStore && finalRevalidate < revalidateStore.revalidate) {\n                // If we were setting the revalidate value to 0, we should try to\n                // postpone instead first.\n                if (finalRevalidate === 0) {\n                    if (workUnitStore) {\n                        switch(workUnitStore.type){\n                            case 'prerender':\n                            case 'prerender-client':\n                            case 'prerender-runtime':\n                                if (cacheSignal) {\n                                    cacheSignal.endRead();\n                                    cacheSignal = null;\n                                }\n                                return makeHangingPromise(workUnitStore.renderSignal, workStore.route, 'fetch()');\n                            case 'request':\n                                if (process.env.NODE_ENV === 'development' && workUnitStore.stagedRendering) {\n                                    if (cacheSignal) {\n                                        cacheSignal.endRead();\n                                        cacheSignal = null;\n                                    }\n                                    await workUnitStore.stagedRendering.waitForStage(RenderStage.Dynamic);\n                                }\n                                break;\n                            case 'prerender-ppr':\n                            case 'prerender-legacy':\n                            case 'cache':\n                            case 'private-cache':\n                            case 'unstable-cache':\n                                break;\n                            default:\n                                workUnitStore;\n                        }\n                    }\n                    markCurrentScopeAsDynamic(workStore, workUnitStore, `revalidate: 0 fetch ${input} ${workStore.route}`);\n                }\n                // We only want to set the revalidate store's revalidate time if it\n                // was explicitly set for the fetch call, i.e.\n                // originalFetchRevalidate.\n                if (revalidateStore && originalFetchRevalidate === finalRevalidate) {\n                    revalidateStore.revalidate = finalRevalidate;\n                }\n            }\n            const isCacheableRevalidate = typeof finalRevalidate === 'number' && finalRevalidate > 0;\n            let cacheKey;\n            const { incrementalCache } = workStore;\n            let isHmrRefresh = false;\n            let serverComponentsHmrCache;\n            if (workUnitStore) {\n                switch(workUnitStore.type){\n                    case 'request':\n                    case 'cache':\n                    case 'private-cache':\n                        isHmrRefresh = workUnitStore.isHmrRefresh ?? false;\n                        serverComponentsHmrCache = workUnitStore.serverComponentsHmrCache;\n                        break;\n                    case 'prerender':\n                    case 'prerender-client':\n                    case 'prerender-runtime':\n                    case 'prerender-ppr':\n                    case 'prerender-legacy':\n                    case 'unstable-cache':\n                        break;\n                    default:\n                        workUnitStore;\n                }\n            }\n            if (incrementalCache && (isCacheableRevalidate || serverComponentsHmrCache)) {\n                try {\n                    cacheKey = await incrementalCache.generateCacheKey(fetchUrl, isRequestInput ? input : init);\n                } catch (err) {\n                    console.error(`Failed to generate cache key for`, input);\n                }\n            }\n            const fetchIdx = workStore.nextFetchId ?? 1;\n            workStore.nextFetchId = fetchIdx + 1;\n            let handleUnlock = ()=>{};\n            const doOriginalFetch = async (isStale, cacheReasonOverride)=>{\n                const requestInputFields = [\n                    'cache',\n                    'credentials',\n                    'headers',\n                    'integrity',\n                    'keepalive',\n                    'method',\n                    'mode',\n                    'redirect',\n                    'referrer',\n                    'referrerPolicy',\n                    'window',\n                    'duplex',\n                    // don't pass through signal when revalidating\n                    ...isStale ? [] : [\n                        'signal'\n                    ]\n                ];\n                if (isRequestInput) {\n                    const reqInput = input;\n                    const reqOptions = {\n                        body: reqInput._ogBody || reqInput.body\n                    };\n                    for (const field of requestInputFields){\n                        // @ts-expect-error custom fields\n                        reqOptions[field] = reqInput[field];\n                    }\n                    input = new Request(reqInput.url, reqOptions);\n                } else if (init) {\n                    const { _ogBody, body, signal, ...otherInput } = init;\n                    init = {\n                        ...otherInput,\n                        body: _ogBody || body,\n                        signal: isStale ? undefined : signal\n                    };\n                }\n                // add metadata to init without editing the original\n                const clonedInit = {\n                    ...init,\n                    next: {\n                        ...init == null ? void 0 : init.next,\n                        fetchType: 'origin',\n                        fetchIdx\n                    }\n                };\n                return originFetch(input, clonedInit).then(async (res)=>{\n                    if (!isStale && fetchStart) {\n                        trackFetchMetric(workStore, {\n                            start: fetchStart,\n                            url: fetchUrl,\n                            cacheReason: cacheReasonOverride || cacheReason,\n                            cacheStatus: finalRevalidate === 0 || cacheReasonOverride ? 'skip' : 'miss',\n                            cacheWarning,\n                            status: res.status,\n                            method: clonedInit.method || 'GET'\n                        });\n                    }\n                    if (res.status === 200 && incrementalCache && cacheKey && (isCacheableRevalidate || serverComponentsHmrCache)) {\n                        const normalizedRevalidate = finalRevalidate >= INFINITE_CACHE ? CACHE_ONE_YEAR : finalRevalidate;\n                        const incrementalCacheConfig = isCacheableRevalidate ? {\n                            fetchCache: true,\n                            fetchUrl,\n                            fetchIdx,\n                            tags,\n                            isImplicitBuildTimeCache\n                        } : undefined;\n                        switch(workUnitStore == null ? void 0 : workUnitStore.type){\n                            case 'prerender':\n                            case 'prerender-client':\n                            case 'prerender-runtime':\n                                return createCachedPrerenderResponse(res, cacheKey, incrementalCacheConfig, incrementalCache, normalizedRevalidate, handleUnlock);\n                            case 'request':\n                                if (process.env.NODE_ENV === 'development' && workUnitStore.stagedRendering && workUnitStore.cacheSignal) {\n                                    // We're filling caches for a staged render,\n                                    // so we need to wait for the response to finish instead of streaming.\n                                    return createCachedPrerenderResponse(res, cacheKey, incrementalCacheConfig, incrementalCache, normalizedRevalidate, handleUnlock);\n                                }\n                            // fallthrough\n                            case 'prerender-ppr':\n                            case 'prerender-legacy':\n                            case 'cache':\n                            case 'private-cache':\n                            case 'unstable-cache':\n                            case undefined:\n                                return createCachedDynamicResponse(workStore, res, cacheKey, incrementalCacheConfig, incrementalCache, serverComponentsHmrCache, normalizedRevalidate, input, handleUnlock);\n                            default:\n                                workUnitStore;\n                        }\n                    }\n                    // we had response that we determined shouldn't be cached so we return it\n                    // and don't cache it. This also needs to unlock the cache lock we acquired.\n                    await handleUnlock();\n                    return res;\n                }).catch((error)=>{\n                    handleUnlock();\n                    throw error;\n                });\n            };\n            let cacheReasonOverride;\n            let isForegroundRevalidate = false;\n            let isHmrRefreshCache = false;\n            if (cacheKey && incrementalCache) {\n                let cachedFetchData;\n                if (isHmrRefresh && serverComponentsHmrCache) {\n                    cachedFetchData = serverComponentsHmrCache.get(cacheKey);\n                    isHmrRefreshCache = true;\n                }\n                if (isCacheableRevalidate && !cachedFetchData) {\n                    handleUnlock = await incrementalCache.lock(cacheKey);\n                    const entry = workStore.isOnDemandRevalidate ? null : await incrementalCache.get(cacheKey, {\n                        kind: IncrementalCacheKind.FETCH,\n                        revalidate: finalRevalidate,\n                        fetchUrl,\n                        fetchIdx,\n                        tags,\n                        softTags: implicitTags == null ? void 0 : implicitTags.tags\n                    });\n                    if (hasNoExplicitCacheConfig && workUnitStore) {\n                        switch(workUnitStore.type){\n                            case 'prerender':\n                            case 'prerender-client':\n                            case 'prerender-runtime':\n                                // We sometimes use the cache to dedupe fetches that do not\n                                // specify a cache configuration. In these cases we want to\n                                // make sure we still exclude them from prerenders if\n                                // cacheComponents is on so we introduce an artificial task boundary\n                                // here.\n                                await getTimeoutBoundary();\n                                break;\n                            case 'request':\n                                if (process.env.NODE_ENV === 'development' && workUnitStore.stagedRendering) {\n                                    await workUnitStore.stagedRendering.waitForStage(RenderStage.Dynamic);\n                                }\n                                break;\n                            case 'prerender-ppr':\n                            case 'prerender-legacy':\n                            case 'cache':\n                            case 'private-cache':\n                            case 'unstable-cache':\n                                break;\n                            default:\n                                workUnitStore;\n                        }\n                    }\n                    if (entry) {\n                        await handleUnlock();\n                    } else {\n                        // in dev, incremental cache response will be null in case the browser adds `cache-control: no-cache` in the request headers\n                        // TODO: it seems like we also hit this after revalidates in dev?\n                        cacheReasonOverride = 'cache-control: no-cache (hard refresh)';\n                    }\n                    if ((entry == null ? void 0 : entry.value) && entry.value.kind === CachedRouteKind.FETCH) {\n                        // when stale and is revalidating we wait for fresh data\n                        // so the revalidated entry has the updated data\n                        if (workStore.isStaticGeneration && entry.isStale) {\n                            isForegroundRevalidate = true;\n                        } else {\n                            if (entry.isStale) {\n                                workStore.pendingRevalidates ??= {};\n                                if (!workStore.pendingRevalidates[cacheKey]) {\n                                    const pendingRevalidate = doOriginalFetch(true).then(async (response)=>({\n                                            body: await response.arrayBuffer(),\n                                            headers: response.headers,\n                                            status: response.status,\n                                            statusText: response.statusText\n                                        })).finally(()=>{\n                                        workStore.pendingRevalidates ??= {};\n                                        delete workStore.pendingRevalidates[cacheKey || ''];\n                                    });\n                                    // Attach the empty catch here so we don't get a \"unhandled\n                                    // promise rejection\" warning.\n                                    pendingRevalidate.catch(console.error);\n                                    workStore.pendingRevalidates[cacheKey] = pendingRevalidate;\n                                }\n                            }\n                            cachedFetchData = entry.value.data;\n                        }\n                    }\n                }\n                if (cachedFetchData) {\n                    if (fetchStart) {\n                        trackFetchMetric(workStore, {\n                            start: fetchStart,\n                            url: fetchUrl,\n                            cacheReason,\n                            cacheStatus: isHmrRefreshCache ? 'hmr' : 'hit',\n                            cacheWarning,\n                            status: cachedFetchData.status || 200,\n                            method: (init == null ? void 0 : init.method) || 'GET'\n                        });\n                    }\n                    const response = new Response(Buffer.from(cachedFetchData.body, 'base64'), {\n                        headers: cachedFetchData.headers,\n                        status: cachedFetchData.status\n                    });\n                    Object.defineProperty(response, 'url', {\n                        value: cachedFetchData.url\n                    });\n                    return response;\n                }\n            }\n            if ((workStore.isStaticGeneration || process.env.NODE_ENV === 'development' && process.env.__NEXT_CACHE_COMPONENTS && workUnitStore && // eslint-disable-next-line no-restricted-syntax\n            workUnitStore.type === 'request' && workUnitStore.stagedRendering) && init && typeof init === 'object') {\n                const { cache } = init;\n                // Delete `cache` property as Cloudflare Workers will throw an error\n                if (isEdgeRuntime) delete init.cache;\n                if (cache === 'no-store') {\n                    // If enabled, we should bail out of static generation.\n                    if (workUnitStore) {\n                        switch(workUnitStore.type){\n                            case 'prerender':\n                            case 'prerender-client':\n                            case 'prerender-runtime':\n                                if (cacheSignal) {\n                                    cacheSignal.endRead();\n                                    cacheSignal = null;\n                                }\n                                return makeHangingPromise(workUnitStore.renderSignal, workStore.route, 'fetch()');\n                            case 'request':\n                                if (process.env.NODE_ENV === 'development' && workUnitStore.stagedRendering) {\n                                    if (cacheSignal) {\n                                        cacheSignal.endRead();\n                                        cacheSignal = null;\n                                    }\n                                    await workUnitStore.stagedRendering.waitForStage(RenderStage.Dynamic);\n                                }\n                                break;\n                            case 'prerender-ppr':\n                            case 'prerender-legacy':\n                            case 'cache':\n                            case 'private-cache':\n                            case 'unstable-cache':\n                                break;\n                            default:\n                                workUnitStore;\n                        }\n                    }\n                    markCurrentScopeAsDynamic(workStore, workUnitStore, `no-store fetch ${input} ${workStore.route}`);\n                }\n                const hasNextConfig = 'next' in init;\n                const { next = {} } = init;\n                if (typeof next.revalidate === 'number' && revalidateStore && next.revalidate < revalidateStore.revalidate) {\n                    if (next.revalidate === 0) {\n                        // If enabled, we should bail out of static generation.\n                        if (workUnitStore) {\n                            switch(workUnitStore.type){\n                                case 'prerender':\n                                case 'prerender-client':\n                                case 'prerender-runtime':\n                                    return makeHangingPromise(workUnitStore.renderSignal, workStore.route, 'fetch()');\n                                case 'request':\n                                    if (process.env.NODE_ENV === 'development' && workUnitStore.stagedRendering) {\n                                        await workUnitStore.stagedRendering.waitForStage(RenderStage.Dynamic);\n                                    }\n                                    break;\n                                case 'cache':\n                                case 'private-cache':\n                                case 'unstable-cache':\n                                case 'prerender-legacy':\n                                case 'prerender-ppr':\n                                    break;\n                                default:\n                                    workUnitStore;\n                            }\n                        }\n                        markCurrentScopeAsDynamic(workStore, workUnitStore, `revalidate: 0 fetch ${input} ${workStore.route}`);\n                    }\n                    if (!workStore.forceStatic || next.revalidate !== 0) {\n                        revalidateStore.revalidate = next.revalidate;\n                    }\n                }\n                if (hasNextConfig) delete init.next;\n            }\n            // if we are revalidating the whole page via time or on-demand and\n            // the fetch cache entry is stale we should still de-dupe the\n            // origin hit if it's a cache-able entry\n            if (cacheKey && isForegroundRevalidate) {\n                const pendingRevalidateKey = cacheKey;\n                workStore.pendingRevalidates ??= {};\n                let pendingRevalidate = workStore.pendingRevalidates[pendingRevalidateKey];\n                if (pendingRevalidate) {\n                    const revalidatedResult = await pendingRevalidate;\n                    return new Response(revalidatedResult.body, {\n                        headers: revalidatedResult.headers,\n                        status: revalidatedResult.status,\n                        statusText: revalidatedResult.statusText\n                    });\n                }\n                // We used to just resolve the Response and clone it however for\n                // static generation with cacheComponents we need the response to be able to\n                // be resolved in a microtask and cloning the response will never have\n                // a body that can resolve in a microtask in node (as observed through\n                // experimentation) So instead we await the body and then when it is\n                // available we construct manually cloned Response objects with the\n                // body as an ArrayBuffer. This will be resolvable in a microtask\n                // making it compatible with cacheComponents.\n                const pendingResponse = doOriginalFetch(true, cacheReasonOverride)// We're cloning the response using this utility because there\n                // exists a bug in the undici library around response cloning.\n                // See the following pull request for more details:\n                // https://github.com/vercel/next.js/pull/73274\n                .then(cloneResponse);\n                pendingRevalidate = pendingResponse.then(async (responses)=>{\n                    const response = responses[0];\n                    return {\n                        body: await response.arrayBuffer(),\n                        headers: response.headers,\n                        status: response.status,\n                        statusText: response.statusText\n                    };\n                }).finally(()=>{\n                    var _workStore_pendingRevalidates;\n                    // If the pending revalidate is not present in the store, then\n                    // we have nothing to delete.\n                    if (!((_workStore_pendingRevalidates = workStore.pendingRevalidates) == null ? void 0 : _workStore_pendingRevalidates[pendingRevalidateKey])) {\n                        return;\n                    }\n                    delete workStore.pendingRevalidates[pendingRevalidateKey];\n                });\n                // Attach the empty catch here so we don't get a \"unhandled promise\n                // rejection\" warning\n                pendingRevalidate.catch(()=>{});\n                workStore.pendingRevalidates[pendingRevalidateKey] = pendingRevalidate;\n                return pendingResponse.then((responses)=>responses[1]);\n            } else {\n                return doOriginalFetch(false, cacheReasonOverride);\n            }\n        });\n        if (cacheSignal) {\n            try {\n                return await result;\n            } finally{\n                if (cacheSignal) {\n                    cacheSignal.endRead();\n                }\n            }\n        }\n        return result;\n    };\n    // Attach the necessary properties to the patched fetch function.\n    // We don't use this to determine if the fetch function has been patched,\n    // but for external consumers to determine if the fetch function has been\n    // patched.\n    patched.__nextPatched = true;\n    patched.__nextGetStaticStore = ()=>workAsyncStorage;\n    patched._nextOriginalFetch = originFetch;\n    globalThis[NEXT_PATCH_SYMBOL] = true;\n    // Assign the function name also as a name property, so that it's preserved\n    // even when mangling is enabled.\n    Object.defineProperty(patched, 'name', {\n        value: 'fetch',\n        writable: false\n    });\n    return patched;\n}\n// we patch fetch to collect cache information used for\n// determining if a page is static or not\nexport function patchFetch(options) {\n    // If we've already patched fetch, we should not patch it again.\n    if (isFetchPatched()) return;\n    // Grab the original fetch function. We'll attach this so we can use it in\n    // the patched fetch function.\n    const original = createDedupeFetch(globalThis.fetch);\n    // Set the global fetch to the patched fetch.\n    globalThis.fetch = createPatchedFetcher(original, options);\n}\nlet currentTimeoutBoundary = null;\nfunction getTimeoutBoundary() {\n    if (!currentTimeoutBoundary) {\n        currentTimeoutBoundary = new Promise((r)=>{\n            setTimeout(()=>{\n                currentTimeoutBoundary = null;\n                r();\n            }, 0);\n        });\n    }\n    return currentTimeoutBoundary;\n}\n\n//# sourceMappingURL=patch-fetch.js.map","/**\n * This file provides some helpers that should be used in conjunction with\n * explicit environment checks. When combined with the environment checks, it\n * will ensure that the correct typings are used as well as enable code\n * elimination.\n */ /**\n * Type guard to determine if a request is a WebNextRequest. This does not\n * actually check the type of the request, but rather the runtime environment.\n * It's expected that when the runtime environment is the edge runtime, that any\n * base request is a WebNextRequest.\n */ export const isWebNextRequest = (req)=>process.env.NEXT_RUNTIME === 'edge';\n/**\n * Type guard to determine if a response is a WebNextResponse. This does not\n * actually check the type of the response, but rather the runtime environment.\n * It's expected that when the runtime environment is the edge runtime, that any\n * base response is a WebNextResponse.\n */ export const isWebNextResponse = (res)=>process.env.NEXT_RUNTIME === 'edge';\n/**\n * Type guard to determine if a request is a NodeNextRequest. This does not\n * actually check the type of the request, but rather the runtime environment.\n * It's expected that when the runtime environment is the node runtime, that any\n * base request is a NodeNextRequest.\n */ export const isNodeNextRequest = (req)=>process.env.NEXT_RUNTIME !== 'edge';\n/**\n * Type guard to determine if a response is a NodeNextResponse. This does not\n * actually check the type of the response, but rather the runtime environment.\n * It's expected that when the runtime environment is the node runtime, that any\n * base response is a NodeNextResponse.\n */ export const isNodeNextResponse = (res)=>process.env.NEXT_RUNTIME !== 'edge';\n\n//# sourceMappingURL=helpers.js.map","/**\n * Route pattern normalization utilities for path-to-regexp compatibility.\n *\n * path-to-regexp 6.3.0+ introduced stricter validation that rejects certain\n * patterns commonly used in Next.js interception routes. This module provides\n * normalization functions to make Next.js route patterns compatible with the\n * updated library while preserving all functionality.\n */ /**\n * Internal separator used to normalize adjacent parameter patterns.\n * This unique marker is inserted between adjacent parameters and stripped out\n * during parameter extraction to avoid conflicts with real URL content.\n */ export const PARAM_SEPARATOR = '_NEXTSEP_';\n/**\n * Detects if a route pattern needs normalization for path-to-regexp compatibility.\n */ export function hasAdjacentParameterIssues(route) {\n    if (typeof route !== 'string') return false;\n    // Check for interception route markers followed immediately by parameters\n    // Pattern: /(.):param, /(..):param, /(...):param, /(.)(.):param etc.\n    // These patterns cause \"Must have text between two parameters\" errors\n    if (/\\/\\(\\.{1,3}\\):[^/\\s]+/.test(route)) {\n        return true;\n    }\n    // Check for basic adjacent parameters without separators\n    // Pattern: :param1:param2 (but not :param* or other URL patterns)\n    if (/:[a-zA-Z_][a-zA-Z0-9_]*:[a-zA-Z_][a-zA-Z0-9_]*/.test(route)) {\n        return true;\n    }\n    return false;\n}\n/**\n * Normalizes route patterns that have adjacent parameters without text between them.\n * Inserts a unique separator that can be safely stripped out later.\n */ export function normalizeAdjacentParameters(route) {\n    let normalized = route;\n    // Handle interception route patterns: (.):param -> (.)_NEXTSEP_:param\n    normalized = normalized.replace(/(\\([^)]*\\)):([^/\\s]+)/g, `$1${PARAM_SEPARATOR}:$2`);\n    // Handle other adjacent parameter patterns: :param1:param2 -> :param1_NEXTSEP_:param2\n    normalized = normalized.replace(/:([^:/\\s)]+)(?=:)/g, `:$1${PARAM_SEPARATOR}`);\n    return normalized;\n}\n/**\n * Normalizes tokens that have repeating modifiers (* or +) but empty prefix and suffix.\n *\n * path-to-regexp 6.3.0+ introduced validation that throws:\n * \"Can not repeat without prefix/suffix\"\n *\n * This occurs when a token has modifier: '*' or '+' with both prefix: '' and suffix: ''\n */ export function normalizeTokensForRegexp(tokens) {\n    return tokens.map((token)=>{\n        // Token union type: Token = string | TokenObject\n        // Literal path segments are strings, parameters/wildcards are objects\n        if (typeof token === 'object' && token !== null && // Not all token objects have 'modifier' property (e.g., simple text tokens)\n        'modifier' in token && // Only repeating modifiers (* or +) cause the validation error\n        // Other modifiers like '?' (optional) are fine\n        (token.modifier === '*' || token.modifier === '+') && // Token objects can have different shapes depending on route pattern\n        'prefix' in token && 'suffix' in token && // Both prefix and suffix must be empty strings\n        // This is what causes the validation error in path-to-regexp\n        token.prefix === '' && token.suffix === '') {\n            // Add minimal prefix to satisfy path-to-regexp validation\n            // We use '/' as it's the most common path delimiter and won't break route matching\n            // The prefix gets used in regex generation but doesn't affect parameter extraction\n            return {\n                ...token,\n                prefix: '/'\n            };\n        }\n        return token;\n    });\n}\n/**\n * Strips normalization separators from compiled pathname.\n * This removes separators that were inserted by normalizeAdjacentParameters\n * to satisfy path-to-regexp validation.\n *\n * Only removes separators in the specific contexts where they were inserted:\n * - After interception route markers: (.)_NEXTSEP_ -> (.)\n *\n * This targeted approach ensures we don't accidentally remove the separator\n * from legitimate user content.\n */ export function stripNormalizedSeparators(pathname) {\n    // Remove separator after interception route markers\n    // Pattern: (.)_NEXTSEP_ -> (.), (..)_NEXTSEP_ -> (..), etc.\n    // The separator appears after the closing paren of interception markers\n    return pathname.replace(new RegExp(`\\\\)${PARAM_SEPARATOR}`, 'g'), ')');\n}\n/**\n * Strips normalization separators from extracted route parameters.\n * Used by both server and client code to clean up parameters after route matching.\n */ export function stripParameterSeparators(params) {\n    const cleaned = {};\n    for (const [key, value] of Object.entries(params)){\n        if (typeof value === 'string') {\n            // Remove the separator if it appears at the start of parameter values\n            cleaned[key] = value.replace(new RegExp(`^${PARAM_SEPARATOR}`), '');\n        } else if (Array.isArray(value)) {\n            // Handle array parameters (from repeated route segments)\n            cleaned[key] = value.map((item)=>typeof item === 'string' ? item.replace(new RegExp(`^${PARAM_SEPARATOR}`), '') : item);\n        } else {\n            cleaned[key] = value;\n        }\n    }\n    return cleaned;\n}\n\n//# sourceMappingURL=route-pattern-normalizer.js.map","import { ensureLeadingSlash } from './ensure-leading-slash';\nimport { isDynamicRoute } from '../router/utils';\nimport { NormalizeError } from '../utils';\n/**\n * Takes a page and transforms it into its file counterpart ensuring that the\n * output is normalized. Note this function is not idempotent because a page\n * `/index` can be referencing `/index/index.js` and `/index/index` could be\n * referencing `/index/index/index.js`. Examples:\n *  - `/` -> `/index`\n *  - `/index/foo` -> `/index/index/foo`\n *  - `/index` -> `/index/index`\n */ export function normalizePagePath(page) {\n    const normalized = /^\\/index(\\/|$)/.test(page) && !isDynamicRoute(page) ? `/index${page}` : page === '/' ? '/index' : ensureLeadingSlash(page);\n    if (process.env.NEXT_RUNTIME !== 'edge') {\n        const { posix } = require('path');\n        const resolvedPage = posix.normalize(normalized);\n        if (resolvedPage !== normalized) {\n            throw new NormalizeError(`Requested and resolved page mismatch: ${normalized} ${resolvedPage}`);\n        }\n    }\n    return normalized;\n}\n\n//# sourceMappingURL=normalize-page-path.js.map","import { normalizeLocalePath } from '../shared/lib/i18n/normalize-locale-path';\nimport { getPathMatch } from '../shared/lib/router/utils/path-match';\nimport { getNamedRouteRegex } from '../shared/lib/router/utils/route-regex';\nimport { getRouteMatcher } from '../shared/lib/router/utils/route-matcher';\nimport { matchHas, prepareDestination } from '../shared/lib/router/utils/prepare-destination';\nimport { removeTrailingSlash } from '../shared/lib/router/utils/remove-trailing-slash';\nimport { normalizeRscURL } from '../shared/lib/router/utils/app-paths';\nimport { NEXT_CACHE_REVALIDATE_TAG_TOKEN_HEADER, NEXT_CACHE_REVALIDATED_TAGS_HEADER, NEXT_INTERCEPTION_MARKER_PREFIX, NEXT_QUERY_PARAM_PREFIX } from '../lib/constants';\nimport { normalizeNextQueryParam } from './web/utils';\nimport { decodeQueryPathParameter } from './lib/decode-query-path-parameter';\nimport { parseReqUrl } from '../lib/url';\nimport { formatUrl } from '../shared/lib/router/utils/format-url';\nfunction filterInternalQuery(query, paramKeys) {\n    // this is used to pass query information in rewrites\n    // but should not be exposed in final query\n    delete query['nextInternalLocale'];\n    for(const key in query){\n        const isNextQueryPrefix = key !== NEXT_QUERY_PARAM_PREFIX && key.startsWith(NEXT_QUERY_PARAM_PREFIX);\n        const isNextInterceptionMarkerPrefix = key !== NEXT_INTERCEPTION_MARKER_PREFIX && key.startsWith(NEXT_INTERCEPTION_MARKER_PREFIX);\n        if (isNextQueryPrefix || isNextInterceptionMarkerPrefix || paramKeys.includes(key)) {\n            delete query[key];\n        }\n    }\n}\nexport function normalizeCdnUrl(req, paramKeys) {\n    // make sure to normalize req.url from CDNs to strip dynamic and rewrite\n    // params from the query which are added during routing\n    const _parsedUrl = parseReqUrl(req.url);\n    // we can't normalize if we can't parse\n    if (!_parsedUrl) {\n        return req.url;\n    }\n    delete _parsedUrl.search;\n    filterInternalQuery(_parsedUrl.query, paramKeys);\n    req.url = formatUrl(_parsedUrl);\n}\nexport function interpolateDynamicPath(pathname, params, defaultRouteRegex) {\n    if (!defaultRouteRegex) return pathname;\n    for (const param of Object.keys(defaultRouteRegex.groups)){\n        const { optional, repeat } = defaultRouteRegex.groups[param];\n        let builtParam = `[${repeat ? '...' : ''}${param}]`;\n        if (optional) {\n            builtParam = `[${builtParam}]`;\n        }\n        let paramValue;\n        const value = params[param];\n        if (Array.isArray(value)) {\n            paramValue = value.map((v)=>v && encodeURIComponent(v)).join('/');\n        } else if (value) {\n            paramValue = encodeURIComponent(value);\n        } else {\n            paramValue = '';\n        }\n        if (paramValue || optional) {\n            pathname = pathname.replaceAll(builtParam, paramValue);\n        }\n    }\n    return pathname;\n}\nexport function normalizeDynamicRouteParams(query, defaultRouteRegex, defaultRouteMatches, ignoreMissingOptional) {\n    let hasValidParams = true;\n    let params = {};\n    for (const key of Object.keys(defaultRouteRegex.groups)){\n        let value = query[key];\n        if (typeof value === 'string') {\n            value = normalizeRscURL(value);\n        } else if (Array.isArray(value)) {\n            value = value.map(normalizeRscURL);\n        }\n        // if the value matches the default value we can't rely\n        // on the parsed params, this is used to signal if we need\n        // to parse x-now-route-matches or not\n        const defaultValue = defaultRouteMatches[key];\n        const isOptional = defaultRouteRegex.groups[key].optional;\n        const isDefaultValue = Array.isArray(defaultValue) ? defaultValue.some((defaultVal)=>{\n            return Array.isArray(value) ? value.some((val)=>val.includes(defaultVal)) : value == null ? void 0 : value.includes(defaultVal);\n        }) : value == null ? void 0 : value.includes(defaultValue);\n        if (isDefaultValue || typeof value === 'undefined' && !(isOptional && ignoreMissingOptional)) {\n            return {\n                params: {},\n                hasValidParams: false\n            };\n        }\n        // non-provided optional values should be undefined so normalize\n        // them to undefined\n        if (isOptional && (!value || Array.isArray(value) && value.length === 1 && // fallback optional catch-all SSG pages have\n        // [[...paramName]] for the root path on Vercel\n        (value[0] === 'index' || value[0] === `[[...${key}]]`) || value === 'index' || value === `[[...${key}]]`)) {\n            value = undefined;\n            delete query[key];\n        }\n        // query values from the proxy aren't already split into arrays\n        // so make sure to normalize catch-all values\n        if (value && typeof value === 'string' && defaultRouteRegex.groups[key].repeat) {\n            value = value.split('/');\n        }\n        if (value) {\n            params[key] = value;\n        }\n    }\n    return {\n        params,\n        hasValidParams\n    };\n}\nexport function getServerUtils({ page, i18n, basePath, rewrites, pageIsDynamic, trailingSlash, caseSensitive }) {\n    let defaultRouteRegex;\n    let dynamicRouteMatcher;\n    let defaultRouteMatches;\n    if (pageIsDynamic) {\n        defaultRouteRegex = getNamedRouteRegex(page, {\n            prefixRouteKeys: false\n        });\n        dynamicRouteMatcher = getRouteMatcher(defaultRouteRegex);\n        defaultRouteMatches = dynamicRouteMatcher(page);\n    }\n    function handleRewrites(req, parsedUrl) {\n        // Here we deep clone the parsedUrl to avoid mutating the original. We also\n        // cast this to a mutable type so we can mutate it within this scope.\n        const rewrittenParsedUrl = structuredClone(parsedUrl);\n        const rewriteParams = {};\n        let fsPathname = rewrittenParsedUrl.pathname;\n        const matchesPage = ()=>{\n            const fsPathnameNoSlash = removeTrailingSlash(fsPathname || '');\n            return fsPathnameNoSlash === removeTrailingSlash(page) || (dynamicRouteMatcher == null ? void 0 : dynamicRouteMatcher(fsPathnameNoSlash));\n        };\n        const checkRewrite = (rewrite)=>{\n            const matcher = getPathMatch(rewrite.source + (trailingSlash ? '(/)?' : ''), {\n                removeUnnamedParams: true,\n                strict: true,\n                sensitive: !!caseSensitive\n            });\n            if (!rewrittenParsedUrl.pathname) return false;\n            let params = matcher(rewrittenParsedUrl.pathname);\n            if ((rewrite.has || rewrite.missing) && params) {\n                const hasParams = matchHas(req, rewrittenParsedUrl.query, rewrite.has, rewrite.missing);\n                if (hasParams) {\n                    Object.assign(params, hasParams);\n                } else {\n                    params = false;\n                }\n            }\n            if (params) {\n                const { parsedDestination, destQuery } = prepareDestination({\n                    appendParamsToQuery: true,\n                    destination: rewrite.destination,\n                    params: params,\n                    query: rewrittenParsedUrl.query\n                });\n                // if the rewrite destination is external break rewrite chain\n                if (parsedDestination.protocol) {\n                    return true;\n                }\n                Object.assign(rewriteParams, destQuery, params);\n                Object.assign(rewrittenParsedUrl.query, parsedDestination.query);\n                delete parsedDestination.query;\n                Object.assign(rewrittenParsedUrl, parsedDestination);\n                fsPathname = rewrittenParsedUrl.pathname;\n                if (!fsPathname) return false;\n                if (basePath) {\n                    fsPathname = fsPathname.replace(new RegExp(`^${basePath}`), '') || '/';\n                }\n                if (i18n) {\n                    const result = normalizeLocalePath(fsPathname, i18n.locales);\n                    fsPathname = result.pathname;\n                    rewrittenParsedUrl.query.nextInternalLocale = result.detectedLocale || params.nextInternalLocale;\n                }\n                if (fsPathname === page) {\n                    return true;\n                }\n                if (pageIsDynamic && dynamicRouteMatcher) {\n                    const dynamicParams = dynamicRouteMatcher(fsPathname);\n                    if (dynamicParams) {\n                        rewrittenParsedUrl.query = {\n                            ...rewrittenParsedUrl.query,\n                            ...dynamicParams\n                        };\n                        return true;\n                    }\n                }\n            }\n            return false;\n        };\n        for (const rewrite of rewrites.beforeFiles || []){\n            checkRewrite(rewrite);\n        }\n        if (fsPathname !== page) {\n            let finished = false;\n            for (const rewrite of rewrites.afterFiles || []){\n                finished = checkRewrite(rewrite);\n                if (finished) break;\n            }\n            if (!finished && !matchesPage()) {\n                for (const rewrite of rewrites.fallback || []){\n                    finished = checkRewrite(rewrite);\n                    if (finished) break;\n                }\n            }\n        }\n        return {\n            rewriteParams,\n            rewrittenParsedUrl\n        };\n    }\n    function getParamsFromRouteMatches(routeMatchesHeader) {\n        // If we don't have a default route regex, we can't get params from route\n        // matches\n        if (!defaultRouteRegex) return null;\n        const { groups, routeKeys } = defaultRouteRegex;\n        const matcher = getRouteMatcher({\n            re: {\n                // Simulate a RegExp match from the \\`req.url\\` input\n                exec: (str)=>{\n                    // Normalize all the prefixed query params.\n                    const obj = Object.fromEntries(new URLSearchParams(str));\n                    for (const [key, value] of Object.entries(obj)){\n                        const normalizedKey = normalizeNextQueryParam(key);\n                        if (!normalizedKey) continue;\n                        obj[normalizedKey] = value;\n                        delete obj[key];\n                    }\n                    // Use all the named route keys.\n                    const result = {};\n                    for (const keyName of Object.keys(routeKeys)){\n                        const paramName = routeKeys[keyName];\n                        // If this param name is not a valid parameter name, then skip it.\n                        if (!paramName) continue;\n                        const group = groups[paramName];\n                        const value = obj[keyName];\n                        // When we're missing a required param, we can't match the route.\n                        if (!group.optional && !value) return null;\n                        result[group.pos] = value;\n                    }\n                    return result;\n                }\n            },\n            groups\n        });\n        const routeMatches = matcher(routeMatchesHeader);\n        if (!routeMatches) return null;\n        return routeMatches;\n    }\n    function normalizeQueryParams(query, routeParamKeys) {\n        // this is used to pass query information in rewrites\n        // but should not be exposed in final query\n        delete query['nextInternalLocale'];\n        for (const [key, value] of Object.entries(query)){\n            const normalizedKey = normalizeNextQueryParam(key);\n            if (!normalizedKey) continue;\n            // Remove the prefixed key from the query params because we want\n            // to consume it for the dynamic route matcher.\n            delete query[key];\n            routeParamKeys.add(normalizedKey);\n            if (typeof value === 'undefined') continue;\n            query[normalizedKey] = Array.isArray(value) ? value.map((v)=>decodeQueryPathParameter(v)) : decodeQueryPathParameter(value);\n        }\n    }\n    return {\n        handleRewrites,\n        defaultRouteRegex,\n        dynamicRouteMatcher,\n        defaultRouteMatches,\n        normalizeQueryParams,\n        getParamsFromRouteMatches,\n        /**\n     * Normalize dynamic route params.\n     *\n     * @param query - The query params to normalize.\n     * @param ignoreMissingOptional - Whether to ignore missing optional params.\n     * @returns The normalized params and whether they are valid.\n     */ normalizeDynamicRouteParams: (query, ignoreMissingOptional)=>{\n            if (!defaultRouteRegex || !defaultRouteMatches) {\n                return {\n                    params: {},\n                    hasValidParams: false\n                };\n            }\n            return normalizeDynamicRouteParams(query, defaultRouteRegex, defaultRouteMatches, ignoreMissingOptional);\n        },\n        normalizeCdnUrl: (req, paramKeys)=>normalizeCdnUrl(req, paramKeys),\n        interpolateDynamicPath: (pathname, params)=>interpolateDynamicPath(pathname, params, defaultRouteRegex),\n        filterInternalQuery: (query, paramKeys)=>filterInternalQuery(query, paramKeys)\n    };\n}\nexport function getPreviouslyRevalidatedTags(headers, previewModeId) {\n    return typeof headers[NEXT_CACHE_REVALIDATED_TAGS_HEADER] === 'string' && headers[NEXT_CACHE_REVALIDATE_TAG_TOKEN_HEADER] === previewModeId ? headers[NEXT_CACHE_REVALIDATED_TAGS_HEADER].split(',') : [];\n}\n\n//# sourceMappingURL=server-utils.js.map","import { IncrementalCacheKind, CachedRouteKind } from '../../response-cache';\nimport FileSystemCache from './file-system-cache';\nimport { normalizePagePath } from '../../../shared/lib/page-path/normalize-page-path';\nimport { CACHE_ONE_YEAR, NEXT_CACHE_TAGS_HEADER, PRERENDER_REVALIDATE_HEADER } from '../../../lib/constants';\nimport { toRoute } from '../to-route';\nimport { SharedCacheControls } from './shared-cache-controls.external';\nimport { getPrerenderResumeDataCache, getRenderResumeDataCache, workUnitAsyncStorage } from '../../app-render/work-unit-async-storage.external';\nimport { InvariantError } from '../../../shared/lib/invariant-error';\nimport { getPreviouslyRevalidatedTags } from '../../server-utils';\nimport { workAsyncStorage } from '../../app-render/work-async-storage.external';\nimport { DetachedPromise } from '../../../lib/detached-promise';\nimport { areTagsExpired, areTagsStale } from './tags-manifest.external';\nexport class CacheHandler {\n    // eslint-disable-next-line\n    constructor(_ctx){}\n    async get(_cacheKey, _ctx) {\n        return {};\n    }\n    async set(_cacheKey, _data, _ctx) {}\n    async revalidateTag(_tags, _durations) {}\n    resetRequestCache() {}\n}\nexport class IncrementalCache {\n    static #_ = this.debug = !!process.env.NEXT_PRIVATE_DEBUG_CACHE;\n    constructor({ fs, dev, flushToDisk, minimalMode, serverDistDir, requestHeaders, maxMemoryCacheSize, getPrerenderManifest, fetchCacheKeyPrefix, CurCacheHandler, allowedRevalidateHeaderKeys }){\n        var _this_prerenderManifest_preview, _this_prerenderManifest;\n        this.locks = new Map();\n        this.hasCustomCacheHandler = Boolean(CurCacheHandler);\n        const cacheHandlersSymbol = Symbol.for('@next/cache-handlers');\n        const _globalThis = globalThis;\n        if (!CurCacheHandler) {\n            // if we have a global cache handler available leverage it\n            const globalCacheHandler = _globalThis[cacheHandlersSymbol];\n            if (globalCacheHandler == null ? void 0 : globalCacheHandler.FetchCache) {\n                CurCacheHandler = globalCacheHandler.FetchCache;\n                if (IncrementalCache.debug) {\n                    console.log('IncrementalCache: using global FetchCache cache handler');\n                }\n            } else {\n                if (fs && serverDistDir) {\n                    if (IncrementalCache.debug) {\n                        console.log('IncrementalCache: using filesystem cache handler');\n                    }\n                    CurCacheHandler = FileSystemCache;\n                }\n            }\n        } else if (IncrementalCache.debug) {\n            console.log('IncrementalCache: using custom cache handler', CurCacheHandler.name);\n        }\n        if (process.env.__NEXT_TEST_MAX_ISR_CACHE) {\n            // Allow cache size to be overridden for testing purposes\n            maxMemoryCacheSize = parseInt(process.env.__NEXT_TEST_MAX_ISR_CACHE, 10);\n        }\n        this.dev = dev;\n        this.disableForTestmode = process.env.NEXT_PRIVATE_TEST_PROXY === 'true';\n        // this is a hack to avoid Webpack knowing this is equal to this.minimalMode\n        // because we replace this.minimalMode to true in production bundles.\n        const minimalModeKey = 'minimalMode';\n        this[minimalModeKey] = minimalMode;\n        this.requestHeaders = requestHeaders;\n        this.allowedRevalidateHeaderKeys = allowedRevalidateHeaderKeys;\n        this.prerenderManifest = getPrerenderManifest();\n        this.cacheControls = new SharedCacheControls(this.prerenderManifest);\n        this.fetchCacheKeyPrefix = fetchCacheKeyPrefix;\n        let revalidatedTags = [];\n        if (requestHeaders[PRERENDER_REVALIDATE_HEADER] === ((_this_prerenderManifest = this.prerenderManifest) == null ? void 0 : (_this_prerenderManifest_preview = _this_prerenderManifest.preview) == null ? void 0 : _this_prerenderManifest_preview.previewModeId)) {\n            this.isOnDemandRevalidate = true;\n        }\n        if (minimalMode) {\n            var _this_prerenderManifest_preview1, _this_prerenderManifest1;\n            revalidatedTags = this.revalidatedTags = getPreviouslyRevalidatedTags(requestHeaders, (_this_prerenderManifest1 = this.prerenderManifest) == null ? void 0 : (_this_prerenderManifest_preview1 = _this_prerenderManifest1.preview) == null ? void 0 : _this_prerenderManifest_preview1.previewModeId);\n        }\n        if (CurCacheHandler) {\n            this.cacheHandler = new CurCacheHandler({\n                dev,\n                fs,\n                flushToDisk,\n                serverDistDir,\n                revalidatedTags,\n                maxMemoryCacheSize,\n                _requestHeaders: requestHeaders,\n                fetchCacheKeyPrefix\n            });\n        }\n    }\n    calculateRevalidate(pathname, fromTime, dev, isFallback) {\n        // in development we don't have a prerender-manifest\n        // and default to always revalidating to allow easier debugging\n        if (dev) return Math.floor(performance.timeOrigin + performance.now() - 1000);\n        const cacheControl = this.cacheControls.get(toRoute(pathname));\n        // if an entry isn't present in routes we fallback to a default\n        // of revalidating after 1 second unless it's a fallback request.\n        const initialRevalidateSeconds = cacheControl ? cacheControl.revalidate : isFallback ? false : 1;\n        const revalidateAfter = typeof initialRevalidateSeconds === 'number' ? initialRevalidateSeconds * 1000 + fromTime : initialRevalidateSeconds;\n        return revalidateAfter;\n    }\n    _getPathname(pathname, fetchCache) {\n        return fetchCache ? pathname : normalizePagePath(pathname);\n    }\n    resetRequestCache() {\n        var _this_cacheHandler_resetRequestCache, _this_cacheHandler;\n        (_this_cacheHandler = this.cacheHandler) == null ? void 0 : (_this_cacheHandler_resetRequestCache = _this_cacheHandler.resetRequestCache) == null ? void 0 : _this_cacheHandler_resetRequestCache.call(_this_cacheHandler);\n    }\n    async lock(cacheKey) {\n        // Wait for any existing lock on this cache key to be released\n        // This implements a simple queue-based locking mechanism\n        while(true){\n            const lock = this.locks.get(cacheKey);\n            if (IncrementalCache.debug) {\n                console.log('IncrementalCache: lock get', cacheKey, !!lock);\n            }\n            // If no lock exists, we can proceed to acquire it\n            if (!lock) break;\n            // Wait for the existing lock to be released before trying again\n            await lock;\n        }\n        // Create a new detached promise that will represent this lock\n        // The resolve function (unlock) will be returned to the caller\n        const { resolve, promise } = new DetachedPromise();\n        if (IncrementalCache.debug) {\n            console.log('IncrementalCache: successfully locked', cacheKey);\n        }\n        // Store the lock promise in the locks map\n        this.locks.set(cacheKey, promise);\n        return ()=>{\n            // Resolve the promise to release the lock.\n            resolve();\n            // Remove the lock from the map once it's released so that future gets\n            // can acquire the lock.\n            this.locks.delete(cacheKey);\n        };\n    }\n    async revalidateTag(tags, durations) {\n        var _this_cacheHandler;\n        return (_this_cacheHandler = this.cacheHandler) == null ? void 0 : _this_cacheHandler.revalidateTag(tags, durations);\n    }\n    // x-ref: https://github.com/facebook/react/blob/2655c9354d8e1c54ba888444220f63e836925caa/packages/react/src/ReactFetch.js#L23\n    async generateCacheKey(url, init = {}) {\n        // this should be bumped anytime a fix is made to cache entries\n        // that should bust the cache\n        const MAIN_KEY_PREFIX = 'v3';\n        const bodyChunks = [];\n        const encoder = new TextEncoder();\n        const decoder = new TextDecoder();\n        if (init.body) {\n            // handle Uint8Array body\n            if (init.body instanceof Uint8Array) {\n                bodyChunks.push(decoder.decode(init.body));\n                init._ogBody = init.body;\n            } else if (typeof init.body.getReader === 'function') {\n                const readableBody = init.body;\n                const chunks = [];\n                try {\n                    await readableBody.pipeTo(new WritableStream({\n                        write (chunk) {\n                            if (typeof chunk === 'string') {\n                                chunks.push(encoder.encode(chunk));\n                                bodyChunks.push(chunk);\n                            } else {\n                                chunks.push(chunk);\n                                bodyChunks.push(decoder.decode(chunk, {\n                                    stream: true\n                                }));\n                            }\n                        }\n                    }));\n                    // Flush the decoder.\n                    bodyChunks.push(decoder.decode());\n                    // Create a new buffer with all the chunks.\n                    const length = chunks.reduce((total, arr)=>total + arr.length, 0);\n                    const arrayBuffer = new Uint8Array(length);\n                    // Push each of the chunks into the new array buffer.\n                    let offset = 0;\n                    for (const chunk of chunks){\n                        arrayBuffer.set(chunk, offset);\n                        offset += chunk.length;\n                    }\n                    ;\n                    init._ogBody = arrayBuffer;\n                } catch (err) {\n                    console.error('Problem reading body', err);\n                }\n            } else if (typeof init.body.keys === 'function') {\n                const formData = init.body;\n                init._ogBody = init.body;\n                for (const key of new Set([\n                    ...formData.keys()\n                ])){\n                    const values = formData.getAll(key);\n                    bodyChunks.push(`${key}=${(await Promise.all(values.map(async (val)=>{\n                        if (typeof val === 'string') {\n                            return val;\n                        } else {\n                            return await val.text();\n                        }\n                    }))).join(',')}`);\n                }\n            // handle blob body\n            } else if (typeof init.body.arrayBuffer === 'function') {\n                const blob = init.body;\n                const arrayBuffer = await blob.arrayBuffer();\n                bodyChunks.push(await blob.text());\n                init._ogBody = new Blob([\n                    arrayBuffer\n                ], {\n                    type: blob.type\n                });\n            } else if (typeof init.body === 'string') {\n                bodyChunks.push(init.body);\n                init._ogBody = init.body;\n            }\n        }\n        const headers = typeof (init.headers || {}).keys === 'function' ? Object.fromEntries(init.headers) : Object.assign({}, init.headers);\n        // w3c trace context headers can break request caching and deduplication\n        // so we remove them from the cache key\n        if ('traceparent' in headers) delete headers['traceparent'];\n        if ('tracestate' in headers) delete headers['tracestate'];\n        const cacheString = JSON.stringify([\n            MAIN_KEY_PREFIX,\n            this.fetchCacheKeyPrefix || '',\n            url,\n            init.method,\n            headers,\n            init.mode,\n            init.redirect,\n            init.credentials,\n            init.referrer,\n            init.referrerPolicy,\n            init.integrity,\n            init.cache,\n            bodyChunks\n        ]);\n        if (process.env.NEXT_RUNTIME === 'edge') {\n            function bufferToHex(buffer) {\n                return Array.prototype.map.call(new Uint8Array(buffer), (b)=>b.toString(16).padStart(2, '0')).join('');\n            }\n            const buffer = encoder.encode(cacheString);\n            return bufferToHex(await crypto.subtle.digest('SHA-256', buffer));\n        } else {\n            const crypto1 = require('crypto');\n            return crypto1.createHash('sha256').update(cacheString).digest('hex');\n        }\n    }\n    async get(cacheKey, ctx) {\n        var _this_cacheHandler, _cacheData_value;\n        // Unlike other caches if we have a resume data cache, we use it even if\n        // testmode would normally disable it or if requestHeaders say 'no-cache'.\n        if (ctx.kind === IncrementalCacheKind.FETCH) {\n            const workUnitStore = workUnitAsyncStorage.getStore();\n            const resumeDataCache = workUnitStore ? getRenderResumeDataCache(workUnitStore) : null;\n            if (resumeDataCache) {\n                const memoryCacheData = resumeDataCache.fetch.get(cacheKey);\n                if ((memoryCacheData == null ? void 0 : memoryCacheData.kind) === CachedRouteKind.FETCH) {\n                    if (IncrementalCache.debug) {\n                        console.log('IncrementalCache: rdc:hit', cacheKey);\n                    }\n                    return {\n                        isStale: false,\n                        value: memoryCacheData\n                    };\n                } else if (IncrementalCache.debug) {\n                    console.log('IncrementalCache: rdc:miss', cacheKey);\n                }\n            } else {\n                if (IncrementalCache.debug) {\n                    console.log('IncrementalCache: rdc:no-resume-data');\n                }\n            }\n        }\n        // we don't leverage the prerender cache in dev mode\n        // so that getStaticProps is always called for easier debugging\n        if (this.disableForTestmode || this.dev && (ctx.kind !== IncrementalCacheKind.FETCH || this.requestHeaders['cache-control'] === 'no-cache')) {\n            return null;\n        }\n        cacheKey = this._getPathname(cacheKey, ctx.kind === IncrementalCacheKind.FETCH);\n        const cacheData = await ((_this_cacheHandler = this.cacheHandler) == null ? void 0 : _this_cacheHandler.get(cacheKey, ctx));\n        if (ctx.kind === IncrementalCacheKind.FETCH) {\n            var _cacheData_value1;\n            if (!cacheData) {\n                return null;\n            }\n            if (((_cacheData_value1 = cacheData.value) == null ? void 0 : _cacheData_value1.kind) !== CachedRouteKind.FETCH) {\n                var _cacheData_value2;\n                throw Object.defineProperty(new InvariantError(`Expected cached value for cache key ${JSON.stringify(cacheKey)} to be a \"FETCH\" kind, got ${JSON.stringify((_cacheData_value2 = cacheData.value) == null ? void 0 : _cacheData_value2.kind)} instead.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E653\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            const workStore = workAsyncStorage.getStore();\n            const combinedTags = [\n                ...ctx.tags || [],\n                ...ctx.softTags || []\n            ];\n            // if a tag was revalidated we don't return stale data\n            if (combinedTags.some((tag)=>{\n                var _this_revalidatedTags, _workStore_pendingRevalidatedTags;\n                return ((_this_revalidatedTags = this.revalidatedTags) == null ? void 0 : _this_revalidatedTags.includes(tag)) || (workStore == null ? void 0 : (_workStore_pendingRevalidatedTags = workStore.pendingRevalidatedTags) == null ? void 0 : _workStore_pendingRevalidatedTags.some((item)=>item.tag === tag));\n            })) {\n                if (IncrementalCache.debug) {\n                    console.log('IncrementalCache: expired tag', cacheKey);\n                }\n                return null;\n            }\n            // As we're able to get the cache entry for this fetch, and the prerender\n            // resume data cache (RDC) is available, it must have been populated by a\n            // previous fetch, but was not yet present in the in-memory cache. This\n            // could be the case when performing multiple renders in parallel during\n            // build time where we de-duplicate the fetch calls.\n            //\n            // We add it to the RDC so that the next fetch call will be able to use it\n            // and it won't have to reach into the fetch cache implementation.\n            const workUnitStore = workUnitAsyncStorage.getStore();\n            if (workUnitStore) {\n                const prerenderResumeDataCache = getPrerenderResumeDataCache(workUnitStore);\n                if (prerenderResumeDataCache) {\n                    if (IncrementalCache.debug) {\n                        console.log('IncrementalCache: rdc:set', cacheKey);\n                    }\n                    prerenderResumeDataCache.fetch.set(cacheKey, cacheData.value);\n                }\n            }\n            const revalidate = ctx.revalidate || cacheData.value.revalidate;\n            const age = (performance.timeOrigin + performance.now() - (cacheData.lastModified || 0)) / 1000;\n            let isStale = age > revalidate;\n            const data = cacheData.value.data;\n            if (areTagsExpired(combinedTags, cacheData.lastModified)) {\n                return null;\n            } else if (areTagsStale(combinedTags, cacheData.lastModified)) {\n                isStale = true;\n            }\n            return {\n                isStale,\n                value: {\n                    kind: CachedRouteKind.FETCH,\n                    data,\n                    revalidate\n                }\n            };\n        } else if ((cacheData == null ? void 0 : (_cacheData_value = cacheData.value) == null ? void 0 : _cacheData_value.kind) === CachedRouteKind.FETCH) {\n            throw Object.defineProperty(new InvariantError(`Expected cached value for cache key ${JSON.stringify(cacheKey)} not to be a ${JSON.stringify(ctx.kind)} kind, got \"FETCH\" instead.`), \"__NEXT_ERROR_CODE\", {\n                value: \"E652\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        let entry = null;\n        const cacheControl = this.cacheControls.get(toRoute(cacheKey));\n        let isStale;\n        let revalidateAfter;\n        if ((cacheData == null ? void 0 : cacheData.lastModified) === -1) {\n            isStale = -1;\n            revalidateAfter = -1 * CACHE_ONE_YEAR;\n        } else {\n            var _cacheData_value3, _cacheData_value4;\n            const now = performance.timeOrigin + performance.now();\n            const lastModified = (cacheData == null ? void 0 : cacheData.lastModified) || now;\n            revalidateAfter = this.calculateRevalidate(cacheKey, lastModified, this.dev ?? false, ctx.isFallback);\n            isStale = revalidateAfter !== false && revalidateAfter < now ? true : undefined;\n            // If the stale time couldn't be determined based on the revalidation\n            // time, we check if the tags are expired or stale.\n            if (isStale === undefined && ((cacheData == null ? void 0 : (_cacheData_value3 = cacheData.value) == null ? void 0 : _cacheData_value3.kind) === CachedRouteKind.APP_PAGE || (cacheData == null ? void 0 : (_cacheData_value4 = cacheData.value) == null ? void 0 : _cacheData_value4.kind) === CachedRouteKind.APP_ROUTE)) {\n                var _cacheData_value_headers;\n                const tagsHeader = (_cacheData_value_headers = cacheData.value.headers) == null ? void 0 : _cacheData_value_headers[NEXT_CACHE_TAGS_HEADER];\n                if (typeof tagsHeader === 'string') {\n                    const cacheTags = tagsHeader.split(',');\n                    if (cacheTags.length > 0) {\n                        if (areTagsExpired(cacheTags, lastModified)) {\n                            isStale = -1;\n                        } else if (areTagsStale(cacheTags, lastModified)) {\n                            isStale = true;\n                        }\n                    }\n                }\n            }\n        }\n        if (cacheData) {\n            entry = {\n                isStale,\n                cacheControl,\n                revalidateAfter,\n                value: cacheData.value\n            };\n        }\n        if (!cacheData && this.prerenderManifest.notFoundRoutes.includes(cacheKey)) {\n            // for the first hit after starting the server the cache\n            // may not have a way to save notFound: true so if\n            // the prerender-manifest marks this as notFound then we\n            // return that entry and trigger a cache set to give it a\n            // chance to update in-memory entries\n            entry = {\n                isStale,\n                value: null,\n                cacheControl,\n                revalidateAfter\n            };\n            this.set(cacheKey, entry.value, {\n                ...ctx,\n                cacheControl\n            });\n        }\n        return entry;\n    }\n    async set(pathname, data, ctx) {\n        // Even if we otherwise disable caching for testMode or if no fetchCache is\n        // configured we still always stash results in the resume data cache if one\n        // exists. This is because this is a transient in memory cache that\n        // populates caches ahead of a dynamic render in dev mode to allow the RSC\n        // debug info to have the right environment associated to it.\n        if ((data == null ? void 0 : data.kind) === CachedRouteKind.FETCH) {\n            const workUnitStore = workUnitAsyncStorage.getStore();\n            const prerenderResumeDataCache = workUnitStore ? getPrerenderResumeDataCache(workUnitStore) : null;\n            if (prerenderResumeDataCache) {\n                if (IncrementalCache.debug) {\n                    console.log('IncrementalCache: rdc:set', pathname);\n                }\n                prerenderResumeDataCache.fetch.set(pathname, data);\n            }\n        }\n        if (this.disableForTestmode || this.dev && !ctx.fetchCache) return;\n        pathname = this._getPathname(pathname, ctx.fetchCache);\n        // FetchCache has upper limit of 2MB per-entry currently\n        const itemSize = JSON.stringify(data).length;\n        if (ctx.fetchCache && itemSize > 2 * 1024 * 1024 && // We ignore the size limit when custom cache handler is being used, as it\n        // might not have this limit\n        !this.hasCustomCacheHandler && // We also ignore the size limit when it's an implicit build-time-only\n        // caching that the user isn't even aware of.\n        !ctx.isImplicitBuildTimeCache) {\n            const warningText = `Failed to set Next.js data cache for ${ctx.fetchUrl || pathname}, items over 2MB can not be cached (${itemSize} bytes)`;\n            if (this.dev) {\n                throw Object.defineProperty(new Error(warningText), \"__NEXT_ERROR_CODE\", {\n                    value: \"E394\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            console.warn(warningText);\n            return;\n        }\n        try {\n            var _this_cacheHandler;\n            if (!ctx.fetchCache && ctx.cacheControl) {\n                this.cacheControls.set(toRoute(pathname), ctx.cacheControl);\n            }\n            await ((_this_cacheHandler = this.cacheHandler) == null ? void 0 : _this_cacheHandler.set(pathname, data, ctx));\n        } catch (error) {\n            console.warn('Failed to update prerender cache for', pathname, error);\n        }\n    }\n}\n\n//# sourceMappingURL=index.js.map","import { ensureLeadingSlash } from '../../page-path/ensure-leading-slash';\nimport { isGroupSegment } from '../../segment';\n/**\n * Normalizes an app route so it represents the actual request path. Essentially\n * performing the following transformations:\n *\n * - `/(dashboard)/user/[id]/page` to `/user/[id]`\n * - `/(dashboard)/account/page` to `/account`\n * - `/user/[id]/page` to `/user/[id]`\n * - `/account/page` to `/account`\n * - `/page` to `/`\n * - `/(dashboard)/user/[id]/route` to `/user/[id]`\n * - `/(dashboard)/account/route` to `/account`\n * - `/user/[id]/route` to `/user/[id]`\n * - `/account/route` to `/account`\n * - `/route` to `/`\n * - `/` to `/`\n *\n * @param route the app route to normalize\n * @returns the normalized pathname\n */ export function normalizeAppPath(route) {\n    return ensureLeadingSlash(route.split('/').reduce((pathname, segment, index, segments)=>{\n        // Empty segments are ignored.\n        if (!segment) {\n            return pathname;\n        }\n        // Groups are ignored.\n        if (isGroupSegment(segment)) {\n            return pathname;\n        }\n        // Parallel segments are ignored.\n        if (segment[0] === '@') {\n            return pathname;\n        }\n        // The last segment (if it's a leaf) should be ignored.\n        if ((segment === 'page' || segment === 'route') && index === segments.length - 1) {\n            return pathname;\n        }\n        return `${pathname}/${segment}`;\n    }, ''));\n}\n/**\n * Strips the `.rsc` extension if it's in the pathname.\n * Since this function is used on full urls it checks `?` for searchParams handling.\n */ export function normalizeRscURL(url) {\n    return url.replace(/\\.rsc($|\\?)/, // $1 ensures `?` is preserved\n    '$1');\n}\n\n//# sourceMappingURL=app-paths.js.map","// Format function modified from nodejs\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\nimport * as querystring from './querystring';\nconst slashedProtocols = /https?|ftp|gopher|file/;\nexport function formatUrl(urlObj) {\n    let { auth, hostname } = urlObj;\n    let protocol = urlObj.protocol || '';\n    let pathname = urlObj.pathname || '';\n    let hash = urlObj.hash || '';\n    let query = urlObj.query || '';\n    let host = false;\n    auth = auth ? encodeURIComponent(auth).replace(/%3A/i, ':') + '@' : '';\n    if (urlObj.host) {\n        host = auth + urlObj.host;\n    } else if (hostname) {\n        host = auth + (~hostname.indexOf(':') ? `[${hostname}]` : hostname);\n        if (urlObj.port) {\n            host += ':' + urlObj.port;\n        }\n    }\n    if (query && typeof query === 'object') {\n        query = String(querystring.urlQueryToSearchParams(query));\n    }\n    let search = urlObj.search || query && `?${query}` || '';\n    if (protocol && !protocol.endsWith(':')) protocol += ':';\n    if (urlObj.slashes || (!protocol || slashedProtocols.test(protocol)) && host !== false) {\n        host = '//' + (host || '');\n        if (pathname && pathname[0] !== '/') pathname = '/' + pathname;\n    } else if (!host) {\n        host = '';\n    }\n    if (hash && hash[0] !== '#') hash = '#' + hash;\n    if (search && search[0] !== '?') search = '?' + search;\n    pathname = pathname.replace(/[?#]/g, encodeURIComponent);\n    search = search.replace('#', '%23');\n    return `${protocol}${host}${pathname}${search}${hash}`;\n}\nexport const urlObjectKeys = [\n    'auth',\n    'hash',\n    'host',\n    'hostname',\n    'href',\n    'path',\n    'pathname',\n    'port',\n    'protocol',\n    'query',\n    'search',\n    'slashes'\n];\nexport function formatWithValidation(url) {\n    if (process.env.NODE_ENV === 'development') {\n        if (url !== null && typeof url === 'object') {\n            Object.keys(url).forEach((key)=>{\n                if (!urlObjectKeys.includes(key)) {\n                    console.warn(`Unknown key passed via urlObject into url.format: ${key}`);\n                }\n            });\n        }\n    }\n    return formatUrl(url);\n}\n\n//# sourceMappingURL=format-url.js.map","/**\n * This transforms a URL pathname into a route. It removes any trailing slashes\n * and the `/index` suffix.\n *\n * @param pathname - The URL path that needs to be optimized.\n * @returns - The route\n *\n * @example\n * // returns '/example'\n * toRoute('/example/index/');\n *\n * @example\n * // returns '/example'\n * toRoute('/example/');\n *\n * @example\n * // returns '/'\n * toRoute('/index/');\n *\n * @example\n * // returns '/'\n * toRoute('/');\n */ export function toRoute(pathname) {\n    return pathname.replace(/(?:\\/index)?\\/?$/, '') || '/';\n}\n\n//# sourceMappingURL=to-route.js.map","(()=>{\"use strict\";var e={328:e=>{function hash(e){var r=5381,_=e.length;while(_){r=r*33^e.charCodeAt(--_)}return r>>>0}e.exports=hash}};var r={};function __nccwpck_require__(_){var a=r[_];if(a!==undefined){return a.exports}var t=r[_]={exports:{}};var i=true;try{e[_](t,t.exports,__nccwpck_require__);i=false}finally{if(i)delete r[_]}return t.exports}if(typeof __nccwpck_require__!==\"undefined\")__nccwpck_require__.ab=__dirname+\"/\";var _=__nccwpck_require__(328);module.exports=_})();","import { createAsyncLocalStorage } from './async-local-storage';\nexport const actionAsyncStorageInstance = createAsyncLocalStorage();\n\n//# sourceMappingURL=action-async-storage-instance.js.map","/**\n * @license React\n * react-dom.react-server.production.js\n *\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\"use strict\";\nvar React = require(\"next/dist/compiled/react\");\nfunction noop() {}\nvar Internals = {\n  d: {\n    f: noop,\n    r: function () {\n      throw Error(\n        \"Invalid form element. requestFormReset must be passed a form that was rendered by React.\"\n      );\n    },\n    D: noop,\n    C: noop,\n    L: noop,\n    m: noop,\n    X: noop,\n    S: noop,\n    M: noop\n  },\n  p: 0,\n  findDOMNode: null\n};\nif (!React.__SERVER_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE)\n  throw Error(\n    'The \"react\" package in this environment is not configured correctly. The \"react-server\" condition must be enabled in any environment that runs React Server Components.'\n  );\nfunction getCrossOriginStringAs(as, input) {\n  if (\"font\" === as) return \"\";\n  if (\"string\" === typeof input)\n    return \"use-credentials\" === input ? input : \"\";\n}\nexports.__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE =\n  Internals;\nexports.preconnect = function (href, options) {\n  \"string\" === typeof href &&\n    (options\n      ? ((options = options.crossOrigin),\n        (options =\n          \"string\" === typeof options\n            ? \"use-credentials\" === options\n              ? options\n              : \"\"\n            : void 0))\n      : (options = null),\n    Internals.d.C(href, options));\n};\nexports.prefetchDNS = function (href) {\n  \"string\" === typeof href && Internals.d.D(href);\n};\nexports.preinit = function (href, options) {\n  if (\"string\" === typeof href && options && \"string\" === typeof options.as) {\n    var as = options.as,\n      crossOrigin = getCrossOriginStringAs(as, options.crossOrigin),\n      integrity =\n        \"string\" === typeof options.integrity ? options.integrity : void 0,\n      fetchPriority =\n        \"string\" === typeof options.fetchPriority\n          ? options.fetchPriority\n          : void 0;\n    \"style\" === as\n      ? Internals.d.S(\n          href,\n          \"string\" === typeof options.precedence ? options.precedence : void 0,\n          {\n            crossOrigin: crossOrigin,\n            integrity: integrity,\n            fetchPriority: fetchPriority\n          }\n        )\n      : \"script\" === as &&\n        Internals.d.X(href, {\n          crossOrigin: crossOrigin,\n          integrity: integrity,\n          fetchPriority: fetchPriority,\n          nonce: \"string\" === typeof options.nonce ? options.nonce : void 0\n        });\n  }\n};\nexports.preinitModule = function (href, options) {\n  if (\"string\" === typeof href)\n    if (\"object\" === typeof options && null !== options) {\n      if (null == options.as || \"script\" === options.as) {\n        var crossOrigin = getCrossOriginStringAs(\n          options.as,\n          options.crossOrigin\n        );\n        Internals.d.M(href, {\n          crossOrigin: crossOrigin,\n          integrity:\n            \"string\" === typeof options.integrity ? options.integrity : void 0,\n          nonce: \"string\" === typeof options.nonce ? options.nonce : void 0\n        });\n      }\n    } else null == options && Internals.d.M(href);\n};\nexports.preload = function (href, options) {\n  if (\n    \"string\" === typeof href &&\n    \"object\" === typeof options &&\n    null !== options &&\n    \"string\" === typeof options.as\n  ) {\n    var as = options.as,\n      crossOrigin = getCrossOriginStringAs(as, options.crossOrigin);\n    Internals.d.L(href, as, {\n      crossOrigin: crossOrigin,\n      integrity:\n        \"string\" === typeof options.integrity ? options.integrity : void 0,\n      nonce: \"string\" === typeof options.nonce ? options.nonce : void 0,\n      type: \"string\" === typeof options.type ? options.type : void 0,\n      fetchPriority:\n        \"string\" === typeof options.fetchPriority\n          ? options.fetchPriority\n          : void 0,\n      referrerPolicy:\n        \"string\" === typeof options.referrerPolicy\n          ? options.referrerPolicy\n          : void 0,\n      imageSrcSet:\n        \"string\" === typeof options.imageSrcSet ? options.imageSrcSet : void 0,\n      imageSizes:\n        \"string\" === typeof options.imageSizes ? options.imageSizes : void 0,\n      media: \"string\" === typeof options.media ? options.media : void 0\n    });\n  }\n};\nexports.preloadModule = function (href, options) {\n  if (\"string\" === typeof href)\n    if (options) {\n      var crossOrigin = getCrossOriginStringAs(options.as, options.crossOrigin);\n      Internals.d.m(href, {\n        as:\n          \"string\" === typeof options.as && \"script\" !== options.as\n            ? options.as\n            : void 0,\n        crossOrigin: crossOrigin,\n        integrity:\n          \"string\" === typeof options.integrity ? options.integrity : void 0\n      });\n    } else Internals.d.m(href);\n};\nexports.version = \"19.3.0-canary-f93b9fd4-20251217\";\n","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('./cjs/react-dom.react-server.production.js');\n} else {\n  module.exports = require('./cjs/react-dom.react-server.development.js');\n}\n","/**\n * @license React\n * react-server-dom-turbopack-server.edge.production.js\n *\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\"use strict\";\nvar ReactDOM = require(\"react-dom\"),\n  React = require(\"react\"),\n  REACT_LEGACY_ELEMENT_TYPE = Symbol.for(\"react.element\"),\n  REACT_ELEMENT_TYPE = Symbol.for(\"react.transitional.element\"),\n  REACT_FRAGMENT_TYPE = Symbol.for(\"react.fragment\"),\n  REACT_CONTEXT_TYPE = Symbol.for(\"react.context\"),\n  REACT_FORWARD_REF_TYPE = Symbol.for(\"react.forward_ref\"),\n  REACT_SUSPENSE_TYPE = Symbol.for(\"react.suspense\"),\n  REACT_SUSPENSE_LIST_TYPE = Symbol.for(\"react.suspense_list\"),\n  REACT_MEMO_TYPE = Symbol.for(\"react.memo\"),\n  REACT_LAZY_TYPE = Symbol.for(\"react.lazy\"),\n  REACT_MEMO_CACHE_SENTINEL = Symbol.for(\"react.memo_cache_sentinel\"),\n  REACT_VIEW_TRANSITION_TYPE = Symbol.for(\"react.view_transition\"),\n  MAYBE_ITERATOR_SYMBOL = Symbol.iterator;\nfunction getIteratorFn(maybeIterable) {\n  if (null === maybeIterable || \"object\" !== typeof maybeIterable) return null;\n  maybeIterable =\n    (MAYBE_ITERATOR_SYMBOL && maybeIterable[MAYBE_ITERATOR_SYMBOL]) ||\n    maybeIterable[\"@@iterator\"];\n  return \"function\" === typeof maybeIterable ? maybeIterable : null;\n}\nvar ASYNC_ITERATOR = Symbol.asyncIterator,\n  REACT_OPTIMISTIC_KEY = Symbol.for(\"react.optimistic_key\");\nfunction handleErrorInNextTick(error) {\n  setTimeout(function () {\n    throw error;\n  });\n}\nvar LocalPromise = Promise,\n  scheduleMicrotask =\n    \"function\" === typeof queueMicrotask\n      ? queueMicrotask\n      : function (callback) {\n          LocalPromise.resolve(null)\n            .then(callback)\n            .catch(handleErrorInNextTick);\n        },\n  currentView = null,\n  writtenBytes = 0;\nfunction writeChunkAndReturn(destination, chunk) {\n  if (0 !== chunk.byteLength)\n    if (4096 < chunk.byteLength)\n      0 < writtenBytes &&\n        (destination.enqueue(\n          new Uint8Array(currentView.buffer, 0, writtenBytes)\n        ),\n        (currentView = new Uint8Array(4096)),\n        (writtenBytes = 0)),\n        destination.enqueue(chunk);\n    else {\n      var allowableBytes = currentView.length - writtenBytes;\n      allowableBytes < chunk.byteLength &&\n        (0 === allowableBytes\n          ? destination.enqueue(currentView)\n          : (currentView.set(chunk.subarray(0, allowableBytes), writtenBytes),\n            destination.enqueue(currentView),\n            (chunk = chunk.subarray(allowableBytes))),\n        (currentView = new Uint8Array(4096)),\n        (writtenBytes = 0));\n      currentView.set(chunk, writtenBytes);\n      writtenBytes += chunk.byteLength;\n    }\n  return !0;\n}\nvar textEncoder = new TextEncoder();\nfunction stringToChunk(content) {\n  return textEncoder.encode(content);\n}\nfunction byteLengthOfChunk(chunk) {\n  return chunk.byteLength;\n}\nfunction closeWithError(destination, error) {\n  \"function\" === typeof destination.error\n    ? destination.error(error)\n    : destination.close();\n}\nvar CLIENT_REFERENCE_TAG$1 = Symbol.for(\"react.client.reference\"),\n  SERVER_REFERENCE_TAG = Symbol.for(\"react.server.reference\");\nfunction registerClientReferenceImpl(proxyImplementation, id, async) {\n  return Object.defineProperties(proxyImplementation, {\n    $$typeof: { value: CLIENT_REFERENCE_TAG$1 },\n    $$id: { value: id },\n    $$async: { value: async }\n  });\n}\nvar FunctionBind = Function.prototype.bind,\n  ArraySlice = Array.prototype.slice;\nfunction bind() {\n  var newFn = FunctionBind.apply(this, arguments);\n  if (this.$$typeof === SERVER_REFERENCE_TAG) {\n    var args = ArraySlice.call(arguments, 1),\n      $$typeof = { value: SERVER_REFERENCE_TAG },\n      $$id = { value: this.$$id };\n    args = { value: this.$$bound ? this.$$bound.concat(args) : args };\n    return Object.defineProperties(newFn, {\n      $$typeof: $$typeof,\n      $$id: $$id,\n      $$bound: args,\n      bind: { value: bind, configurable: !0 }\n    });\n  }\n  return newFn;\n}\nvar serverReferenceToString = {\n    value: function () {\n      return \"function () { [omitted code] }\";\n    },\n    configurable: !0,\n    writable: !0\n  },\n  PROMISE_PROTOTYPE = Promise.prototype,\n  deepProxyHandlers = {\n    get: function (target, name) {\n      switch (name) {\n        case \"$$typeof\":\n          return target.$$typeof;\n        case \"$$id\":\n          return target.$$id;\n        case \"$$async\":\n          return target.$$async;\n        case \"name\":\n          return target.name;\n        case \"displayName\":\n          return;\n        case \"defaultProps\":\n          return;\n        case \"_debugInfo\":\n          return;\n        case \"toJSON\":\n          return;\n        case Symbol.toPrimitive:\n          return Object.prototype[Symbol.toPrimitive];\n        case Symbol.toStringTag:\n          return Object.prototype[Symbol.toStringTag];\n        case \"Provider\":\n          throw Error(\n            \"Cannot render a Client Context Provider on the Server. Instead, you can export a Client Component wrapper that itself renders a Client Context Provider.\"\n          );\n        case \"then\":\n          throw Error(\n            \"Cannot await or return from a thenable. You cannot await a client module from a server component.\"\n          );\n      }\n      throw Error(\n        \"Cannot access \" +\n          (String(target.name) + \".\" + String(name)) +\n          \" on the server. You cannot dot into a client module from a server component. You can only pass the imported name through.\"\n      );\n    },\n    set: function () {\n      throw Error(\"Cannot assign to a client module from a server module.\");\n    }\n  };\nfunction getReference(target, name) {\n  switch (name) {\n    case \"$$typeof\":\n      return target.$$typeof;\n    case \"$$id\":\n      return target.$$id;\n    case \"$$async\":\n      return target.$$async;\n    case \"name\":\n      return target.name;\n    case \"defaultProps\":\n      return;\n    case \"_debugInfo\":\n      return;\n    case \"toJSON\":\n      return;\n    case Symbol.toPrimitive:\n      return Object.prototype[Symbol.toPrimitive];\n    case Symbol.toStringTag:\n      return Object.prototype[Symbol.toStringTag];\n    case \"__esModule\":\n      var moduleId = target.$$id;\n      target.default = registerClientReferenceImpl(\n        function () {\n          throw Error(\n            \"Attempted to call the default export of \" +\n              moduleId +\n              \" from the server but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"\n          );\n        },\n        target.$$id + \"#\",\n        target.$$async\n      );\n      return !0;\n    case \"then\":\n      if (target.then) return target.then;\n      if (target.$$async) return;\n      var clientReference = registerClientReferenceImpl({}, target.$$id, !0),\n        proxy = new Proxy(clientReference, proxyHandlers$1);\n      target.status = \"fulfilled\";\n      target.value = proxy;\n      return (target.then = registerClientReferenceImpl(\n        function (resolve) {\n          return Promise.resolve(resolve(proxy));\n        },\n        target.$$id + \"#then\",\n        !1\n      ));\n  }\n  if (\"symbol\" === typeof name)\n    throw Error(\n      \"Cannot read Symbol exports. Only named exports are supported on a client module imported on the server.\"\n    );\n  clientReference = target[name];\n  clientReference ||\n    ((clientReference = registerClientReferenceImpl(\n      function () {\n        throw Error(\n          \"Attempted to call \" +\n            String(name) +\n            \"() from the server but \" +\n            String(name) +\n            \" is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"\n        );\n      },\n      target.$$id + \"#\" + name,\n      target.$$async\n    )),\n    Object.defineProperty(clientReference, \"name\", { value: name }),\n    (clientReference = target[name] =\n      new Proxy(clientReference, deepProxyHandlers)));\n  return clientReference;\n}\nvar proxyHandlers$1 = {\n    get: function (target, name) {\n      return getReference(target, name);\n    },\n    getOwnPropertyDescriptor: function (target, name) {\n      var descriptor = Object.getOwnPropertyDescriptor(target, name);\n      descriptor ||\n        ((descriptor = {\n          value: getReference(target, name),\n          writable: !1,\n          configurable: !1,\n          enumerable: !1\n        }),\n        Object.defineProperty(target, name, descriptor));\n      return descriptor;\n    },\n    getPrototypeOf: function () {\n      return PROMISE_PROTOTYPE;\n    },\n    set: function () {\n      throw Error(\"Cannot assign to a client module from a server module.\");\n    }\n  },\n  ReactDOMSharedInternals =\n    ReactDOM.__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,\n  previousDispatcher = ReactDOMSharedInternals.d;\nReactDOMSharedInternals.d = {\n  f: previousDispatcher.f,\n  r: previousDispatcher.r,\n  D: prefetchDNS,\n  C: preconnect,\n  L: preload,\n  m: preloadModule$1,\n  X: preinitScript,\n  S: preinitStyle,\n  M: preinitModuleScript\n};\nfunction prefetchDNS(href) {\n  if (\"string\" === typeof href && href) {\n    var request = resolveRequest();\n    if (request) {\n      var hints = request.hints,\n        key = \"D|\" + href;\n      hints.has(key) || (hints.add(key), emitHint(request, \"D\", href));\n    } else previousDispatcher.D(href);\n  }\n}\nfunction preconnect(href, crossOrigin) {\n  if (\"string\" === typeof href) {\n    var request = resolveRequest();\n    if (request) {\n      var hints = request.hints,\n        key = \"C|\" + (null == crossOrigin ? \"null\" : crossOrigin) + \"|\" + href;\n      hints.has(key) ||\n        (hints.add(key),\n        \"string\" === typeof crossOrigin\n          ? emitHint(request, \"C\", [href, crossOrigin])\n          : emitHint(request, \"C\", href));\n    } else previousDispatcher.C(href, crossOrigin);\n  }\n}\nfunction preload(href, as, options) {\n  if (\"string\" === typeof href) {\n    var request = resolveRequest();\n    if (request) {\n      var hints = request.hints,\n        key = \"L\";\n      if (\"image\" === as && options) {\n        var imageSrcSet = options.imageSrcSet,\n          imageSizes = options.imageSizes,\n          uniquePart = \"\";\n        \"string\" === typeof imageSrcSet && \"\" !== imageSrcSet\n          ? ((uniquePart += \"[\" + imageSrcSet + \"]\"),\n            \"string\" === typeof imageSizes &&\n              (uniquePart += \"[\" + imageSizes + \"]\"))\n          : (uniquePart += \"[][]\" + href);\n        key += \"[image]\" + uniquePart;\n      } else key += \"[\" + as + \"]\" + href;\n      hints.has(key) ||\n        (hints.add(key),\n        (options = trimOptions(options))\n          ? emitHint(request, \"L\", [href, as, options])\n          : emitHint(request, \"L\", [href, as]));\n    } else previousDispatcher.L(href, as, options);\n  }\n}\nfunction preloadModule$1(href, options) {\n  if (\"string\" === typeof href) {\n    var request = resolveRequest();\n    if (request) {\n      var hints = request.hints,\n        key = \"m|\" + href;\n      if (hints.has(key)) return;\n      hints.add(key);\n      return (options = trimOptions(options))\n        ? emitHint(request, \"m\", [href, options])\n        : emitHint(request, \"m\", href);\n    }\n    previousDispatcher.m(href, options);\n  }\n}\nfunction preinitStyle(href, precedence, options) {\n  if (\"string\" === typeof href) {\n    var request = resolveRequest();\n    if (request) {\n      var hints = request.hints,\n        key = \"S|\" + href;\n      if (hints.has(key)) return;\n      hints.add(key);\n      return (options = trimOptions(options))\n        ? emitHint(request, \"S\", [\n            href,\n            \"string\" === typeof precedence ? precedence : 0,\n            options\n          ])\n        : \"string\" === typeof precedence\n          ? emitHint(request, \"S\", [href, precedence])\n          : emitHint(request, \"S\", href);\n    }\n    previousDispatcher.S(href, precedence, options);\n  }\n}\nfunction preinitScript(src, options) {\n  if (\"string\" === typeof src) {\n    var request = resolveRequest();\n    if (request) {\n      var hints = request.hints,\n        key = \"X|\" + src;\n      if (hints.has(key)) return;\n      hints.add(key);\n      return (options = trimOptions(options))\n        ? emitHint(request, \"X\", [src, options])\n        : emitHint(request, \"X\", src);\n    }\n    previousDispatcher.X(src, options);\n  }\n}\nfunction preinitModuleScript(src, options) {\n  if (\"string\" === typeof src) {\n    var request = resolveRequest();\n    if (request) {\n      var hints = request.hints,\n        key = \"M|\" + src;\n      if (hints.has(key)) return;\n      hints.add(key);\n      return (options = trimOptions(options))\n        ? emitHint(request, \"M\", [src, options])\n        : emitHint(request, \"M\", src);\n    }\n    previousDispatcher.M(src, options);\n  }\n}\nfunction trimOptions(options) {\n  if (null == options) return null;\n  var hasProperties = !1,\n    trimmed = {},\n    key;\n  for (key in options)\n    null != options[key] &&\n      ((hasProperties = !0), (trimmed[key] = options[key]));\n  return hasProperties ? trimmed : null;\n}\nfunction getChildFormatContext(parentContext, type, props) {\n  switch (type) {\n    case \"img\":\n      type = props.src;\n      var srcSet = props.srcSet;\n      if (\n        !(\n          \"lazy\" === props.loading ||\n          (!type && !srcSet) ||\n          (\"string\" !== typeof type && null != type) ||\n          (\"string\" !== typeof srcSet && null != srcSet) ||\n          \"low\" === props.fetchPriority ||\n          parentContext & 3\n        ) &&\n        (\"string\" !== typeof type ||\n          \":\" !== type[4] ||\n          (\"d\" !== type[0] && \"D\" !== type[0]) ||\n          (\"a\" !== type[1] && \"A\" !== type[1]) ||\n          (\"t\" !== type[2] && \"T\" !== type[2]) ||\n          (\"a\" !== type[3] && \"A\" !== type[3])) &&\n        (\"string\" !== typeof srcSet ||\n          \":\" !== srcSet[4] ||\n          (\"d\" !== srcSet[0] && \"D\" !== srcSet[0]) ||\n          (\"a\" !== srcSet[1] && \"A\" !== srcSet[1]) ||\n          (\"t\" !== srcSet[2] && \"T\" !== srcSet[2]) ||\n          (\"a\" !== srcSet[3] && \"A\" !== srcSet[3]))\n      ) {\n        var sizes = \"string\" === typeof props.sizes ? props.sizes : void 0;\n        var input = props.crossOrigin;\n        preload(type || \"\", \"image\", {\n          imageSrcSet: srcSet,\n          imageSizes: sizes,\n          crossOrigin:\n            \"string\" === typeof input\n              ? \"use-credentials\" === input\n                ? input\n                : \"\"\n              : void 0,\n          integrity: props.integrity,\n          type: props.type,\n          fetchPriority: props.fetchPriority,\n          referrerPolicy: props.referrerPolicy\n        });\n      }\n      return parentContext;\n    case \"link\":\n      type = props.rel;\n      srcSet = props.href;\n      if (\n        !(\n          parentContext & 1 ||\n          null != props.itemProp ||\n          \"string\" !== typeof type ||\n          \"string\" !== typeof srcSet ||\n          \"\" === srcSet\n        )\n      )\n        switch (type) {\n          case \"preload\":\n            preload(srcSet, props.as, {\n              crossOrigin: props.crossOrigin,\n              integrity: props.integrity,\n              nonce: props.nonce,\n              type: props.type,\n              fetchPriority: props.fetchPriority,\n              referrerPolicy: props.referrerPolicy,\n              imageSrcSet: props.imageSrcSet,\n              imageSizes: props.imageSizes,\n              media: props.media\n            });\n            break;\n          case \"modulepreload\":\n            preloadModule$1(srcSet, {\n              as: props.as,\n              crossOrigin: props.crossOrigin,\n              integrity: props.integrity,\n              nonce: props.nonce\n            });\n            break;\n          case \"stylesheet\":\n            preload(srcSet, \"style\", {\n              crossOrigin: props.crossOrigin,\n              integrity: props.integrity,\n              nonce: props.nonce,\n              type: props.type,\n              fetchPriority: props.fetchPriority,\n              referrerPolicy: props.referrerPolicy,\n              media: props.media\n            });\n        }\n      return parentContext;\n    case \"picture\":\n      return parentContext | 2;\n    case \"noscript\":\n      return parentContext | 1;\n    default:\n      return parentContext;\n  }\n}\nvar supportsRequestStorage = \"function\" === typeof AsyncLocalStorage,\n  requestStorage = supportsRequestStorage ? new AsyncLocalStorage() : null,\n  TEMPORARY_REFERENCE_TAG = Symbol.for(\"react.temporary.reference\"),\n  proxyHandlers = {\n    get: function (target, name) {\n      switch (name) {\n        case \"$$typeof\":\n          return target.$$typeof;\n        case \"name\":\n          return;\n        case \"displayName\":\n          return;\n        case \"defaultProps\":\n          return;\n        case \"_debugInfo\":\n          return;\n        case \"toJSON\":\n          return;\n        case Symbol.toPrimitive:\n          return Object.prototype[Symbol.toPrimitive];\n        case Symbol.toStringTag:\n          return Object.prototype[Symbol.toStringTag];\n        case \"Provider\":\n          throw Error(\n            \"Cannot render a Client Context Provider on the Server. Instead, you can export a Client Component wrapper that itself renders a Client Context Provider.\"\n          );\n        case \"then\":\n          return;\n      }\n      throw Error(\n        \"Cannot access \" +\n          String(name) +\n          \" on the server. You cannot dot into a temporary client reference from a server component. You can only pass the value through to the client.\"\n      );\n    },\n    set: function () {\n      throw Error(\n        \"Cannot assign to a temporary client reference from a server module.\"\n      );\n    }\n  };\nfunction createTemporaryReference(temporaryReferences, id) {\n  var reference = Object.defineProperties(\n    function () {\n      throw Error(\n        \"Attempted to call a temporary Client Reference from the server but it is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"\n      );\n    },\n    { $$typeof: { value: TEMPORARY_REFERENCE_TAG } }\n  );\n  reference = new Proxy(reference, proxyHandlers);\n  temporaryReferences.set(reference, id);\n  return reference;\n}\nfunction noop() {}\nvar SuspenseException = Error(\n  \"Suspense Exception: This is not a real error! It's an implementation detail of `use` to interrupt the current render. You must either rethrow it immediately, or move the `use` call outside of the `try/catch` block. Capturing without rethrowing will lead to unexpected behavior.\\n\\nTo handle async errors, wrap your component in an error boundary, or call the promise's `.catch` method and pass the result to `use`.\"\n);\nfunction trackUsedThenable(thenableState, thenable, index) {\n  index = thenableState[index];\n  void 0 === index\n    ? thenableState.push(thenable)\n    : index !== thenable && (thenable.then(noop, noop), (thenable = index));\n  switch (thenable.status) {\n    case \"fulfilled\":\n      return thenable.value;\n    case \"rejected\":\n      throw thenable.reason;\n    default:\n      \"string\" === typeof thenable.status\n        ? thenable.then(noop, noop)\n        : ((thenableState = thenable),\n          (thenableState.status = \"pending\"),\n          thenableState.then(\n            function (fulfilledValue) {\n              if (\"pending\" === thenable.status) {\n                var fulfilledThenable = thenable;\n                fulfilledThenable.status = \"fulfilled\";\n                fulfilledThenable.value = fulfilledValue;\n              }\n            },\n            function (error) {\n              if (\"pending\" === thenable.status) {\n                var rejectedThenable = thenable;\n                rejectedThenable.status = \"rejected\";\n                rejectedThenable.reason = error;\n              }\n            }\n          ));\n      switch (thenable.status) {\n        case \"fulfilled\":\n          return thenable.value;\n        case \"rejected\":\n          throw thenable.reason;\n      }\n      suspendedThenable = thenable;\n      throw SuspenseException;\n  }\n}\nvar suspendedThenable = null;\nfunction getSuspendedThenable() {\n  if (null === suspendedThenable)\n    throw Error(\n      \"Expected a suspended thenable. This is a bug in React. Please file an issue.\"\n    );\n  var thenable = suspendedThenable;\n  suspendedThenable = null;\n  return thenable;\n}\nvar currentRequest$1 = null,\n  thenableIndexCounter = 0,\n  thenableState = null;\nfunction getThenableStateAfterSuspending() {\n  var state = thenableState || [];\n  thenableState = null;\n  return state;\n}\nvar HooksDispatcher = {\n  readContext: unsupportedContext,\n  use: use,\n  useCallback: function (callback) {\n    return callback;\n  },\n  useContext: unsupportedContext,\n  useEffect: unsupportedHook,\n  useImperativeHandle: unsupportedHook,\n  useLayoutEffect: unsupportedHook,\n  useInsertionEffect: unsupportedHook,\n  useMemo: function (nextCreate) {\n    return nextCreate();\n  },\n  useReducer: unsupportedHook,\n  useRef: unsupportedHook,\n  useState: unsupportedHook,\n  useDebugValue: function () {},\n  useDeferredValue: unsupportedHook,\n  useTransition: unsupportedHook,\n  useSyncExternalStore: unsupportedHook,\n  useId: useId,\n  useHostTransitionStatus: unsupportedHook,\n  useFormState: unsupportedHook,\n  useActionState: unsupportedHook,\n  useOptimistic: unsupportedHook,\n  useMemoCache: function (size) {\n    for (var data = Array(size), i = 0; i < size; i++)\n      data[i] = REACT_MEMO_CACHE_SENTINEL;\n    return data;\n  },\n  useCacheRefresh: function () {\n    return unsupportedRefresh;\n  }\n};\nHooksDispatcher.useEffectEvent = unsupportedHook;\nfunction unsupportedHook() {\n  throw Error(\"This Hook is not supported in Server Components.\");\n}\nfunction unsupportedRefresh() {\n  throw Error(\"Refreshing the cache is not supported in Server Components.\");\n}\nfunction unsupportedContext() {\n  throw Error(\"Cannot read a Client Context from a Server Component.\");\n}\nfunction useId() {\n  if (null === currentRequest$1)\n    throw Error(\"useId can only be used while React is rendering\");\n  var id = currentRequest$1.identifierCount++;\n  return \"_\" + currentRequest$1.identifierPrefix + \"S_\" + id.toString(32) + \"_\";\n}\nfunction use(usable) {\n  if (\n    (null !== usable && \"object\" === typeof usable) ||\n    \"function\" === typeof usable\n  ) {\n    if (\"function\" === typeof usable.then) {\n      var index = thenableIndexCounter;\n      thenableIndexCounter += 1;\n      null === thenableState && (thenableState = []);\n      return trackUsedThenable(thenableState, usable, index);\n    }\n    usable.$$typeof === REACT_CONTEXT_TYPE && unsupportedContext();\n  }\n  if (usable.$$typeof === CLIENT_REFERENCE_TAG$1) {\n    if (null != usable.value && usable.value.$$typeof === REACT_CONTEXT_TYPE)\n      throw Error(\"Cannot read a Client Context from a Server Component.\");\n    throw Error(\"Cannot use() an already resolved Client Reference.\");\n  }\n  throw Error(\"An unsupported type was passed to use(): \" + String(usable));\n}\nvar DefaultAsyncDispatcher = {\n    getCacheForType: function (resourceType) {\n      var JSCompiler_inline_result = (JSCompiler_inline_result =\n        resolveRequest())\n        ? JSCompiler_inline_result.cache\n        : new Map();\n      var entry = JSCompiler_inline_result.get(resourceType);\n      void 0 === entry &&\n        ((entry = resourceType()),\n        JSCompiler_inline_result.set(resourceType, entry));\n      return entry;\n    },\n    cacheSignal: function () {\n      var request = resolveRequest();\n      return request ? request.cacheController.signal : null;\n    }\n  },\n  ReactSharedInternalsServer =\n    React.__SERVER_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE;\nif (!ReactSharedInternalsServer)\n  throw Error(\n    'The \"react\" package in this environment is not configured correctly. The \"react-server\" condition must be enabled in any environment that runs React Server Components.'\n  );\nvar isArrayImpl = Array.isArray,\n  getPrototypeOf = Object.getPrototypeOf;\nfunction objectName(object) {\n  object = Object.prototype.toString.call(object);\n  return object.slice(8, object.length - 1);\n}\nfunction describeValueForErrorMessage(value) {\n  switch (typeof value) {\n    case \"string\":\n      return JSON.stringify(\n        10 >= value.length ? value : value.slice(0, 10) + \"...\"\n      );\n    case \"object\":\n      if (isArrayImpl(value)) return \"[...]\";\n      if (null !== value && value.$$typeof === CLIENT_REFERENCE_TAG)\n        return \"client\";\n      value = objectName(value);\n      return \"Object\" === value ? \"{...}\" : value;\n    case \"function\":\n      return value.$$typeof === CLIENT_REFERENCE_TAG\n        ? \"client\"\n        : (value = value.displayName || value.name)\n          ? \"function \" + value\n          : \"function\";\n    default:\n      return String(value);\n  }\n}\nfunction describeElementType(type) {\n  if (\"string\" === typeof type) return type;\n  switch (type) {\n    case REACT_SUSPENSE_TYPE:\n      return \"Suspense\";\n    case REACT_SUSPENSE_LIST_TYPE:\n      return \"SuspenseList\";\n    case REACT_VIEW_TRANSITION_TYPE:\n      return \"ViewTransition\";\n  }\n  if (\"object\" === typeof type)\n    switch (type.$$typeof) {\n      case REACT_FORWARD_REF_TYPE:\n        return describeElementType(type.render);\n      case REACT_MEMO_TYPE:\n        return describeElementType(type.type);\n      case REACT_LAZY_TYPE:\n        var payload = type._payload;\n        type = type._init;\n        try {\n          return describeElementType(type(payload));\n        } catch (x) {}\n    }\n  return \"\";\n}\nvar CLIENT_REFERENCE_TAG = Symbol.for(\"react.client.reference\");\nfunction describeObjectForErrorMessage(objectOrArray, expandedName) {\n  var objKind = objectName(objectOrArray);\n  if (\"Object\" !== objKind && \"Array\" !== objKind) return objKind;\n  objKind = -1;\n  var length = 0;\n  if (isArrayImpl(objectOrArray)) {\n    var str = \"[\";\n    for (var i = 0; i < objectOrArray.length; i++) {\n      0 < i && (str += \", \");\n      var value = objectOrArray[i];\n      value =\n        \"object\" === typeof value && null !== value\n          ? describeObjectForErrorMessage(value)\n          : describeValueForErrorMessage(value);\n      \"\" + i === expandedName\n        ? ((objKind = str.length), (length = value.length), (str += value))\n        : (str =\n            10 > value.length && 40 > str.length + value.length\n              ? str + value\n              : str + \"...\");\n    }\n    str += \"]\";\n  } else if (objectOrArray.$$typeof === REACT_ELEMENT_TYPE)\n    str = \"<\" + describeElementType(objectOrArray.type) + \"/>\";\n  else {\n    if (objectOrArray.$$typeof === CLIENT_REFERENCE_TAG) return \"client\";\n    str = \"{\";\n    i = Object.keys(objectOrArray);\n    for (value = 0; value < i.length; value++) {\n      0 < value && (str += \", \");\n      var name = i[value],\n        encodedKey = JSON.stringify(name);\n      str += ('\"' + name + '\"' === encodedKey ? name : encodedKey) + \": \";\n      encodedKey = objectOrArray[name];\n      encodedKey =\n        \"object\" === typeof encodedKey && null !== encodedKey\n          ? describeObjectForErrorMessage(encodedKey)\n          : describeValueForErrorMessage(encodedKey);\n      name === expandedName\n        ? ((objKind = str.length),\n          (length = encodedKey.length),\n          (str += encodedKey))\n        : (str =\n            10 > encodedKey.length && 40 > str.length + encodedKey.length\n              ? str + encodedKey\n              : str + \"...\");\n    }\n    str += \"}\";\n  }\n  return void 0 === expandedName\n    ? str\n    : -1 < objKind && 0 < length\n      ? ((objectOrArray = \" \".repeat(objKind) + \"^\".repeat(length)),\n        \"\\n  \" + str + \"\\n  \" + objectOrArray)\n      : \"\\n  \" + str;\n}\nvar hasOwnProperty = Object.prototype.hasOwnProperty,\n  ObjectPrototype$1 = Object.prototype,\n  stringify = JSON.stringify;\nfunction defaultErrorHandler(error) {\n  console.error(error);\n}\nfunction RequestInstance(\n  type,\n  model,\n  bundlerConfig,\n  onError,\n  onAllReady,\n  onFatalError,\n  identifierPrefix,\n  temporaryReferences\n) {\n  if (\n    null !== ReactSharedInternalsServer.A &&\n    ReactSharedInternalsServer.A !== DefaultAsyncDispatcher\n  )\n    throw Error(\"Currently React only supports one RSC renderer at a time.\");\n  ReactSharedInternalsServer.A = DefaultAsyncDispatcher;\n  var abortSet = new Set(),\n    pingedTasks = [],\n    hints = new Set();\n  this.type = type;\n  this.status = 10;\n  this.flushScheduled = !1;\n  this.destination = this.fatalError = null;\n  this.bundlerConfig = bundlerConfig;\n  this.cache = new Map();\n  this.cacheController = new AbortController();\n  this.pendingChunks = this.nextChunkId = 0;\n  this.hints = hints;\n  this.abortableTasks = abortSet;\n  this.pingedTasks = pingedTasks;\n  this.completedImportChunks = [];\n  this.completedHintChunks = [];\n  this.completedRegularChunks = [];\n  this.completedErrorChunks = [];\n  this.writtenSymbols = new Map();\n  this.writtenClientReferences = new Map();\n  this.writtenServerReferences = new Map();\n  this.writtenObjects = new WeakMap();\n  this.temporaryReferences = temporaryReferences;\n  this.identifierPrefix = identifierPrefix || \"\";\n  this.identifierCount = 1;\n  this.taintCleanupQueue = [];\n  this.onError = void 0 === onError ? defaultErrorHandler : onError;\n  this.onAllReady = onAllReady;\n  this.onFatalError = onFatalError;\n  type = createTask(this, model, null, !1, 0, abortSet);\n  pingedTasks.push(type);\n}\nvar currentRequest = null;\nfunction resolveRequest() {\n  if (currentRequest) return currentRequest;\n  if (supportsRequestStorage) {\n    var store = requestStorage.getStore();\n    if (store) return store;\n  }\n  return null;\n}\nfunction serializeThenable(request, task, thenable) {\n  var newTask = createTask(\n    request,\n    thenable,\n    task.keyPath,\n    task.implicitSlot,\n    task.formatContext,\n    request.abortableTasks\n  );\n  switch (thenable.status) {\n    case \"fulfilled\":\n      return (\n        (newTask.model = thenable.value), pingTask(request, newTask), newTask.id\n      );\n    case \"rejected\":\n      return erroredTask(request, newTask, thenable.reason), newTask.id;\n    default:\n      if (12 === request.status)\n        return (\n          request.abortableTasks.delete(newTask),\n          21 === request.type\n            ? (haltTask(newTask), finishHaltedTask(newTask, request))\n            : ((task = request.fatalError),\n              abortTask(newTask),\n              finishAbortedTask(newTask, request, task)),\n          newTask.id\n        );\n      \"string\" !== typeof thenable.status &&\n        ((thenable.status = \"pending\"),\n        thenable.then(\n          function (fulfilledValue) {\n            \"pending\" === thenable.status &&\n              ((thenable.status = \"fulfilled\"),\n              (thenable.value = fulfilledValue));\n          },\n          function (error) {\n            \"pending\" === thenable.status &&\n              ((thenable.status = \"rejected\"), (thenable.reason = error));\n          }\n        ));\n  }\n  thenable.then(\n    function (value) {\n      newTask.model = value;\n      pingTask(request, newTask);\n    },\n    function (reason) {\n      0 === newTask.status &&\n        (erroredTask(request, newTask, reason), enqueueFlush(request));\n    }\n  );\n  return newTask.id;\n}\nfunction serializeReadableStream(request, task, stream) {\n  function progress(entry) {\n    if (0 === streamTask.status)\n      if (entry.done)\n        (streamTask.status = 1),\n          (entry = streamTask.id.toString(16) + \":C\\n\"),\n          request.completedRegularChunks.push(stringToChunk(entry)),\n          request.abortableTasks.delete(streamTask),\n          request.cacheController.signal.removeEventListener(\n            \"abort\",\n            abortStream\n          ),\n          enqueueFlush(request),\n          callOnAllReadyIfReady(request);\n      else\n        try {\n          request.pendingChunks++,\n            (streamTask.model = entry.value),\n            isByteStream\n              ? emitTypedArrayChunk(\n                  request,\n                  streamTask.id,\n                  \"b\",\n                  streamTask.model,\n                  !1\n                )\n              : tryStreamTask(request, streamTask),\n            enqueueFlush(request),\n            reader.read().then(progress, error);\n        } catch (x$11) {\n          error(x$11);\n        }\n  }\n  function error(reason) {\n    0 === streamTask.status &&\n      (request.cacheController.signal.removeEventListener(\"abort\", abortStream),\n      erroredTask(request, streamTask, reason),\n      enqueueFlush(request),\n      reader.cancel(reason).then(error, error));\n  }\n  function abortStream() {\n    if (0 === streamTask.status) {\n      var signal = request.cacheController.signal;\n      signal.removeEventListener(\"abort\", abortStream);\n      signal = signal.reason;\n      21 === request.type\n        ? (request.abortableTasks.delete(streamTask),\n          haltTask(streamTask),\n          finishHaltedTask(streamTask, request))\n        : (erroredTask(request, streamTask, signal), enqueueFlush(request));\n      reader.cancel(signal).then(error, error);\n    }\n  }\n  var supportsBYOB = stream.supportsBYOB;\n  if (void 0 === supportsBYOB)\n    try {\n      stream.getReader({ mode: \"byob\" }).releaseLock(), (supportsBYOB = !0);\n    } catch (x) {\n      supportsBYOB = !1;\n    }\n  var isByteStream = supportsBYOB,\n    reader = stream.getReader(),\n    streamTask = createTask(\n      request,\n      task.model,\n      task.keyPath,\n      task.implicitSlot,\n      task.formatContext,\n      request.abortableTasks\n    );\n  request.pendingChunks++;\n  task = streamTask.id.toString(16) + \":\" + (isByteStream ? \"r\" : \"R\") + \"\\n\";\n  request.completedRegularChunks.push(stringToChunk(task));\n  request.cacheController.signal.addEventListener(\"abort\", abortStream);\n  reader.read().then(progress, error);\n  return serializeByValueID(streamTask.id);\n}\nfunction serializeAsyncIterable(request, task, iterable, iterator) {\n  function progress(entry) {\n    if (0 === streamTask.status)\n      if (entry.done) {\n        streamTask.status = 1;\n        if (void 0 === entry.value)\n          var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n        else\n          try {\n            var chunkId = outlineModelWithFormatContext(\n              request,\n              entry.value,\n              0\n            );\n            endStreamRow =\n              streamTask.id.toString(16) +\n              \":C\" +\n              stringify(serializeByValueID(chunkId)) +\n              \"\\n\";\n          } catch (x) {\n            error(x);\n            return;\n          }\n        request.completedRegularChunks.push(stringToChunk(endStreamRow));\n        request.abortableTasks.delete(streamTask);\n        request.cacheController.signal.removeEventListener(\n          \"abort\",\n          abortIterable\n        );\n        enqueueFlush(request);\n        callOnAllReadyIfReady(request);\n      } else\n        try {\n          (streamTask.model = entry.value),\n            request.pendingChunks++,\n            tryStreamTask(request, streamTask),\n            enqueueFlush(request),\n            iterator.next().then(progress, error);\n        } catch (x$12) {\n          error(x$12);\n        }\n  }\n  function error(reason) {\n    0 === streamTask.status &&\n      (request.cacheController.signal.removeEventListener(\n        \"abort\",\n        abortIterable\n      ),\n      erroredTask(request, streamTask, reason),\n      enqueueFlush(request),\n      \"function\" === typeof iterator.throw &&\n        iterator.throw(reason).then(error, error));\n  }\n  function abortIterable() {\n    if (0 === streamTask.status) {\n      var signal = request.cacheController.signal;\n      signal.removeEventListener(\"abort\", abortIterable);\n      var reason = signal.reason;\n      21 === request.type\n        ? (request.abortableTasks.delete(streamTask),\n          haltTask(streamTask),\n          finishHaltedTask(streamTask, request))\n        : (erroredTask(request, streamTask, signal.reason),\n          enqueueFlush(request));\n      \"function\" === typeof iterator.throw &&\n        iterator.throw(reason).then(error, error);\n    }\n  }\n  iterable = iterable === iterator;\n  var streamTask = createTask(\n    request,\n    task.model,\n    task.keyPath,\n    task.implicitSlot,\n    task.formatContext,\n    request.abortableTasks\n  );\n  request.pendingChunks++;\n  task = streamTask.id.toString(16) + \":\" + (iterable ? \"x\" : \"X\") + \"\\n\";\n  request.completedRegularChunks.push(stringToChunk(task));\n  request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n  iterator.next().then(progress, error);\n  return serializeByValueID(streamTask.id);\n}\nfunction emitHint(request, code, model) {\n  model = stringify(model);\n  code = stringToChunk(\":H\" + code + model + \"\\n\");\n  request.completedHintChunks.push(code);\n  enqueueFlush(request);\n}\nfunction readThenable(thenable) {\n  if (\"fulfilled\" === thenable.status) return thenable.value;\n  if (\"rejected\" === thenable.status) throw thenable.reason;\n  throw thenable;\n}\nfunction createLazyWrapperAroundWakeable(request, task, wakeable) {\n  switch (wakeable.status) {\n    case \"fulfilled\":\n      return wakeable.value;\n    case \"rejected\":\n      break;\n    default:\n      \"string\" !== typeof wakeable.status &&\n        ((wakeable.status = \"pending\"),\n        wakeable.then(\n          function (fulfilledValue) {\n            \"pending\" === wakeable.status &&\n              ((wakeable.status = \"fulfilled\"),\n              (wakeable.value = fulfilledValue));\n          },\n          function (error) {\n            \"pending\" === wakeable.status &&\n              ((wakeable.status = \"rejected\"), (wakeable.reason = error));\n          }\n        ));\n  }\n  return { $$typeof: REACT_LAZY_TYPE, _payload: wakeable, _init: readThenable };\n}\nfunction voidHandler() {}\nfunction processServerComponentReturnValue(request, task, Component, result) {\n  if (\n    \"object\" !== typeof result ||\n    null === result ||\n    result.$$typeof === CLIENT_REFERENCE_TAG$1\n  )\n    return result;\n  if (\"function\" === typeof result.then)\n    return createLazyWrapperAroundWakeable(request, task, result);\n  var iteratorFn = getIteratorFn(result);\n  return iteratorFn\n    ? ((request = {}),\n      (request[Symbol.iterator] = function () {\n        return iteratorFn.call(result);\n      }),\n      request)\n    : \"function\" !== typeof result[ASYNC_ITERATOR] ||\n        (\"function\" === typeof ReadableStream &&\n          result instanceof ReadableStream)\n      ? result\n      : ((request = {}),\n        (request[ASYNC_ITERATOR] = function () {\n          return result[ASYNC_ITERATOR]();\n        }),\n        request);\n}\nfunction renderFunctionComponent(request, task, key, Component, props) {\n  var prevThenableState = task.thenableState;\n  task.thenableState = null;\n  thenableIndexCounter = 0;\n  thenableState = prevThenableState;\n  props = Component(props, void 0);\n  if (12 === request.status)\n    throw (\n      (\"object\" === typeof props &&\n        null !== props &&\n        \"function\" === typeof props.then &&\n        props.$$typeof !== CLIENT_REFERENCE_TAG$1 &&\n        props.then(voidHandler, voidHandler),\n      null)\n    );\n  props = processServerComponentReturnValue(request, task, Component, props);\n  Component = task.keyPath;\n  prevThenableState = task.implicitSlot;\n  null !== key\n    ? (task.keyPath =\n        key === REACT_OPTIMISTIC_KEY || Component === REACT_OPTIMISTIC_KEY\n          ? REACT_OPTIMISTIC_KEY\n          : null === Component\n            ? key\n            : Component + \",\" + key)\n    : null === Component && (task.implicitSlot = !0);\n  request = renderModelDestructive(request, task, emptyRoot, \"\", props);\n  task.keyPath = Component;\n  task.implicitSlot = prevThenableState;\n  return request;\n}\nfunction renderFragment(request, task, children) {\n  return null !== task.keyPath\n    ? ((request = [\n        REACT_ELEMENT_TYPE,\n        REACT_FRAGMENT_TYPE,\n        task.keyPath,\n        { children: children }\n      ]),\n      task.implicitSlot ? [request] : request)\n    : children;\n}\nvar serializedSize = 0;\nfunction deferTask(request, task) {\n  task = createTask(\n    request,\n    task.model,\n    task.keyPath,\n    task.implicitSlot,\n    task.formatContext,\n    request.abortableTasks\n  );\n  pingTask(request, task);\n  return serializeLazyID(task.id);\n}\nfunction renderElement(request, task, type, key, ref, props) {\n  if (null !== ref && void 0 !== ref)\n    throw Error(\n      \"Refs cannot be used in Server Components, nor passed to Client Components.\"\n    );\n  if (\n    \"function\" === typeof type &&\n    type.$$typeof !== CLIENT_REFERENCE_TAG$1 &&\n    type.$$typeof !== TEMPORARY_REFERENCE_TAG\n  )\n    return renderFunctionComponent(request, task, key, type, props);\n  if (type === REACT_FRAGMENT_TYPE && null === key)\n    return (\n      (type = task.implicitSlot),\n      null === task.keyPath && (task.implicitSlot = !0),\n      (props = renderModelDestructive(\n        request,\n        task,\n        emptyRoot,\n        \"\",\n        props.children\n      )),\n      (task.implicitSlot = type),\n      props\n    );\n  if (\n    null != type &&\n    \"object\" === typeof type &&\n    type.$$typeof !== CLIENT_REFERENCE_TAG$1\n  )\n    switch (type.$$typeof) {\n      case REACT_LAZY_TYPE:\n        var init = type._init;\n        type = init(type._payload);\n        if (12 === request.status) throw null;\n        return renderElement(request, task, type, key, ref, props);\n      case REACT_FORWARD_REF_TYPE:\n        return renderFunctionComponent(request, task, key, type.render, props);\n      case REACT_MEMO_TYPE:\n        return renderElement(request, task, type.type, key, ref, props);\n    }\n  else\n    \"string\" === typeof type &&\n      ((ref = task.formatContext),\n      (init = getChildFormatContext(ref, type, props)),\n      ref !== init &&\n        null != props.children &&\n        outlineModelWithFormatContext(request, props.children, init));\n  request = key;\n  key = task.keyPath;\n  null === request\n    ? (request = key)\n    : null !== key &&\n      (request =\n        key === REACT_OPTIMISTIC_KEY || request === REACT_OPTIMISTIC_KEY\n          ? REACT_OPTIMISTIC_KEY\n          : key + \",\" + request);\n  props = [REACT_ELEMENT_TYPE, type, request, props];\n  task = task.implicitSlot && null !== request ? [props] : props;\n  return task;\n}\nfunction pingTask(request, task) {\n  var pingedTasks = request.pingedTasks;\n  pingedTasks.push(task);\n  1 === pingedTasks.length &&\n    ((request.flushScheduled = null !== request.destination),\n    21 === request.type || 10 === request.status\n      ? scheduleMicrotask(function () {\n          return performWork(request);\n        })\n      : setTimeout(function () {\n          return performWork(request);\n        }, 0));\n}\nfunction createTask(\n  request,\n  model,\n  keyPath,\n  implicitSlot,\n  formatContext,\n  abortSet\n) {\n  request.pendingChunks++;\n  var id = request.nextChunkId++;\n  \"object\" !== typeof model ||\n    null === model ||\n    null !== keyPath ||\n    implicitSlot ||\n    request.writtenObjects.set(model, serializeByValueID(id));\n  var task = {\n    id: id,\n    status: 0,\n    model: model,\n    keyPath: keyPath,\n    implicitSlot: implicitSlot,\n    formatContext: formatContext,\n    ping: function () {\n      return pingTask(request, task);\n    },\n    toJSON: function (parentPropertyName, value) {\n      serializedSize += parentPropertyName.length;\n      var prevKeyPath = task.keyPath,\n        prevImplicitSlot = task.implicitSlot;\n      try {\n        var JSCompiler_inline_result = renderModelDestructive(\n          request,\n          task,\n          this,\n          parentPropertyName,\n          value\n        );\n      } catch (thrownValue) {\n        if (\n          ((parentPropertyName = task.model),\n          (parentPropertyName =\n            \"object\" === typeof parentPropertyName &&\n            null !== parentPropertyName &&\n            (parentPropertyName.$$typeof === REACT_ELEMENT_TYPE ||\n              parentPropertyName.$$typeof === REACT_LAZY_TYPE)),\n          12 === request.status)\n        )\n          (task.status = 3),\n            21 === request.type\n              ? ((prevKeyPath = request.nextChunkId++),\n                (prevKeyPath = parentPropertyName\n                  ? serializeLazyID(prevKeyPath)\n                  : serializeByValueID(prevKeyPath)),\n                (JSCompiler_inline_result = prevKeyPath))\n              : ((prevKeyPath = request.fatalError),\n                (JSCompiler_inline_result = parentPropertyName\n                  ? serializeLazyID(prevKeyPath)\n                  : serializeByValueID(prevKeyPath)));\n        else if (\n          ((value =\n            thrownValue === SuspenseException\n              ? getSuspendedThenable()\n              : thrownValue),\n          \"object\" === typeof value &&\n            null !== value &&\n            \"function\" === typeof value.then)\n        ) {\n          JSCompiler_inline_result = createTask(\n            request,\n            task.model,\n            task.keyPath,\n            task.implicitSlot,\n            task.formatContext,\n            request.abortableTasks\n          );\n          var ping = JSCompiler_inline_result.ping;\n          value.then(ping, ping);\n          JSCompiler_inline_result.thenableState =\n            getThenableStateAfterSuspending();\n          task.keyPath = prevKeyPath;\n          task.implicitSlot = prevImplicitSlot;\n          JSCompiler_inline_result = parentPropertyName\n            ? serializeLazyID(JSCompiler_inline_result.id)\n            : serializeByValueID(JSCompiler_inline_result.id);\n        } else\n          (task.keyPath = prevKeyPath),\n            (task.implicitSlot = prevImplicitSlot),\n            request.pendingChunks++,\n            (prevKeyPath = request.nextChunkId++),\n            (prevImplicitSlot = logRecoverableError(request, value, task)),\n            emitErrorChunk(request, prevKeyPath, prevImplicitSlot),\n            (JSCompiler_inline_result = parentPropertyName\n              ? serializeLazyID(prevKeyPath)\n              : serializeByValueID(prevKeyPath));\n      }\n      return JSCompiler_inline_result;\n    },\n    thenableState: null\n  };\n  abortSet.add(task);\n  return task;\n}\nfunction serializeByValueID(id) {\n  return \"$\" + id.toString(16);\n}\nfunction serializeLazyID(id) {\n  return \"$L\" + id.toString(16);\n}\nfunction encodeReferenceChunk(request, id, reference) {\n  request = stringify(reference);\n  id = id.toString(16) + \":\" + request + \"\\n\";\n  return stringToChunk(id);\n}\nfunction serializeClientReference(\n  request,\n  parent,\n  parentPropertyName,\n  clientReference\n) {\n  var clientReferenceKey = clientReference.$$async\n      ? clientReference.$$id + \"#async\"\n      : clientReference.$$id,\n    writtenClientReferences = request.writtenClientReferences,\n    existingId = writtenClientReferences.get(clientReferenceKey);\n  if (void 0 !== existingId)\n    return parent[0] === REACT_ELEMENT_TYPE && \"1\" === parentPropertyName\n      ? serializeLazyID(existingId)\n      : serializeByValueID(existingId);\n  try {\n    var config = request.bundlerConfig,\n      modulePath = clientReference.$$id;\n    existingId = \"\";\n    var resolvedModuleData = config[modulePath];\n    if (resolvedModuleData) existingId = resolvedModuleData.name;\n    else {\n      var idx = modulePath.lastIndexOf(\"#\");\n      -1 !== idx &&\n        ((existingId = modulePath.slice(idx + 1)),\n        (resolvedModuleData = config[modulePath.slice(0, idx)]));\n      if (!resolvedModuleData)\n        throw Error(\n          'Could not find the module \"' +\n            modulePath +\n            '\" in the React Client Manifest. This is probably a bug in the React Server Components bundler.'\n        );\n    }\n    if (!0 === resolvedModuleData.async && !0 === clientReference.$$async)\n      throw Error(\n        'The module \"' +\n          modulePath +\n          '\" is marked as an async ESM module but was loaded as a CJS proxy. This is probably a bug in the React Server Components bundler.'\n      );\n    var JSCompiler_inline_result =\n      !0 === resolvedModuleData.async || !0 === clientReference.$$async\n        ? [resolvedModuleData.id, resolvedModuleData.chunks, existingId, 1]\n        : [resolvedModuleData.id, resolvedModuleData.chunks, existingId];\n    request.pendingChunks++;\n    var importId = request.nextChunkId++,\n      json = stringify(JSCompiler_inline_result),\n      row = importId.toString(16) + \":I\" + json + \"\\n\",\n      processedChunk = stringToChunk(row);\n    request.completedImportChunks.push(processedChunk);\n    writtenClientReferences.set(clientReferenceKey, importId);\n    return parent[0] === REACT_ELEMENT_TYPE && \"1\" === parentPropertyName\n      ? serializeLazyID(importId)\n      : serializeByValueID(importId);\n  } catch (x) {\n    return (\n      request.pendingChunks++,\n      (parent = request.nextChunkId++),\n      (parentPropertyName = logRecoverableError(request, x, null)),\n      emitErrorChunk(request, parent, parentPropertyName),\n      serializeByValueID(parent)\n    );\n  }\n}\nfunction outlineModelWithFormatContext(request, value, formatContext) {\n  value = createTask(\n    request,\n    value,\n    null,\n    !1,\n    formatContext,\n    request.abortableTasks\n  );\n  retryTask(request, value);\n  return value.id;\n}\nfunction serializeTypedArray(request, tag, typedArray) {\n  request.pendingChunks++;\n  var bufferId = request.nextChunkId++;\n  emitTypedArrayChunk(request, bufferId, tag, typedArray, !1);\n  return serializeByValueID(bufferId);\n}\nfunction serializeBlob(request, blob) {\n  function progress(entry) {\n    if (0 === newTask.status)\n      if (entry.done)\n        request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n          pingTask(request, newTask);\n      else\n        return (\n          model.push(entry.value), reader.read().then(progress).catch(error)\n        );\n  }\n  function error(reason) {\n    0 === newTask.status &&\n      (request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n      erroredTask(request, newTask, reason),\n      enqueueFlush(request),\n      reader.cancel(reason).then(error, error));\n  }\n  function abortBlob() {\n    if (0 === newTask.status) {\n      var signal = request.cacheController.signal;\n      signal.removeEventListener(\"abort\", abortBlob);\n      signal = signal.reason;\n      21 === request.type\n        ? (request.abortableTasks.delete(newTask),\n          haltTask(newTask),\n          finishHaltedTask(newTask, request))\n        : (erroredTask(request, newTask, signal), enqueueFlush(request));\n      reader.cancel(signal).then(error, error);\n    }\n  }\n  var model = [blob.type],\n    newTask = createTask(request, model, null, !1, 0, request.abortableTasks),\n    reader = blob.stream().getReader();\n  request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n  reader.read().then(progress).catch(error);\n  return \"$B\" + newTask.id.toString(16);\n}\nvar modelRoot = !1;\nfunction renderModelDestructive(\n  request,\n  task,\n  parent,\n  parentPropertyName,\n  value\n) {\n  task.model = value;\n  if (value === REACT_ELEMENT_TYPE) return \"$\";\n  if (null === value) return null;\n  if (\"object\" === typeof value) {\n    switch (value.$$typeof) {\n      case REACT_ELEMENT_TYPE:\n        var elementReference = null,\n          writtenObjects = request.writtenObjects;\n        if (null === task.keyPath && !task.implicitSlot) {\n          var existingReference = writtenObjects.get(value);\n          if (void 0 !== existingReference)\n            if (modelRoot === value) modelRoot = null;\n            else return existingReference;\n          else\n            -1 === parentPropertyName.indexOf(\":\") &&\n              ((parent = writtenObjects.get(parent)),\n              void 0 !== parent &&\n                ((elementReference = parent + \":\" + parentPropertyName),\n                writtenObjects.set(value, elementReference)));\n        }\n        if (3200 < serializedSize) return deferTask(request, task);\n        parentPropertyName = value.props;\n        parent = parentPropertyName.ref;\n        request = renderElement(\n          request,\n          task,\n          value.type,\n          value.key,\n          void 0 !== parent ? parent : null,\n          parentPropertyName\n        );\n        \"object\" === typeof request &&\n          null !== request &&\n          null !== elementReference &&\n          (writtenObjects.has(request) ||\n            writtenObjects.set(request, elementReference));\n        return request;\n      case REACT_LAZY_TYPE:\n        if (3200 < serializedSize) return deferTask(request, task);\n        task.thenableState = null;\n        parentPropertyName = value._init;\n        value = parentPropertyName(value._payload);\n        if (12 === request.status) throw null;\n        return renderModelDestructive(request, task, emptyRoot, \"\", value);\n      case REACT_LEGACY_ELEMENT_TYPE:\n        throw Error(\n          'A React Element from an older version of React was rendered. This is not supported. It can happen if:\\n- Multiple copies of the \"react\" package is used.\\n- A library pre-bundled an old copy of \"react\" or \"react/jsx-runtime\".\\n- A compiler tries to \"inline\" JSX instead of using the runtime.'\n        );\n    }\n    if (value.$$typeof === CLIENT_REFERENCE_TAG$1)\n      return serializeClientReference(\n        request,\n        parent,\n        parentPropertyName,\n        value\n      );\n    if (\n      void 0 !== request.temporaryReferences &&\n      ((elementReference = request.temporaryReferences.get(value)),\n      void 0 !== elementReference)\n    )\n      return \"$T\" + elementReference;\n    elementReference = request.writtenObjects;\n    writtenObjects = elementReference.get(value);\n    if (\"function\" === typeof value.then) {\n      if (void 0 !== writtenObjects) {\n        if (null !== task.keyPath || task.implicitSlot)\n          return \"$@\" + serializeThenable(request, task, value).toString(16);\n        if (modelRoot === value) modelRoot = null;\n        else return writtenObjects;\n      }\n      request = \"$@\" + serializeThenable(request, task, value).toString(16);\n      elementReference.set(value, request);\n      return request;\n    }\n    if (void 0 !== writtenObjects)\n      if (modelRoot === value) {\n        if (writtenObjects !== serializeByValueID(task.id))\n          return writtenObjects;\n        modelRoot = null;\n      } else return writtenObjects;\n    else if (\n      -1 === parentPropertyName.indexOf(\":\") &&\n      ((writtenObjects = elementReference.get(parent)),\n      void 0 !== writtenObjects)\n    ) {\n      existingReference = parentPropertyName;\n      if (isArrayImpl(parent) && parent[0] === REACT_ELEMENT_TYPE)\n        switch (parentPropertyName) {\n          case \"1\":\n            existingReference = \"type\";\n            break;\n          case \"2\":\n            existingReference = \"key\";\n            break;\n          case \"3\":\n            existingReference = \"props\";\n            break;\n          case \"4\":\n            existingReference = \"_owner\";\n        }\n      elementReference.set(value, writtenObjects + \":\" + existingReference);\n    }\n    if (isArrayImpl(value)) return renderFragment(request, task, value);\n    if (value instanceof Map)\n      return (\n        (value = Array.from(value)),\n        \"$Q\" + outlineModelWithFormatContext(request, value, 0).toString(16)\n      );\n    if (value instanceof Set)\n      return (\n        (value = Array.from(value)),\n        \"$W\" + outlineModelWithFormatContext(request, value, 0).toString(16)\n      );\n    if (\"function\" === typeof FormData && value instanceof FormData)\n      return (\n        (value = Array.from(value.entries())),\n        \"$K\" + outlineModelWithFormatContext(request, value, 0).toString(16)\n      );\n    if (value instanceof Error) return \"$Z\";\n    if (value instanceof ArrayBuffer)\n      return serializeTypedArray(request, \"A\", new Uint8Array(value));\n    if (value instanceof Int8Array)\n      return serializeTypedArray(request, \"O\", value);\n    if (value instanceof Uint8Array)\n      return serializeTypedArray(request, \"o\", value);\n    if (value instanceof Uint8ClampedArray)\n      return serializeTypedArray(request, \"U\", value);\n    if (value instanceof Int16Array)\n      return serializeTypedArray(request, \"S\", value);\n    if (value instanceof Uint16Array)\n      return serializeTypedArray(request, \"s\", value);\n    if (value instanceof Int32Array)\n      return serializeTypedArray(request, \"L\", value);\n    if (value instanceof Uint32Array)\n      return serializeTypedArray(request, \"l\", value);\n    if (value instanceof Float32Array)\n      return serializeTypedArray(request, \"G\", value);\n    if (value instanceof Float64Array)\n      return serializeTypedArray(request, \"g\", value);\n    if (value instanceof BigInt64Array)\n      return serializeTypedArray(request, \"M\", value);\n    if (value instanceof BigUint64Array)\n      return serializeTypedArray(request, \"m\", value);\n    if (value instanceof DataView)\n      return serializeTypedArray(request, \"V\", value);\n    if (\"function\" === typeof Blob && value instanceof Blob)\n      return serializeBlob(request, value);\n    if ((elementReference = getIteratorFn(value)))\n      return (\n        (parentPropertyName = elementReference.call(value)),\n        parentPropertyName === value\n          ? ((value = Array.from(parentPropertyName)),\n            \"$i\" +\n              outlineModelWithFormatContext(request, value, 0).toString(16))\n          : renderFragment(request, task, Array.from(parentPropertyName))\n      );\n    if (\"function\" === typeof ReadableStream && value instanceof ReadableStream)\n      return serializeReadableStream(request, task, value);\n    elementReference = value[ASYNC_ITERATOR];\n    if (\"function\" === typeof elementReference)\n      return (\n        null !== task.keyPath\n          ? ((request = [\n              REACT_ELEMENT_TYPE,\n              REACT_FRAGMENT_TYPE,\n              task.keyPath,\n              { children: value }\n            ]),\n            (request = task.implicitSlot ? [request] : request))\n          : ((parentPropertyName = elementReference.call(value)),\n            (request = serializeAsyncIterable(\n              request,\n              task,\n              value,\n              parentPropertyName\n            ))),\n        request\n      );\n    if (value instanceof Date) return \"$D\" + value.toJSON();\n    request = getPrototypeOf(value);\n    if (\n      request !== ObjectPrototype$1 &&\n      (null === request || null !== getPrototypeOf(request))\n    )\n      throw Error(\n        \"Only plain objects, and a few built-ins, can be passed to Client Components from Server Components. Classes or null prototypes are not supported.\" +\n          describeObjectForErrorMessage(parent, parentPropertyName)\n      );\n    return value;\n  }\n  if (\"string\" === typeof value) {\n    serializedSize += value.length;\n    if (\n      \"Z\" === value[value.length - 1] &&\n      parent[parentPropertyName] instanceof Date\n    )\n      return \"$D\" + value;\n    if (1024 <= value.length && null !== byteLengthOfChunk)\n      return (\n        request.pendingChunks++,\n        (task = request.nextChunkId++),\n        emitTextChunk(request, task, value, !1),\n        serializeByValueID(task)\n      );\n    request = \"$\" === value[0] ? \"$\" + value : value;\n    return request;\n  }\n  if (\"boolean\" === typeof value) return value;\n  if (\"number\" === typeof value)\n    return Number.isFinite(value)\n      ? 0 === value && -Infinity === 1 / value\n        ? \"$-0\"\n        : value\n      : Infinity === value\n        ? \"$Infinity\"\n        : -Infinity === value\n          ? \"$-Infinity\"\n          : \"$NaN\";\n  if (\"undefined\" === typeof value) return \"$undefined\";\n  if (\"function\" === typeof value) {\n    if (value.$$typeof === CLIENT_REFERENCE_TAG$1)\n      return serializeClientReference(\n        request,\n        parent,\n        parentPropertyName,\n        value\n      );\n    if (value.$$typeof === SERVER_REFERENCE_TAG)\n      return (\n        (task = request.writtenServerReferences),\n        (parentPropertyName = task.get(value)),\n        void 0 !== parentPropertyName\n          ? (request = \"$h\" + parentPropertyName.toString(16))\n          : ((parentPropertyName = value.$$bound),\n            (parentPropertyName =\n              null === parentPropertyName\n                ? null\n                : Promise.resolve(parentPropertyName)),\n            (request = outlineModelWithFormatContext(\n              request,\n              { id: value.$$id, bound: parentPropertyName },\n              0\n            )),\n            task.set(value, request),\n            (request = \"$h\" + request.toString(16))),\n        request\n      );\n    if (\n      void 0 !== request.temporaryReferences &&\n      ((request = request.temporaryReferences.get(value)), void 0 !== request)\n    )\n      return \"$T\" + request;\n    if (value.$$typeof === TEMPORARY_REFERENCE_TAG)\n      throw Error(\n        \"Could not reference an opaque temporary reference. This is likely due to misconfiguring the temporaryReferences options on the server.\"\n      );\n    if (/^on[A-Z]/.test(parentPropertyName))\n      throw Error(\n        \"Event handlers cannot be passed to Client Component props.\" +\n          describeObjectForErrorMessage(parent, parentPropertyName) +\n          \"\\nIf you need interactivity, consider converting part of this to a Client Component.\"\n      );\n    throw Error(\n      'Functions cannot be passed directly to Client Components unless you explicitly expose it by marking it with \"use server\". Or maybe you meant to call this function rather than return it.' +\n        describeObjectForErrorMessage(parent, parentPropertyName)\n    );\n  }\n  if (\"symbol\" === typeof value) {\n    task = request.writtenSymbols;\n    elementReference = task.get(value);\n    if (void 0 !== elementReference)\n      return serializeByValueID(elementReference);\n    elementReference = value.description;\n    if (Symbol.for(elementReference) !== value)\n      throw Error(\n        \"Only global symbols received from Symbol.for(...) can be passed to Client Components. The symbol Symbol.for(\" +\n          (value.description + \") cannot be found among global symbols.\") +\n          describeObjectForErrorMessage(parent, parentPropertyName)\n      );\n    request.pendingChunks++;\n    parentPropertyName = request.nextChunkId++;\n    parent = encodeReferenceChunk(\n      request,\n      parentPropertyName,\n      \"$S\" + elementReference\n    );\n    request.completedImportChunks.push(parent);\n    task.set(value, parentPropertyName);\n    return serializeByValueID(parentPropertyName);\n  }\n  if (\"bigint\" === typeof value) return \"$n\" + value.toString(10);\n  throw Error(\n    \"Type \" +\n      typeof value +\n      \" is not supported in Client Component props.\" +\n      describeObjectForErrorMessage(parent, parentPropertyName)\n  );\n}\nfunction logRecoverableError(request, error) {\n  var prevRequest = currentRequest;\n  currentRequest = null;\n  try {\n    var onError = request.onError;\n    var errorDigest = supportsRequestStorage\n      ? requestStorage.run(void 0, onError, error)\n      : onError(error);\n  } finally {\n    currentRequest = prevRequest;\n  }\n  if (null != errorDigest && \"string\" !== typeof errorDigest)\n    throw Error(\n      'onError returned something with a type other than \"string\". onError should return a string and may return null or undefined but must not return anything else. It received something of type \"' +\n        typeof errorDigest +\n        '\" instead'\n    );\n  return errorDigest || \"\";\n}\nfunction fatalError(request, error) {\n  var onFatalError = request.onFatalError;\n  onFatalError(error);\n  null !== request.destination\n    ? ((request.status = 14), closeWithError(request.destination, error))\n    : ((request.status = 13), (request.fatalError = error));\n  request.cacheController.abort(\n    Error(\"The render was aborted due to a fatal error.\", { cause: error })\n  );\n}\nfunction emitErrorChunk(request, id, digest) {\n  digest = { digest: digest };\n  id = id.toString(16) + \":E\" + stringify(digest) + \"\\n\";\n  id = stringToChunk(id);\n  request.completedErrorChunks.push(id);\n}\nfunction emitModelChunk(request, id, json) {\n  id = id.toString(16) + \":\" + json + \"\\n\";\n  id = stringToChunk(id);\n  request.completedRegularChunks.push(id);\n}\nfunction emitTypedArrayChunk(request, id, tag, typedArray, debug) {\n  debug ? request.pendingDebugChunks++ : request.pendingChunks++;\n  typedArray = new Uint8Array(\n    typedArray.buffer,\n    typedArray.byteOffset,\n    typedArray.byteLength\n  );\n  debug = typedArray.byteLength;\n  id = id.toString(16) + \":\" + tag + debug.toString(16) + \",\";\n  id = stringToChunk(id);\n  request.completedRegularChunks.push(id, typedArray);\n}\nfunction emitTextChunk(request, id, text, debug) {\n  if (null === byteLengthOfChunk)\n    throw Error(\n      \"Existence of byteLengthOfChunk should have already been checked. This is a bug in React.\"\n    );\n  debug ? request.pendingDebugChunks++ : request.pendingChunks++;\n  text = stringToChunk(text);\n  debug = text.byteLength;\n  id = id.toString(16) + \":T\" + debug.toString(16) + \",\";\n  id = stringToChunk(id);\n  request.completedRegularChunks.push(id, text);\n}\nfunction emitChunk(request, task, value) {\n  var id = task.id;\n  \"string\" === typeof value && null !== byteLengthOfChunk\n    ? emitTextChunk(request, id, value, !1)\n    : value instanceof ArrayBuffer\n      ? emitTypedArrayChunk(request, id, \"A\", new Uint8Array(value), !1)\n      : value instanceof Int8Array\n        ? emitTypedArrayChunk(request, id, \"O\", value, !1)\n        : value instanceof Uint8Array\n          ? emitTypedArrayChunk(request, id, \"o\", value, !1)\n          : value instanceof Uint8ClampedArray\n            ? emitTypedArrayChunk(request, id, \"U\", value, !1)\n            : value instanceof Int16Array\n              ? emitTypedArrayChunk(request, id, \"S\", value, !1)\n              : value instanceof Uint16Array\n                ? emitTypedArrayChunk(request, id, \"s\", value, !1)\n                : value instanceof Int32Array\n                  ? emitTypedArrayChunk(request, id, \"L\", value, !1)\n                  : value instanceof Uint32Array\n                    ? emitTypedArrayChunk(request, id, \"l\", value, !1)\n                    : value instanceof Float32Array\n                      ? emitTypedArrayChunk(request, id, \"G\", value, !1)\n                      : value instanceof Float64Array\n                        ? emitTypedArrayChunk(request, id, \"g\", value, !1)\n                        : value instanceof BigInt64Array\n                          ? emitTypedArrayChunk(request, id, \"M\", value, !1)\n                          : value instanceof BigUint64Array\n                            ? emitTypedArrayChunk(request, id, \"m\", value, !1)\n                            : value instanceof DataView\n                              ? emitTypedArrayChunk(request, id, \"V\", value, !1)\n                              : ((value = stringify(value, task.toJSON)),\n                                emitModelChunk(request, task.id, value));\n}\nfunction erroredTask(request, task, error) {\n  task.status = 4;\n  error = logRecoverableError(request, error, task);\n  emitErrorChunk(request, task.id, error);\n  request.abortableTasks.delete(task);\n  callOnAllReadyIfReady(request);\n}\nvar emptyRoot = {};\nfunction retryTask(request, task) {\n  if (0 === task.status) {\n    task.status = 5;\n    var parentSerializedSize = serializedSize;\n    try {\n      modelRoot = task.model;\n      var resolvedModel = renderModelDestructive(\n        request,\n        task,\n        emptyRoot,\n        \"\",\n        task.model\n      );\n      modelRoot = resolvedModel;\n      task.keyPath = null;\n      task.implicitSlot = !1;\n      if (\"object\" === typeof resolvedModel && null !== resolvedModel)\n        request.writtenObjects.set(resolvedModel, serializeByValueID(task.id)),\n          emitChunk(request, task, resolvedModel);\n      else {\n        var json = stringify(resolvedModel);\n        emitModelChunk(request, task.id, json);\n      }\n      task.status = 1;\n      request.abortableTasks.delete(task);\n      callOnAllReadyIfReady(request);\n    } catch (thrownValue) {\n      if (12 === request.status)\n        if (\n          (request.abortableTasks.delete(task),\n          (task.status = 0),\n          21 === request.type)\n        )\n          haltTask(task), finishHaltedTask(task, request);\n        else {\n          var errorId = request.fatalError;\n          abortTask(task);\n          finishAbortedTask(task, request, errorId);\n        }\n      else {\n        var x =\n          thrownValue === SuspenseException\n            ? getSuspendedThenable()\n            : thrownValue;\n        if (\n          \"object\" === typeof x &&\n          null !== x &&\n          \"function\" === typeof x.then\n        ) {\n          task.status = 0;\n          task.thenableState = getThenableStateAfterSuspending();\n          var ping = task.ping;\n          x.then(ping, ping);\n        } else erroredTask(request, task, x);\n      }\n    } finally {\n      serializedSize = parentSerializedSize;\n    }\n  }\n}\nfunction tryStreamTask(request, task) {\n  var parentSerializedSize = serializedSize;\n  try {\n    emitChunk(request, task, task.model);\n  } finally {\n    serializedSize = parentSerializedSize;\n  }\n}\nfunction performWork(request) {\n  var prevDispatcher = ReactSharedInternalsServer.H;\n  ReactSharedInternalsServer.H = HooksDispatcher;\n  var prevRequest = currentRequest;\n  currentRequest$1 = currentRequest = request;\n  try {\n    var pingedTasks = request.pingedTasks;\n    request.pingedTasks = [];\n    for (var i = 0; i < pingedTasks.length; i++)\n      retryTask(request, pingedTasks[i]);\n    flushCompletedChunks(request);\n  } catch (error) {\n    logRecoverableError(request, error, null), fatalError(request, error);\n  } finally {\n    (ReactSharedInternalsServer.H = prevDispatcher),\n      (currentRequest$1 = null),\n      (currentRequest = prevRequest);\n  }\n}\nfunction abortTask(task) {\n  0 === task.status && (task.status = 3);\n}\nfunction finishAbortedTask(task, request, errorId) {\n  3 === task.status &&\n    ((errorId = serializeByValueID(errorId)),\n    (task = encodeReferenceChunk(request, task.id, errorId)),\n    request.completedErrorChunks.push(task));\n}\nfunction haltTask(task) {\n  0 === task.status && (task.status = 3);\n}\nfunction finishHaltedTask(task, request) {\n  3 === task.status && request.pendingChunks--;\n}\nfunction flushCompletedChunks(request) {\n  var destination = request.destination;\n  if (null !== destination) {\n    currentView = new Uint8Array(4096);\n    writtenBytes = 0;\n    try {\n      for (\n        var importsChunks = request.completedImportChunks, i = 0;\n        i < importsChunks.length;\n        i++\n      )\n        request.pendingChunks--,\n          writeChunkAndReturn(destination, importsChunks[i]);\n      importsChunks.splice(0, i);\n      var hintChunks = request.completedHintChunks;\n      for (i = 0; i < hintChunks.length; i++)\n        writeChunkAndReturn(destination, hintChunks[i]);\n      hintChunks.splice(0, i);\n      var regularChunks = request.completedRegularChunks;\n      for (i = 0; i < regularChunks.length; i++)\n        request.pendingChunks--,\n          writeChunkAndReturn(destination, regularChunks[i]);\n      regularChunks.splice(0, i);\n      var errorChunks = request.completedErrorChunks;\n      for (i = 0; i < errorChunks.length; i++)\n        request.pendingChunks--,\n          writeChunkAndReturn(destination, errorChunks[i]);\n      errorChunks.splice(0, i);\n    } finally {\n      (request.flushScheduled = !1),\n        currentView &&\n          0 < writtenBytes &&\n          (destination.enqueue(\n            new Uint8Array(currentView.buffer, 0, writtenBytes)\n          ),\n          (currentView = null),\n          (writtenBytes = 0));\n    }\n  }\n  0 === request.pendingChunks &&\n    (12 > request.status &&\n      request.cacheController.abort(\n        Error(\n          \"This render completed successfully. All cacheSignals are now aborted to allow clean up of any unused resources.\"\n        )\n      ),\n    null !== request.destination &&\n      ((request.status = 14),\n      request.destination.close(),\n      (request.destination = null)));\n}\nfunction startWork(request) {\n  request.flushScheduled = null !== request.destination;\n  supportsRequestStorage\n    ? scheduleMicrotask(function () {\n        requestStorage.run(request, performWork, request);\n      })\n    : scheduleMicrotask(function () {\n        return performWork(request);\n      });\n  setTimeout(function () {\n    10 === request.status && (request.status = 11);\n  }, 0);\n}\nfunction enqueueFlush(request) {\n  !1 === request.flushScheduled &&\n    0 === request.pingedTasks.length &&\n    null !== request.destination &&\n    ((request.flushScheduled = !0),\n    setTimeout(function () {\n      request.flushScheduled = !1;\n      flushCompletedChunks(request);\n    }, 0));\n}\nfunction callOnAllReadyIfReady(request) {\n  0 === request.abortableTasks.size &&\n    ((request = request.onAllReady), request());\n}\nfunction startFlowing(request, destination) {\n  if (13 === request.status)\n    (request.status = 14), closeWithError(destination, request.fatalError);\n  else if (14 !== request.status && null === request.destination) {\n    request.destination = destination;\n    try {\n      flushCompletedChunks(request);\n    } catch (error) {\n      logRecoverableError(request, error, null), fatalError(request, error);\n    }\n  }\n}\nfunction finishHalt(request, abortedTasks) {\n  try {\n    abortedTasks.forEach(function (task) {\n      return finishHaltedTask(task, request);\n    });\n    var onAllReady = request.onAllReady;\n    onAllReady();\n    flushCompletedChunks(request);\n  } catch (error) {\n    logRecoverableError(request, error, null), fatalError(request, error);\n  }\n}\nfunction finishAbort(request, abortedTasks, errorId) {\n  try {\n    abortedTasks.forEach(function (task) {\n      return finishAbortedTask(task, request, errorId);\n    });\n    var onAllReady = request.onAllReady;\n    onAllReady();\n    flushCompletedChunks(request);\n  } catch (error) {\n    logRecoverableError(request, error, null), fatalError(request, error);\n  }\n}\nfunction abort(request, reason) {\n  if (!(11 < request.status))\n    try {\n      request.status = 12;\n      request.cacheController.abort(reason);\n      var abortableTasks = request.abortableTasks;\n      if (0 < abortableTasks.size)\n        if (21 === request.type)\n          abortableTasks.forEach(function (task) {\n            return haltTask(task, request);\n          }),\n            setTimeout(function () {\n              return finishHalt(request, abortableTasks);\n            }, 0);\n        else {\n          var error =\n              void 0 === reason\n                ? Error(\n                    \"The render was aborted by the server without a reason.\"\n                  )\n                : \"object\" === typeof reason &&\n                    null !== reason &&\n                    \"function\" === typeof reason.then\n                  ? Error(\n                      \"The render was aborted by the server with a promise.\"\n                    )\n                  : reason,\n            digest = logRecoverableError(request, error, null),\n            errorId = request.nextChunkId++;\n          request.fatalError = errorId;\n          request.pendingChunks++;\n          emitErrorChunk(request, errorId, digest, error, !1, null);\n          abortableTasks.forEach(function (task) {\n            return abortTask(task, request, errorId);\n          });\n          setTimeout(function () {\n            return finishAbort(request, abortableTasks, errorId);\n          }, 0);\n        }\n      else {\n        var onAllReady = request.onAllReady;\n        onAllReady();\n        flushCompletedChunks(request);\n      }\n    } catch (error$26) {\n      logRecoverableError(request, error$26, null),\n        fatalError(request, error$26);\n    }\n}\nfunction resolveServerReference(bundlerConfig, id) {\n  var name = \"\",\n    resolvedModuleData = bundlerConfig[id];\n  if (resolvedModuleData) name = resolvedModuleData.name;\n  else {\n    var idx = id.lastIndexOf(\"#\");\n    -1 !== idx &&\n      ((name = id.slice(idx + 1)),\n      (resolvedModuleData = bundlerConfig[id.slice(0, idx)]));\n    if (!resolvedModuleData)\n      throw Error(\n        'Could not find the module \"' +\n          id +\n          '\" in the React Server Manifest. This is probably a bug in the React Server Components bundler.'\n      );\n  }\n  return resolvedModuleData.async\n    ? [resolvedModuleData.id, resolvedModuleData.chunks, name, 1]\n    : [resolvedModuleData.id, resolvedModuleData.chunks, name];\n}\nfunction requireAsyncModule(id) {\n  var promise = globalThis.__next_require__(id);\n  if (\"function\" !== typeof promise.then || \"fulfilled\" === promise.status)\n    return null;\n  promise.then(\n    function (value) {\n      promise.status = \"fulfilled\";\n      promise.value = value;\n    },\n    function (reason) {\n      promise.status = \"rejected\";\n      promise.reason = reason;\n    }\n  );\n  return promise;\n}\nvar instrumentedChunks = new WeakSet(),\n  loadedChunks = new WeakSet();\nfunction ignoreReject() {}\nfunction preloadModule(metadata) {\n  for (var chunks = metadata[1], promises = [], i = 0; i < chunks.length; i++) {\n    var thenable = globalThis.__next_chunk_load__(chunks[i]);\n    loadedChunks.has(thenable) || promises.push(thenable);\n    if (!instrumentedChunks.has(thenable)) {\n      var resolve = loadedChunks.add.bind(loadedChunks, thenable);\n      thenable.then(resolve, ignoreReject);\n      instrumentedChunks.add(thenable);\n    }\n  }\n  return 4 === metadata.length\n    ? 0 === promises.length\n      ? requireAsyncModule(metadata[0])\n      : Promise.all(promises).then(function () {\n          return requireAsyncModule(metadata[0]);\n        })\n    : 0 < promises.length\n      ? Promise.all(promises)\n      : null;\n}\nfunction requireModule(metadata) {\n  var moduleExports = globalThis.__next_require__(metadata[0]);\n  if (4 === metadata.length && \"function\" === typeof moduleExports.then)\n    if (\"fulfilled\" === moduleExports.status)\n      moduleExports = moduleExports.value;\n    else throw moduleExports.reason;\n  if (\"*\" === metadata[2]) return moduleExports;\n  if (\"\" === metadata[2])\n    return moduleExports.__esModule ? moduleExports.default : moduleExports;\n  if (hasOwnProperty.call(moduleExports, metadata[2]))\n    return moduleExports[metadata[2]];\n}\nvar RESPONSE_SYMBOL = Symbol();\nfunction ReactPromise(status, value, reason) {\n  this.status = status;\n  this.value = value;\n  this.reason = reason;\n}\nReactPromise.prototype = Object.create(Promise.prototype);\nReactPromise.prototype.then = function (resolve, reject) {\n  switch (this.status) {\n    case \"resolved_model\":\n      initializeModelChunk(this);\n  }\n  switch (this.status) {\n    case \"fulfilled\":\n      if (\"function\" === typeof resolve) {\n        for (\n          var inspectedValue = this.value,\n            cycleProtection = 0,\n            visited = new Set();\n          inspectedValue instanceof ReactPromise;\n\n        ) {\n          cycleProtection++;\n          if (\n            inspectedValue === this ||\n            visited.has(inspectedValue) ||\n            1e3 < cycleProtection\n          ) {\n            \"function\" === typeof reject &&\n              reject(Error(\"Cannot have cyclic thenables.\"));\n            return;\n          }\n          visited.add(inspectedValue);\n          if (\"fulfilled\" === inspectedValue.status)\n            inspectedValue = inspectedValue.value;\n          else break;\n        }\n        resolve(this.value);\n      }\n      break;\n    case \"pending\":\n    case \"blocked\":\n      \"function\" === typeof resolve &&\n        (null === this.value && (this.value = []), this.value.push(resolve));\n      \"function\" === typeof reject &&\n        (null === this.reason && (this.reason = []), this.reason.push(reject));\n      break;\n    default:\n      \"function\" === typeof reject && reject(this.reason);\n  }\n};\nvar ObjectPrototype = Object.prototype,\n  ArrayPrototype = Array.prototype;\nfunction wakeChunk(response, listeners, value, chunk) {\n  for (var i = 0; i < listeners.length; i++) {\n    var listener = listeners[i];\n    \"function\" === typeof listener\n      ? listener(value)\n      : fulfillReference(response, listener, value, chunk.reason);\n  }\n}\nfunction rejectChunk(response, listeners, error) {\n  for (var i = 0; i < listeners.length; i++) {\n    var listener = listeners[i];\n    \"function\" === typeof listener\n      ? listener(error)\n      : rejectReference(response, listener.handler, error);\n  }\n}\nfunction triggerErrorOnChunk(response, chunk, error) {\n  if (\"pending\" !== chunk.status && \"blocked\" !== chunk.status)\n    chunk.reason.error(error);\n  else {\n    var listeners = chunk.reason;\n    chunk.status = \"rejected\";\n    chunk.reason = error;\n    null !== listeners && rejectChunk(response, listeners, error);\n  }\n}\nfunction createResolvedModelChunk(response, value, id) {\n  var $jscomp$compprop2 = {};\n  return new ReactPromise(\n    \"resolved_model\",\n    value,\n    (($jscomp$compprop2.id = id),\n    ($jscomp$compprop2[RESPONSE_SYMBOL] = response),\n    $jscomp$compprop2)\n  );\n}\nfunction resolveModelChunk(response, chunk, value, id) {\n  if (\"pending\" !== chunk.status)\n    (chunk = chunk.reason),\n      \"C\" === value[0]\n        ? chunk.close(\"C\" === value ? '\"$undefined\"' : value.slice(1))\n        : chunk.enqueueModel(value);\n  else {\n    var resolveListeners = chunk.value,\n      rejectListeners = chunk.reason;\n    chunk.status = \"resolved_model\";\n    chunk.value = value;\n    value = {};\n    chunk.reason =\n      ((value.id = id), (value[RESPONSE_SYMBOL] = response), value);\n    if (null !== resolveListeners)\n      switch ((initializeModelChunk(chunk), chunk.status)) {\n        case \"fulfilled\":\n          wakeChunk(response, resolveListeners, chunk.value, chunk);\n          break;\n        case \"blocked\":\n        case \"pending\":\n          if (chunk.value)\n            for (response = 0; response < resolveListeners.length; response++)\n              chunk.value.push(resolveListeners[response]);\n          else chunk.value = resolveListeners;\n          if (chunk.reason) {\n            if (rejectListeners)\n              for (\n                resolveListeners = 0;\n                resolveListeners < rejectListeners.length;\n                resolveListeners++\n              )\n                chunk.reason.push(rejectListeners[resolveListeners]);\n          } else chunk.reason = rejectListeners;\n          break;\n        case \"rejected\":\n          rejectListeners &&\n            rejectChunk(response, rejectListeners, chunk.reason);\n      }\n  }\n}\nfunction createResolvedIteratorResultChunk(response, value, done) {\n  var $jscomp$compprop4 = {};\n  return new ReactPromise(\n    \"resolved_model\",\n    (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n    (($jscomp$compprop4.id = -1),\n    ($jscomp$compprop4[RESPONSE_SYMBOL] = response),\n    $jscomp$compprop4)\n  );\n}\nfunction resolveIteratorResultChunk(response, chunk, value, done) {\n  resolveModelChunk(\n    response,\n    chunk,\n    (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n    -1\n  );\n}\nfunction loadServerReference$1(response, metaData, parentObject, key) {\n  function reject(error) {\n    var rejectListeners = blockedPromise.reason,\n      erroredPromise = blockedPromise;\n    erroredPromise.status = \"rejected\";\n    erroredPromise.value = null;\n    erroredPromise.reason = error;\n    null !== rejectListeners && rejectChunk(response, rejectListeners, error);\n    rejectReference(response, handler, error);\n  }\n  var id = metaData.id;\n  if (\"string\" !== typeof id || \"then\" === key) return null;\n  var cachedPromise = metaData.$$promise;\n  if (void 0 !== cachedPromise) {\n    if (\"fulfilled\" === cachedPromise.status)\n      return (\n        (cachedPromise = cachedPromise.value),\n        \"__proto__\" === key ? null : (parentObject[key] = cachedPromise)\n      );\n    initializingHandler\n      ? ((id = initializingHandler), id.deps++)\n      : (id = initializingHandler =\n          { chunk: null, value: null, reason: null, deps: 1, errored: !1 });\n    cachedPromise.then(\n      resolveReference.bind(null, response, id, parentObject, key),\n      rejectReference.bind(null, response, id)\n    );\n    return null;\n  }\n  var blockedPromise = new ReactPromise(\"blocked\", null, null);\n  metaData.$$promise = blockedPromise;\n  var serverReference = resolveServerReference(response._bundlerConfig, id);\n  cachedPromise = metaData.bound;\n  if ((id = preloadModule(serverReference)))\n    cachedPromise instanceof ReactPromise &&\n      (id = Promise.all([id, cachedPromise]));\n  else if (cachedPromise instanceof ReactPromise)\n    id = Promise.resolve(cachedPromise);\n  else\n    return (\n      (cachedPromise = requireModule(serverReference)),\n      (id = blockedPromise),\n      (id.status = \"fulfilled\"),\n      (id.value = cachedPromise)\n    );\n  if (initializingHandler) {\n    var handler = initializingHandler;\n    handler.deps++;\n  } else\n    handler = initializingHandler = {\n      chunk: null,\n      value: null,\n      reason: null,\n      deps: 1,\n      errored: !1\n    };\n  id.then(function () {\n    var resolvedValue = requireModule(serverReference);\n    if (metaData.bound) {\n      var promiseValue = metaData.bound.value;\n      promiseValue = isArrayImpl(promiseValue) ? promiseValue.slice(0) : [];\n      if (1e3 < promiseValue.length) {\n        reject(\n          Error(\n            \"Server Function has too many bound arguments. Received \" +\n              promiseValue.length +\n              \" but the limit is 1000.\"\n          )\n        );\n        return;\n      }\n      promiseValue.unshift(null);\n      resolvedValue = resolvedValue.bind.apply(resolvedValue, promiseValue);\n    }\n    promiseValue = blockedPromise.value;\n    var initializedPromise = blockedPromise;\n    initializedPromise.status = \"fulfilled\";\n    initializedPromise.value = resolvedValue;\n    initializedPromise.reason = null;\n    null !== promiseValue &&\n      wakeChunk(response, promiseValue, resolvedValue, initializedPromise);\n    resolveReference(response, handler, parentObject, key, resolvedValue);\n  }, reject);\n  return null;\n}\nfunction reviveModel(\n  response,\n  parentObj,\n  parentKey,\n  value,\n  reference,\n  arrayRoot\n) {\n  if (\"string\" === typeof value)\n    return parseModelString(\n      response,\n      parentObj,\n      parentKey,\n      value,\n      reference,\n      arrayRoot\n    );\n  if (\"object\" === typeof value && null !== value)\n    if (\n      (void 0 !== reference &&\n        void 0 !== response._temporaryReferences &&\n        response._temporaryReferences.set(value, reference),\n      isArrayImpl(value))\n    ) {\n      if (null === arrayRoot) {\n        var childContext = { count: 0, fork: !1 };\n        response._rootArrayContexts.set(value, childContext);\n      } else childContext = arrayRoot;\n      1 < value.length && (childContext.fork = !0);\n      bumpArrayCount(childContext, value.length + 1, response);\n      for (parentObj = 0; parentObj < value.length; parentObj++)\n        value[parentObj] = reviveModel(\n          response,\n          value,\n          \"\" + parentObj,\n          value[parentObj],\n          void 0 !== reference ? reference + \":\" + parentObj : void 0,\n          childContext\n        );\n    } else\n      for (childContext in value)\n        hasOwnProperty.call(value, childContext) &&\n          (\"__proto__\" === childContext\n            ? delete value[childContext]\n            : ((parentObj =\n                void 0 !== reference && -1 === childContext.indexOf(\":\")\n                  ? reference + \":\" + childContext\n                  : void 0),\n              (parentObj = reviveModel(\n                response,\n                value,\n                childContext,\n                value[childContext],\n                parentObj,\n                null\n              )),\n              void 0 !== parentObj\n                ? (value[childContext] = parentObj)\n                : delete value[childContext]));\n  return value;\n}\nfunction bumpArrayCount(arrayContext, slots, response) {\n  if (\n    (arrayContext.count += slots) > response._arraySizeLimit &&\n    arrayContext.fork\n  )\n    throw Error(\n      \"Maximum array nesting exceeded. Large nested arrays can be dangerous. Try adding intermediate objects.\"\n    );\n}\nvar initializingHandler = null;\nfunction initializeModelChunk(chunk) {\n  var prevHandler = initializingHandler;\n  initializingHandler = null;\n  var _chunk$reason = chunk.reason,\n    response = _chunk$reason[RESPONSE_SYMBOL];\n  _chunk$reason = _chunk$reason.id;\n  _chunk$reason = -1 === _chunk$reason ? void 0 : _chunk$reason.toString(16);\n  var resolvedModel = chunk.value;\n  chunk.status = \"blocked\";\n  chunk.value = null;\n  chunk.reason = null;\n  try {\n    var rawModel = JSON.parse(resolvedModel);\n    resolvedModel = { count: 0, fork: !1 };\n    var value = reviveModel(\n        response,\n        { \"\": rawModel },\n        \"\",\n        rawModel,\n        _chunk$reason,\n        resolvedModel\n      ),\n      resolveListeners = chunk.value;\n    if (null !== resolveListeners)\n      for (\n        chunk.value = null, chunk.reason = null, rawModel = 0;\n        rawModel < resolveListeners.length;\n        rawModel++\n      ) {\n        var listener = resolveListeners[rawModel];\n        \"function\" === typeof listener\n          ? listener(value)\n          : fulfillReference(response, listener, value, resolvedModel);\n      }\n    if (null !== initializingHandler) {\n      if (initializingHandler.errored) throw initializingHandler.reason;\n      if (0 < initializingHandler.deps) {\n        initializingHandler.value = value;\n        initializingHandler.reason = resolvedModel;\n        initializingHandler.chunk = chunk;\n        return;\n      }\n    }\n    chunk.status = \"fulfilled\";\n    chunk.value = value;\n    chunk.reason = resolvedModel;\n  } catch (error) {\n    (chunk.status = \"rejected\"), (chunk.reason = error);\n  } finally {\n    initializingHandler = prevHandler;\n  }\n}\nfunction reportGlobalError(response, error) {\n  response._closed = !0;\n  response._closedReason = error;\n  response._chunks.forEach(function (chunk) {\n    \"pending\" === chunk.status\n      ? triggerErrorOnChunk(response, chunk, error)\n      : \"fulfilled\" === chunk.status &&\n        null !== chunk.reason &&\n        ((chunk = chunk.reason),\n        \"function\" === typeof chunk.error && chunk.error(error));\n  });\n}\nfunction getChunk(response, id) {\n  var chunks = response._chunks,\n    chunk = chunks.get(id);\n  chunk ||\n    ((chunk = response._formData.get(response._prefix + id)),\n    (chunk =\n      \"string\" === typeof chunk\n        ? createResolvedModelChunk(response, chunk, id)\n        : response._closed\n          ? new ReactPromise(\"rejected\", null, response._closedReason)\n          : new ReactPromise(\"pending\", null, null)),\n    chunks.set(id, chunk));\n  return chunk;\n}\nfunction fulfillReference(response, reference, value, arrayRoot) {\n  var handler = reference.handler,\n    parentObject = reference.parentObject,\n    key = reference.key,\n    map = reference.map,\n    path = reference.path;\n  try {\n    for (\n      var localLength = 0,\n        rootArrayContexts = response._rootArrayContexts,\n        i = 1;\n      i < path.length;\n      i++\n    ) {\n      var name = path[i];\n      if (\n        \"object\" !== typeof value ||\n        null === value ||\n        (getPrototypeOf(value) !== ObjectPrototype &&\n          getPrototypeOf(value) !== ArrayPrototype) ||\n        !hasOwnProperty.call(value, name)\n      )\n        throw Error(\"Invalid reference.\");\n      value = value[name];\n      if (isArrayImpl(value))\n        (localLength = 0),\n          (arrayRoot = rootArrayContexts.get(value) || arrayRoot);\n      else if (((arrayRoot = null), \"string\" === typeof value))\n        localLength = value.length;\n      else if (\"bigint\" === typeof value) {\n        var n = Math.abs(Number(value));\n        localLength = 0 === n ? 1 : Math.floor(Math.log10(n)) + 1;\n      } else localLength = ArrayBuffer.isView(value) ? value.byteLength : 0;\n    }\n    var resolvedValue = map(response, value, parentObject, key);\n    var referenceArrayRoot = reference.arrayRoot;\n    null !== referenceArrayRoot &&\n      (null !== arrayRoot\n        ? (arrayRoot.fork && (referenceArrayRoot.fork = !0),\n          bumpArrayCount(referenceArrayRoot, arrayRoot.count, response))\n        : 0 < localLength &&\n          bumpArrayCount(referenceArrayRoot, localLength, response));\n  } catch (error) {\n    rejectReference(response, handler, error);\n    return;\n  }\n  resolveReference(response, handler, parentObject, key, resolvedValue);\n}\nfunction resolveReference(response, handler, parentObject, key, resolvedValue) {\n  \"__proto__\" !== key && (parentObject[key] = resolvedValue);\n  \"\" === key && null === handler.value && (handler.value = resolvedValue);\n  handler.deps--;\n  0 === handler.deps &&\n    ((parentObject = handler.chunk),\n    null !== parentObject &&\n      \"blocked\" === parentObject.status &&\n      ((key = parentObject.value),\n      (parentObject.status = \"fulfilled\"),\n      (parentObject.value = handler.value),\n      (parentObject.reason = handler.reason),\n      null !== key && wakeChunk(response, key, handler.value, parentObject)));\n}\nfunction rejectReference(response, handler, error) {\n  handler.errored ||\n    ((handler.errored = !0),\n    (handler.value = null),\n    (handler.reason = error),\n    (handler = handler.chunk),\n    null !== handler &&\n      \"blocked\" === handler.status &&\n      triggerErrorOnChunk(response, handler, error));\n}\nfunction getOutlinedModel(\n  response,\n  reference,\n  parentObject,\n  key,\n  referenceArrayRoot,\n  map\n) {\n  reference = reference.split(\":\");\n  var id = parseInt(reference[0], 16),\n    chunk = getChunk(response, id);\n  switch (chunk.status) {\n    case \"resolved_model\":\n      initializeModelChunk(chunk);\n  }\n  switch (chunk.status) {\n    case \"fulfilled\":\n      id = chunk.value;\n      chunk = chunk.reason;\n      for (\n        var localLength = 0,\n          rootArrayContexts = response._rootArrayContexts,\n          i = 1;\n        i < reference.length;\n        i++\n      ) {\n        localLength = reference[i];\n        if (\n          \"object\" !== typeof id ||\n          null === id ||\n          (getPrototypeOf(id) !== ObjectPrototype &&\n            getPrototypeOf(id) !== ArrayPrototype) ||\n          !hasOwnProperty.call(id, localLength)\n        )\n          throw Error(\"Invalid reference.\");\n        id = id[localLength];\n        isArrayImpl(id)\n          ? ((localLength = 0), (chunk = rootArrayContexts.get(id) || chunk))\n          : ((chunk = null),\n            \"string\" === typeof id\n              ? (localLength = id.length)\n              : \"bigint\" === typeof id\n                ? ((localLength = Math.abs(Number(id))),\n                  (localLength =\n                    0 === localLength\n                      ? 1\n                      : Math.floor(Math.log10(localLength)) + 1))\n                : (localLength = ArrayBuffer.isView(id) ? id.byteLength : 0));\n      }\n      parentObject = map(response, id, parentObject, key);\n      null !== referenceArrayRoot &&\n        (null !== chunk\n          ? (chunk.fork && (referenceArrayRoot.fork = !0),\n            bumpArrayCount(referenceArrayRoot, chunk.count, response))\n          : 0 < localLength &&\n            bumpArrayCount(referenceArrayRoot, localLength, response));\n      return parentObject;\n    case \"blocked\":\n      return (\n        initializingHandler\n          ? ((response = initializingHandler), response.deps++)\n          : (response = initializingHandler =\n              { chunk: null, value: null, reason: null, deps: 1, errored: !1 }),\n        (referenceArrayRoot = {\n          handler: response,\n          parentObject: parentObject,\n          key: key,\n          map: map,\n          path: reference,\n          arrayRoot: referenceArrayRoot\n        }),\n        null === chunk.value\n          ? (chunk.value = [referenceArrayRoot])\n          : chunk.value.push(referenceArrayRoot),\n        null === chunk.reason\n          ? (chunk.reason = [referenceArrayRoot])\n          : chunk.reason.push(referenceArrayRoot),\n        null\n      );\n    case \"pending\":\n      throw Error(\"Invalid forward reference.\");\n    default:\n      return (\n        initializingHandler\n          ? ((initializingHandler.errored = !0),\n            (initializingHandler.value = null),\n            (initializingHandler.reason = chunk.reason))\n          : (initializingHandler = {\n              chunk: null,\n              value: null,\n              reason: chunk.reason,\n              deps: 0,\n              errored: !0\n            }),\n        null\n      );\n  }\n}\nfunction createMap(response, model) {\n  if (!isArrayImpl(model)) throw Error(\"Invalid Map initializer.\");\n  if (!0 === model.$$consumed) throw Error(\"Already initialized Map.\");\n  response = new Map(model);\n  model.$$consumed = !0;\n  return response;\n}\nfunction createSet(response, model) {\n  if (!isArrayImpl(model)) throw Error(\"Invalid Set initializer.\");\n  if (!0 === model.$$consumed) throw Error(\"Already initialized Set.\");\n  response = new Set(model);\n  model.$$consumed = !0;\n  return response;\n}\nfunction extractIterator(response, model) {\n  if (!isArrayImpl(model)) throw Error(\"Invalid Iterator initializer.\");\n  if (!0 === model.$$consumed) throw Error(\"Already initialized Iterator.\");\n  response = model[Symbol.iterator]();\n  model.$$consumed = !0;\n  return response;\n}\nfunction createModel(response, model, parentObject, key) {\n  return \"then\" === key && \"function\" === typeof model ? null : model;\n}\nfunction parseTypedArray(\n  response,\n  reference,\n  constructor,\n  bytesPerElement,\n  parentObject,\n  parentKey,\n  referenceArrayRoot\n) {\n  function reject(error) {\n    if (!handler.errored) {\n      handler.errored = !0;\n      handler.value = null;\n      handler.reason = error;\n      var chunk = handler.chunk;\n      null !== chunk &&\n        \"blocked\" === chunk.status &&\n        triggerErrorOnChunk(response, chunk, error);\n    }\n  }\n  reference = parseInt(reference.slice(2), 16);\n  var key = response._prefix + reference;\n  bytesPerElement = response._chunks;\n  if (bytesPerElement.has(reference))\n    throw Error(\"Already initialized typed array.\");\n  bytesPerElement.set(\n    reference,\n    new ReactPromise(\n      \"rejected\",\n      null,\n      Error(\"Already initialized typed array.\")\n    )\n  );\n  reference = response._formData.get(key).arrayBuffer();\n  if (initializingHandler) {\n    var handler = initializingHandler;\n    handler.deps++;\n  } else\n    handler = initializingHandler = {\n      chunk: null,\n      value: null,\n      reason: null,\n      deps: 1,\n      errored: !1\n    };\n  reference.then(function (buffer) {\n    try {\n      null !== referenceArrayRoot &&\n        bumpArrayCount(referenceArrayRoot, buffer.byteLength, response);\n      var resolvedValue =\n        constructor === ArrayBuffer ? buffer : new constructor(buffer);\n      \"__proto__\" !== key && (parentObject[parentKey] = resolvedValue);\n      \"\" === parentKey &&\n        null === handler.value &&\n        (handler.value = resolvedValue);\n    } catch (x) {\n      reject(x);\n      return;\n    }\n    handler.deps--;\n    0 === handler.deps &&\n      ((buffer = handler.chunk),\n      null !== buffer &&\n        \"blocked\" === buffer.status &&\n        ((resolvedValue = buffer.value),\n        (buffer.status = \"fulfilled\"),\n        (buffer.value = handler.value),\n        (buffer.reason = null),\n        null !== resolvedValue &&\n          wakeChunk(response, resolvedValue, handler.value, buffer)));\n  }, reject);\n  return null;\n}\nfunction resolveStream(response, id, stream, controller) {\n  var chunks = response._chunks;\n  stream = new ReactPromise(\"fulfilled\", stream, controller);\n  chunks.set(id, stream);\n  response = response._formData.getAll(response._prefix + id);\n  for (id = 0; id < response.length; id++)\n    (chunks = response[id]),\n      \"string\" === typeof chunks &&\n        (\"C\" === chunks[0]\n          ? controller.close(\"C\" === chunks ? '\"$undefined\"' : chunks.slice(1))\n          : controller.enqueueModel(chunks));\n}\nfunction parseReadableStream(response, reference, type) {\n  function enqueue(value) {\n    \"bytes\" !== type || ArrayBuffer.isView(value)\n      ? controller.enqueue(value)\n      : flightController.error(Error(\"Invalid data for bytes stream.\"));\n  }\n  reference = parseInt(reference.slice(2), 16);\n  if (response._chunks.has(reference))\n    throw Error(\"Already initialized stream.\");\n  var controller = null,\n    closed = !1,\n    stream = new ReadableStream({\n      type: type,\n      start: function (c) {\n        controller = c;\n      }\n    }),\n    previousBlockedChunk = null,\n    flightController = {\n      enqueueModel: function (json) {\n        if (null === previousBlockedChunk) {\n          var chunk = createResolvedModelChunk(response, json, -1);\n          initializeModelChunk(chunk);\n          \"fulfilled\" === chunk.status\n            ? enqueue(chunk.value)\n            : (chunk.then(enqueue, flightController.error),\n              (previousBlockedChunk = chunk));\n        } else {\n          chunk = previousBlockedChunk;\n          var chunk$31 = new ReactPromise(\"pending\", null, null);\n          chunk$31.then(enqueue, flightController.error);\n          previousBlockedChunk = chunk$31;\n          chunk.then(function () {\n            previousBlockedChunk === chunk$31 && (previousBlockedChunk = null);\n            resolveModelChunk(response, chunk$31, json, -1);\n          });\n        }\n      },\n      close: function () {\n        if (!closed)\n          if (((closed = !0), null === previousBlockedChunk))\n            controller.close();\n          else {\n            var blockedChunk = previousBlockedChunk;\n            previousBlockedChunk = null;\n            blockedChunk.then(function () {\n              return controller.close();\n            });\n          }\n      },\n      error: function (error) {\n        if (!closed)\n          if (((closed = !0), null === previousBlockedChunk))\n            controller.error(error);\n          else {\n            var blockedChunk = previousBlockedChunk;\n            previousBlockedChunk = null;\n            blockedChunk.then(function () {\n              return controller.error(error);\n            });\n          }\n      }\n    };\n  resolveStream(response, reference, stream, flightController);\n  return stream;\n}\nfunction FlightIterator(next) {\n  this.next = next;\n}\nFlightIterator.prototype = {};\nFlightIterator.prototype[ASYNC_ITERATOR] = function () {\n  return this;\n};\nfunction parseAsyncIterable(response, reference, iterator) {\n  reference = parseInt(reference.slice(2), 16);\n  if (response._chunks.has(reference))\n    throw Error(\"Already initialized stream.\");\n  var buffer = [],\n    closed = !1,\n    nextWriteIndex = 0,\n    $jscomp$compprop5 = {};\n  $jscomp$compprop5 =\n    (($jscomp$compprop5[ASYNC_ITERATOR] = function () {\n      var nextReadIndex = 0;\n      return new FlightIterator(function (arg) {\n        if (void 0 !== arg)\n          throw Error(\n            \"Values cannot be passed to next() of AsyncIterables passed to Client Components.\"\n          );\n        if (nextReadIndex === buffer.length) {\n          if (closed)\n            return new ReactPromise(\n              \"fulfilled\",\n              { done: !0, value: void 0 },\n              null\n            );\n          buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n        }\n        return buffer[nextReadIndex++];\n      });\n    }),\n    $jscomp$compprop5);\n  iterator = iterator ? $jscomp$compprop5[ASYNC_ITERATOR]() : $jscomp$compprop5;\n  resolveStream(response, reference, iterator, {\n    enqueueModel: function (value) {\n      nextWriteIndex === buffer.length\n        ? (buffer[nextWriteIndex] = createResolvedIteratorResultChunk(\n            response,\n            value,\n            !1\n          ))\n        : resolveIteratorResultChunk(\n            response,\n            buffer[nextWriteIndex],\n            value,\n            !1\n          );\n      nextWriteIndex++;\n    },\n    close: function (value) {\n      if (!closed)\n        for (\n          closed = !0,\n            nextWriteIndex === buffer.length\n              ? (buffer[nextWriteIndex] = createResolvedIteratorResultChunk(\n                  response,\n                  value,\n                  !0\n                ))\n              : resolveIteratorResultChunk(\n                  response,\n                  buffer[nextWriteIndex],\n                  value,\n                  !0\n                ),\n            nextWriteIndex++;\n          nextWriteIndex < buffer.length;\n\n        )\n          resolveIteratorResultChunk(\n            response,\n            buffer[nextWriteIndex++],\n            '\"$undefined\"',\n            !0\n          );\n    },\n    error: function (error) {\n      if (!closed)\n        for (\n          closed = !0,\n            nextWriteIndex === buffer.length &&\n              (buffer[nextWriteIndex] = new ReactPromise(\n                \"pending\",\n                null,\n                null\n              ));\n          nextWriteIndex < buffer.length;\n\n        )\n          triggerErrorOnChunk(response, buffer[nextWriteIndex++], error);\n    }\n  });\n  return iterator;\n}\nfunction parseModelString(response, obj, key, value, reference, arrayRoot) {\n  if (\"$\" === value[0]) {\n    switch (value[1]) {\n      case \"$\":\n        return (\n          null !== arrayRoot &&\n            bumpArrayCount(arrayRoot, value.length - 1, response),\n          value.slice(1)\n        );\n      case \"@\":\n        return (obj = parseInt(value.slice(2), 16)), getChunk(response, obj);\n      case \"h\":\n        return (\n          (arrayRoot = value.slice(2)),\n          getOutlinedModel(\n            response,\n            arrayRoot,\n            obj,\n            key,\n            null,\n            loadServerReference$1\n          )\n        );\n      case \"T\":\n        if (void 0 === reference || void 0 === response._temporaryReferences)\n          throw Error(\n            \"Could not reference an opaque temporary reference. This is likely due to misconfiguring the temporaryReferences options on the server.\"\n          );\n        return createTemporaryReference(\n          response._temporaryReferences,\n          reference\n        );\n      case \"Q\":\n        return (\n          (arrayRoot = value.slice(2)),\n          getOutlinedModel(response, arrayRoot, obj, key, null, createMap)\n        );\n      case \"W\":\n        return (\n          (arrayRoot = value.slice(2)),\n          getOutlinedModel(response, arrayRoot, obj, key, null, createSet)\n        );\n      case \"K\":\n        obj = value.slice(2);\n        obj = response._prefix + obj + \"_\";\n        key = new FormData();\n        response = response._formData;\n        arrayRoot = Array.from(response.keys());\n        for (value = 0; value < arrayRoot.length; value++)\n          if (((reference = arrayRoot[value]), reference.startsWith(obj))) {\n            for (\n              var entries = response.getAll(reference),\n                newKey = reference.slice(obj.length),\n                j = 0;\n              j < entries.length;\n              j++\n            )\n              key.append(newKey, entries[j]);\n            response.delete(reference);\n          }\n        return key;\n      case \"i\":\n        return (\n          (arrayRoot = value.slice(2)),\n          getOutlinedModel(response, arrayRoot, obj, key, null, extractIterator)\n        );\n      case \"I\":\n        return Infinity;\n      case \"-\":\n        return \"$-0\" === value ? -0 : -Infinity;\n      case \"N\":\n        return NaN;\n      case \"u\":\n        return;\n      case \"D\":\n        return new Date(Date.parse(value.slice(2)));\n      case \"n\":\n        obj = value.slice(2);\n        if (300 < obj.length)\n          throw Error(\n            \"BigInt is too large. Received \" +\n              obj.length +\n              \" digits but the limit is 300.\"\n          );\n        null !== arrayRoot && bumpArrayCount(arrayRoot, obj.length, response);\n        return BigInt(obj);\n      case \"A\":\n        return parseTypedArray(\n          response,\n          value,\n          ArrayBuffer,\n          1,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"O\":\n        return parseTypedArray(\n          response,\n          value,\n          Int8Array,\n          1,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"o\":\n        return parseTypedArray(\n          response,\n          value,\n          Uint8Array,\n          1,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"U\":\n        return parseTypedArray(\n          response,\n          value,\n          Uint8ClampedArray,\n          1,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"S\":\n        return parseTypedArray(\n          response,\n          value,\n          Int16Array,\n          2,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"s\":\n        return parseTypedArray(\n          response,\n          value,\n          Uint16Array,\n          2,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"L\":\n        return parseTypedArray(\n          response,\n          value,\n          Int32Array,\n          4,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"l\":\n        return parseTypedArray(\n          response,\n          value,\n          Uint32Array,\n          4,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"G\":\n        return parseTypedArray(\n          response,\n          value,\n          Float32Array,\n          4,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"g\":\n        return parseTypedArray(\n          response,\n          value,\n          Float64Array,\n          8,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"M\":\n        return parseTypedArray(\n          response,\n          value,\n          BigInt64Array,\n          8,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"m\":\n        return parseTypedArray(\n          response,\n          value,\n          BigUint64Array,\n          8,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"V\":\n        return parseTypedArray(\n          response,\n          value,\n          DataView,\n          1,\n          obj,\n          key,\n          arrayRoot\n        );\n      case \"B\":\n        return (\n          (obj = parseInt(value.slice(2), 16)),\n          response._formData.get(response._prefix + obj)\n        );\n      case \"R\":\n        return parseReadableStream(response, value, void 0);\n      case \"r\":\n        return parseReadableStream(response, value, \"bytes\");\n      case \"X\":\n        return parseAsyncIterable(response, value, !1);\n      case \"x\":\n        return parseAsyncIterable(response, value, !0);\n    }\n    value = value.slice(1);\n    return getOutlinedModel(response, value, obj, key, arrayRoot, createModel);\n  }\n  null !== arrayRoot && bumpArrayCount(arrayRoot, value.length, response);\n  return value;\n}\nfunction createResponse(bundlerConfig, formFieldPrefix, temporaryReferences) {\n  var backingFormData =\n      3 < arguments.length && void 0 !== arguments[3]\n        ? arguments[3]\n        : new FormData(),\n    arraySizeLimit =\n      4 < arguments.length && void 0 !== arguments[4] ? arguments[4] : 1e6,\n    chunks = new Map();\n  return {\n    _bundlerConfig: bundlerConfig,\n    _prefix: formFieldPrefix,\n    _formData: backingFormData,\n    _chunks: chunks,\n    _closed: !1,\n    _closedReason: null,\n    _temporaryReferences: temporaryReferences,\n    _rootArrayContexts: new WeakMap(),\n    _arraySizeLimit: arraySizeLimit\n  };\n}\nfunction close(response) {\n  reportGlobalError(response, Error(\"Connection closed.\"));\n}\nfunction loadServerReference(bundlerConfig, metaData) {\n  var id = metaData.id;\n  if (\"string\" !== typeof id) return null;\n  var serverReference = resolveServerReference(bundlerConfig, id);\n  bundlerConfig = preloadModule(serverReference);\n  metaData = metaData.bound;\n  return metaData instanceof Promise\n    ? Promise.all([metaData, bundlerConfig]).then(function (_ref) {\n        _ref = _ref[0];\n        var fn = requireModule(serverReference);\n        if (1e3 < _ref.length)\n          throw Error(\n            \"Server Function has too many bound arguments. Received \" +\n              _ref.length +\n              \" but the limit is 1000.\"\n          );\n        return fn.bind.apply(fn, [null].concat(_ref));\n      })\n    : bundlerConfig\n      ? Promise.resolve(bundlerConfig).then(function () {\n          return requireModule(serverReference);\n        })\n      : Promise.resolve(requireModule(serverReference));\n}\nfunction decodeBoundActionMetaData(\n  body,\n  serverManifest,\n  formFieldPrefix,\n  arraySizeLimit\n) {\n  body = createResponse(\n    serverManifest,\n    formFieldPrefix,\n    void 0,\n    body,\n    arraySizeLimit\n  );\n  close(body);\n  body = getChunk(body, 0);\n  body.then(function () {});\n  if (\"fulfilled\" !== body.status) throw body.reason;\n  return body.value;\n}\nexports.createClientModuleProxy = function (moduleId) {\n  moduleId = registerClientReferenceImpl({}, moduleId, !1);\n  return new Proxy(moduleId, proxyHandlers$1);\n};\nexports.createTemporaryReferenceSet = function () {\n  return new WeakMap();\n};\nexports.decodeAction = function (body, serverManifest) {\n  var formData = new FormData(),\n    action = null,\n    seenActions = new Set();\n  body.forEach(function (value, key) {\n    key.startsWith(\"$ACTION_\")\n      ? key.startsWith(\"$ACTION_REF_\")\n        ? seenActions.has(key) ||\n          (seenActions.add(key),\n          (value = \"$ACTION_\" + key.slice(12) + \":\"),\n          (value = decodeBoundActionMetaData(body, serverManifest, value)),\n          (action = loadServerReference(serverManifest, value)))\n        : key.startsWith(\"$ACTION_ID_\") &&\n          !seenActions.has(key) &&\n          (seenActions.add(key),\n          (value = key.slice(11)),\n          (action = loadServerReference(serverManifest, {\n            id: value,\n            bound: null\n          })))\n      : formData.append(key, value);\n  });\n  return null === action\n    ? null\n    : action.then(function (fn) {\n        return fn.bind(null, formData);\n      });\n};\nexports.decodeFormState = function (actionResult, body, serverManifest) {\n  var keyPath = body.get(\"$ACTION_KEY\");\n  if (\"string\" !== typeof keyPath) return Promise.resolve(null);\n  var metaData = null;\n  body.forEach(function (value, key) {\n    key.startsWith(\"$ACTION_REF_\") &&\n      ((value = \"$ACTION_\" + key.slice(12) + \":\"),\n      (metaData = decodeBoundActionMetaData(body, serverManifest, value)));\n  });\n  if (null === metaData) return Promise.resolve(null);\n  var referenceId = metaData.id;\n  return Promise.resolve(metaData.bound).then(function (bound) {\n    return null === bound\n      ? null\n      : [actionResult, keyPath, referenceId, bound.length - 1];\n  });\n};\nexports.decodeReply = function (body, turbopackMap, options) {\n  if (\"string\" === typeof body) {\n    var form = new FormData();\n    form.append(\"0\", body);\n    body = form;\n  }\n  body = createResponse(\n    turbopackMap,\n    \"\",\n    options ? options.temporaryReferences : void 0,\n    body,\n    options ? options.arraySizeLimit : void 0\n  );\n  turbopackMap = getChunk(body, 0);\n  close(body);\n  return turbopackMap;\n};\nexports.decodeReplyFromAsyncIterable = function (\n  iterable,\n  turbopackMap,\n  options\n) {\n  function progress(entry) {\n    if (entry.done) close(response);\n    else {\n      entry = entry.value;\n      var name = entry[0];\n      entry = entry[1];\n      if (\"string\" === typeof entry) {\n        response._formData.append(name, entry);\n        var prefix = response._prefix;\n        if (name.startsWith(prefix)) {\n          var chunks = response._chunks;\n          name = +name.slice(prefix.length);\n          (chunks = chunks.get(name)) &&\n            resolveModelChunk(response, chunks, entry, name);\n        }\n      } else response._formData.append(name, entry);\n      iterator.next().then(progress, error);\n    }\n  }\n  function error(reason) {\n    reportGlobalError(response, reason);\n    \"function\" === typeof iterator.throw &&\n      iterator.throw(reason).then(error, error);\n  }\n  var iterator = iterable[ASYNC_ITERATOR](),\n    response = createResponse(\n      turbopackMap,\n      \"\",\n      options ? options.temporaryReferences : void 0,\n      void 0,\n      options ? options.arraySizeLimit : void 0\n    );\n  iterator.next().then(progress, error);\n  return getChunk(response, 0);\n};\nexports.prerender = function (model, turbopackMap, options) {\n  return new Promise(function (resolve, reject) {\n    var request = new RequestInstance(\n      21,\n      model,\n      turbopackMap,\n      options ? options.onError : void 0,\n      function () {\n        var stream = new ReadableStream(\n          {\n            type: \"bytes\",\n            pull: function (controller) {\n              startFlowing(request, controller);\n            },\n            cancel: function (reason) {\n              request.destination = null;\n              abort(request, reason);\n            }\n          },\n          { highWaterMark: 0 }\n        );\n        resolve({ prelude: stream });\n      },\n      reject,\n      options ? options.identifierPrefix : void 0,\n      options ? options.temporaryReferences : void 0\n    );\n    if (options && options.signal) {\n      var signal = options.signal;\n      if (signal.aborted) abort(request, signal.reason);\n      else {\n        var listener = function () {\n          abort(request, signal.reason);\n          signal.removeEventListener(\"abort\", listener);\n        };\n        signal.addEventListener(\"abort\", listener);\n      }\n    }\n    startWork(request);\n  });\n};\nexports.registerClientReference = function (\n  proxyImplementation,\n  id,\n  exportName\n) {\n  return registerClientReferenceImpl(\n    proxyImplementation,\n    id + \"#\" + exportName,\n    !1\n  );\n};\nexports.registerServerReference = function (reference, id, exportName) {\n  return Object.defineProperties(reference, {\n    $$typeof: { value: SERVER_REFERENCE_TAG },\n    $$id: {\n      value: null === exportName ? id : id + \"#\" + exportName,\n      configurable: !0\n    },\n    $$bound: { value: null, configurable: !0 },\n    bind: { value: bind, configurable: !0 },\n    toString: serverReferenceToString\n  });\n};\nexports.renderToReadableStream = function (model, turbopackMap, options) {\n  var request = new RequestInstance(\n    20,\n    model,\n    turbopackMap,\n    options ? options.onError : void 0,\n    noop,\n    noop,\n    options ? options.identifierPrefix : void 0,\n    options ? options.temporaryReferences : void 0\n  );\n  if (options && options.signal) {\n    var signal = options.signal;\n    if (signal.aborted) abort(request, signal.reason);\n    else {\n      var listener = function () {\n        abort(request, signal.reason);\n        signal.removeEventListener(\"abort\", listener);\n      };\n      signal.addEventListener(\"abort\", listener);\n    }\n  }\n  return new ReadableStream(\n    {\n      type: \"bytes\",\n      start: function () {\n        startWork(request);\n      },\n      pull: function (controller) {\n        startFlowing(request, controller);\n      },\n      cancel: function (reason) {\n        request.destination = null;\n        abort(request, reason);\n      }\n    },\n    { highWaterMark: 0 }\n  );\n};\n","'use strict';\n\nvar s;\nif (process.env.NODE_ENV === 'production') {\n  s = require('./cjs/react-server-dom-turbopack-server.edge.production.js');\n} else {\n  s = require('./cjs/react-server-dom-turbopack-server.edge.development.js');\n}\n\nexports.renderToReadableStream = s.renderToReadableStream;\nexports.decodeReply = s.decodeReply;\nexports.decodeReplyFromAsyncIterable = s.decodeReplyFromAsyncIterable;\nexports.decodeAction = s.decodeAction;\nexports.decodeFormState = s.decodeFormState;\nexports.registerServerReference = s.registerServerReference;\nexports.registerClientReference = s.registerClientReference;\nexports.createClientModuleProxy = s.createClientModuleProxy;\nexports.createTemporaryReferenceSet = s.createTemporaryReferenceSet;\n","// This file is generated by next-core EcmascriptClientReferenceModule.\nconst { createClientModuleProxy } = require(\"react-server-dom-turbopack/server\");\n\n__turbopack_context__.n(createClientModuleProxy(\"[project]/Documents/hhkb/ai-scholar-writer/node_modules/next/dist/shared/lib/app-router-context.shared-runtime.js\"));\n","'use client'\n\nimport type {\n  FocusAndScrollRef,\n  PrefetchKind,\n} from '../../client/components/router-reducer/router-reducer-types'\nimport type { Params } from '../../server/request/params'\nimport type {\n  FlightRouterState,\n  FlightSegmentPath,\n  CacheNode,\n} from './app-router-types'\nimport React from 'react'\n\nexport interface NavigateOptions {\n  scroll?: boolean\n}\n\nexport interface PrefetchOptions {\n  kind: PrefetchKind\n  onInvalidate?: () => void\n}\n\nexport interface AppRouterInstance {\n  /**\n   * Navigate to the previous history entry.\n   */\n  back(): void\n  /**\n   * Navigate to the next history entry.\n   */\n  forward(): void\n  /**\n   * Refresh the current page.\n   */\n  refresh(): void\n  /**\n   * Refresh the current page. Use in development only.\n   * @internal\n   */\n  hmrRefresh(): void\n  /**\n   * Navigate to the provided href.\n   * Pushes a new history entry.\n   */\n  push(href: string, options?: NavigateOptions): void\n  /**\n   * Navigate to the provided href.\n   * Replaces the current history entry.\n   */\n  replace(href: string, options?: NavigateOptions): void\n  /**\n   * Prefetch the provided href.\n   */\n  prefetch(href: string, options?: PrefetchOptions): void\n}\n\nexport const AppRouterContext = React.createContext<AppRouterInstance | null>(\n  null\n)\nexport const LayoutRouterContext = React.createContext<{\n  parentTree: FlightRouterState\n  parentCacheNode: CacheNode\n  parentSegmentPath: FlightSegmentPath | null\n  parentParams: Params\n  debugNameContext: string\n  url: string\n  isActive: boolean\n} | null>(null)\n\nexport const GlobalLayoutRouterContext = React.createContext<{\n  tree: FlightRouterState\n  focusAndScrollRef: FocusAndScrollRef\n  nextUrl: string | null\n  previousNextUrl: string | null\n}>(null as any)\n\nexport const TemplateContext = React.createContext<React.ReactNode>(null as any)\n\nif (process.env.NODE_ENV !== 'production') {\n  AppRouterContext.displayName = 'AppRouterContext'\n  LayoutRouterContext.displayName = 'LayoutRouterContext'\n  GlobalLayoutRouterContext.displayName = 'GlobalLayoutRouterContext'\n  TemplateContext.displayName = 'TemplateContext'\n}\n\nexport const MissingSlotContext = React.createContext<Set<string>>(new Set())\n","import { pathHasPrefix } from '../router/utils/path-has-prefix';\n/**\n * strip _next/data/<build-id>/ prefix and .json suffix\n */ export function normalizeDataPath(pathname) {\n    if (!pathHasPrefix(pathname || '/', '/_next/data')) {\n        return pathname;\n    }\n    pathname = pathname.replace(/\\/_next\\/data\\/[^/]{1,}/, '').replace(/\\.json$/, '');\n    if (pathname === '/index') {\n        return '/';\n    }\n    return pathname;\n}\n\n//# sourceMappingURL=normalize-data-path.js.map","import { NEXT_URL } from '../client/components/app-router-headers';\nimport { extractInterceptionRouteInformation, isInterceptionRouteAppPath } from '../shared/lib/router/utils/interception-routes';\nimport { getNamedRouteRegex } from '../shared/lib/router/utils/route-regex';\nexport function generateInterceptionRoutesRewrites(appPaths, basePath = '') {\n    const rewrites = [];\n    for (const appPath of appPaths){\n        if (isInterceptionRouteAppPath(appPath)) {\n            const { interceptingRoute, interceptedRoute } = extractInterceptionRouteInformation(appPath);\n            const destination = getNamedRouteRegex(basePath + appPath, {\n                prefixRouteKeys: true\n            });\n            const header = getNamedRouteRegex(interceptingRoute, {\n                prefixRouteKeys: true,\n                reference: destination.reference\n            });\n            const source = getNamedRouteRegex(basePath + interceptedRoute, {\n                prefixRouteKeys: true,\n                reference: header.reference\n            });\n            const headerRegex = header.namedRegex// Strip ^ and $ anchors since matchHas() will add them automatically\n            .replace(/^\\^/, '').replace(/\\$$/, '')// Replace matching the `/` with matching any route segment.\n            .replace(/^\\/\\(\\?:\\/\\)\\?$/, '/.*')// Replace the optional trailing with slash capture group with one that\n            // will match any descendants.\n            .replace(/\\(\\?:\\/\\)\\?$/, '(?:/.*)?');\n            rewrites.push({\n                source: source.pathToRegexpPattern,\n                destination: destination.pathToRegexpPattern,\n                has: [\n                    {\n                        type: 'header',\n                        key: NEXT_URL,\n                        value: headerRegex\n                    }\n                ],\n                regex: source.namedRegex\n            });\n        }\n    }\n    return rewrites;\n}\nexport function isInterceptionRouteRewrite(route) {\n    var _route_has_, _route_has;\n    // When we generate interception rewrites in the above implementation, we always do so with only a single `has` condition.\n    return ((_route_has = route.has) == null ? void 0 : (_route_has_ = _route_has[0]) == null ? void 0 : _route_has_.key) === NEXT_URL;\n}\n\n//# sourceMappingURL=generate-interception-routes-rewrites.js.map","import stringHash from 'next/dist/compiled/string-hash';\nimport { formatServerError } from '../../lib/format-server-error';\nimport { SpanStatusCode, getTracer } from '../lib/trace/tracer';\nimport { isAbortError } from '../pipe-readable';\nimport { isBailoutToCSRError } from '../../shared/lib/lazy-dynamic/bailout-to-csr';\nimport { isDynamicServerError } from '../../client/components/hooks-server-context';\nimport { isNextRouterError } from '../../client/components/is-next-router-error';\nimport { isPrerenderInterruptedError } from './dynamic-rendering';\nimport { getProperError } from '../../lib/is-error';\nimport { createDigestWithErrorCode } from '../../lib/error-telemetry-utils';\nimport { isReactLargeShellError } from './react-large-shell-error';\n/**\n * Returns a digest for well-known Next.js errors, otherwise `undefined`. If a\n * digest is returned this also means that the error does not need to be\n * reported.\n */ export function getDigestForWellKnownError(error) {\n    // If we're bailing out to CSR, we don't need to log the error.\n    if (isBailoutToCSRError(error)) return error.digest;\n    // If this is a navigation error, we don't need to log the error.\n    if (isNextRouterError(error)) return error.digest;\n    // If this error occurs, we know that we should be stopping the static\n    // render. This is only thrown in static generation when PPR is not enabled,\n    // which causes the whole page to be marked as dynamic. We don't need to\n    // tell the user about this error, as it's not actionable.\n    if (isDynamicServerError(error)) return error.digest;\n    // If this is a prerender interrupted error, we don't need to log the error.\n    if (isPrerenderInterruptedError(error)) return error.digest;\n    return undefined;\n}\nexport function createReactServerErrorHandler(shouldFormatError, isNextExport, reactServerErrors, onReactServerRenderError, spanToRecordOn) {\n    return (thrownValue)=>{\n        var _err_message;\n        if (typeof thrownValue === 'string') {\n            // TODO-APP: look at using webcrypto instead. Requires a promise to be awaited.\n            return stringHash(thrownValue).toString();\n        }\n        // If the response was closed, we don't need to log the error.\n        if (isAbortError(thrownValue)) return;\n        const digest = getDigestForWellKnownError(thrownValue);\n        if (digest) {\n            return digest;\n        }\n        if (isReactLargeShellError(thrownValue)) {\n            // TODO: Aggregate\n            console.error(thrownValue);\n            return undefined;\n        }\n        let err = getProperError(thrownValue);\n        let silenceLog = false;\n        // If the error already has a digest, respect the original digest,\n        // so it won't get re-generated into another new error.\n        if (err.digest) {\n            if (process.env.NODE_ENV === 'production' && reactServerErrors.has(err.digest)) {\n                // This error is likely an obfuscated error from another react-server\n                // environment (e.g. 'use cache'). We recover the original error here\n                // for reporting purposes.\n                err = reactServerErrors.get(err.digest);\n                // We don't log it again though, as it was already logged in the\n                // original environment.\n                silenceLog = true;\n            } else {\n            // Either we're in development (where we want to keep the transported\n            // error with environmentName), or the error is not in reactServerErrors\n            // but has a digest from other means. Keep the error as-is.\n            }\n        } else {\n            err.digest = createDigestWithErrorCode(err, // TODO-APP: look at using webcrypto instead. Requires a promise to be awaited.\n            stringHash(err.message + (err.stack || '')).toString());\n        }\n        // @TODO by putting this here and not at the top it is possible that\n        // we don't error the build in places we actually expect to\n        if (!reactServerErrors.has(err.digest)) {\n            reactServerErrors.set(err.digest, err);\n        }\n        // Format server errors in development to add more helpful error messages\n        if (shouldFormatError) {\n            formatServerError(err);\n        }\n        // Don't log the suppressed error during export\n        if (!(isNextExport && (err == null ? void 0 : (_err_message = err.message) == null ? void 0 : _err_message.includes('The specific message is omitted in production builds to avoid leaking sensitive details.')))) {\n            // Record exception on the provided span if available, otherwise try active span.\n            const span = spanToRecordOn ?? getTracer().getActiveScopeSpan();\n            if (span) {\n                span.recordException(err);\n                span.setAttribute('error.type', err.name);\n                span.setStatus({\n                    code: SpanStatusCode.ERROR,\n                    message: err.message\n                });\n            }\n            onReactServerRenderError(err, silenceLog);\n        }\n        return err.digest;\n    };\n}\nexport function createHTMLErrorHandler(shouldFormatError, isNextExport, reactServerErrors, allCapturedErrors, onHTMLRenderSSRError, spanToRecordOn) {\n    return (thrownValue, errorInfo)=>{\n        var _err_message;\n        if (isReactLargeShellError(thrownValue)) {\n            // TODO: Aggregate\n            console.error(thrownValue);\n            return undefined;\n        }\n        let isSSRError = true;\n        allCapturedErrors.push(thrownValue);\n        // If the response was closed, we don't need to log the error.\n        if (isAbortError(thrownValue)) return;\n        const digest = getDigestForWellKnownError(thrownValue);\n        if (digest) {\n            return digest;\n        }\n        const err = getProperError(thrownValue);\n        // If the error already has a digest, respect the original digest,\n        // so it won't get re-generated into another new error.\n        if (err.digest) {\n            if (reactServerErrors.has(err.digest)) {\n                // This error is likely an obfuscated error from react-server.\n                // We recover the original error here.\n                thrownValue = reactServerErrors.get(err.digest);\n                isSSRError = false;\n            } else {\n            // The error is not from react-server but has a digest\n            // from other means so we don't need to produce a new one\n            }\n        } else {\n            err.digest = createDigestWithErrorCode(err, stringHash(err.message + ((errorInfo == null ? void 0 : errorInfo.componentStack) || err.stack || '')).toString());\n        }\n        // Format server errors in development to add more helpful error messages\n        if (shouldFormatError) {\n            formatServerError(err);\n        }\n        // Don't log the suppressed error during export\n        if (!(isNextExport && (err == null ? void 0 : (_err_message = err.message) == null ? void 0 : _err_message.includes('The specific message is omitted in production builds to avoid leaking sensitive details.')))) {\n            // HTML errors contain RSC errors as well, filter them out before reporting\n            if (isSSRError) {\n                // Record exception on the provided span if available, otherwise try active span.\n                const span = spanToRecordOn ?? getTracer().getActiveScopeSpan();\n                if (span) {\n                    span.recordException(err);\n                    span.setAttribute('error.type', err.name);\n                    span.setStatus({\n                        code: SpanStatusCode.ERROR,\n                        message: err.message\n                    });\n                }\n                onHTMLRenderSSRError(err, errorInfo);\n            }\n        }\n        return err.digest;\n    };\n}\nexport function isUserLandError(err) {\n    return !isAbortError(err) && !isBailoutToCSRError(err) && !isNextRouterError(err);\n}\n\n//# sourceMappingURL=create-error-handler.js.map","const invalidServerComponentReactHooks = [\n    'useDeferredValue',\n    'useEffect',\n    'useImperativeHandle',\n    'useInsertionEffect',\n    'useLayoutEffect',\n    'useReducer',\n    'useRef',\n    'useState',\n    'useSyncExternalStore',\n    'useTransition',\n    'experimental_useOptimistic',\n    'useOptimistic'\n];\nfunction setMessage(error, message) {\n    error.message = message;\n    if (error.stack) {\n        const lines = error.stack.split('\\n');\n        lines[0] = message;\n        error.stack = lines.join('\\n');\n    }\n}\n/**\n * Input:\n * Error: Something went wrong\n    at funcName (/path/to/file.js:10:5)\n    at anotherFunc (/path/to/file.js:15:10)\n \n * Output:\n    at funcName (/path/to/file.js:10:5)\n    at anotherFunc (/path/to/file.js:15:10) \n */ export function getStackWithoutErrorMessage(error) {\n    const stack = error.stack;\n    if (!stack) return '';\n    return stack.replace(/^[^\\n]*\\n/, '');\n}\nexport function formatServerError(error) {\n    if (typeof (error == null ? void 0 : error.message) !== 'string') return;\n    if (error.message.includes('Class extends value undefined is not a constructor or null')) {\n        const addedMessage = 'This might be caused by a React Class Component being rendered in a Server Component, React Class Components only works in Client Components. Read more: https://nextjs.org/docs/messages/class-component-in-server-component';\n        // If this error instance already has the message, don't add it again\n        if (error.message.includes(addedMessage)) return;\n        setMessage(error, `${error.message}\n\n${addedMessage}`);\n        return;\n    }\n    if (error.message.includes('createContext is not a function')) {\n        setMessage(error, 'createContext only works in Client Components. Add the \"use client\" directive at the top of the file to use it. Read more: https://nextjs.org/docs/messages/context-in-server-component');\n        return;\n    }\n    for (const clientHook of invalidServerComponentReactHooks){\n        const regex = new RegExp(`\\\\b${clientHook}\\\\b.*is not a function`);\n        if (regex.test(error.message)) {\n            setMessage(error, `${clientHook} only works in Client Components. Add the \"use client\" directive at the top of the file to use it. Read more: https://nextjs.org/docs/messages/react-client-hook-in-server-component`);\n            return;\n        }\n    }\n}\n\n//# sourceMappingURL=format-server-error.js.map","import { RedirectStatusCode } from './redirect-status-code';\nexport const REDIRECT_ERROR_CODE = 'NEXT_REDIRECT';\nexport var RedirectType = /*#__PURE__*/ function(RedirectType) {\n    RedirectType[\"push\"] = \"push\";\n    RedirectType[\"replace\"] = \"replace\";\n    return RedirectType;\n}({});\n/**\n * Checks an error to determine if it's an error generated by the\n * `redirect(url)` helper.\n *\n * @param error the error that may reference a redirect error\n * @returns true if the error is a redirect error\n */ export function isRedirectError(error) {\n    if (typeof error !== 'object' || error === null || !('digest' in error) || typeof error.digest !== 'string') {\n        return false;\n    }\n    const digest = error.digest.split(';');\n    const [errorCode, type] = digest;\n    const destination = digest.slice(2, -2).join(';');\n    const status = digest.at(-2);\n    const statusCode = Number(status);\n    return errorCode === REDIRECT_ERROR_CODE && (type === 'replace' || type === 'push') && typeof destination === 'string' && !isNaN(statusCode) && statusCode in RedirectStatusCode;\n}\n\n//# sourceMappingURL=redirect-error.js.map","const ERROR_CODE_DELIMITER = '@';\n/**\n * Augments the digest field of errors thrown in React Server Components (RSC) with an error code.\n * Since RSC errors can only be serialized through the digest field, this provides a way to include\n * an additional error code that can be extracted client-side via `extractNextErrorCode`.\n *\n * The error code is appended to the digest string with a semicolon separator, allowing it to be\n * parsed out later while preserving the original digest value.\n */ export const createDigestWithErrorCode = (thrownValue, originalDigest)=>{\n    if (typeof thrownValue === 'object' && thrownValue !== null && '__NEXT_ERROR_CODE' in thrownValue) {\n        return `${originalDigest}${ERROR_CODE_DELIMITER}${thrownValue.__NEXT_ERROR_CODE}`;\n    }\n    return originalDigest;\n};\nexport const extractNextErrorCode = (error)=>{\n    if (typeof error === 'object' && error !== null && '__NEXT_ERROR_CODE' in error && typeof error.__NEXT_ERROR_CODE === 'string') {\n        return error.__NEXT_ERROR_CODE;\n    }\n    if (typeof error === 'object' && error !== null && 'digest' in error && typeof error.digest === 'string') {\n        const segments = error.digest.split(ERROR_CODE_DELIMITER);\n        const errorCode = segments.find((segment)=>segment.startsWith('E'));\n        return errorCode;\n    }\n    return undefined;\n};\n\n//# sourceMappingURL=error-telemetry-utils.js.map","// the name of the export has to be the camelCase version of the file name (without the extension)\n// TODO: remove this. We need it because using notFound from next/navigation imports this file :(\nexport * as appRouterContext from '../../../shared/lib/app-router-context.shared-runtime';\n\n//# sourceMappingURL=shared-modules.js.map","/**\n * This class is used to detect when all cache reads for a given render are settled.\n * We do this to allow for cache warming the prerender without having to continue rendering\n * the remainder of the page. This feature is really only useful when the cacheComponents flag is on\n * and should only be used in codepaths gated with this feature.\n */ import { InvariantError } from '../../shared/lib/invariant-error';\nexport class CacheSignal {\n    constructor(){\n        this.count = 0;\n        this.earlyListeners = [];\n        this.listeners = [];\n        this.tickPending = false;\n        this.pendingTimeoutCleanup = null;\n        this.subscribedSignals = null;\n        this.invokeListenersIfNoPendingReads = ()=>{\n            this.pendingTimeoutCleanup = null;\n            if (this.count === 0) {\n                for(let i = 0; i < this.listeners.length; i++){\n                    this.listeners[i]();\n                }\n                this.listeners.length = 0;\n            }\n        };\n        if (process.env.NEXT_RUNTIME === 'edge') {\n            // we rely on `process.nextTick`, which is not supported in edge\n            throw Object.defineProperty(new InvariantError('CacheSignal cannot be used in the edge runtime, because `cacheComponents` does not support it.'), \"__NEXT_ERROR_CODE\", {\n                value: \"E728\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n    noMorePendingCaches() {\n        if (!this.tickPending) {\n            this.tickPending = true;\n            queueMicrotask(()=>process.nextTick(()=>{\n                    this.tickPending = false;\n                    if (this.count === 0) {\n                        for(let i = 0; i < this.earlyListeners.length; i++){\n                            this.earlyListeners[i]();\n                        }\n                        this.earlyListeners.length = 0;\n                    }\n                }));\n        }\n        // After a cache resolves, React will schedule new rendering work:\n        // - in a microtask (when prerendering)\n        // - in setImmediate (when rendering)\n        // To cover both of these, we have to make sure that we let immediates execute at least once after each cache resolved.\n        // We don't know when the pending timeout was scheduled (and if it's about to resolve),\n        // so by scheduling a new one, we can be sure that we'll go around the event loop at least once.\n        if (this.pendingTimeoutCleanup) {\n            // We cancel the timeout in beginRead, so this shouldn't ever be active here,\n            // but we still cancel it defensively.\n            this.pendingTimeoutCleanup();\n        }\n        this.pendingTimeoutCleanup = scheduleImmediateAndTimeoutWithCleanup(this.invokeListenersIfNoPendingReads);\n    }\n    /**\n   * This promise waits until there are no more in progress cache reads but no later.\n   * This allows for adding more cache reads after to delay cacheReady.\n   */ inputReady() {\n        return new Promise((resolve)=>{\n            this.earlyListeners.push(resolve);\n            if (this.count === 0) {\n                this.noMorePendingCaches();\n            }\n        });\n    }\n    /**\n   * If there are inflight cache reads this Promise can resolve in a microtask however\n   * if there are no inflight cache reads then we wait at least one task to allow initial\n   * cache reads to be initiated.\n   */ cacheReady() {\n        return new Promise((resolve)=>{\n            this.listeners.push(resolve);\n            if (this.count === 0) {\n                this.noMorePendingCaches();\n            }\n        });\n    }\n    beginRead() {\n        this.count++;\n        // There's a new pending cache, so if there's a `noMorePendingCaches` timeout running,\n        // we should cancel it.\n        if (this.pendingTimeoutCleanup) {\n            this.pendingTimeoutCleanup();\n            this.pendingTimeoutCleanup = null;\n        }\n        if (this.subscribedSignals !== null) {\n            for (const subscriber of this.subscribedSignals){\n                subscriber.beginRead();\n            }\n        }\n    }\n    endRead() {\n        if (this.count === 0) {\n            throw Object.defineProperty(new InvariantError('CacheSignal got more endRead() calls than beginRead() calls'), \"__NEXT_ERROR_CODE\", {\n                value: \"E678\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        // If this is the last read we need to wait a task before we can claim the cache is settled.\n        // The cache read will likely ping a Server Component which can read from the cache again and this\n        // will play out in a microtask so we need to only resolve pending listeners if we're still at 0\n        // after at least one task.\n        // We only want one task scheduled at a time so when we hit count 1 we don't decrement the counter immediately.\n        // If intervening reads happen before the scheduled task runs they will never observe count 1 preventing reentrency\n        this.count--;\n        if (this.count === 0) {\n            this.noMorePendingCaches();\n        }\n        if (this.subscribedSignals !== null) {\n            for (const subscriber of this.subscribedSignals){\n                subscriber.endRead();\n            }\n        }\n    }\n    hasPendingReads() {\n        return this.count > 0;\n    }\n    trackRead(promise) {\n        this.beginRead();\n        // `promise.finally()` still rejects, so don't use it here to avoid unhandled rejections\n        const onFinally = this.endRead.bind(this);\n        promise.then(onFinally, onFinally);\n        return promise;\n    }\n    subscribeToReads(subscriber) {\n        if (subscriber === this) {\n            throw Object.defineProperty(new InvariantError('A CacheSignal cannot subscribe to itself'), \"__NEXT_ERROR_CODE\", {\n                value: \"E679\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        if (this.subscribedSignals === null) {\n            this.subscribedSignals = new Set();\n        }\n        this.subscribedSignals.add(subscriber);\n        // we'll notify the subscriber of each endRead() on this signal,\n        // so we need to give it a corresponding beginRead() for each read we have in flight now.\n        for(let i = 0; i < this.count; i++){\n            subscriber.beginRead();\n        }\n        return this.unsubscribeFromReads.bind(this, subscriber);\n    }\n    unsubscribeFromReads(subscriber) {\n        if (!this.subscribedSignals) {\n            return;\n        }\n        this.subscribedSignals.delete(subscriber);\n    // we don't need to set the set back to `null` if it's empty --\n    // if other signals are subscribing to this one, it'll likely get more subscriptions later,\n    // so we'd have to allocate a fresh set again when that happens.\n    }\n}\nfunction scheduleImmediateAndTimeoutWithCleanup(cb) {\n    // If we decide to clean up the timeout, we want to remove\n    // either the immediate or the timeout, whichever is still pending.\n    let clearPending;\n    const immediate = setImmediate(()=>{\n        const timeout = setTimeout(cb, 0);\n        clearPending = clearTimeout.bind(null, timeout);\n    });\n    clearPending = clearImmediate.bind(null, immediate);\n    return ()=>clearPending();\n}\n\n//# sourceMappingURL=cache-signal.js.map","// This regex will have fast negatives meaning valid identifiers may not pass\n// this test. However this is only used during static generation to provide hints\n// about why a page bailed out of some or all prerendering and we can use bracket notation\n// for example while `_` is a valid identifier it's ok to print `searchParams['_']`\n// even if this would have been fine too `searchParams._`\nconst isDefinitelyAValidIdentifier = /^[A-Za-z_$][A-Za-z0-9_$]*$/;\nexport function describeStringPropertyAccess(target, prop) {\n    if (isDefinitelyAValidIdentifier.test(prop)) {\n        return `\\`${target}.${prop}\\``;\n    }\n    return `\\`${target}[${JSON.stringify(prop)}]\\``;\n}\nexport function describeHasCheckingStringProperty(target, prop) {\n    const stringifiedProp = JSON.stringify(prop);\n    return `\\`Reflect.has(${target}, ${stringifiedProp})\\`, \\`${stringifiedProp} in ${target}\\`, or similar`;\n}\nexport const wellKnownProperties = new Set([\n    'hasOwnProperty',\n    'isPrototypeOf',\n    'propertyIsEnumerable',\n    'toString',\n    'valueOf',\n    'toLocaleString',\n    // Promise prototype\n    'then',\n    'catch',\n    'finally',\n    // React Promise extension\n    'status',\n    // 'value',\n    // 'error',\n    // React introspection\n    'displayName',\n    '_debugInfo',\n    // Common tested properties\n    'toJSON',\n    '$$typeof',\n    '__esModule'\n]);\n\n//# sourceMappingURL=reflect-utils.js.map","import * as React from 'react';\nconst errorRef = {\n    current: null\n};\n// React.cache is currently only available in canary/experimental React channels.\nconst cache = typeof React.cache === 'function' ? React.cache : (fn)=>fn;\n// When Cache Components is enabled, we record these as errors so that they\n// are captured by the dev overlay as it's more critical to fix these\n// when enabled.\nconst logErrorOrWarn = process.env.__NEXT_CACHE_COMPONENTS ? console.error : console.warn;\n// We don't want to dedupe across requests.\n// The developer might've just attempted to fix the warning so we should warn again if it still happens.\nconst flushCurrentErrorIfNew = cache(// eslint-disable-next-line @typescript-eslint/no-unused-vars -- cache key\n(key)=>{\n    try {\n        logErrorOrWarn(errorRef.current);\n    } finally{\n        errorRef.current = null;\n    }\n});\n/**\n * Creates a function that logs an error message that is deduped by the userland\n * callsite.\n * This requires no indirection between the call of this function and the userland\n * callsite i.e. there's only a single library frame above this.\n * Do not use on the Client where sourcemaps and ignore listing might be enabled.\n * Only use that for warnings need a fix independent of the callstack.\n *\n * @param getMessage\n * @returns\n */ export function createDedupedByCallsiteServerErrorLoggerDev(getMessage) {\n    return function logDedupedError(...args) {\n        const message = getMessage(...args);\n        if (process.env.NODE_ENV !== 'production') {\n            var _stack;\n            const callStackFrames = (_stack = new Error().stack) == null ? void 0 : _stack.split('\\n');\n            if (callStackFrames === undefined || callStackFrames.length < 4) {\n                logErrorOrWarn(message);\n            } else {\n                // Error:\n                //   logDedupedError\n                //   asyncApiBeingAccessedSynchronously\n                //   <userland callsite>\n                // TODO: This breaks if sourcemaps with ignore lists are enabled.\n                const key = callStackFrames[4];\n                errorRef.current = message;\n                flushCurrentErrorIfNew(key);\n            }\n        } else {\n            logErrorOrWarn(message);\n        }\n    };\n}\n\n//# sourceMappingURL=create-deduped-by-callsite-server-error-logger.js.map","import { createAsyncLocalStorage } from './async-local-storage';\nexport const dynamicAccessAsyncStorageInstance = createAsyncLocalStorage();\n\n//# sourceMappingURL=dynamic-access-async-storage-instance.js.map","import MODERN_BROWSERSLIST_TARGET from './modern-browserslist-target';\nexport { MODERN_BROWSERSLIST_TARGET };\nexport const COMPILER_NAMES = {\n    client: 'client',\n    server: 'server',\n    edgeServer: 'edge-server'\n};\nexport const COMPILER_INDEXES = {\n    [COMPILER_NAMES.client]: 0,\n    [COMPILER_NAMES.server]: 1,\n    [COMPILER_NAMES.edgeServer]: 2\n};\n// Re-export entry constants for backward compatibility\nexport { UNDERSCORE_NOT_FOUND_ROUTE, UNDERSCORE_NOT_FOUND_ROUTE_ENTRY, UNDERSCORE_GLOBAL_ERROR_ROUTE, UNDERSCORE_GLOBAL_ERROR_ROUTE_ENTRY } from './entry-constants';\nexport var AdapterOutputType = /*#__PURE__*/ function(AdapterOutputType) {\n    /**\n   * `PAGES` represents all the React pages that are under `pages/`.\n   */ AdapterOutputType[\"PAGES\"] = \"PAGES\";\n    /**\n   * `PAGES_API` represents all the API routes under `pages/api/`.\n   */ AdapterOutputType[\"PAGES_API\"] = \"PAGES_API\";\n    /**\n   * `APP_PAGE` represents all the React pages that are under `app/` with the\n   * filename of `page.{j,t}s{,x}`.\n   */ AdapterOutputType[\"APP_PAGE\"] = \"APP_PAGE\";\n    /**\n   * `APP_ROUTE` represents all the API routes and metadata routes that are under `app/` with the\n   * filename of `route.{j,t}s{,x}`.\n   */ AdapterOutputType[\"APP_ROUTE\"] = \"APP_ROUTE\";\n    /**\n   * `PRERENDER` represents an ISR enabled route that might\n   * have a seeded cache entry or fallback generated during build\n   */ AdapterOutputType[\"PRERENDER\"] = \"PRERENDER\";\n    /**\n   * `STATIC_FILE` represents a static file (ie /_next/static)\n   */ AdapterOutputType[\"STATIC_FILE\"] = \"STATIC_FILE\";\n    /**\n   * `MIDDLEWARE` represents the middleware output if present\n   */ AdapterOutputType[\"MIDDLEWARE\"] = \"MIDDLEWARE\";\n    return AdapterOutputType;\n}({});\nexport const PHASE_EXPORT = 'phase-export';\nexport const PHASE_ANALYZE = 'phase-analyze';\nexport const PHASE_PRODUCTION_BUILD = 'phase-production-build';\nexport const PHASE_PRODUCTION_SERVER = 'phase-production-server';\nexport const PHASE_DEVELOPMENT_SERVER = 'phase-development-server';\nexport const PHASE_TEST = 'phase-test';\nexport const PHASE_INFO = 'phase-info';\nexport const PAGES_MANIFEST = 'pages-manifest.json';\nexport const WEBPACK_STATS = 'webpack-stats.json';\nexport const APP_PATHS_MANIFEST = 'app-paths-manifest.json';\nexport const APP_PATH_ROUTES_MANIFEST = 'app-path-routes-manifest.json';\nexport const BUILD_MANIFEST = 'build-manifest.json';\nexport const FUNCTIONS_CONFIG_MANIFEST = 'functions-config-manifest.json';\nexport const SUBRESOURCE_INTEGRITY_MANIFEST = 'subresource-integrity-manifest';\nexport const NEXT_FONT_MANIFEST = 'next-font-manifest';\nexport const EXPORT_MARKER = 'export-marker.json';\nexport const EXPORT_DETAIL = 'export-detail.json';\nexport const PRERENDER_MANIFEST = 'prerender-manifest.json';\nexport const ROUTES_MANIFEST = 'routes-manifest.json';\nexport const IMAGES_MANIFEST = 'images-manifest.json';\nexport const SERVER_FILES_MANIFEST = 'required-server-files';\nexport const DEV_CLIENT_PAGES_MANIFEST = '_devPagesManifest.json';\nexport const MIDDLEWARE_MANIFEST = 'middleware-manifest.json';\nexport const TURBOPACK_CLIENT_MIDDLEWARE_MANIFEST = '_clientMiddlewareManifest.json';\nexport const TURBOPACK_CLIENT_BUILD_MANIFEST = 'client-build-manifest.json';\nexport const DEV_CLIENT_MIDDLEWARE_MANIFEST = '_devMiddlewareManifest.json';\nexport const REACT_LOADABLE_MANIFEST = 'react-loadable-manifest.json';\nexport const SERVER_DIRECTORY = 'server';\nexport const CONFIG_FILES = [\n    'next.config.js',\n    'next.config.mjs',\n    'next.config.ts',\n    // process.features can be undefined on Edge runtime\n    // TODO: Remove `as any` once we bump @types/node to v22.10.0+\n    ...process?.features?.typescript ? [\n        'next.config.mts'\n    ] : []\n];\nexport const BUILD_ID_FILE = 'BUILD_ID';\nexport const BLOCKED_PAGES = [\n    '/_document',\n    '/_app',\n    '/_error'\n];\nexport const CLIENT_PUBLIC_FILES_PATH = 'public';\nexport const CLIENT_STATIC_FILES_PATH = 'static';\nexport const STRING_LITERAL_DROP_BUNDLE = '__NEXT_DROP_CLIENT_FILE__';\nexport const NEXT_BUILTIN_DOCUMENT = '__NEXT_BUILTIN_DOCUMENT__';\nexport const BARREL_OPTIMIZATION_PREFIX = '__barrel_optimize__';\n// server/[entry]/page_client-reference-manifest.js\nexport const CLIENT_REFERENCE_MANIFEST = 'client-reference-manifest';\n// server/server-reference-manifest\nexport const SERVER_REFERENCE_MANIFEST = 'server-reference-manifest';\n// server/middleware-build-manifest.js\nexport const MIDDLEWARE_BUILD_MANIFEST = 'middleware-build-manifest';\n// server/middleware-react-loadable-manifest.js\nexport const MIDDLEWARE_REACT_LOADABLE_MANIFEST = 'middleware-react-loadable-manifest';\n// server/interception-route-rewrite-manifest.js\nexport const INTERCEPTION_ROUTE_REWRITE_MANIFEST = 'interception-route-rewrite-manifest';\n// server/dynamic-css-manifest.js\nexport const DYNAMIC_CSS_MANIFEST = 'dynamic-css-manifest';\n// static/runtime/main.js\nexport const CLIENT_STATIC_FILES_RUNTIME_MAIN = `main`;\nexport const CLIENT_STATIC_FILES_RUNTIME_MAIN_APP = `${CLIENT_STATIC_FILES_RUNTIME_MAIN}-app`;\n// next internal client components chunk for layouts\nexport const APP_CLIENT_INTERNALS = 'app-pages-internals';\n// static/runtime/react-refresh.js\nexport const CLIENT_STATIC_FILES_RUNTIME_REACT_REFRESH = `react-refresh`;\n// static/runtime/webpack.js\nexport const CLIENT_STATIC_FILES_RUNTIME_WEBPACK = `webpack`;\n// static/runtime/polyfills.js\nexport const CLIENT_STATIC_FILES_RUNTIME_POLYFILLS = 'polyfills';\nexport const CLIENT_STATIC_FILES_RUNTIME_POLYFILLS_SYMBOL = Symbol(CLIENT_STATIC_FILES_RUNTIME_POLYFILLS);\nexport const DEFAULT_RUNTIME_WEBPACK = 'webpack-runtime';\nexport const EDGE_RUNTIME_WEBPACK = 'edge-runtime-webpack';\nexport const STATIC_PROPS_ID = '__N_SSG';\nexport const SERVER_PROPS_ID = '__N_SSP';\nexport const DEFAULT_SERIF_FONT = {\n    name: 'Times New Roman',\n    xAvgCharWidth: 821,\n    azAvgWidth: 854.3953488372093,\n    unitsPerEm: 2048\n};\nexport const DEFAULT_SANS_SERIF_FONT = {\n    name: 'Arial',\n    xAvgCharWidth: 904,\n    azAvgWidth: 934.5116279069767,\n    unitsPerEm: 2048\n};\nexport const STATIC_STATUS_PAGES = [\n    '/500'\n];\nexport const TRACE_OUTPUT_VERSION = 1;\n// in `MB`\nexport const TURBO_TRACE_DEFAULT_MEMORY_LIMIT = 6000;\nexport const RSC_MODULE_TYPES = {\n    client: 'client',\n    server: 'server'\n};\n// comparing\n// https://nextjs.org/docs/api-reference/edge-runtime\n// with\n// https://nodejs.org/docs/latest/api/globals.html\nexport const EDGE_UNSUPPORTED_NODE_APIS = [\n    'clearImmediate',\n    'setImmediate',\n    'BroadcastChannel',\n    'ByteLengthQueuingStrategy',\n    'CompressionStream',\n    'CountQueuingStrategy',\n    'DecompressionStream',\n    'DomException',\n    'MessageChannel',\n    'MessageEvent',\n    'MessagePort',\n    'ReadableByteStreamController',\n    'ReadableStreamBYOBRequest',\n    'ReadableStreamDefaultController',\n    'TransformStreamDefaultController',\n    'WritableStreamDefaultController'\n];\nexport const SYSTEM_ENTRYPOINTS = new Set([\n    CLIENT_STATIC_FILES_RUNTIME_MAIN,\n    CLIENT_STATIC_FILES_RUNTIME_REACT_REFRESH,\n    CLIENT_STATIC_FILES_RUNTIME_MAIN_APP\n]);\n\n//# sourceMappingURL=constants.js.map","export function isAppRouteRoute(route) {\n    return route.endsWith('/route');\n}\n\n//# sourceMappingURL=is-app-route-route.js.map","export const UNDERSCORE_NOT_FOUND_ROUTE = '/_not-found';\nexport const UNDERSCORE_NOT_FOUND_ROUTE_ENTRY = `${UNDERSCORE_NOT_FOUND_ROUTE}/page`;\nexport const UNDERSCORE_GLOBAL_ERROR_ROUTE = '/_global-error';\nexport const UNDERSCORE_GLOBAL_ERROR_ROUTE_ENTRY = `${UNDERSCORE_GLOBAL_ERROR_ROUTE}/page`;\n\n//# sourceMappingURL=entry-constants.js.map","export const RouterServerContextSymbol = Symbol.for('@next/router-server-methods');\nexport const routerServerGlobal = globalThis;\n\n//# sourceMappingURL=router-server-context.js.map","export const HTTPAccessErrorStatus = {\n    NOT_FOUND: 404,\n    FORBIDDEN: 403,\n    UNAUTHORIZED: 401\n};\nconst ALLOWED_CODES = new Set(Object.values(HTTPAccessErrorStatus));\nexport const HTTP_ERROR_FALLBACK_ERROR_CODE = 'NEXT_HTTP_ERROR_FALLBACK';\n/**\n * Checks an error to determine if it's an error generated by\n * the HTTP navigation APIs `notFound()`, `forbidden()` or `unauthorized()`.\n *\n * @param error the error that may reference a HTTP access error\n * @returns true if the error is a HTTP access error\n */ export function isHTTPAccessFallbackError(error) {\n    if (typeof error !== 'object' || error === null || !('digest' in error) || typeof error.digest !== 'string') {\n        return false;\n    }\n    const [prefix, httpStatus] = error.digest.split(';');\n    return prefix === HTTP_ERROR_FALLBACK_ERROR_CODE && ALLOWED_CODES.has(Number(httpStatus));\n}\nexport function getAccessFallbackHTTPStatus(error) {\n    const httpStatus = error.digest.split(';')[1];\n    return Number(httpStatus);\n}\nexport function getAccessFallbackErrorTypeByStatus(status) {\n    switch(status){\n        case 401:\n            return 'unauthorized';\n        case 403:\n            return 'forbidden';\n        case 404:\n            return 'not-found';\n        default:\n            return;\n    }\n}\n\n//# sourceMappingURL=http-access-fallback.js.map","export function getObjectClassLabel(value) {\n    return Object.prototype.toString.call(value);\n}\nexport function isPlainObject(value) {\n    if (getObjectClassLabel(value) !== '[object Object]') {\n        return false;\n    }\n    const prototype = Object.getPrototypeOf(value);\n    /**\n   * this used to be previously:\n   *\n   * `return prototype === null || prototype === Object.prototype`\n   *\n   * but Edge Runtime expose Object from vm, being that kind of type-checking wrongly fail.\n   *\n   * It was changed to the current implementation since it's resilient to serialization.\n   */ return prototype === null || prototype.hasOwnProperty('isPrototypeOf');\n}\n\n//# sourceMappingURL=is-plain-object.js.map","export const DYNAMIC_EXPIRE = 300 // 5 minutes\n;\nexport const RUNTIME_PREFETCH_DYNAMIC_STALE = 30 // 30 seconds\n;\n\n//# sourceMappingURL=constants.js.map","import { InvariantError } from '../../shared/lib/invariant-error';\nimport { getServerActionsManifest } from './manifests-singleton';\nlet __next_loaded_action_key;\nexport function arrayBufferToString(buffer) {\n    const bytes = new Uint8Array(buffer);\n    const len = bytes.byteLength;\n    // @anonrig: V8 has a limit of 65535 arguments in a function.\n    // For len < 65535, this is faster.\n    // https://github.com/vercel/next.js/pull/56377#pullrequestreview-1656181623\n    if (len < 65535) {\n        return String.fromCharCode.apply(null, bytes);\n    }\n    let binary = '';\n    for(let i = 0; i < len; i++){\n        binary += String.fromCharCode(bytes[i]);\n    }\n    return binary;\n}\nexport function stringToUint8Array(binary) {\n    const len = binary.length;\n    const arr = new Uint8Array(len);\n    for(let i = 0; i < len; i++){\n        arr[i] = binary.charCodeAt(i);\n    }\n    return arr;\n}\nexport function encrypt(key, iv, data) {\n    return crypto.subtle.encrypt({\n        name: 'AES-GCM',\n        iv\n    }, key, data);\n}\nexport function decrypt(key, iv, data) {\n    return crypto.subtle.decrypt({\n        name: 'AES-GCM',\n        iv\n    }, key, data);\n}\nexport async function getActionEncryptionKey() {\n    if (__next_loaded_action_key) {\n        return __next_loaded_action_key;\n    }\n    const serverActionsManifest = getServerActionsManifest();\n    const rawKey = process.env.NEXT_SERVER_ACTIONS_ENCRYPTION_KEY || serverActionsManifest.encryptionKey;\n    if (rawKey === undefined) {\n        throw Object.defineProperty(new InvariantError('Missing encryption key for Server Actions'), \"__NEXT_ERROR_CODE\", {\n            value: \"E571\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    __next_loaded_action_key = await crypto.subtle.importKey('raw', stringToUint8Array(atob(rawKey)), 'AES-GCM', true, [\n        'encrypt',\n        'decrypt'\n    ]);\n    return __next_loaded_action_key;\n}\n\n//# sourceMappingURL=encryption-utils.js.map","import { RouteModule } from '../route-module';\nimport { createRequestStoreForAPI } from '../../async-storage/request-store';\nimport { createWorkStore } from '../../async-storage/work-store';\nimport { HTTP_METHODS, isHTTPMethod } from '../../web/http';\nimport { getImplicitTags } from '../../lib/implicit-tags';\nimport { patchFetch } from '../../lib/patch-fetch';\nimport { getTracer } from '../../lib/trace/tracer';\nimport { AppRouteRouteHandlersSpan } from '../../lib/trace/constants';\nimport * as Log from '../../../build/output/log';\nimport { autoImplementMethods } from './helpers/auto-implement-methods';\nimport { appendMutableCookies } from '../../web/spec-extension/adapters/request-cookies';\nimport { HeadersAdapter } from '../../web/spec-extension/adapters/headers';\nimport { RequestCookiesAdapter } from '../../web/spec-extension/adapters/request-cookies';\nimport { parsedUrlQueryToParams } from './helpers/parsed-url-query-to-params';\nimport { Phase, printDebugThrownValueForProspectiveRender } from '../../app-render/prospective-render-utils';\nimport * as serverHooks from '../../../client/components/hooks-server-context';\nimport { DynamicServerError } from '../../../client/components/hooks-server-context';\nimport { workAsyncStorage } from '../../app-render/work-async-storage.external';\nimport { workUnitAsyncStorage } from '../../app-render/work-unit-async-storage.external';\nimport { actionAsyncStorage } from '../../app-render/action-async-storage.external';\nimport * as sharedModules from './shared-modules';\nimport { getIsPossibleServerAction } from '../../lib/server-action-request-meta';\nimport { RequestCookies } from 'next/dist/compiled/@edge-runtime/cookies';\nimport { cleanURL } from './helpers/clean-url';\nimport { StaticGenBailoutError } from '../../../client/components/static-generation-bailout';\nimport { isStaticGenEnabled } from './helpers/is-static-gen-enabled';\nimport { abortAndThrowOnSynchronousRequestDataAccess, postponeWithTracking, createDynamicTrackingState, getFirstDynamicReason } from '../../app-render/dynamic-rendering';\nimport { ReflectAdapter } from '../../web/spec-extension/adapters/reflect';\nimport { CacheSignal } from '../../app-render/cache-signal';\nimport { scheduleImmediate } from '../../../lib/scheduler';\nimport { createServerParamsForRoute } from '../../request/params';\nimport { getRedirectStatusCodeFromError, getURLFromRedirectError } from '../../../client/components/redirect';\nimport { isRedirectError } from '../../../client/components/redirect-error';\nimport { getAccessFallbackHTTPStatus, isHTTPAccessFallbackError } from '../../../client/components/http-access-fallback/http-access-fallback';\nimport { RedirectStatusCode } from '../../../client/components/redirect-status-code';\nimport { INFINITE_CACHE } from '../../../lib/constants';\nimport { executeRevalidates } from '../../revalidation-utils';\nimport { trackPendingModules } from '../../app-render/module-loading/track-module-loading.external';\nimport { InvariantError } from '../../../shared/lib/invariant-error';\nimport { createPrerenderResumeDataCache } from '../../resume-data-cache/resume-data-cache';\nexport class WrappedNextRouterError {\n    constructor(error, headers){\n        this.error = error;\n        this.headers = headers;\n    }\n}\n/**\n * AppRouteRouteHandler is the handler for app routes.\n */ export class AppRouteRouteModule extends RouteModule {\n    static #_ = this.sharedModules = sharedModules;\n    constructor({ userland, definition, distDir, relativeProjectDir, resolvedPagePath, nextConfigOutput }){\n        super({\n            userland,\n            definition,\n            distDir,\n            relativeProjectDir\n        }), /**\n   * A reference to the request async storage.\n   */ this.workUnitAsyncStorage = workUnitAsyncStorage, /**\n   * A reference to the static generation async storage.\n   */ this.workAsyncStorage = workAsyncStorage, /**\n   * An interface to call server hooks which interact with the underlying\n   * storage.\n   */ this.serverHooks = serverHooks, /**\n   * A reference to the mutation related async storage, such as mutations of\n   * cookies.\n   */ this.actionAsyncStorage = actionAsyncStorage;\n        this.resolvedPagePath = resolvedPagePath;\n        this.nextConfigOutput = nextConfigOutput;\n        // Automatically implement some methods if they aren't implemented by the\n        // userland module.\n        this.methods = autoImplementMethods(userland);\n        // Get the non-static methods for this route.\n        this.hasNonStaticMethods = hasNonStaticMethods(userland);\n        // Get the dynamic property from the userland module.\n        this.dynamic = this.userland.dynamic;\n        if (this.nextConfigOutput === 'export') {\n            if (this.dynamic === 'force-dynamic') {\n                throw Object.defineProperty(new Error(`export const dynamic = \"force-dynamic\" on page \"${definition.pathname}\" cannot be used with \"output: export\". See more info here: https://nextjs.org/docs/advanced-features/static-html-export`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E278\",\n                    enumerable: false,\n                    configurable: true\n                });\n            } else if (!isStaticGenEnabled(this.userland) && this.userland['GET']) {\n                throw Object.defineProperty(new Error(`export const dynamic = \"force-static\"/export const revalidate not configured on route \"${definition.pathname}\" with \"output: export\". See more info here: https://nextjs.org/docs/advanced-features/static-html-export`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E301\",\n                    enumerable: false,\n                    configurable: true\n                });\n            } else {\n                this.dynamic = 'error';\n            }\n        }\n        // We only warn in development after here, so return if we're not in\n        // development.\n        if (process.env.NODE_ENV === 'development') {\n            // Print error in development if the exported handlers are in lowercase, only\n            // uppercase handlers are supported.\n            const lowercased = HTTP_METHODS.map((method)=>method.toLowerCase());\n            for (const method of lowercased){\n                if (method in this.userland) {\n                    Log.error(`Detected lowercase method '${method}' in '${this.resolvedPagePath}'. Export the uppercase '${method.toUpperCase()}' method name to fix this error.`);\n                }\n            }\n            // Print error if the module exports a default handler, they must use named\n            // exports for each HTTP method.\n            if ('default' in this.userland) {\n                Log.error(`Detected default export in '${this.resolvedPagePath}'. Export a named export for each HTTP method instead.`);\n            }\n            // If there is no methods exported by this module, then return a not found\n            // response.\n            if (!HTTP_METHODS.some((method)=>method in this.userland)) {\n                Log.error(`No HTTP methods exported in '${this.resolvedPagePath}'. Export a named export for each HTTP method.`);\n            }\n        }\n    }\n    /**\n   * Resolves the handler function for the given method.\n   *\n   * @param method the requested method\n   * @returns the handler function for the given method\n   */ resolve(method) {\n        // Ensure that the requested method is a valid method (to prevent RCE's).\n        if (!isHTTPMethod(method)) return ()=>new Response(null, {\n                status: 400\n            });\n        // Return the handler.\n        return this.methods[method];\n    }\n    async do(handler, actionStore, workStore, // @TODO refactor to not take this argument but instead construct the RequestStore\n    // inside this function. Right now we get passed a RequestStore even when\n    // we're going to do a prerender. We should probably just split do up into prexecute and execute\n    requestStore, implicitTags, request, context) {\n        const isStaticGeneration = workStore.isStaticGeneration;\n        const cacheComponentsEnabled = !!context.renderOpts.cacheComponents;\n        // Patch the global fetch.\n        patchFetch({\n            workAsyncStorage: this.workAsyncStorage,\n            workUnitAsyncStorage: this.workUnitAsyncStorage\n        });\n        const handlerContext = {\n            params: context.params ? createServerParamsForRoute(parsedUrlQueryToParams(context.params), workStore) : undefined\n        };\n        const resolvePendingRevalidations = ()=>{\n            context.renderOpts.pendingWaitUntil = executeRevalidates(workStore).finally(()=>{\n                if (process.env.NEXT_PRIVATE_DEBUG_CACHE) {\n                    console.log('pending revalidates promise finished for:', requestStore.url);\n                }\n            });\n        };\n        let prerenderStore = null;\n        let res;\n        try {\n            if (isStaticGeneration) {\n                const userlandRevalidate = this.userland.revalidate;\n                const defaultRevalidate = // If the static generation store does not have a revalidate value\n                // set, then we should set it the revalidate value from the userland\n                // module or default to false.\n                userlandRevalidate === false || userlandRevalidate === undefined ? INFINITE_CACHE : userlandRevalidate;\n                if (cacheComponentsEnabled) {\n                    /**\n           * When we are attempting to statically prerender the GET handler of a route.ts module\n           * and cacheComponents is on we follow a similar pattern to rendering.\n           *\n           * We first run the handler letting caches fill. If something synchronously dynamic occurs\n           * during this prospective render then we can infer it will happen on every render and we\n           * just bail out of prerendering.\n           *\n           * Next we run the handler again and we check if we get a result back in a microtask.\n           * Next.js expects the return value to be a Response or a Thenable that resolves to a Response.\n           * Unfortunately Response's do not allow for accessing the response body synchronously or in\n           * a microtask so we need to allow one more task to unwrap the response body. This is a slightly\n           * different semantic than what we have when we render and it means that certain tasks can still\n           * execute before a prerender completes such as a carefully timed setImmediate.\n           *\n           * Functionally though IO should still take longer than the time it takes to unwrap the response body\n           * so our heuristic of excluding any IO should be preserved.\n           */ const prospectiveController = new AbortController();\n                    let prospectiveRenderIsDynamic = false;\n                    const cacheSignal = new CacheSignal();\n                    let dynamicTracking = createDynamicTrackingState(undefined);\n                    // TODO: Route handlers are never resumed, so it's counter-intuitive\n                    // to use an RDC here. However, we need the data cache to store cached\n                    // results in memory during the prospective prerender, so that they\n                    // can be retrieved during the final prerender within microtasks. This\n                    // is crucial when doing revalidations of a deployed route handler,\n                    // where the default cache handler does not do any in-memory caching.\n                    // We should replace the `prerenderResumeDataCache` and\n                    // `renderResumeDataCache` with a single `dataCache` property that is\n                    // conceptually not tied to resuming, and also avoids the unnecessary\n                    // complexity of using a mutable and an immutable resume data cache.\n                    const prerenderResumeDataCache = createPrerenderResumeDataCache();\n                    const prospectiveRoutePrerenderStore = prerenderStore = {\n                        type: 'prerender',\n                        phase: 'action',\n                        // This replicates prior behavior where rootParams is empty in routes\n                        // TODO we need to make this have the proper rootParams for this route\n                        rootParams: {},\n                        fallbackRouteParams: null,\n                        implicitTags,\n                        renderSignal: prospectiveController.signal,\n                        controller: prospectiveController,\n                        cacheSignal,\n                        // During prospective render we don't use a controller\n                        // because we need to let all caches fill.\n                        dynamicTracking,\n                        allowEmptyStaticShell: false,\n                        revalidate: defaultRevalidate,\n                        expire: INFINITE_CACHE,\n                        stale: INFINITE_CACHE,\n                        tags: [\n                            ...implicitTags.tags\n                        ],\n                        prerenderResumeDataCache,\n                        renderResumeDataCache: null,\n                        hmrRefreshHash: undefined\n                    };\n                    let prospectiveResult;\n                    try {\n                        prospectiveResult = this.workUnitAsyncStorage.run(prospectiveRoutePrerenderStore, handler, request, handlerContext);\n                    } catch (err) {\n                        if (prospectiveController.signal.aborted) {\n                            // the route handler called an API which is always dynamic\n                            // there is no need to try again\n                            prospectiveRenderIsDynamic = true;\n                        } else if (process.env.NEXT_DEBUG_BUILD || process.env.__NEXT_VERBOSE_LOGGING) {\n                            printDebugThrownValueForProspectiveRender(err, workStore.route, Phase.ProspectiveRender);\n                        }\n                    }\n                    if (typeof prospectiveResult === 'object' && prospectiveResult !== null && typeof prospectiveResult.then === 'function') {\n                        // The handler returned a Thenable. We'll listen for rejections to determine\n                        // if the route is erroring for dynamic reasons.\n                        ;\n                        prospectiveResult.then(()=>{}, (err)=>{\n                            if (prospectiveController.signal.aborted) {\n                                // the route handler called an API which is always dynamic\n                                // there is no need to try again\n                                prospectiveRenderIsDynamic = true;\n                            } else if (process.env.NEXT_DEBUG_BUILD) {\n                                printDebugThrownValueForProspectiveRender(err, workStore.route, Phase.ProspectiveRender);\n                            }\n                        });\n                    }\n                    trackPendingModules(cacheSignal);\n                    await cacheSignal.cacheReady();\n                    if (prospectiveRenderIsDynamic) {\n                        // the route handler called an API which is always dynamic\n                        // there is no need to try again\n                        const dynamicReason = getFirstDynamicReason(dynamicTracking);\n                        if (dynamicReason) {\n                            throw Object.defineProperty(new DynamicServerError(`Route ${workStore.route} couldn't be rendered statically because it used \\`${dynamicReason}\\`. See more info here: https://nextjs.org/docs/messages/dynamic-server-error`), \"__NEXT_ERROR_CODE\", {\n                                value: \"E558\",\n                                enumerable: false,\n                                configurable: true\n                            });\n                        } else {\n                            console.error('Expected Next.js to keep track of reason for opting out of static rendering but one was not found. This is a bug in Next.js');\n                            throw Object.defineProperty(new DynamicServerError(`Route ${workStore.route} couldn't be rendered statically because it used a dynamic API. See more info here: https://nextjs.org/docs/messages/dynamic-server-error`), \"__NEXT_ERROR_CODE\", {\n                                value: \"E577\",\n                                enumerable: false,\n                                configurable: true\n                            });\n                        }\n                    }\n                    // TODO start passing this controller to the route handler. We should expose\n                    // it so the handler to abort inflight requests and other operations if we abort\n                    // the prerender.\n                    const finalController = new AbortController();\n                    dynamicTracking = createDynamicTrackingState(undefined);\n                    const finalRoutePrerenderStore = prerenderStore = {\n                        type: 'prerender',\n                        phase: 'action',\n                        rootParams: {},\n                        fallbackRouteParams: null,\n                        implicitTags,\n                        renderSignal: finalController.signal,\n                        controller: finalController,\n                        cacheSignal: null,\n                        dynamicTracking,\n                        allowEmptyStaticShell: false,\n                        revalidate: defaultRevalidate,\n                        expire: INFINITE_CACHE,\n                        stale: INFINITE_CACHE,\n                        tags: [\n                            ...implicitTags.tags\n                        ],\n                        prerenderResumeDataCache,\n                        renderResumeDataCache: null,\n                        hmrRefreshHash: undefined\n                    };\n                    let responseHandled = false;\n                    res = await new Promise((resolve, reject)=>{\n                        scheduleImmediate(async ()=>{\n                            try {\n                                const result = await this.workUnitAsyncStorage.run(finalRoutePrerenderStore, handler, request, handlerContext);\n                                if (responseHandled) {\n                                    // we already rejected in the followup task\n                                    return;\n                                } else if (!(result instanceof Response)) {\n                                    // This is going to error but we let that happen below\n                                    resolve(result);\n                                    return;\n                                }\n                                responseHandled = true;\n                                let bodyHandled = false;\n                                result.arrayBuffer().then((body)=>{\n                                    if (!bodyHandled) {\n                                        bodyHandled = true;\n                                        resolve(new Response(body, {\n                                            headers: result.headers,\n                                            status: result.status,\n                                            statusText: result.statusText\n                                        }));\n                                    }\n                                }, reject);\n                                scheduleImmediate(()=>{\n                                    if (!bodyHandled) {\n                                        bodyHandled = true;\n                                        finalController.abort();\n                                        reject(createCacheComponentsError(workStore.route));\n                                    }\n                                });\n                            } catch (err) {\n                                reject(err);\n                            }\n                        });\n                        scheduleImmediate(()=>{\n                            if (!responseHandled) {\n                                responseHandled = true;\n                                finalController.abort();\n                                reject(createCacheComponentsError(workStore.route));\n                            }\n                        });\n                    });\n                    if (finalController.signal.aborted) {\n                        // We aborted from within the execution\n                        throw createCacheComponentsError(workStore.route);\n                    } else {\n                        // We didn't abort during the execution. We can abort now as a matter of semantics\n                        // though at the moment nothing actually consumes this signal so it won't halt any\n                        // inflight work.\n                        finalController.abort();\n                    }\n                } else {\n                    prerenderStore = {\n                        type: 'prerender-legacy',\n                        phase: 'action',\n                        rootParams: {},\n                        implicitTags,\n                        revalidate: defaultRevalidate,\n                        expire: INFINITE_CACHE,\n                        stale: INFINITE_CACHE,\n                        tags: [\n                            ...implicitTags.tags\n                        ]\n                    };\n                    res = await workUnitAsyncStorage.run(prerenderStore, handler, request, handlerContext);\n                }\n            } else {\n                res = await workUnitAsyncStorage.run(requestStore, handler, request, handlerContext);\n            }\n        } catch (err) {\n            if (isRedirectError(err)) {\n                const url = getURLFromRedirectError(err);\n                if (!url) {\n                    throw Object.defineProperty(new Error('Invariant: Unexpected redirect url format'), \"__NEXT_ERROR_CODE\", {\n                        value: \"E399\",\n                        enumerable: false,\n                        configurable: true\n                    });\n                }\n                // We need to capture any headers that should be sent on\n                // the response.\n                const headers = new Headers({\n                    Location: url\n                });\n                // Let's append any cookies that were added by the\n                // cookie API.\n                // TODO leaving the gate here b/c it indicates that we might not actually want to do this\n                // on every `do` call. During prerender there should be no mutableCookies because\n                appendMutableCookies(headers, requestStore.mutableCookies);\n                resolvePendingRevalidations();\n                // Return the redirect response.\n                return new Response(null, {\n                    // If we're in an action, we want to use a 303 redirect as we don't\n                    // want the POST request to follow the redirect, as it could result in\n                    // erroneous re-submissions.\n                    status: actionStore.isAction ? RedirectStatusCode.SeeOther : getRedirectStatusCodeFromError(err),\n                    headers\n                });\n            } else if (isHTTPAccessFallbackError(err)) {\n                const httpStatus = getAccessFallbackHTTPStatus(err);\n                return new Response(null, {\n                    status: httpStatus\n                });\n            }\n            throw err;\n        }\n        // Validate that the response is a valid response object.\n        if (!(res instanceof Response)) {\n            throw Object.defineProperty(new Error(`No response is returned from route handler '${this.resolvedPagePath}'. Ensure you return a \\`Response\\` or a \\`NextResponse\\` in all branches of your handler.`), \"__NEXT_ERROR_CODE\", {\n                value: \"E325\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        context.renderOpts.fetchMetrics = workStore.fetchMetrics;\n        resolvePendingRevalidations();\n        if (prerenderStore) {\n            var _prerenderStore_tags;\n            context.renderOpts.collectedTags = (_prerenderStore_tags = prerenderStore.tags) == null ? void 0 : _prerenderStore_tags.join(',');\n            context.renderOpts.collectedRevalidate = prerenderStore.revalidate;\n            context.renderOpts.collectedExpire = prerenderStore.expire;\n            context.renderOpts.collectedStale = prerenderStore.stale;\n        }\n        // It's possible cookies were set in the handler, so we need\n        // to merge the modified cookies and the returned response\n        // here.\n        const headers = new Headers(res.headers);\n        if (appendMutableCookies(headers, requestStore.mutableCookies)) {\n            return new Response(res.body, {\n                status: res.status,\n                statusText: res.statusText,\n                headers\n            });\n        }\n        return res;\n    }\n    async handle(req, context) {\n        // Get the handler function for the given method.\n        const handler = this.resolve(req.method);\n        // Get the context for the static generation.\n        const staticGenerationContext = {\n            page: this.definition.page,\n            renderOpts: context.renderOpts,\n            buildId: context.sharedContext.buildId,\n            previouslyRevalidatedTags: []\n        };\n        // Add the fetchCache option to the renderOpts.\n        staticGenerationContext.renderOpts.fetchCache = this.userland.fetchCache;\n        const actionStore = {\n            isAppRoute: true,\n            isAction: getIsPossibleServerAction(req)\n        };\n        const implicitTags = await getImplicitTags(this.definition.page, req.nextUrl, // App Routes don't support unknown route params.\n        null);\n        const requestStore = createRequestStoreForAPI(req, req.nextUrl, implicitTags, undefined, context.prerenderManifest.preview);\n        const workStore = createWorkStore(staticGenerationContext);\n        // Run the handler with the request AsyncLocalStorage to inject the helper\n        // support. We set this to `unknown` because the type is not known until\n        // runtime when we do a instanceof check below.\n        const response = await this.actionAsyncStorage.run(actionStore, ()=>this.workUnitAsyncStorage.run(requestStore, ()=>this.workAsyncStorage.run(workStore, async ()=>{\n                    // Check to see if we should bail out of static generation based on\n                    // having non-static methods.\n                    if (this.hasNonStaticMethods) {\n                        if (workStore.isStaticGeneration) {\n                            const err = Object.defineProperty(new DynamicServerError('Route is configured with methods that cannot be statically generated.'), \"__NEXT_ERROR_CODE\", {\n                                value: \"E582\",\n                                enumerable: false,\n                                configurable: true\n                            });\n                            workStore.dynamicUsageDescription = err.message;\n                            workStore.dynamicUsageStack = err.stack;\n                            throw err;\n                        }\n                    }\n                    // We assume we can pass the original request through however we may end up\n                    // proxying it in certain circumstances based on execution type and configuration\n                    let request = req;\n                    // Update the static generation store based on the dynamic property.\n                    switch(this.dynamic){\n                        case 'force-dynamic':\n                            {\n                                // Routes of generated paths should be dynamic\n                                workStore.forceDynamic = true;\n                                if (workStore.isStaticGeneration) {\n                                    const err = Object.defineProperty(new DynamicServerError('Route is configured with dynamic = error which cannot be statically generated.'), \"__NEXT_ERROR_CODE\", {\n                                        value: \"E703\",\n                                        enumerable: false,\n                                        configurable: true\n                                    });\n                                    workStore.dynamicUsageDescription = err.message;\n                                    workStore.dynamicUsageStack = err.stack;\n                                    throw err;\n                                }\n                                break;\n                            }\n                        case 'force-static':\n                            // The dynamic property is set to force-static, so we should\n                            // force the page to be static.\n                            workStore.forceStatic = true;\n                            // We also Proxy the request to replace dynamic data on the request\n                            // with empty stubs to allow for safely executing as static\n                            request = new Proxy(req, forceStaticRequestHandlers);\n                            break;\n                        case 'error':\n                            // The dynamic property is set to error, so we should throw an\n                            // error if the page is being statically generated.\n                            workStore.dynamicShouldError = true;\n                            if (workStore.isStaticGeneration) request = new Proxy(req, requireStaticRequestHandlers);\n                            break;\n                        case undefined:\n                        case 'auto':\n                            // We proxy `NextRequest` to track dynamic access, and\n                            // potentially bail out of static generation.\n                            request = proxyNextRequest(req, workStore);\n                            break;\n                        default:\n                            this.dynamic;\n                    }\n                    const tracer = getTracer();\n                    // Update the root span attribute for the route.\n                    const { pathname } = this.definition;\n                    tracer.setRootSpanAttribute('next.route', pathname);\n                    return tracer.trace(AppRouteRouteHandlersSpan.runHandler, {\n                        spanName: `executing api route (app) ${pathname}`,\n                        attributes: {\n                            'next.route': pathname\n                        }\n                    }, async ()=>this.do(handler, actionStore, workStore, requestStore, implicitTags, request, context));\n                })));\n        // If the handler did't return a valid response, then return the internal\n        // error response.\n        if (!(response instanceof Response)) {\n            // TODO: validate the correct handling behavior, maybe log something?\n            return new Response(null, {\n                status: 500\n            });\n        }\n        if (response.headers.has('x-middleware-rewrite')) {\n            throw Object.defineProperty(new Error('NextResponse.rewrite() was used in a app route handler, this is not currently supported. Please remove the invocation to continue.'), \"__NEXT_ERROR_CODE\", {\n                value: \"E374\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        if (response.headers.get('x-middleware-next') === '1') {\n            // TODO: move this error into the `NextResponse.next()` function.\n            throw Object.defineProperty(new Error('NextResponse.next() was used in a app route handler, this is not supported. See here for more info: https://nextjs.org/docs/messages/next-response-next-in-app-route-handler'), \"__NEXT_ERROR_CODE\", {\n                value: \"E385\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        return response;\n    }\n}\nexport default AppRouteRouteModule;\n/**\n * Gets all the method names for handlers that are not considered static.\n *\n * @param handlers the handlers from the userland module\n * @returns the method names that are not considered static or false if all\n *          methods are static\n */ export function hasNonStaticMethods(handlers) {\n    if (// Order these by how common they are to be used\n    handlers.POST || handlers.PUT || handlers.DELETE || handlers.PATCH || handlers.OPTIONS) {\n        return true;\n    }\n    return false;\n}\n// These symbols will be used to stash cached values on Proxied requests without requiring\n// additional closures or storage such as WeakMaps.\nconst nextURLSymbol = Symbol('nextUrl');\nconst requestCloneSymbol = Symbol('clone');\nconst urlCloneSymbol = Symbol('clone');\nconst searchParamsSymbol = Symbol('searchParams');\nconst hrefSymbol = Symbol('href');\nconst toStringSymbol = Symbol('toString');\nconst headersSymbol = Symbol('headers');\nconst cookiesSymbol = Symbol('cookies');\n/**\n * The general technique with these proxy handlers is to prioritize keeping them static\n * by stashing computed values on the Proxy itself. This is safe because the Proxy is\n * inaccessible to the consumer since all operations are forwarded\n */ const forceStaticRequestHandlers = {\n    get (target, prop, receiver) {\n        switch(prop){\n            case 'headers':\n                return target[headersSymbol] || (target[headersSymbol] = HeadersAdapter.seal(new Headers({})));\n            case 'cookies':\n                return target[cookiesSymbol] || (target[cookiesSymbol] = RequestCookiesAdapter.seal(new RequestCookies(new Headers({}))));\n            case 'nextUrl':\n                return target[nextURLSymbol] || (target[nextURLSymbol] = new Proxy(target.nextUrl, forceStaticNextUrlHandlers));\n            case 'url':\n                // we don't need to separately cache this we can just read the nextUrl\n                // and return the href since we know it will have been stripped of any\n                // dynamic parts. We access via the receiver to trigger the get trap\n                return receiver.nextUrl.href;\n            case 'geo':\n            case 'ip':\n                return undefined;\n            case 'clone':\n                return target[requestCloneSymbol] || (target[requestCloneSymbol] = ()=>new Proxy(// This is vaguely unsafe but it's required since NextRequest does not implement\n                    // clone. The reason we might expect this to work in this context is the Proxy will\n                    // respond with static-amenable values anyway somewhat restoring the interface.\n                    // @TODO we need to rethink NextRequest and NextURL because they are not sufficientlly\n                    // sophisticated to adequately represent themselves in all contexts. A better approach is\n                    // to probably embed the static generation logic into the class itself removing the need\n                    // for any kind of proxying\n                    target.clone(), forceStaticRequestHandlers));\n            default:\n                return ReflectAdapter.get(target, prop, receiver);\n        }\n    }\n};\nconst forceStaticNextUrlHandlers = {\n    get (target, prop, receiver) {\n        switch(prop){\n            // URL properties\n            case 'search':\n                return '';\n            case 'searchParams':\n                return target[searchParamsSymbol] || (target[searchParamsSymbol] = new URLSearchParams());\n            case 'href':\n                return target[hrefSymbol] || (target[hrefSymbol] = cleanURL(target.href).href);\n            case 'toJSON':\n            case 'toString':\n                return target[toStringSymbol] || (target[toStringSymbol] = ()=>receiver.href);\n            // NextUrl properties\n            case 'url':\n                // Currently nextURL does not expose url but our Docs indicate that it is an available property\n                // I am forcing this to undefined here to avoid accidentally exposing a dynamic value later if\n                // the underlying nextURL ends up adding this property\n                return undefined;\n            case 'clone':\n                return target[urlCloneSymbol] || (target[urlCloneSymbol] = ()=>new Proxy(target.clone(), forceStaticNextUrlHandlers));\n            default:\n                return ReflectAdapter.get(target, prop, receiver);\n        }\n    }\n};\nfunction proxyNextRequest(request, workStore) {\n    const nextUrlHandlers = {\n        get (target, prop, receiver) {\n            switch(prop){\n                case 'search':\n                case 'searchParams':\n                case 'url':\n                case 'href':\n                case 'toJSON':\n                case 'toString':\n                case 'origin':\n                    {\n                        const workUnitStore = workUnitAsyncStorage.getStore();\n                        trackDynamic(workStore, workUnitStore, `nextUrl.${prop}`);\n                        return ReflectAdapter.get(target, prop, receiver);\n                    }\n                case 'clone':\n                    return target[urlCloneSymbol] || (target[urlCloneSymbol] = ()=>new Proxy(target.clone(), nextUrlHandlers));\n                default:\n                    return ReflectAdapter.get(target, prop, receiver);\n            }\n        }\n    };\n    const nextRequestHandlers = {\n        get (target, prop) {\n            switch(prop){\n                case 'nextUrl':\n                    return target[nextURLSymbol] || (target[nextURLSymbol] = new Proxy(target.nextUrl, nextUrlHandlers));\n                case 'headers':\n                case 'cookies':\n                case 'url':\n                case 'body':\n                case 'blob':\n                case 'json':\n                case 'text':\n                case 'arrayBuffer':\n                case 'formData':\n                    {\n                        const workUnitStore = workUnitAsyncStorage.getStore();\n                        trackDynamic(workStore, workUnitStore, `request.${prop}`);\n                        // The receiver arg is intentionally the same as the target to fix an issue with\n                        // edge runtime, where attempting to access internal slots with the wrong `this` context\n                        // results in an error.\n                        return ReflectAdapter.get(target, prop, target);\n                    }\n                case 'clone':\n                    return target[requestCloneSymbol] || (target[requestCloneSymbol] = ()=>new Proxy(// This is vaguely unsafe but it's required since NextRequest does not implement\n                        // clone. The reason we might expect this to work in this context is the Proxy will\n                        // respond with static-amenable values anyway somewhat restoring the interface.\n                        // @TODO we need to rethink NextRequest and NextURL because they are not sufficientlly\n                        // sophisticated to adequately represent themselves in all contexts. A better approach is\n                        // to probably embed the static generation logic into the class itself removing the need\n                        // for any kind of proxying\n                        target.clone(), nextRequestHandlers));\n                default:\n                    // The receiver arg is intentionally the same as the target to fix an issue with\n                    // edge runtime, where attempting to access internal slots with the wrong `this` context\n                    // results in an error.\n                    return ReflectAdapter.get(target, prop, target);\n            }\n        }\n    };\n    return new Proxy(request, nextRequestHandlers);\n}\nconst requireStaticRequestHandlers = {\n    get (target, prop, receiver) {\n        switch(prop){\n            case 'nextUrl':\n                return target[nextURLSymbol] || (target[nextURLSymbol] = new Proxy(target.nextUrl, requireStaticNextUrlHandlers));\n            case 'headers':\n            case 'cookies':\n            case 'url':\n            case 'body':\n            case 'blob':\n            case 'json':\n            case 'text':\n            case 'arrayBuffer':\n            case 'formData':\n                throw Object.defineProperty(new StaticGenBailoutError(`Route ${target.nextUrl.pathname} with \\`dynamic = \"error\"\\` couldn't be rendered statically because it used \\`request.${prop}\\`.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E611\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'clone':\n                return target[requestCloneSymbol] || (target[requestCloneSymbol] = ()=>new Proxy(// This is vaguely unsafe but it's required since NextRequest does not implement\n                    // clone. The reason we might expect this to work in this context is the Proxy will\n                    // respond with static-amenable values anyway somewhat restoring the interface.\n                    // @TODO we need to rethink NextRequest and NextURL because they are not sufficientlly\n                    // sophisticated to adequately represent themselves in all contexts. A better approach is\n                    // to probably embed the static generation logic into the class itself removing the need\n                    // for any kind of proxying\n                    target.clone(), requireStaticRequestHandlers));\n            default:\n                return ReflectAdapter.get(target, prop, receiver);\n        }\n    }\n};\nconst requireStaticNextUrlHandlers = {\n    get (target, prop, receiver) {\n        switch(prop){\n            case 'search':\n            case 'searchParams':\n            case 'url':\n            case 'href':\n            case 'toJSON':\n            case 'toString':\n            case 'origin':\n                throw Object.defineProperty(new StaticGenBailoutError(`Route ${target.pathname} with \\`dynamic = \"error\"\\` couldn't be rendered statically because it used \\`nextUrl.${prop}\\`.`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E575\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'clone':\n                return target[urlCloneSymbol] || (target[urlCloneSymbol] = ()=>new Proxy(target.clone(), requireStaticNextUrlHandlers));\n            default:\n                return ReflectAdapter.get(target, prop, receiver);\n        }\n    }\n};\nfunction createCacheComponentsError(route) {\n    return Object.defineProperty(new DynamicServerError(`Route ${route} couldn't be rendered statically because it used IO that was not cached. See more info here: https://nextjs.org/docs/messages/cache-components`), \"__NEXT_ERROR_CODE\", {\n        value: \"E727\",\n        enumerable: false,\n        configurable: true\n    });\n}\nfunction trackDynamic(store, workUnitStore, expression) {\n    if (store.dynamicShouldError) {\n        throw Object.defineProperty(new StaticGenBailoutError(`Route ${store.route} with \\`dynamic = \"error\"\\` couldn't be rendered statically because it used \\`${expression}\\`. See more info here: https://nextjs.org/docs/app/building-your-application/rendering/static-and-dynamic#dynamic-rendering`), \"__NEXT_ERROR_CODE\", {\n            value: \"E553\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    if (workUnitStore) {\n        switch(workUnitStore.type){\n            case 'cache':\n            case 'private-cache':\n                // TODO: Should we allow reading cookies and search params from the\n                // request for private caches in route handlers?\n                throw Object.defineProperty(new Error(`Route ${store.route} used \"${expression}\" inside \"use cache\". Accessing Dynamic data sources inside a cache scope is not supported. If you need this data inside a cached function use \"${expression}\" outside of the cached function and pass the required dynamic data in as an argument. See more info here: https://nextjs.org/docs/messages/next-request-in-use-cache`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E178\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'unstable-cache':\n                throw Object.defineProperty(new Error(`Route ${store.route} used \"${expression}\" inside a function cached with \"unstable_cache(...)\". Accessing Dynamic data sources inside a cache scope is not supported. If you need this data inside a cached function use \"${expression}\" outside of the cached function and pass the required dynamic data in as an argument. See more info here: https://nextjs.org/docs/app/api-reference/functions/unstable_cache`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E133\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender':\n                const error = Object.defineProperty(new Error(`Route ${store.route} used ${expression} without first calling \\`await connection()\\`. See more info here: https://nextjs.org/docs/messages/next-prerender-sync-request`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E261\",\n                    enumerable: false,\n                    configurable: true\n                });\n                return abortAndThrowOnSynchronousRequestDataAccess(store.route, expression, error, workUnitStore);\n            case 'prerender-client':\n                throw Object.defineProperty(new InvariantError('A client prerender store should not be used for a route handler.'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E720\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender-runtime':\n                throw Object.defineProperty(new InvariantError('A runtime prerender store should not be used for a route handler.'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E767\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender-ppr':\n                return postponeWithTracking(store.route, expression, workUnitStore.dynamicTracking);\n            case 'prerender-legacy':\n                workUnitStore.revalidate = 0;\n                const err = Object.defineProperty(new DynamicServerError(`Route ${store.route} couldn't be rendered statically because it used \\`${expression}\\`. See more info here: https://nextjs.org/docs/messages/dynamic-server-error`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E558\",\n                    enumerable: false,\n                    configurable: true\n                });\n                store.dynamicUsageDescription = expression;\n                store.dynamicUsageStack = err.stack;\n                throw err;\n            case 'request':\n                if (process.env.NODE_ENV !== 'production') {\n                    // TODO: This is currently not really needed for route handlers, as it\n                    // only controls the ISR status that's shown for pages.\n                    workUnitStore.usedDynamic = true;\n                }\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n}\n\n//# sourceMappingURL=module.js.map","import { BUILD_ID_FILE, BUILD_MANIFEST, CLIENT_REFERENCE_MANIFEST, DYNAMIC_CSS_MANIFEST, NEXT_FONT_MANIFEST, PRERENDER_MANIFEST, REACT_LOADABLE_MANIFEST, ROUTES_MANIFEST, SERVER_FILES_MANIFEST, SERVER_REFERENCE_MANIFEST, SUBRESOURCE_INTEGRITY_MANIFEST } from '../../shared/lib/constants';\nimport { parseReqUrl } from '../../lib/url';\nimport { normalizeLocalePath } from '../../shared/lib/i18n/normalize-locale-path';\nimport { isDynamicRoute } from '../../shared/lib/router/utils';\nimport { removePathPrefix } from '../../shared/lib/router/utils/remove-path-prefix';\nimport { getServerUtils } from '../server-utils';\nimport { detectDomainLocale } from '../../shared/lib/i18n/detect-domain-locale';\nimport { getHostname } from '../../shared/lib/get-hostname';\nimport { checkIsOnDemandRevalidate } from '../api-utils';\nimport { normalizeDataPath } from '../../shared/lib/page-path/normalize-data-path';\nimport { pathHasPrefix } from '../../shared/lib/router/utils/path-has-prefix';\nimport { addRequestMeta, getRequestMeta } from '../request-meta';\nimport { normalizePagePath } from '../../shared/lib/page-path/normalize-page-path';\nimport { isStaticMetadataRoute } from '../../lib/metadata/is-metadata-route';\nimport { IncrementalCache } from '../lib/incremental-cache';\nimport { initializeCacheHandlers, setCacheHandler } from '../use-cache/handlers';\nimport { interopDefault } from '../app-render/interop-default';\nimport { RouteKind } from '../route-kind';\nimport ResponseCache from '../response-cache';\nimport { normalizeAppPath } from '../../shared/lib/router/utils/app-paths';\nimport { RouterServerContextSymbol, routerServerGlobal } from '../lib/router-utils/router-server-context';\nimport { decodePathParams } from '../lib/router-utils/decode-path-params';\nimport { removeTrailingSlash } from '../../shared/lib/router/utils/remove-trailing-slash';\nimport { isInterceptionRouteRewrite } from '../../lib/generate-interception-routes-rewrites';\nconst dynamicImportEsmDefault = (id)=>import(/* webpackIgnore: true */ /* turbopackIgnore: true */ id).then((mod)=>mod.default || mod);\n/**\n * RouteModule is the base class for all route modules. This class should be\n * extended by all route modules.\n */ export class RouteModule {\n    constructor({ userland, definition, distDir, relativeProjectDir }){\n        this.userland = userland;\n        this.definition = definition;\n        this.isDev = process.env.NODE_ENV === 'development';\n        this.distDir = distDir;\n        this.relativeProjectDir = relativeProjectDir;\n    }\n    async instrumentationOnRequestError(req, ...args) {\n        if (process.env.NEXT_RUNTIME === 'edge') {\n            const { getEdgeInstrumentationModule } = await import('../web/globals');\n            const instrumentation = await getEdgeInstrumentationModule();\n            if (instrumentation) {\n                await (instrumentation.onRequestError == null ? void 0 : instrumentation.onRequestError.call(instrumentation, ...args));\n            }\n        } else {\n            const { join } = require('node:path');\n            const absoluteProjectDir = join(/* turbopackIgnore: true */ process.cwd(), getRequestMeta(req, 'relativeProjectDir') || this.relativeProjectDir);\n            const { instrumentationOnRequestError } = await import('../lib/router-utils/instrumentation-globals.external.js');\n            return instrumentationOnRequestError(absoluteProjectDir, this.distDir, ...args);\n        }\n    }\n    loadManifests(srcPage, projectDir) {\n        let result;\n        if (process.env.NEXT_RUNTIME === 'edge') {\n            var _self___RSC_MANIFEST;\n            const { getEdgePreviewProps } = require('../web/get-edge-preview-props');\n            const maybeJSONParse = (str)=>str ? JSON.parse(str) : undefined;\n            result = {\n                buildId: process.env.__NEXT_BUILD_ID || '',\n                buildManifest: self.__BUILD_MANIFEST,\n                fallbackBuildManifest: {},\n                reactLoadableManifest: maybeJSONParse(self.__REACT_LOADABLE_MANIFEST),\n                nextFontManifest: maybeJSONParse(self.__NEXT_FONT_MANIFEST),\n                prerenderManifest: {\n                    routes: {},\n                    dynamicRoutes: {},\n                    notFoundRoutes: [],\n                    version: 4,\n                    preview: getEdgePreviewProps()\n                },\n                routesManifest: {\n                    version: 4,\n                    caseSensitive: Boolean(process.env.__NEXT_CASE_SENSITIVE_ROUTES),\n                    basePath: process.env.__NEXT_BASE_PATH || '',\n                    rewrites: process.env.__NEXT_REWRITES || {\n                        beforeFiles: [],\n                        afterFiles: [],\n                        fallback: []\n                    },\n                    redirects: [],\n                    headers: [],\n                    i18n: process.env.__NEXT_I18N_CONFIG || undefined,\n                    skipProxyUrlNormalize: Boolean(process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE)\n                },\n                serverFilesManifest: self.__SERVER_FILES_MANIFEST,\n                clientReferenceManifest: (_self___RSC_MANIFEST = self.__RSC_MANIFEST) == null ? void 0 : _self___RSC_MANIFEST[srcPage],\n                serverActionsManifest: maybeJSONParse(self.__RSC_SERVER_MANIFEST),\n                subresourceIntegrityManifest: maybeJSONParse(self.__SUBRESOURCE_INTEGRITY_MANIFEST),\n                dynamicCssManifest: maybeJSONParse(self.__DYNAMIC_CSS_MANIFEST),\n                interceptionRoutePatterns: (maybeJSONParse(self.__INTERCEPTION_ROUTE_REWRITE_MANIFEST) ?? []).map((rewrite)=>new RegExp(rewrite.regex))\n            };\n        } else {\n            var _clientReferenceManifest___RSC_MANIFEST;\n            if (!projectDir) {\n                throw Object.defineProperty(new Error('Invariant: projectDir is required for node runtime'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E718\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            const { loadManifestFromRelativePath } = require('../load-manifest.external');\n            const normalizedPagePath = normalizePagePath(srcPage);\n            const router = this.definition.kind === RouteKind.PAGES || this.definition.kind === RouteKind.PAGES_API ? 'pages' : 'app';\n            const [routesManifest, prerenderManifest, buildManifest, fallbackBuildManifest, reactLoadableManifest, nextFontManifest, clientReferenceManifest, serverActionsManifest, subresourceIntegrityManifest, serverFilesManifest, buildId, dynamicCssManifest] = [\n                loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: ROUTES_MANIFEST,\n                    shouldCache: !this.isDev\n                }),\n                loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: PRERENDER_MANIFEST,\n                    shouldCache: !this.isDev\n                }),\n                loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: BUILD_MANIFEST,\n                    shouldCache: !this.isDev\n                }),\n                srcPage === '/_error' ? loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: `fallback-${BUILD_MANIFEST}`,\n                    shouldCache: !this.isDev,\n                    handleMissing: true\n                }) : {},\n                loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: process.env.TURBOPACK ? `server/${router === 'app' ? 'app' : 'pages'}${normalizedPagePath}/${REACT_LOADABLE_MANIFEST}` : REACT_LOADABLE_MANIFEST,\n                    handleMissing: true,\n                    shouldCache: !this.isDev\n                }),\n                loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: `server/${NEXT_FONT_MANIFEST}.json`,\n                    shouldCache: !this.isDev\n                }),\n                router === 'app' && !isStaticMetadataRoute(srcPage) ? loadManifestFromRelativePath({\n                    distDir: this.distDir,\n                    projectDir,\n                    useEval: true,\n                    handleMissing: true,\n                    manifest: `server/app${srcPage.replace(/%5F/g, '_') + '_' + CLIENT_REFERENCE_MANIFEST}.js`,\n                    shouldCache: !this.isDev\n                }) : undefined,\n                router === 'app' ? loadManifestFromRelativePath({\n                    distDir: this.distDir,\n                    projectDir,\n                    manifest: `server/${SERVER_REFERENCE_MANIFEST}.json`,\n                    handleMissing: true,\n                    shouldCache: !this.isDev\n                }) : {},\n                loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: `server/${SUBRESOURCE_INTEGRITY_MANIFEST}.json`,\n                    handleMissing: true,\n                    shouldCache: !this.isDev\n                }),\n                this.isDev ? undefined : loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: `${SERVER_FILES_MANIFEST}.json`\n                }),\n                this.isDev ? 'development' : loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: BUILD_ID_FILE,\n                    skipParse: true\n                }),\n                loadManifestFromRelativePath({\n                    projectDir,\n                    distDir: this.distDir,\n                    manifest: DYNAMIC_CSS_MANIFEST,\n                    handleMissing: true\n                })\n            ];\n            result = {\n                buildId,\n                buildManifest,\n                fallbackBuildManifest,\n                routesManifest,\n                nextFontManifest,\n                prerenderManifest,\n                serverFilesManifest,\n                reactLoadableManifest,\n                clientReferenceManifest: clientReferenceManifest == null ? void 0 : (_clientReferenceManifest___RSC_MANIFEST = clientReferenceManifest.__RSC_MANIFEST) == null ? void 0 : _clientReferenceManifest___RSC_MANIFEST[srcPage.replace(/%5F/g, '_')],\n                serverActionsManifest,\n                subresourceIntegrityManifest,\n                dynamicCssManifest,\n                interceptionRoutePatterns: routesManifest.rewrites.beforeFiles.filter(isInterceptionRouteRewrite).map((rewrite)=>new RegExp(rewrite.regex))\n            };\n        }\n        return result;\n    }\n    async loadCustomCacheHandlers(req, nextConfig) {\n        if (process.env.NEXT_RUNTIME !== 'edge') {\n            const { cacheMaxMemorySize, cacheHandlers } = nextConfig;\n            if (!cacheHandlers) return;\n            // If we've already initialized the cache handlers interface, don't do it\n            // again.\n            if (!initializeCacheHandlers(cacheMaxMemorySize)) return;\n            for (const [kind, handler] of Object.entries(cacheHandlers)){\n                if (!handler) continue;\n                const { formatDynamicImportPath } = require('../../lib/format-dynamic-import-path');\n                const { join } = require('node:path');\n                const absoluteProjectDir = join(/* turbopackIgnore: true */ process.cwd(), getRequestMeta(req, 'relativeProjectDir') || this.relativeProjectDir);\n                setCacheHandler(kind, interopDefault(await dynamicImportEsmDefault(formatDynamicImportPath(`${absoluteProjectDir}/${this.distDir}`, handler))));\n            }\n        }\n    }\n    async getIncrementalCache(req, nextConfig, prerenderManifest, isMinimalMode) {\n        if (process.env.NEXT_RUNTIME === 'edge') {\n            return globalThis.__incrementalCache;\n        } else {\n            let CacheHandler;\n            const { cacheHandler } = nextConfig;\n            if (cacheHandler) {\n                const { formatDynamicImportPath } = require('../../lib/format-dynamic-import-path');\n                CacheHandler = interopDefault(await dynamicImportEsmDefault(formatDynamicImportPath(this.distDir, cacheHandler)));\n            }\n            const { join } = require('node:path');\n            const projectDir = join(/* turbopackIgnore: true */ process.cwd(), getRequestMeta(req, 'relativeProjectDir') || this.relativeProjectDir);\n            await this.loadCustomCacheHandlers(req, nextConfig);\n            // incremental-cache is request specific\n            // although can have shared caches in module scope\n            // per-cache handler\n            const incrementalCache = new IncrementalCache({\n                fs: require('../lib/node-fs-methods').nodeFs,\n                dev: this.isDev,\n                requestHeaders: req.headers,\n                allowedRevalidateHeaderKeys: nextConfig.experimental.allowedRevalidateHeaderKeys,\n                minimalMode: isMinimalMode,\n                serverDistDir: `${projectDir}/${this.distDir}/server`,\n                fetchCacheKeyPrefix: nextConfig.experimental.fetchCacheKeyPrefix,\n                maxMemoryCacheSize: nextConfig.cacheMaxMemorySize,\n                flushToDisk: !isMinimalMode && nextConfig.experimental.isrFlushToDisk,\n                getPrerenderManifest: ()=>prerenderManifest,\n                CurCacheHandler: CacheHandler\n            });\n            globalThis.__incrementalCache = incrementalCache;\n            return incrementalCache;\n        }\n    }\n    async onRequestError(req, err, errorContext, silenceLog, routerServerContext) {\n        if (!silenceLog) {\n            if (routerServerContext == null ? void 0 : routerServerContext.logErrorWithOriginalStack) {\n                routerServerContext.logErrorWithOriginalStack(err, 'app-dir');\n            } else {\n                console.error(err);\n            }\n        }\n        await this.instrumentationOnRequestError(req, err, {\n            path: req.url || '/',\n            headers: req.headers,\n            method: req.method || 'GET'\n        }, errorContext);\n    }\n    /** A more lightweight version of `prepare()` for only retrieving the config on edge */ getNextConfigEdge(req) {\n        var _routerServerGlobal_RouterServerContextSymbol, _nextConfig_experimental;\n        if (process.env.NEXT_RUNTIME !== 'edge') {\n            throw Object.defineProperty(new Error('Invariant: getNextConfigEdge must only be called in edge runtime'), \"__NEXT_ERROR_CODE\", {\n                value: \"E968\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        let serverFilesManifest = self.__SERVER_FILES_MANIFEST;\n        const relativeProjectDir = getRequestMeta(req, 'relativeProjectDir') || this.relativeProjectDir;\n        const routerServerContext = (_routerServerGlobal_RouterServerContextSymbol = routerServerGlobal[RouterServerContextSymbol]) == null ? void 0 : _routerServerGlobal_RouterServerContextSymbol[relativeProjectDir];\n        const nextConfig = (routerServerContext == null ? void 0 : routerServerContext.nextConfig) || (serverFilesManifest == null ? void 0 : serverFilesManifest.config);\n        if (!nextConfig) {\n            throw Object.defineProperty(new Error(\"Invariant: nextConfig couldn't be loaded\"), \"__NEXT_ERROR_CODE\", {\n                value: \"E969\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        let deploymentId;\n        if ((_nextConfig_experimental = nextConfig.experimental) == null ? void 0 : _nextConfig_experimental.runtimeServerDeploymentId) {\n            if (!process.env.NEXT_DEPLOYMENT_ID) {\n                throw Object.defineProperty(new Error('process.env.NEXT_DEPLOYMENT_ID is missing but runtimeServerDeploymentId is enabled'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E970\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            deploymentId = process.env.NEXT_DEPLOYMENT_ID;\n        } else {\n            deploymentId = nextConfig.deploymentId || '';\n        }\n        return {\n            nextConfig,\n            deploymentId\n        };\n    }\n    async prepare(req, res, { srcPage, multiZoneDraftMode }) {\n        var _routerServerGlobal_RouterServerContextSymbol, _nextConfig_experimental;\n        let absoluteProjectDir;\n        // edge runtime handles loading instrumentation at the edge adapter level\n        if (process.env.NEXT_RUNTIME !== 'edge') {\n            const { join, relative } = require('node:path');\n            absoluteProjectDir = join(/* turbopackIgnore: true */ process.cwd(), getRequestMeta(req, 'relativeProjectDir') || this.relativeProjectDir);\n            const absoluteDistDir = getRequestMeta(req, 'distDir');\n            if (absoluteDistDir) {\n                this.distDir = relative(absoluteProjectDir, absoluteDistDir);\n            }\n            const { ensureInstrumentationRegistered } = await import('../lib/router-utils/instrumentation-globals.external.js');\n            // ensure instrumentation is registered and pass\n            // onRequestError below\n            ensureInstrumentationRegistered(absoluteProjectDir, this.distDir);\n        }\n        const manifests = await this.loadManifests(srcPage, absoluteProjectDir);\n        const { routesManifest, prerenderManifest, serverFilesManifest } = manifests;\n        const { basePath, i18n, rewrites } = routesManifest;\n        if (basePath) {\n            req.url = removePathPrefix(req.url || '/', basePath);\n        }\n        const parsedUrl = parseReqUrl(req.url || '/');\n        // if we couldn't parse the URL we can't continue\n        if (!parsedUrl) {\n            return;\n        }\n        let isNextDataRequest = false;\n        if (pathHasPrefix(parsedUrl.pathname || '/', '/_next/data')) {\n            isNextDataRequest = true;\n            parsedUrl.pathname = normalizeDataPath(parsedUrl.pathname || '/');\n        }\n        let originalPathname = parsedUrl.pathname || '/';\n        const originalQuery = {\n            ...parsedUrl.query\n        };\n        const pageIsDynamic = isDynamicRoute(srcPage);\n        let localeResult;\n        let detectedLocale;\n        if (i18n) {\n            localeResult = normalizeLocalePath(parsedUrl.pathname || '/', i18n.locales);\n            if (localeResult.detectedLocale) {\n                req.url = `${localeResult.pathname}${parsedUrl.search}`;\n                originalPathname = localeResult.pathname;\n                if (!detectedLocale) {\n                    detectedLocale = localeResult.detectedLocale;\n                }\n            }\n        }\n        // Normalize the page path for route matching. The srcPage contains the\n        // internal page path (e.g., /app/[slug]/page), but route matchers expect\n        // the pathname format (e.g., /app/[slug]).\n        const normalizedSrcPage = normalizeAppPath(srcPage);\n        const serverUtils = getServerUtils({\n            page: normalizedSrcPage,\n            i18n,\n            basePath,\n            rewrites,\n            pageIsDynamic,\n            trailingSlash: process.env.__NEXT_TRAILING_SLASH,\n            caseSensitive: Boolean(routesManifest.caseSensitive)\n        });\n        const domainLocale = detectDomainLocale(i18n == null ? void 0 : i18n.domains, getHostname(parsedUrl, req.headers), detectedLocale);\n        addRequestMeta(req, 'isLocaleDomain', Boolean(domainLocale));\n        const defaultLocale = (domainLocale == null ? void 0 : domainLocale.defaultLocale) || (i18n == null ? void 0 : i18n.defaultLocale);\n        // Ensure parsedUrl.pathname includes locale before processing\n        // rewrites or they won't match correctly.\n        if (defaultLocale && !detectedLocale) {\n            parsedUrl.pathname = `/${defaultLocale}${parsedUrl.pathname === '/' ? '' : parsedUrl.pathname}`;\n        }\n        const locale = getRequestMeta(req, 'locale') || detectedLocale || defaultLocale;\n        // we apply rewrites against cloned URL so that we don't\n        // modify the original with the rewrite destination\n        const { rewriteParams, rewrittenParsedUrl } = serverUtils.handleRewrites(req, parsedUrl);\n        const rewriteParamKeys = Object.keys(rewriteParams);\n        Object.assign(parsedUrl.query, rewrittenParsedUrl.query);\n        // after processing rewrites we want to remove locale\n        // from parsedUrl pathname\n        if (i18n) {\n            parsedUrl.pathname = normalizeLocalePath(parsedUrl.pathname || '/', i18n.locales).pathname;\n            rewrittenParsedUrl.pathname = normalizeLocalePath(rewrittenParsedUrl.pathname || '/', i18n.locales).pathname;\n        }\n        let params = getRequestMeta(req, 'params');\n        // attempt parsing from pathname\n        if (!params && serverUtils.dynamicRouteMatcher) {\n            const paramsMatch = serverUtils.dynamicRouteMatcher(normalizeDataPath((rewrittenParsedUrl == null ? void 0 : rewrittenParsedUrl.pathname) || parsedUrl.pathname || '/'));\n            const paramsResult = serverUtils.normalizeDynamicRouteParams(paramsMatch || {}, true);\n            if (paramsResult.hasValidParams) {\n                params = paramsResult.params;\n            }\n        }\n        // Local \"next start\" expects the routing parsed query values\n        // to not be present in the URL although when deployed proxies\n        // will add query values from resolving the routes to pass to function.\n        // TODO: do we want to change expectations for \"next start\"\n        // to include these query values in the URL which affects asPath\n        // but would match deployed behavior, e.g. a rewrite from middleware\n        // that adds a query param would be in asPath as query but locally\n        // it won't be in the asPath but still available in the query object\n        const query = getRequestMeta(req, 'query') || {\n            ...parsedUrl.query\n        };\n        const routeParamKeys = new Set();\n        const combinedParamKeys = [];\n        // We don't include rewriteParamKeys in the combinedParamKeys\n        // for app router since the searchParams is populated from the\n        // URL so we don't want to strip the rewrite params from the URL\n        // so that searchParams can include them.\n        if (this.definition.kind === RouteKind.PAGES || this.definition.kind === RouteKind.PAGES_API) {\n            for (const key of [\n                ...rewriteParamKeys,\n                ...Object.keys(serverUtils.defaultRouteMatches || {})\n            ]){\n                // We only want to filter rewrite param keys from the URL\n                // if they are matches from the URL e.g. the key/value matches\n                // before and after applying the rewrites /:path for /hello and\n                // { path: 'hello' } but not for { path: 'another' } and /hello\n                // TODO: we should prefix rewrite param keys the same as we do\n                // for dynamic routes so we can identify them properly\n                const originalValue = Array.isArray(originalQuery[key]) ? originalQuery[key].join('') : originalQuery[key];\n                const queryValue = Array.isArray(query[key]) ? query[key].join('') : query[key];\n                if (!(key in originalQuery) || originalValue === queryValue) {\n                    combinedParamKeys.push(key);\n                }\n            }\n        }\n        serverUtils.normalizeCdnUrl(req, combinedParamKeys);\n        serverUtils.normalizeQueryParams(query, routeParamKeys);\n        serverUtils.filterInternalQuery(originalQuery, combinedParamKeys);\n        if (pageIsDynamic) {\n            const queryResult = serverUtils.normalizeDynamicRouteParams(query, true);\n            const paramsResult = serverUtils.normalizeDynamicRouteParams(params || {}, true);\n            let paramsToInterpolate;\n            if (// if both query and params are valid but one\n            // provided more information rely on that one\n            query && params && paramsResult.hasValidParams && queryResult.hasValidParams && Object.keys(paramsResult.params).length < Object.keys(queryResult.params).length) {\n                paramsToInterpolate = queryResult.params;\n                params = Object.assign(queryResult.params);\n            } else {\n                paramsToInterpolate = paramsResult.hasValidParams && params ? params : queryResult.hasValidParams ? query : {};\n            }\n            req.url = serverUtils.interpolateDynamicPath(req.url || '/', paramsToInterpolate);\n            parsedUrl.pathname = serverUtils.interpolateDynamicPath(parsedUrl.pathname || '/', paramsToInterpolate);\n            originalPathname = serverUtils.interpolateDynamicPath(originalPathname, paramsToInterpolate);\n            // try pulling from query if valid\n            if (!params) {\n                if (queryResult.hasValidParams) {\n                    params = Object.assign({}, queryResult.params);\n                    // If we pulled from query remove it so it's\n                    // only in params\n                    for(const key in serverUtils.defaultRouteMatches){\n                        delete query[key];\n                    }\n                } else {\n                    // use final params from URL matching\n                    const paramsMatch = serverUtils.dynamicRouteMatcher == null ? void 0 : serverUtils.dynamicRouteMatcher.call(serverUtils, normalizeDataPath((localeResult == null ? void 0 : localeResult.pathname) || parsedUrl.pathname || '/'));\n                    // we don't normalize these as they are allowed to be\n                    // the literal slug matches here e.g. /blog/[slug]\n                    // actually being requested\n                    if (paramsMatch) {\n                        params = Object.assign({}, paramsMatch);\n                    }\n                }\n            }\n        }\n        // Remove any normalized params from the query if they\n        // weren't present as non-prefixed query key e.g.\n        // ?search=1&nxtPsearch=hello we don't delete search\n        for (const key of routeParamKeys){\n            if (!(key in originalQuery)) {\n                delete query[key];\n            }\n        }\n        const { isOnDemandRevalidate, revalidateOnlyGenerated } = checkIsOnDemandRevalidate(req, prerenderManifest.preview);\n        let isDraftMode = false;\n        let previewData;\n        // preview data relies on non-edge utils\n        if (process.env.NEXT_RUNTIME !== 'edge' && res) {\n            const { tryGetPreviewData } = require('../api-utils/node/try-get-preview-data');\n            previewData = tryGetPreviewData(req, res, prerenderManifest.preview, Boolean(multiZoneDraftMode));\n            isDraftMode = previewData !== false;\n        }\n        const relativeProjectDir = getRequestMeta(req, 'relativeProjectDir') || this.relativeProjectDir;\n        const routerServerContext = (_routerServerGlobal_RouterServerContextSymbol = routerServerGlobal[RouterServerContextSymbol]) == null ? void 0 : _routerServerGlobal_RouterServerContextSymbol[relativeProjectDir];\n        const nextConfig = (routerServerContext == null ? void 0 : routerServerContext.nextConfig) || (serverFilesManifest == null ? void 0 : serverFilesManifest.config);\n        if (!nextConfig) {\n            throw Object.defineProperty(new Error(\"Invariant: nextConfig couldn't be loaded\"), \"__NEXT_ERROR_CODE\", {\n                value: \"E969\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        let resolvedPathname = normalizedSrcPage;\n        if (isDynamicRoute(resolvedPathname) && params) {\n            resolvedPathname = serverUtils.interpolateDynamicPath(resolvedPathname, params);\n        }\n        if (resolvedPathname === '/index') {\n            resolvedPathname = '/';\n        }\n        const encodedResolvedPathname = resolvedPathname;\n        // we decode for cache key/manifest usage encoded is\n        // for URL building\n        try {\n            resolvedPathname = decodePathParams(resolvedPathname);\n        } catch (_) {}\n        resolvedPathname = removeTrailingSlash(resolvedPathname);\n        let deploymentId;\n        if ((_nextConfig_experimental = nextConfig.experimental) == null ? void 0 : _nextConfig_experimental.runtimeServerDeploymentId) {\n            if (!process.env.NEXT_DEPLOYMENT_ID) {\n                throw Object.defineProperty(new Error('process.env.NEXT_DEPLOYMENT_ID is missing but runtimeServerDeploymentId is enabled'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E970\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            deploymentId = process.env.NEXT_DEPLOYMENT_ID;\n        } else {\n            deploymentId = nextConfig.deploymentId || '';\n        }\n        return {\n            query,\n            originalQuery,\n            originalPathname,\n            params,\n            parsedUrl,\n            locale,\n            isNextDataRequest,\n            locales: i18n == null ? void 0 : i18n.locales,\n            defaultLocale,\n            isDraftMode,\n            previewData,\n            pageIsDynamic,\n            resolvedPathname,\n            encodedResolvedPathname,\n            isOnDemandRevalidate,\n            revalidateOnlyGenerated,\n            ...manifests,\n            // loadManifest returns a readonly object, but we don't want to propagate that throughout the\n            // whole codebase (for now)\n            nextConfig: nextConfig,\n            routerServerContext,\n            deploymentId\n        };\n    }\n    getResponseCache(req) {\n        if (!this.responseCache) {\n            const minimalMode = (Boolean(process.env.MINIMAL_MODE) || getRequestMeta(req, 'minimalMode')) ?? false;\n            this.responseCache = new ResponseCache(minimalMode);\n        }\n        return this.responseCache;\n    }\n    async handleResponse({ req, nextConfig, cacheKey, routeKind, isFallback, prerenderManifest, isRoutePPREnabled, isOnDemandRevalidate, revalidateOnlyGenerated, responseGenerator, waitUntil, isMinimalMode }) {\n        const responseCache = this.getResponseCache(req);\n        const cacheEntry = await responseCache.get(cacheKey, responseGenerator, {\n            routeKind,\n            isFallback,\n            isRoutePPREnabled,\n            isOnDemandRevalidate,\n            isPrefetch: req.headers.purpose === 'prefetch',\n            // Use x-invocation-id header to scope the in-memory cache to a single\n            // revalidation request in minimal mode.\n            invocationID: req.headers['x-invocation-id'],\n            incrementalCache: await this.getIncrementalCache(req, nextConfig, prerenderManifest, isMinimalMode),\n            waitUntil\n        });\n        if (!cacheEntry) {\n            if (cacheKey && // revalidate only generated can bail even if cacheKey is provided\n            !(isOnDemandRevalidate && revalidateOnlyGenerated)) {\n                // A cache entry might not be generated if a response is written\n                // in `getInitialProps` or `getServerSideProps`, but those shouldn't\n                // have a cache key. If we do have a cache key but we don't end up\n                // with a cache entry, then either Next.js or the application has a\n                // bug that needs fixing.\n                throw Object.defineProperty(new Error('invariant: cache entry required but not generated'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E62\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n        }\n        return cacheEntry;\n    }\n}\n\n//# sourceMappingURL=route-module.js.map","import { isPlainObject } from '../shared/lib/is-plain-object';\n/**\n * This is a safe stringify function that handles circular references.\n * We're using a simpler version here to avoid introducing\n * the dependency `safe-stable-stringify` into production bundle.\n *\n * This helper is used both in development and production.\n */ function safeStringifyLite(obj) {\n    const seen = new WeakSet();\n    return JSON.stringify(obj, (_key, value)=>{\n        // If value is an object and already seen, replace with \"[Circular]\"\n        if (typeof value === 'object' && value !== null) {\n            if (seen.has(value)) {\n                return '[Circular]';\n            }\n            seen.add(value);\n        }\n        return value;\n    });\n}\n/**\n * Checks whether the given value is a NextError.\n * This can be used to print a more detailed error message with properties like `code` & `digest`.\n */ export default function isError(err) {\n    return typeof err === 'object' && err !== null && 'name' in err && 'message' in err;\n}\nexport function getProperError(err) {\n    if (isError(err)) {\n        return err;\n    }\n    if (process.env.NODE_ENV === 'development') {\n        // provide better error for case where `throw undefined`\n        // is called in development\n        if (typeof err === 'undefined') {\n            return Object.defineProperty(new Error('An undefined error was thrown, ' + 'see here for more info: https://nextjs.org/docs/messages/threw-undefined'), \"__NEXT_ERROR_CODE\", {\n                value: \"E98\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        if (err === null) {\n            return Object.defineProperty(new Error('A null error was thrown, ' + 'see here for more info: https://nextjs.org/docs/messages/threw-undefined'), \"__NEXT_ERROR_CODE\", {\n                value: \"E336\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n    return Object.defineProperty(new Error(isPlainObject(err) ? safeStringifyLite(err) : err + ''), \"__NEXT_ERROR_CODE\", {\n        value: \"E394\",\n        enumerable: false,\n        configurable: true\n    });\n}\n\n//# sourceMappingURL=is-error.js.map","import { normalizePathSep } from '../../shared/lib/page-path/normalize-path-sep';\nimport { normalizeAppPath } from '../../shared/lib/router/utils/app-paths';\nimport { isAppRouteRoute } from '../is-app-route-route';\nexport const STATIC_METADATA_IMAGES = {\n    icon: {\n        filename: 'icon',\n        extensions: [\n            'ico',\n            'jpg',\n            'jpeg',\n            'png',\n            'svg'\n        ]\n    },\n    apple: {\n        filename: 'apple-icon',\n        extensions: [\n            'jpg',\n            'jpeg',\n            'png'\n        ]\n    },\n    favicon: {\n        filename: 'favicon',\n        extensions: [\n            'ico'\n        ]\n    },\n    openGraph: {\n        filename: 'opengraph-image',\n        extensions: [\n            'jpg',\n            'jpeg',\n            'png',\n            'gif'\n        ]\n    },\n    twitter: {\n        filename: 'twitter-image',\n        extensions: [\n            'jpg',\n            'jpeg',\n            'png',\n            'gif'\n        ]\n    }\n};\n// Match routes that are metadata routes, e.g. /sitemap.xml, /favicon.<ext>, /<icon>.<ext>, etc.\n// TODO-METADATA: support more metadata routes with more extensions\nexport const DEFAULT_METADATA_ROUTE_EXTENSIONS = [\n    'js',\n    'jsx',\n    'ts',\n    'tsx'\n];\n// Match the file extension with the dynamic multi-routes extensions\n// e.g. ([xml, js], null) -> can match `/sitemap.xml/route`, `sitemap.js/route`\n// e.g. ([png], [ts]) -> can match `/opengraph-image.png`, `/opengraph-image.ts`\nexport const getExtensionRegexString = (staticExtensions, dynamicExtensions)=>{\n    let result;\n    // If there's no possible multi dynamic routes, will not match any <name>[].<ext> files\n    if (!dynamicExtensions || dynamicExtensions.length === 0) {\n        result = `(\\\\.(?:${staticExtensions.join('|')}))`;\n    } else {\n        result = `(?:\\\\.(${staticExtensions.join('|')})|(\\\\.(${dynamicExtensions.join('|')})))`;\n    }\n    return result;\n};\n/**\n * Matches the static metadata files, e.g. /robots.txt, /sitemap.xml, /favicon.ico, etc.\n * @param appDirRelativePath the relative file path to app/\n * @returns if the path is a static metadata file route\n */ export function isStaticMetadataFile(appDirRelativePath) {\n    return isMetadataRouteFile(appDirRelativePath, [], true);\n}\n// Pre-compiled static regexes for common cases\nconst FAVICON_REGEX = /^[\\\\/]favicon\\.ico$/;\nconst ROBOTS_TXT_REGEX = /^[\\\\/]robots\\.txt$/;\nconst MANIFEST_JSON_REGEX = /^[\\\\/]manifest\\.json$/;\nconst MANIFEST_WEBMANIFEST_REGEX = /^[\\\\/]manifest\\.webmanifest$/;\nconst SITEMAP_XML_REGEX = /[\\\\/]sitemap\\.xml$/;\n// Cache for compiled regex patterns based on parameters\nconst compiledRegexCache = new Map();\n// Fast path checks for common metadata files\nfunction fastPathCheck(normalizedPath) {\n    // Check favicon.ico first (most common)\n    if (FAVICON_REGEX.test(normalizedPath)) return true;\n    // Check other common static files\n    if (ROBOTS_TXT_REGEX.test(normalizedPath)) return true;\n    if (MANIFEST_JSON_REGEX.test(normalizedPath)) return true;\n    if (MANIFEST_WEBMANIFEST_REGEX.test(normalizedPath)) return true;\n    if (SITEMAP_XML_REGEX.test(normalizedPath)) return true;\n    // Quick negative check - if it doesn't contain any metadata keywords, skip\n    if (!normalizedPath.includes('robots') && !normalizedPath.includes('manifest') && !normalizedPath.includes('sitemap') && !normalizedPath.includes('icon') && !normalizedPath.includes('apple-icon') && !normalizedPath.includes('opengraph-image') && !normalizedPath.includes('twitter-image') && !normalizedPath.includes('favicon')) {\n        return false;\n    }\n    return null // Continue with full regex matching\n    ;\n}\nfunction getCompiledRegexes(pageExtensions, strictlyMatchExtensions) {\n    // Create cache key\n    const cacheKey = `${pageExtensions.join(',')}|${strictlyMatchExtensions}`;\n    const cached = compiledRegexCache.get(cacheKey);\n    if (cached) {\n        return cached;\n    }\n    // Pre-compute common strings\n    const trailingMatcher = strictlyMatchExtensions ? '$' : '?$';\n    const variantsMatcher = '\\\\d?';\n    const groupSuffix = strictlyMatchExtensions ? '' : '(-\\\\w{6})?';\n    const suffixMatcher = variantsMatcher + groupSuffix;\n    // Pre-compute extension arrays to avoid repeated concatenation\n    const robotsExts = pageExtensions.length > 0 ? [\n        ...pageExtensions,\n        'txt'\n    ] : [\n        'txt'\n    ];\n    const manifestExts = pageExtensions.length > 0 ? [\n        ...pageExtensions,\n        'webmanifest',\n        'json'\n    ] : [\n        'webmanifest',\n        'json'\n    ];\n    const regexes = [\n        new RegExp(`^[\\\\\\\\/]robots${getExtensionRegexString(robotsExts, null)}${trailingMatcher}`),\n        new RegExp(`^[\\\\\\\\/]manifest${getExtensionRegexString(manifestExts, null)}${trailingMatcher}`),\n        // FAVICON_REGEX removed - already handled in fastPathCheck\n        new RegExp(`[\\\\\\\\/]sitemap${getExtensionRegexString([\n            'xml'\n        ], pageExtensions)}${trailingMatcher}`),\n        new RegExp(`[\\\\\\\\/]icon${suffixMatcher}${getExtensionRegexString(STATIC_METADATA_IMAGES.icon.extensions, pageExtensions)}${trailingMatcher}`),\n        new RegExp(`[\\\\\\\\/]apple-icon${suffixMatcher}${getExtensionRegexString(STATIC_METADATA_IMAGES.apple.extensions, pageExtensions)}${trailingMatcher}`),\n        new RegExp(`[\\\\\\\\/]opengraph-image${suffixMatcher}${getExtensionRegexString(STATIC_METADATA_IMAGES.openGraph.extensions, pageExtensions)}${trailingMatcher}`),\n        new RegExp(`[\\\\\\\\/]twitter-image${suffixMatcher}${getExtensionRegexString(STATIC_METADATA_IMAGES.twitter.extensions, pageExtensions)}${trailingMatcher}`)\n    ];\n    compiledRegexCache.set(cacheKey, regexes);\n    return regexes;\n}\n/**\n * Determine if the file is a metadata route file entry\n * @param appDirRelativePath the relative file path to app/\n * @param pageExtensions the js extensions, such as ['js', 'jsx', 'ts', 'tsx']\n * @param strictlyMatchExtensions if it's true, match the file with page extension, otherwise match the file with default corresponding extension\n * @returns if the file is a metadata route file\n */ export function isMetadataRouteFile(appDirRelativePath, pageExtensions, strictlyMatchExtensions) {\n    // Early exit for empty or obviously non-metadata paths\n    if (!appDirRelativePath || appDirRelativePath.length < 2) {\n        return false;\n    }\n    const normalizedPath = normalizePathSep(appDirRelativePath);\n    // Fast path check for common cases\n    const fastResult = fastPathCheck(normalizedPath);\n    if (fastResult !== null) {\n        return fastResult;\n    }\n    // Get compiled regexes from cache\n    const regexes = getCompiledRegexes(pageExtensions, strictlyMatchExtensions);\n    // Use for loop instead of .some() for better performance\n    for(let i = 0; i < regexes.length; i++){\n        if (regexes[i].test(normalizedPath)) {\n            return true;\n        }\n    }\n    return false;\n}\n// Check if the route is a static metadata route, with /route suffix\n// e.g. /favicon.ico/route, /icon.png/route, etc.\n// But skip the text routes like robots.txt since they might also be dynamic.\n// Checking route path is not enough to determine if text routes is dynamic.\nexport function isStaticMetadataRoute(route) {\n    // extract ext with regex\n    const pathname = route.replace(/\\/route$/, '');\n    const matched = isAppRouteRoute(route) && isMetadataRouteFile(pathname, [], true) && // These routes can either be built by static or dynamic entrypoints,\n    // so we assume they're dynamic\n    pathname !== '/robots.txt' && pathname !== '/manifest.webmanifest' && !pathname.endsWith('/sitemap.xml');\n    return matched;\n}\n/**\n * Determine if a page or pathname is a metadata page.\n *\n * The input is a page or pathname, which can be with or without page suffix /foo/page or /foo.\n * But it will not contain the /route suffix.\n *\n * .e.g\n * /robots -> true\n * /sitemap -> true\n * /foo -> false\n */ export function isMetadataPage(page) {\n    const matched = !isAppRouteRoute(page) && isMetadataRouteFile(page, [], false);\n    return matched;\n}\n/*\n * Determine if a Next.js route is a metadata route.\n * `route` will has a route suffix.\n *\n * e.g.\n * /app/robots/route -> true\n * /robots/route -> true\n * /sitemap/[__metadata_id__]/route -> true\n * /app/sitemap/page -> false\n * /icon-a102f4/route -> true\n */ export function isMetadataRoute(route) {\n    let page = normalizeAppPath(route).replace(/^\\/?app\\//, '')// Remove the dynamic route id\n    .replace('/[__metadata_id__]', '')// Remove the /route suffix\n    .replace(/\\/route$/, '');\n    if (page[0] !== '/') page = '/' + page;\n    const matched = isAppRouteRoute(route) && isMetadataRouteFile(page, [], false);\n    return matched;\n}\n\n//# sourceMappingURL=is-metadata-route.js.map","import escapePathDelimiters from '../../../shared/lib/router/utils/escape-path-delimiters';\nimport { DecodeError } from '../../../shared/lib/utils';\n/**\n * We only encode path delimiters for path segments from\n * getStaticPaths so we need to attempt decoding the URL\n * to match against and only escape the path delimiters\n * this allows non-ascii values to be handled e.g.\n * Japanese characters.\n * */ function decodePathParams(pathname) {\n    // TODO: investigate adding this handling for non-SSG\n    // pages so non-ascii names also work there.\n    return pathname.split('/').map((seg)=>{\n        try {\n            seg = escapePathDelimiters(decodeURIComponent(seg), true);\n        } catch (_) {\n            // An improperly encoded URL was provided\n            throw Object.defineProperty(new DecodeError('Failed to decode path param(s).'), \"__NEXT_ERROR_CODE\", {\n                value: \"E539\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        return seg;\n    }).join('/');\n}\nexport { decodePathParams };\n\n//# sourceMappingURL=decode-path-params.js.map","import { HTTP_METHODS } from '../../../web/http';\nconst AUTOMATIC_ROUTE_METHODS = [\n    'HEAD',\n    'OPTIONS'\n];\nfunction handleMethodNotAllowedResponse() {\n    return new Response(null, {\n        status: 405\n    });\n}\nexport function autoImplementMethods(handlers) {\n    // Loop through all the HTTP methods to create the initial methods object.\n    // Each of the methods will be set to the 405 response handler.\n    const methods = HTTP_METHODS.reduce((acc, method)=>({\n            ...acc,\n            // If the userland module implements the method, then use it. Otherwise,\n            // use the 405 response handler.\n            [method]: handlers[method] ?? handleMethodNotAllowedResponse\n        }), {});\n    // Get all the methods that could be automatically implemented that were not\n    // implemented by the userland module.\n    const implemented = new Set(HTTP_METHODS.filter((method)=>handlers[method]));\n    const missing = AUTOMATIC_ROUTE_METHODS.filter((method)=>!implemented.has(method));\n    // Loop over the missing methods to automatically implement them if we can.\n    for (const method of missing){\n        // If the userland module doesn't implement the HEAD method, then\n        // we'll automatically implement it by calling the GET method (if it\n        // exists).\n        if (method === 'HEAD') {\n            if (handlers.GET) {\n                // Implement the HEAD method by calling the GET method.\n                methods.HEAD = handlers.GET;\n                // Mark it as implemented.\n                implemented.add('HEAD');\n            }\n            continue;\n        }\n        // If OPTIONS is not provided then implement it.\n        if (method === 'OPTIONS') {\n            // TODO: check if HEAD is implemented, if so, use it to add more headers\n            // Get all the methods that were implemented by the userland module.\n            const allow = [\n                'OPTIONS',\n                ...implemented\n            ];\n            // If the list of methods doesn't include HEAD, but it includes GET, then\n            // add HEAD as it's automatically implemented.\n            if (!implemented.has('HEAD') && implemented.has('GET')) {\n                allow.push('HEAD');\n            }\n            // Sort and join the list with commas to create the `Allow` header. See:\n            // https://httpwg.org/specs/rfc9110.html#field.allow\n            const headers = {\n                Allow: allow.sort().join(', ')\n            };\n            // Implement the OPTIONS method by returning a 204 response with the\n            // `Allow` header.\n            methods.OPTIONS = ()=>new Response(null, {\n                    status: 204,\n                    headers\n                });\n            // Mark this method as implemented.\n            implemented.add('OPTIONS');\n            continue;\n        }\n        throw Object.defineProperty(new Error(`Invariant: should handle all automatic implementable methods, got method: ${method}`), \"__NEXT_ERROR_CODE\", {\n            value: \"E211\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    return methods;\n}\n\n//# sourceMappingURL=auto-implement-methods.js.map","import { ACTION_HEADER } from '../../client/components/app-router-headers';\nexport function getServerActionRequestMetadata(req) {\n    let actionId;\n    let contentType;\n    if (req.headers instanceof Headers) {\n        actionId = req.headers.get(ACTION_HEADER) ?? null;\n        contentType = req.headers.get('content-type');\n    } else {\n        actionId = req.headers[ACTION_HEADER] ?? null;\n        contentType = req.headers['content-type'] ?? null;\n    }\n    // We don't actually support URL encoded actions, and the action handler will bail out if it sees one.\n    // But we still want it to flow through to the action handler, to prevent changes in behavior when a regular\n    // page component tries to handle a POST.\n    const isURLEncodedAction = Boolean(req.method === 'POST' && contentType === 'application/x-www-form-urlencoded');\n    const isMultipartAction = Boolean(req.method === 'POST' && (contentType == null ? void 0 : contentType.startsWith('multipart/form-data')));\n    const isFetchAction = Boolean(actionId !== undefined && typeof actionId === 'string' && req.method === 'POST');\n    const isPossibleServerAction = Boolean(isFetchAction || isURLEncodedAction || isMultipartAction);\n    return {\n        actionId,\n        isURLEncodedAction,\n        isMultipartAction,\n        isFetchAction,\n        isPossibleServerAction\n    };\n}\nexport function getIsPossibleServerAction(req) {\n    return getServerActionRequestMetadata(req).isPossibleServerAction;\n}\n\n//# sourceMappingURL=server-action-request-meta.js.map","// escape delimiters used by path-to-regexp\nexport default function escapePathDelimiters(segment, escapeEncoded) {\n    return segment.replace(new RegExp(`([/#?]${escapeEncoded ? '|%(2f|23|3f|5c)' : ''})`, 'gi'), (char)=>encodeURIComponent(char));\n}\n\n//# sourceMappingURL=escape-path-delimiters.js.map","import { RedirectStatusCode } from './redirect-status-code';\nimport { RedirectType, isRedirectError, REDIRECT_ERROR_CODE } from './redirect-error';\nconst actionAsyncStorage = typeof window === 'undefined' ? require('../../server/app-render/action-async-storage.external').actionAsyncStorage : undefined;\nexport function getRedirectError(url, type, statusCode = RedirectStatusCode.TemporaryRedirect) {\n    const error = Object.defineProperty(new Error(REDIRECT_ERROR_CODE), \"__NEXT_ERROR_CODE\", {\n        value: \"E394\",\n        enumerable: false,\n        configurable: true\n    });\n    error.digest = `${REDIRECT_ERROR_CODE};${type};${url};${statusCode};`;\n    return error;\n}\n/**\n * This function allows you to redirect the user to another URL. It can be used in\n * [Server Components](https://nextjs.org/docs/app/building-your-application/rendering/server-components),\n * [Route Handlers](https://nextjs.org/docs/app/building-your-application/routing/route-handlers), and\n * [Server Actions](https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations).\n *\n * - In a Server Component, this will insert a meta tag to redirect the user to the target page.\n * - In a Route Handler or Server Action, it will serve a 307/303 to the caller.\n * - In a Server Action, type defaults to 'push' and 'replace' elsewhere.\n *\n * Read more: [Next.js Docs: `redirect`](https://nextjs.org/docs/app/api-reference/functions/redirect)\n */ export function redirect(/** The URL to redirect to */ url, type) {\n    type ??= actionAsyncStorage?.getStore()?.isAction ? RedirectType.push : RedirectType.replace;\n    throw getRedirectError(url, type, RedirectStatusCode.TemporaryRedirect);\n}\n/**\n * This function allows you to redirect the user to another URL. It can be used in\n * [Server Components](https://nextjs.org/docs/app/building-your-application/rendering/server-components),\n * [Route Handlers](https://nextjs.org/docs/app/building-your-application/routing/route-handlers), and\n * [Server Actions](https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations).\n *\n * - In a Server Component, this will insert a meta tag to redirect the user to the target page.\n * - In a Route Handler or Server Action, it will serve a 308/303 to the caller.\n *\n * Read more: [Next.js Docs: `redirect`](https://nextjs.org/docs/app/api-reference/functions/redirect)\n */ export function permanentRedirect(/** The URL to redirect to */ url, type = RedirectType.replace) {\n    throw getRedirectError(url, type, RedirectStatusCode.PermanentRedirect);\n}\nexport function getURLFromRedirectError(error) {\n    if (!isRedirectError(error)) return null;\n    // Slices off the beginning of the digest that contains the code and the\n    // separating ';'.\n    return error.digest.split(';').slice(2, -2).join(';');\n}\nexport function getRedirectTypeFromError(error) {\n    if (!isRedirectError(error)) {\n        throw Object.defineProperty(new Error('Not a redirect error'), \"__NEXT_ERROR_CODE\", {\n            value: \"E260\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    return error.digest.split(';', 2)[1];\n}\nexport function getRedirectStatusCodeFromError(error) {\n    if (!isRedirectError(error)) {\n        throw Object.defineProperty(new Error('Not a redirect error'), \"__NEXT_ERROR_CODE\", {\n            value: \"E260\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    return Number(error.digest.split(';').at(-2));\n}\n\n//# sourceMappingURL=redirect.js.map","import { CacheSignal } from '../cache-signal';\nimport { isThenable } from '../../../shared/lib/is-thenable';\n/**\n * Tracks all in-flight async imports and chunk loads.\n * Initialized lazily, because we don't want this to error in case it gets pulled into an edge runtime module.\n */ let _moduleLoadingSignal;\nfunction getModuleLoadingSignal() {\n    if (!_moduleLoadingSignal) {\n        _moduleLoadingSignal = new CacheSignal();\n    }\n    return _moduleLoadingSignal;\n}\nexport function trackPendingChunkLoad(promise) {\n    const moduleLoadingSignal = getModuleLoadingSignal();\n    moduleLoadingSignal.trackRead(promise);\n}\nexport function trackPendingImport(exportsOrPromise) {\n    const moduleLoadingSignal = getModuleLoadingSignal();\n    // requiring an async module returns a promise.\n    // if it's sync, there's nothing to track.\n    if (isThenable(exportsOrPromise)) {\n        // A client reference proxy might look like a promise, but we can only call `.then()` on it, not e.g. `.finally()`.\n        // Turn it into a real promise to avoid issues elsewhere.\n        const promise = Promise.resolve(exportsOrPromise);\n        moduleLoadingSignal.trackRead(promise);\n    }\n}\n/**\n * A top-level dynamic import (or chunk load):\n *\n *   1. delays a prerender (potentially for a task or longer)\n *   2. may reveal more caches that need be filled\n *\n * So if we see one, we want to extend the duration of `cacheSignal` at least until the import/chunk-load is done.\n */ export function trackPendingModules(cacheSignal) {\n    const moduleLoadingSignal = getModuleLoadingSignal();\n    // We can't just use `cacheSignal.trackRead(moduleLoadingSignal.cacheReady())`,\n    // because we might start and finish multiple batches of module loads while waiting for caches,\n    // and `moduleLoadingSignal.cacheReady()` would resolve after the first batch.\n    // Instead, we'll keep notifying `cacheSignal` of each import/chunk-load.\n    const unsubscribe = moduleLoadingSignal.subscribeToReads(cacheSignal);\n    // Later, when `cacheSignal` is no longer waiting for any caches (or imports that we've notified it of),\n    // we can unsubscribe it.\n    cacheSignal.cacheReady().then(unsubscribe);\n}\n\n//# sourceMappingURL=track-module-loading.instance.js.map","// TODO: isWellKnownError -> isNextInternalError\n// isReactLargeShellError -> isWarning\nexport function isReactLargeShellError(error) {\n    return typeof error === 'object' && error !== null && 'message' in error && typeof error.message === 'string' && error.message.startsWith('This rendered a large document (>');\n}\n\n//# sourceMappingURL=react-large-shell-error.js.map","import { getDigestForWellKnownError } from './create-error-handler';\nimport { isReactLargeShellError } from './react-large-shell-error';\nexport var Phase = /*#__PURE__*/ function(Phase) {\n    Phase[\"ProspectiveRender\"] = \"the prospective render\";\n    Phase[\"SegmentCollection\"] = \"segment collection\";\n    return Phase;\n}({});\nexport function printDebugThrownValueForProspectiveRender(thrownValue, route, phase) {\n    // We don't need to print well-known Next.js errors.\n    if (getDigestForWellKnownError(thrownValue)) {\n        return;\n    }\n    if (isReactLargeShellError(thrownValue)) {\n        // TODO: Aggregate\n        console.error(thrownValue);\n        return undefined;\n    }\n    let message;\n    if (typeof thrownValue === 'object' && thrownValue !== null && typeof thrownValue.message === 'string') {\n        message = thrownValue.message;\n        if (typeof thrownValue.stack === 'string') {\n            const originalErrorStack = thrownValue.stack;\n            const stackStart = originalErrorStack.indexOf('\\n');\n            if (stackStart > -1) {\n                const error = Object.defineProperty(new Error(`Route ${route} errored during ${phase}. These errors are normally ignored and may not prevent the route from prerendering but are logged here because build debugging is enabled.\n          \nOriginal Error: ${message}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E949\",\n                    enumerable: false,\n                    configurable: true\n                });\n                error.stack = 'Error: ' + error.message + originalErrorStack.slice(stackStart);\n                console.error(error);\n                return;\n            }\n        }\n    } else if (typeof thrownValue === 'string') {\n        message = thrownValue;\n    }\n    if (message) {\n        console.error(`Route ${route} errored during ${phase}. These errors are normally ignored and may not prevent the route from prerendering but are logged here because build debugging is enabled. No stack was provided.\n          \nOriginal Message: ${message}`);\n        return;\n    }\n    console.error(`Route ${route} errored during ${phase}. These errors are normally ignored and may not prevent the route from prerendering but are logged here because build debugging is enabled. The thrown value is logged just following this message`);\n    console.error(thrownValue);\n    return;\n}\n\n//# sourceMappingURL=prospective-render-utils.js.map","/**\n * Interop between \"export default\" and \"module.exports\".\n */ export function interopDefault(mod) {\n    return mod.default || mod;\n}\n\n//# sourceMappingURL=interop-default.js.map","/**\n * List of valid HTTP methods that can be implemented by Next.js's Custom App\n * Routes.\n */ export const HTTP_METHODS = [\n    'GET',\n    'HEAD',\n    'OPTIONS',\n    'POST',\n    'PUT',\n    'DELETE',\n    'PATCH'\n];\n/**\n * Checks to see if the passed string is an HTTP method. Note that this is case\n * sensitive.\n *\n * @param maybeMethod the string that may be an HTTP method\n * @returns true if the string is an HTTP method\n */ export function isHTTPMethod(maybeMethod) {\n    return HTTP_METHODS.includes(maybeMethod);\n}\n\n//# sourceMappingURL=http.js.map","/**\n * For a given page path, this function ensures that there is no backslash\n * escaping slashes in the path. Example:\n *  - `foo\\/bar\\/baz` -> `foo/bar/baz`\n */ export function normalizePathSep(path) {\n    return path.replace(/\\\\/g, '/');\n}\n\n//# sourceMappingURL=normalize-path-sep.js.map","/**\n * Converts the query into params.\n *\n * @param query the query to convert to params\n * @returns the params\n */ export function parsedUrlQueryToParams(query) {\n    const params = {};\n    for (const [key, value] of Object.entries(query)){\n        if (typeof value === 'undefined') continue;\n        params[key] = value;\n    }\n    return params;\n}\n\n//# sourceMappingURL=parsed-url-query-to-params.js.map","/**\n * Cleans a URL by stripping the protocol, host, and search params.\n *\n * @param urlString the url to clean\n * @returns the cleaned url\n */ export function cleanURL(url) {\n    const u = new URL(url);\n    u.host = 'localhost:3000';\n    u.search = '';\n    u.protocol = 'http';\n    return u;\n}\n\n//# sourceMappingURL=clean-url.js.map","import { workAsyncStorage } from '../app-render/work-async-storage.external';\nimport { ReflectAdapter } from '../web/spec-extension/adapters/reflect';\nimport { throwToInterruptStaticGeneration, postponeWithTracking, delayUntilRuntimeStage } from '../app-render/dynamic-rendering';\nimport { workUnitAsyncStorage, throwInvariantForMissingStore } from '../app-render/work-unit-async-storage.external';\nimport { InvariantError } from '../../shared/lib/invariant-error';\nimport { describeStringPropertyAccess, wellKnownProperties } from '../../shared/lib/utils/reflect-utils';\nimport { makeDevtoolsIOAwarePromise, makeHangingPromise } from '../dynamic-rendering-utils';\nimport { createDedupedByCallsiteServerErrorLoggerDev } from '../create-deduped-by-callsite-server-error-logger';\nimport { dynamicAccessAsyncStorage } from '../app-render/dynamic-access-async-storage.external';\nimport { RenderStage } from '../app-render/staged-rendering';\nexport function createParamsFromClient(underlyingParams, workStore) {\n    const workUnitStore = workUnitAsyncStorage.getStore();\n    if (workUnitStore) {\n        switch(workUnitStore.type){\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n                return createStaticPrerenderParams(underlyingParams, workStore, workUnitStore);\n            case 'cache':\n            case 'private-cache':\n            case 'unstable-cache':\n                throw Object.defineProperty(new InvariantError('createParamsFromClient should not be called in cache contexts.'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E736\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender-runtime':\n                throw Object.defineProperty(new InvariantError('createParamsFromClient should not be called in a runtime prerender.'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E770\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'request':\n                if (process.env.NODE_ENV === 'development') {\n                    // Semantically we only need the dev tracking when running in `next dev`\n                    // but since you would never use next dev with production NODE_ENV we use this\n                    // as a proxy so we can statically exclude this code from production builds.\n                    const devFallbackParams = workUnitStore.devFallbackParams;\n                    return createRenderParamsInDev(underlyingParams, devFallbackParams, workStore, workUnitStore);\n                } else {\n                    return createRenderParamsInProd(underlyingParams);\n                }\n            default:\n                workUnitStore;\n        }\n    }\n    throwInvariantForMissingStore();\n}\nexport const createServerParamsForMetadata = createServerParamsForServerSegment;\n// routes always runs in RSC context so it is equivalent to a Server Page Component\nexport function createServerParamsForRoute(underlyingParams, workStore) {\n    const workUnitStore = workUnitAsyncStorage.getStore();\n    if (workUnitStore) {\n        switch(workUnitStore.type){\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n                return createStaticPrerenderParams(underlyingParams, workStore, workUnitStore);\n            case 'cache':\n            case 'private-cache':\n            case 'unstable-cache':\n                throw Object.defineProperty(new InvariantError('createServerParamsForRoute should not be called in cache contexts.'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E738\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender-runtime':\n                return createRuntimePrerenderParams(underlyingParams, workUnitStore);\n            case 'request':\n                if (process.env.NODE_ENV === 'development') {\n                    // Semantically we only need the dev tracking when running in `next dev`\n                    // but since you would never use next dev with production NODE_ENV we use this\n                    // as a proxy so we can statically exclude this code from production builds.\n                    const devFallbackParams = workUnitStore.devFallbackParams;\n                    return createRenderParamsInDev(underlyingParams, devFallbackParams, workStore, workUnitStore);\n                } else {\n                    return createRenderParamsInProd(underlyingParams);\n                }\n            default:\n                workUnitStore;\n        }\n    }\n    throwInvariantForMissingStore();\n}\nexport function createServerParamsForServerSegment(underlyingParams, workStore) {\n    const workUnitStore = workUnitAsyncStorage.getStore();\n    if (workUnitStore) {\n        switch(workUnitStore.type){\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n                return createStaticPrerenderParams(underlyingParams, workStore, workUnitStore);\n            case 'cache':\n            case 'private-cache':\n            case 'unstable-cache':\n                throw Object.defineProperty(new InvariantError('createServerParamsForServerSegment should not be called in cache contexts.'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E743\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender-runtime':\n                return createRuntimePrerenderParams(underlyingParams, workUnitStore);\n            case 'request':\n                if (process.env.NODE_ENV === 'development') {\n                    // Semantically we only need the dev tracking when running in `next dev`\n                    // but since you would never use next dev with production NODE_ENV we use this\n                    // as a proxy so we can statically exclude this code from production builds.\n                    const devFallbackParams = workUnitStore.devFallbackParams;\n                    return createRenderParamsInDev(underlyingParams, devFallbackParams, workStore, workUnitStore);\n                } else {\n                    return createRenderParamsInProd(underlyingParams);\n                }\n            default:\n                workUnitStore;\n        }\n    }\n    throwInvariantForMissingStore();\n}\nexport function createPrerenderParamsForClientSegment(underlyingParams) {\n    const workStore = workAsyncStorage.getStore();\n    if (!workStore) {\n        throw Object.defineProperty(new InvariantError('Missing workStore in createPrerenderParamsForClientSegment'), \"__NEXT_ERROR_CODE\", {\n            value: \"E773\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    const workUnitStore = workUnitAsyncStorage.getStore();\n    if (workUnitStore) {\n        switch(workUnitStore.type){\n            case 'prerender':\n            case 'prerender-client':\n                const fallbackParams = workUnitStore.fallbackRouteParams;\n                if (fallbackParams) {\n                    for(let key in underlyingParams){\n                        if (fallbackParams.has(key)) {\n                            // This params object has one or more fallback params, so we need\n                            // to consider the awaiting of this params object \"dynamic\". Since\n                            // we are in cacheComponents mode we encode this as a promise that never\n                            // resolves.\n                            return makeHangingPromise(workUnitStore.renderSignal, workStore.route, '`params`');\n                        }\n                    }\n                }\n                break;\n            case 'cache':\n            case 'private-cache':\n            case 'unstable-cache':\n                throw Object.defineProperty(new InvariantError('createPrerenderParamsForClientSegment should not be called in cache contexts.'), \"__NEXT_ERROR_CODE\", {\n                    value: \"E734\",\n                    enumerable: false,\n                    configurable: true\n                });\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'prerender-runtime':\n            case 'request':\n                break;\n            default:\n                workUnitStore;\n        }\n    }\n    // We're prerendering in a mode that does not abort. We resolve the promise without\n    // any tracking because we're just transporting a value from server to client where the tracking\n    // will be applied.\n    return Promise.resolve(underlyingParams);\n}\nfunction createStaticPrerenderParams(underlyingParams, workStore, prerenderStore) {\n    switch(prerenderStore.type){\n        case 'prerender':\n        case 'prerender-client':\n            {\n                const fallbackParams = prerenderStore.fallbackRouteParams;\n                if (fallbackParams) {\n                    for(const key in underlyingParams){\n                        if (fallbackParams.has(key)) {\n                            // This params object has one or more fallback params, so we need\n                            // to consider the awaiting of this params object \"dynamic\". Since\n                            // we are in cacheComponents mode we encode this as a promise that never\n                            // resolves.\n                            return makeHangingParams(underlyingParams, workStore, prerenderStore);\n                        }\n                    }\n                }\n                break;\n            }\n        case 'prerender-ppr':\n            {\n                const fallbackParams = prerenderStore.fallbackRouteParams;\n                if (fallbackParams) {\n                    for(const key in underlyingParams){\n                        if (fallbackParams.has(key)) {\n                            return makeErroringParams(underlyingParams, fallbackParams, workStore, prerenderStore);\n                        }\n                    }\n                }\n                break;\n            }\n        case 'prerender-legacy':\n            break;\n        default:\n            prerenderStore;\n    }\n    return makeUntrackedParams(underlyingParams);\n}\nfunction createRuntimePrerenderParams(underlyingParams, workUnitStore) {\n    return delayUntilRuntimeStage(workUnitStore, makeUntrackedParams(underlyingParams));\n}\nfunction createRenderParamsInProd(underlyingParams) {\n    return makeUntrackedParams(underlyingParams);\n}\nfunction createRenderParamsInDev(underlyingParams, devFallbackParams, workStore, requestStore) {\n    let hasFallbackParams = false;\n    if (devFallbackParams) {\n        for(let key in underlyingParams){\n            if (devFallbackParams.has(key)) {\n                hasFallbackParams = true;\n                break;\n            }\n        }\n    }\n    return makeDynamicallyTrackedParamsWithDevWarnings(underlyingParams, hasFallbackParams, workStore, requestStore);\n}\nconst CachedParams = new WeakMap();\nconst fallbackParamsProxyHandler = {\n    get: function get(target, prop, receiver) {\n        if (prop === 'then' || prop === 'catch' || prop === 'finally') {\n            const originalMethod = ReflectAdapter.get(target, prop, receiver);\n            return ({\n                [prop]: (...args)=>{\n                    const store = dynamicAccessAsyncStorage.getStore();\n                    if (store) {\n                        store.abortController.abort(Object.defineProperty(new Error(`Accessed fallback \\`params\\` during prerendering.`), \"__NEXT_ERROR_CODE\", {\n                            value: \"E691\",\n                            enumerable: false,\n                            configurable: true\n                        }));\n                    }\n                    return new Proxy(originalMethod.apply(target, args), fallbackParamsProxyHandler);\n                }\n            })[prop];\n        }\n        return ReflectAdapter.get(target, prop, receiver);\n    }\n};\nfunction makeHangingParams(underlyingParams, workStore, prerenderStore) {\n    const cachedParams = CachedParams.get(underlyingParams);\n    if (cachedParams) {\n        return cachedParams;\n    }\n    const promise = new Proxy(makeHangingPromise(prerenderStore.renderSignal, workStore.route, '`params`'), fallbackParamsProxyHandler);\n    CachedParams.set(underlyingParams, promise);\n    return promise;\n}\nfunction makeErroringParams(underlyingParams, fallbackParams, workStore, prerenderStore) {\n    const cachedParams = CachedParams.get(underlyingParams);\n    if (cachedParams) {\n        return cachedParams;\n    }\n    const augmentedUnderlying = {\n        ...underlyingParams\n    };\n    // We don't use makeResolvedReactPromise here because params\n    // supports copying with spread and we don't want to unnecessarily\n    // instrument the promise with spreadable properties of ReactPromise.\n    const promise = Promise.resolve(augmentedUnderlying);\n    CachedParams.set(underlyingParams, promise);\n    Object.keys(underlyingParams).forEach((prop)=>{\n        if (wellKnownProperties.has(prop)) {\n        // These properties cannot be shadowed because they need to be the\n        // true underlying value for Promises to work correctly at runtime\n        } else {\n            if (fallbackParams.has(prop)) {\n                Object.defineProperty(augmentedUnderlying, prop, {\n                    get () {\n                        const expression = describeStringPropertyAccess('params', prop);\n                        // In most dynamic APIs we also throw if `dynamic = \"error\"` however\n                        // for params is only dynamic when we're generating a fallback shell\n                        // and even when `dynamic = \"error\"` we still support generating dynamic\n                        // fallback shells\n                        // TODO remove this comment when cacheComponents is the default since there\n                        // will be no `dynamic = \"error\"`\n                        if (prerenderStore.type === 'prerender-ppr') {\n                            // PPR Prerender (no cacheComponents)\n                            postponeWithTracking(workStore.route, expression, prerenderStore.dynamicTracking);\n                        } else {\n                            // Legacy Prerender\n                            throwToInterruptStaticGeneration(expression, workStore, prerenderStore);\n                        }\n                    },\n                    enumerable: true\n                });\n            }\n        }\n    });\n    return promise;\n}\nfunction makeUntrackedParams(underlyingParams) {\n    const cachedParams = CachedParams.get(underlyingParams);\n    if (cachedParams) {\n        return cachedParams;\n    }\n    const promise = Promise.resolve(underlyingParams);\n    CachedParams.set(underlyingParams, promise);\n    return promise;\n}\nfunction makeDynamicallyTrackedParamsWithDevWarnings(underlyingParams, hasFallbackParams, workStore, requestStore) {\n    if (requestStore.asyncApiPromises && hasFallbackParams) {\n        // We wrap each instance of params in a `new Promise()`, because deduping\n        // them across requests doesn't work anyway and this let us show each\n        // await a different set of values. This is important when all awaits\n        // are in third party which would otherwise track all the way to the\n        // internal params.\n        const sharedParamsParent = requestStore.asyncApiPromises.sharedParamsParent;\n        const promise = new Promise((resolve, reject)=>{\n            sharedParamsParent.then(()=>resolve(underlyingParams), reject);\n        });\n        // @ts-expect-error\n        promise.displayName = 'params';\n        return instrumentParamsPromiseWithDevWarnings(underlyingParams, promise, workStore);\n    }\n    const cachedParams = CachedParams.get(underlyingParams);\n    if (cachedParams) {\n        return cachedParams;\n    }\n    // We don't use makeResolvedReactPromise here because params\n    // supports copying with spread and we don't want to unnecessarily\n    // instrument the promise with spreadable properties of ReactPromise.\n    const promise = hasFallbackParams ? makeDevtoolsIOAwarePromise(underlyingParams, requestStore, RenderStage.Runtime) : Promise.resolve(underlyingParams);\n    const proxiedPromise = instrumentParamsPromiseWithDevWarnings(underlyingParams, promise, workStore);\n    CachedParams.set(underlyingParams, proxiedPromise);\n    return proxiedPromise;\n}\nfunction instrumentParamsPromiseWithDevWarnings(underlyingParams, promise, workStore) {\n    // Track which properties we should warn for.\n    const proxiedProperties = new Set();\n    Object.keys(underlyingParams).forEach((prop)=>{\n        if (wellKnownProperties.has(prop)) {\n        // These properties cannot be shadowed because they need to be the\n        // true underlying value for Promises to work correctly at runtime\n        } else {\n            proxiedProperties.add(prop);\n        }\n    });\n    return new Proxy(promise, {\n        get (target, prop, receiver) {\n            if (typeof prop === 'string') {\n                if (// We are accessing a property that was proxied to the promise instance\n                proxiedProperties.has(prop)) {\n                    const expression = describeStringPropertyAccess('params', prop);\n                    warnForSyncAccess(workStore.route, expression);\n                }\n            }\n            return ReflectAdapter.get(target, prop, receiver);\n        },\n        set (target, prop, value, receiver) {\n            if (typeof prop === 'string') {\n                proxiedProperties.delete(prop);\n            }\n            return ReflectAdapter.set(target, prop, value, receiver);\n        },\n        ownKeys (target) {\n            const expression = '`...params` or similar expression';\n            warnForSyncAccess(workStore.route, expression);\n            return Reflect.ownKeys(target);\n        }\n    });\n}\nconst warnForSyncAccess = createDedupedByCallsiteServerErrorLoggerDev(createParamsAccessError);\nfunction createParamsAccessError(route, expression) {\n    const prefix = route ? `Route \"${route}\" ` : 'This route ';\n    return Object.defineProperty(new Error(`${prefix}used ${expression}. ` + `\\`params\\` is a Promise and must be unwrapped with \\`await\\` or \\`React.use()\\` before accessing its properties. ` + `Learn more: https://nextjs.org/docs/messages/sync-dynamic-apis`), \"__NEXT_ERROR_CODE\", {\n        value: \"E834\",\n        enumerable: false,\n        configurable: true\n    });\n}\n\n//# sourceMappingURL=params.js.map","import { isHTTPAccessFallbackError } from './http-access-fallback/http-access-fallback';\nimport { isRedirectError } from './redirect-error';\n/**\n * Returns true if the error is a navigation signal error. These errors are\n * thrown by user code to perform navigation operations and interrupt the React\n * render.\n */ export function isNextRouterError(error) {\n    return isRedirectError(error) || isHTTPAccessFallbackError(error);\n}\n\n//# sourceMappingURL=is-next-router-error.js.map","import { arrayBufferToString, stringToUint8Array } from '../app-render/encryption-utils';\nimport { DYNAMIC_EXPIRE } from '../use-cache/constants';\n/**\n * Parses serialized cache entries into a UseCacheCacheStore\n * @param entries - The serialized entries to parse\n * @returns A new UseCacheCacheStore containing the parsed entries\n */ export function parseUseCacheCacheStore(entries) {\n    const store = new Map();\n    for (const [key, { value, tags, stale, timestamp, expire, revalidate }] of entries){\n        store.set(key, Promise.resolve({\n            // Create a ReadableStream from the Uint8Array\n            value: new ReadableStream({\n                start (controller) {\n                    // Enqueue the Uint8Array to the stream\n                    controller.enqueue(stringToUint8Array(atob(value)));\n                    // Close the stream\n                    controller.close();\n                }\n            }),\n            tags,\n            stale,\n            timestamp,\n            expire,\n            revalidate\n        }));\n    }\n    return store;\n}\n/**\n * Serializes UseCacheCacheStore entries into an array of key-value pairs\n * @param entries - The store entries to stringify\n * @returns A promise that resolves to an array of key-value pairs with serialized values\n */ export async function serializeUseCacheCacheStore(entries, isCacheComponentsEnabled) {\n    return Promise.all(Array.from(entries).map(([key, value])=>{\n        return value.then(async (entry)=>{\n            if (isCacheComponentsEnabled && (entry.revalidate === 0 || entry.expire < DYNAMIC_EXPIRE)) {\n                // The entry was omitted from the prerender result, and subsequently\n                // does not need to be included in the serialized RDC.\n                return null;\n            }\n            const [left, right] = entry.value.tee();\n            entry.value = right;\n            let binaryString = '';\n            // We want to encode the value as a string, but we aren't sure if the\n            // value is a a stream of UTF-8 bytes or not, so let's just encode it\n            // as a string using base64.\n            for await (const chunk of left){\n                binaryString += arrayBufferToString(chunk);\n            }\n            return [\n                key,\n                {\n                    // Encode the value as a base64 string.\n                    value: btoa(binaryString),\n                    tags: entry.tags,\n                    stale: entry.stale,\n                    timestamp: entry.timestamp,\n                    expire: entry.expire,\n                    revalidate: entry.revalidate\n                }\n            ];\n        }).catch(()=>{\n            // Any failed cache writes should be ignored as to not discard the\n            // entire cache.\n            return null;\n        });\n    }));\n}\n\n//# sourceMappingURL=cache-store.js.map","// route handlers are only statically optimized if they define\n// one of these top-level configs manually\n//   - dynamic = 'force-static'\n//   - dynamic = 'error'\n//   - revalidate > 0\n//   - revalidate = false\n//   - generateStaticParams\nexport function isStaticGenEnabled(mod) {\n    return mod.dynamic === 'force-static' || mod.dynamic === 'error' || mod.revalidate === false || mod.revalidate !== undefined && mod.revalidate > 0 || typeof mod.generateStaticParams == 'function';\n}\n\n//# sourceMappingURL=is-static-gen-enabled.js.map","import { InvariantError } from '../../shared/lib/invariant-error';\nimport { serializeUseCacheCacheStore, parseUseCacheCacheStore } from './cache-store';\n/**\n * Serializes a resume data cache into a JSON string for storage or\n * transmission. Handles 'use cache' values, fetch responses, and encrypted\n * bound args for inline server functions.\n *\n * @param resumeDataCache - The immutable cache to serialize\n * @returns A Promise that resolves to the serialized cache as a JSON string, or\n * 'null' if empty\n */ export async function stringifyResumeDataCache(resumeDataCache, isCacheComponentsEnabled) {\n    if (process.env.NEXT_RUNTIME === 'edge') {\n        throw Object.defineProperty(new InvariantError('`stringifyResumeDataCache` should not be called in edge runtime.'), \"__NEXT_ERROR_CODE\", {\n            value: \"E602\",\n            enumerable: false,\n            configurable: true\n        });\n    } else {\n        if (resumeDataCache.fetch.size === 0 && resumeDataCache.cache.size === 0) {\n            return 'null';\n        }\n        const json = {\n            store: {\n                fetch: Object.fromEntries(Array.from(resumeDataCache.fetch.entries())),\n                cache: Object.fromEntries((await serializeUseCacheCacheStore(resumeDataCache.cache.entries(), isCacheComponentsEnabled)).filter((entry)=>entry !== null)),\n                encryptedBoundArgs: Object.fromEntries(Array.from(resumeDataCache.encryptedBoundArgs.entries()))\n            }\n        };\n        // Compress the JSON string using zlib. As the data we already want to\n        // decompress is in memory, we use the synchronous deflateSync function.\n        const { deflateSync } = require('node:zlib');\n        return deflateSync(JSON.stringify(json)).toString('base64');\n    }\n}\n/**\n * Creates a new empty mutable resume data cache for pre-rendering.\n * Initializes fresh Map instances for both the 'use cache' and fetch caches.\n * Used at the start of pre-rendering to begin collecting cached values.\n *\n * @returns A new empty PrerenderResumeDataCache instance\n */ export function createPrerenderResumeDataCache() {\n    return {\n        cache: new Map(),\n        fetch: new Map(),\n        encryptedBoundArgs: new Map(),\n        decryptedBoundArgs: new Map()\n    };\n}\nexport function createRenderResumeDataCache(resumeDataCacheOrPersistedCache, maxPostponedStateSizeBytes) {\n    if (process.env.NEXT_RUNTIME === 'edge') {\n        throw Object.defineProperty(new InvariantError('`createRenderResumeDataCache` should not be called in edge runtime.'), \"__NEXT_ERROR_CODE\", {\n            value: \"E556\",\n            enumerable: false,\n            configurable: true\n        });\n    } else {\n        if (typeof resumeDataCacheOrPersistedCache !== 'string') {\n            // If the cache is already a prerender or render cache, we can return it\n            // directly. For the former, we're just performing a type change.\n            return resumeDataCacheOrPersistedCache;\n        }\n        if (resumeDataCacheOrPersistedCache === 'null') {\n            return {\n                cache: new Map(),\n                fetch: new Map(),\n                encryptedBoundArgs: new Map(),\n                decryptedBoundArgs: new Map()\n            };\n        }\n        // This should be a compressed string. Let's decompress it using zlib.\n        // As the data we already want to decompress is in memory, we use the\n        // synchronous inflateSync function.\n        const { inflateSync } = require('node:zlib');\n        // Limit decompressed size to prevent zipbomb attacks. This is 5x the\n        // configured maxPostponedStateSize, allowing reasonable compression\n        // ratios while preventing extreme decompression bombs.\n        // Default is 500MB (5x the default 100MB compressed limit).\n        const maxDecompressedSize = maxPostponedStateSizeBytes ? maxPostponedStateSizeBytes * 5 : 500 * 1024 * 1024;\n        let json;\n        try {\n            json = JSON.parse(inflateSync(Buffer.from(resumeDataCacheOrPersistedCache, 'base64'), {\n                maxOutputLength: maxDecompressedSize\n            }).toString('utf-8'));\n        } catch (err) {\n            if (err instanceof RangeError && err.code === 'ERR_BUFFER_TOO_LARGE') {\n                throw Object.defineProperty(new Error(`Decompressed resume data cache exceeded ${maxDecompressedSize} byte limit`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E976\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            throw err;\n        }\n        return {\n            cache: parseUseCacheCacheStore(Object.entries(json.store.cache)),\n            fetch: new Map(Object.entries(json.store.fetch)),\n            encryptedBoundArgs: new Map(Object.entries(json.store.encryptedBoundArgs)),\n            decryptedBoundArgs: new Map()\n        };\n    }\n}\n\n//# sourceMappingURL=resume-data-cache.js.map","if (process.env.NEXT_RUNTIME === 'edge') {\n  module.exports = require('next/dist/server/route-modules/app-route/module.js')\n} else {\n  if (process.env.__NEXT_EXPERIMENTAL_REACT) {\n    if (process.env.NODE_ENV === 'development') {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-route-turbo-experimental.runtime.dev.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-route-experimental.runtime.dev.js')\n      }\n    } else {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-route-turbo-experimental.runtime.prod.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-route-experimental.runtime.prod.js')\n      }\n    }\n  } else {\n    if (process.env.NODE_ENV === 'development') {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-route-turbo.runtime.dev.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-route.runtime.dev.js')\n      }\n    } else {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-route-turbo.runtime.prod.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-route.runtime.prod.js')\n      }\n    }\n  }\n}\n","import { isDynamicRoute } from '../../shared/lib/router/utils';\nimport { getRouteMatcher } from '../../shared/lib/router/utils/route-matcher';\nimport { getRouteRegex } from '../../shared/lib/router/utils/route-regex';\nexport class RouteMatcher {\n    constructor(definition){\n        this.definition = definition;\n        if (isDynamicRoute(definition.pathname)) {\n            this.dynamic = getRouteMatcher(getRouteRegex(definition.pathname));\n        }\n    }\n    /**\n   * Identity returns the identity part of the matcher. This is used to compare\n   * a unique matcher to another. This is also used when sorting dynamic routes,\n   * so it must contain the pathname part.\n   */ get identity() {\n        return this.definition.pathname;\n    }\n    get isDynamic() {\n        return this.dynamic !== undefined;\n    }\n    match(pathname) {\n        const result = this.test(pathname);\n        if (!result) return null;\n        return {\n            definition: this.definition,\n            params: result.params\n        };\n    }\n    test(pathname) {\n        if (this.dynamic) {\n            const params = this.dynamic(pathname);\n            if (!params) return null;\n            return {\n                params\n            };\n        }\n        if (pathname === this.definition.pathname) {\n            return {};\n        }\n        return null;\n    }\n}\n\n//# sourceMappingURL=route-matcher.js.map","// An internal module to expose the \"waitUntil\" API to Edge SSR and Edge Route Handler functions.\n// This is highly experimental and subject to change.\n// We still need a global key to bypass Webpack's layering of modules.\nconst GLOBAL_KEY = Symbol.for('__next_internal_waitUntil__');\nconst state = // @ts-ignore\nglobalThis[GLOBAL_KEY] || // @ts-ignore\n(globalThis[GLOBAL_KEY] = {\n    waitUntilCounter: 0,\n    waitUntilResolve: undefined,\n    waitUntilPromise: null\n});\n// No matter how many concurrent requests are being handled, we want to make sure\n// that the final promise is only resolved once all of the waitUntil promises have\n// settled.\nfunction resolveOnePromise() {\n    state.waitUntilCounter--;\n    if (state.waitUntilCounter === 0) {\n        state.waitUntilResolve();\n        state.waitUntilPromise = null;\n    }\n}\nexport function internal_getCurrentFunctionWaitUntil() {\n    return state.waitUntilPromise;\n}\nexport function internal_runWithWaitUntil(fn) {\n    const result = fn();\n    if (result && typeof result === 'object' && 'then' in result && 'finally' in result && typeof result.then === 'function' && typeof result.finally === 'function') {\n        if (!state.waitUntilCounter) {\n            // Create the promise for the next batch of waitUntil calls.\n            state.waitUntilPromise = new Promise((resolve)=>{\n                state.waitUntilResolve = resolve;\n            });\n        }\n        state.waitUntilCounter++;\n        return result.finally(()=>{\n            resolveOnePromise();\n        });\n    }\n    return result;\n}\n\n//# sourceMappingURL=internal-edge-wait-until.js.map","import { RedirectStatusCode } from '../../client/components/redirect-status-code';\nimport { getCookieParser } from '../api-utils/get-cookie-parser';\nexport class BaseNextRequest {\n    constructor(method, url, body){\n        this.method = method;\n        this.url = url;\n        this.body = body;\n    }\n    // Utils implemented using the abstract methods above\n    get cookies() {\n        if (this._cookies) return this._cookies;\n        return this._cookies = getCookieParser(this.headers)();\n    }\n}\nexport class BaseNextResponse {\n    constructor(destination){\n        this.destination = destination;\n    }\n    // Utils implemented using the abstract methods above\n    redirect(destination, statusCode) {\n        this.setHeader('Location', destination);\n        this.statusCode = statusCode;\n        // Since IE11 doesn't support the 308 header add backwards\n        // compatibility using refresh header\n        if (statusCode === RedirectStatusCode.PermanentRedirect) {\n            this.setHeader('Refresh', `0;url=${destination}`);\n        }\n        return this;\n    }\n}\n\n//# sourceMappingURL=index.js.map","import { PageSignatureError } from './error';\nimport { fromNodeOutgoingHttpHeaders, normalizeNextQueryParam } from './utils';\nimport { NextFetchEvent, getWaitUntilPromiseFromEvent } from './spec-extension/fetch-event';\nimport { NextRequest } from './spec-extension/request';\nimport { NextResponse } from './spec-extension/response';\nimport { parseRelativeURL, getRelativeURL } from '../../shared/lib/router/utils/relativize-url';\nimport { NextURL } from './next-url';\nimport { stripInternalSearchParams } from '../internal-utils';\nimport { normalizeRscURL } from '../../shared/lib/router/utils/app-paths';\nimport { FLIGHT_HEADERS, NEXT_REWRITTEN_PATH_HEADER, NEXT_REWRITTEN_QUERY_HEADER, NEXT_RSC_UNION_QUERY, RSC_HEADER } from '../../client/components/app-router-headers';\nimport { ensureInstrumentationRegistered } from './globals';\nimport { createRequestStoreForAPI } from '../async-storage/request-store';\nimport { workUnitAsyncStorage } from '../app-render/work-unit-async-storage.external';\nimport { createWorkStore } from '../async-storage/work-store';\nimport { workAsyncStorage } from '../app-render/work-async-storage.external';\nimport { NEXT_ROUTER_PREFETCH_HEADER } from '../../client/components/app-router-headers';\nimport { getTracer } from '../lib/trace/tracer';\nimport { MiddlewareSpan } from '../lib/trace/constants';\nimport { CloseController } from './web-on-close';\nimport { getEdgePreviewProps } from './get-edge-preview-props';\nimport { getBuiltinRequestContext } from '../after/builtin-request-context';\nimport { getImplicitTags } from '../lib/implicit-tags';\nexport class NextRequestHint extends NextRequest {\n    constructor(params){\n        super(params.input, params.init);\n        this.sourcePage = params.page;\n    }\n    get request() {\n        throw Object.defineProperty(new PageSignatureError({\n            page: this.sourcePage\n        }), \"__NEXT_ERROR_CODE\", {\n            value: \"E394\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    respondWith() {\n        throw Object.defineProperty(new PageSignatureError({\n            page: this.sourcePage\n        }), \"__NEXT_ERROR_CODE\", {\n            value: \"E394\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    waitUntil() {\n        throw Object.defineProperty(new PageSignatureError({\n            page: this.sourcePage\n        }), \"__NEXT_ERROR_CODE\", {\n            value: \"E394\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n}\nconst headersGetter = {\n    keys: (headers)=>Array.from(headers.keys()),\n    get: (headers, key)=>headers.get(key) ?? undefined\n};\nlet propagator = (request, fn)=>{\n    const tracer = getTracer();\n    return tracer.withPropagatedContext(request.headers, fn, headersGetter);\n};\nlet testApisIntercepted = false;\nfunction ensureTestApisIntercepted() {\n    if (!testApisIntercepted) {\n        testApisIntercepted = true;\n        if (process.env.NEXT_PRIVATE_TEST_PROXY === 'true') {\n            const { interceptTestApis, wrapRequestHandler } = // eslint-disable-next-line @next/internal/typechecked-require -- experimental/testmode is not built ins next/dist/esm\n            require('next/dist/experimental/testmode/server-edge');\n            interceptTestApis();\n            propagator = wrapRequestHandler(propagator);\n        }\n    }\n}\nexport async function adapter(params) {\n    var _getBuiltinRequestContext;\n    ensureTestApisIntercepted();\n    await ensureInstrumentationRegistered();\n    // TODO-APP: use explicit marker for this\n    const isEdgeRendering = typeof globalThis.__BUILD_MANIFEST !== 'undefined';\n    params.request.url = normalizeRscURL(params.request.url);\n    const requestURL = params.bypassNextUrl ? new URL(params.request.url) : new NextURL(params.request.url, {\n        headers: params.request.headers,\n        nextConfig: params.request.nextConfig\n    });\n    // Iterator uses an index to keep track of the current iteration. Because of deleting and appending below we can't just use the iterator.\n    // Instead we use the keys before iteration.\n    const keys = [\n        ...requestURL.searchParams.keys()\n    ];\n    for (const key of keys){\n        const value = requestURL.searchParams.getAll(key);\n        const normalizedKey = normalizeNextQueryParam(key);\n        if (normalizedKey) {\n            requestURL.searchParams.delete(normalizedKey);\n            for (const val of value){\n                requestURL.searchParams.append(normalizedKey, val);\n            }\n            requestURL.searchParams.delete(key);\n        }\n    }\n    // Ensure users only see page requests, never data requests.\n    let buildId = process.env.__NEXT_BUILD_ID || '';\n    if ('buildId' in requestURL) {\n        buildId = requestURL.buildId || '';\n        requestURL.buildId = '';\n    }\n    const requestHeaders = fromNodeOutgoingHttpHeaders(params.request.headers);\n    const isNextDataRequest = requestHeaders.has('x-nextjs-data');\n    const isRSCRequest = requestHeaders.get(RSC_HEADER) === '1';\n    if (isNextDataRequest && requestURL.pathname === '/index') {\n        requestURL.pathname = '/';\n    }\n    const flightHeaders = new Map();\n    // Headers should only be stripped for middleware\n    if (!isEdgeRendering) {\n        for (const header of FLIGHT_HEADERS){\n            const value = requestHeaders.get(header);\n            if (value !== null) {\n                flightHeaders.set(header, value);\n                requestHeaders.delete(header);\n            }\n        }\n    }\n    const normalizeURL = process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE ? new URL(params.request.url) : requestURL;\n    const rscHash = normalizeURL.searchParams.get(NEXT_RSC_UNION_QUERY);\n    const request = new NextRequestHint({\n        page: params.page,\n        // Strip internal query parameters off the request.\n        input: stripInternalSearchParams(normalizeURL).toString(),\n        init: {\n            body: params.request.body,\n            headers: requestHeaders,\n            method: params.request.method,\n            nextConfig: params.request.nextConfig,\n            signal: params.request.signal\n        }\n    });\n    /**\n   * This allows to identify the request as a data request. The user doesn't\n   * need to know about this property neither use it. We add it for testing\n   * purposes.\n   */ if (isNextDataRequest) {\n        Object.defineProperty(request, '__isData', {\n            enumerable: false,\n            value: true\n        });\n    }\n    if (// If we are inside of the next start sandbox\n    // leverage the shared instance if not we need\n    // to create a fresh cache instance each time\n    !globalThis.__incrementalCacheShared && params.IncrementalCache) {\n        ;\n        globalThis.__incrementalCache = new params.IncrementalCache({\n            CurCacheHandler: params.incrementalCacheHandler,\n            minimalMode: process.env.NODE_ENV !== 'development',\n            fetchCacheKeyPrefix: process.env.__NEXT_FETCH_CACHE_KEY_PREFIX,\n            dev: process.env.NODE_ENV === 'development',\n            requestHeaders: params.request.headers,\n            getPrerenderManifest: ()=>{\n                return {\n                    version: -1,\n                    routes: {},\n                    dynamicRoutes: {},\n                    notFoundRoutes: [],\n                    preview: getEdgePreviewProps()\n                };\n            }\n        });\n    }\n    // if we're in an edge runtime sandbox, we should use the waitUntil\n    // that we receive from the enclosing NextServer\n    const outerWaitUntil = params.request.waitUntil ?? ((_getBuiltinRequestContext = getBuiltinRequestContext()) == null ? void 0 : _getBuiltinRequestContext.waitUntil);\n    const event = new NextFetchEvent({\n        request,\n        page: params.page,\n        context: outerWaitUntil ? {\n            waitUntil: outerWaitUntil\n        } : undefined\n    });\n    let response;\n    let cookiesFromResponse;\n    response = await propagator(request, ()=>{\n        // we only care to make async storage available for middleware\n        const isMiddleware = params.page === '/middleware' || params.page === '/src/middleware' || params.page === '/proxy' || params.page === '/src/proxy';\n        if (isMiddleware) {\n            // if we're in an edge function, we only get a subset of `nextConfig` (no `experimental`),\n            // so we have to inject it via DefinePlugin.\n            // in `next start` this will be passed normally (see `NextNodeServer.runMiddleware`).\n            const waitUntil = event.waitUntil.bind(event);\n            const closeController = new CloseController();\n            return getTracer().trace(MiddlewareSpan.execute, {\n                spanName: `middleware ${request.method}`,\n                attributes: {\n                    'http.target': request.nextUrl.pathname,\n                    'http.method': request.method\n                }\n            }, async ()=>{\n                try {\n                    var _params_request_nextConfig_experimental, _params_request_nextConfig, _params_request_nextConfig_experimental1, _params_request_nextConfig1;\n                    const onUpdateCookies = (cookies)=>{\n                        cookiesFromResponse = cookies;\n                    };\n                    const previewProps = getEdgePreviewProps();\n                    const page = '/' // Fake Work\n                    ;\n                    const fallbackRouteParams = null;\n                    const implicitTags = await getImplicitTags(page, request.nextUrl, fallbackRouteParams);\n                    const requestStore = createRequestStoreForAPI(request, request.nextUrl, implicitTags, onUpdateCookies, previewProps);\n                    const workStore = createWorkStore({\n                        page,\n                        renderOpts: {\n                            cacheLifeProfiles: (_params_request_nextConfig = params.request.nextConfig) == null ? void 0 : (_params_request_nextConfig_experimental = _params_request_nextConfig.experimental) == null ? void 0 : _params_request_nextConfig_experimental.cacheLife,\n                            cacheComponents: false,\n                            experimental: {\n                                isRoutePPREnabled: false,\n                                authInterrupts: !!((_params_request_nextConfig1 = params.request.nextConfig) == null ? void 0 : (_params_request_nextConfig_experimental1 = _params_request_nextConfig1.experimental) == null ? void 0 : _params_request_nextConfig_experimental1.authInterrupts)\n                            },\n                            supportsDynamicResponse: true,\n                            waitUntil,\n                            onClose: closeController.onClose.bind(closeController),\n                            onAfterTaskError: undefined\n                        },\n                        isPrefetchRequest: request.headers.get(NEXT_ROUTER_PREFETCH_HEADER) === '1',\n                        buildId: buildId ?? '',\n                        previouslyRevalidatedTags: []\n                    });\n                    return await workAsyncStorage.run(workStore, ()=>workUnitAsyncStorage.run(requestStore, params.handler, request, event));\n                } finally{\n                    // middleware cannot stream, so we can consider the response closed\n                    // as soon as the handler returns.\n                    // we can delay running it until a bit later --\n                    // if it's needed, we'll have a `waitUntil` lock anyway.\n                    setTimeout(()=>{\n                        closeController.dispatchClose();\n                    }, 0);\n                }\n            });\n        }\n        return params.handler(request, event);\n    });\n    // check if response is a Response object\n    if (response && !(response instanceof Response)) {\n        throw Object.defineProperty(new TypeError('Expected an instance of Response to be returned'), \"__NEXT_ERROR_CODE\", {\n            value: \"E567\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    if (response && cookiesFromResponse) {\n        response.headers.set('set-cookie', cookiesFromResponse);\n    }\n    /**\n   * For rewrites we must always include the locale in the final pathname\n   * so we re-create the NextURL forcing it to include it when the it is\n   * an internal rewrite. Also we make sure the outgoing rewrite URL is\n   * a data URL if the request was a data request.\n   */ const rewrite = response == null ? void 0 : response.headers.get('x-middleware-rewrite');\n    if (response && rewrite && (isRSCRequest || !isEdgeRendering)) {\n        var _params_request_nextConfig_experimental_clientParamParsingOrigins, _params_request_nextConfig_experimental, _params_request_nextConfig;\n        const destination = new NextURL(rewrite, {\n            forceLocale: true,\n            headers: params.request.headers,\n            nextConfig: params.request.nextConfig\n        });\n        if (!process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE && !isEdgeRendering) {\n            if (destination.host === request.nextUrl.host) {\n                destination.buildId = buildId || destination.buildId;\n                response.headers.set('x-middleware-rewrite', String(destination));\n            }\n        }\n        /**\n     * When the request is a data request we must show if there was a rewrite\n     * with an internal header so the client knows which component to load\n     * from the data request.\n     */ const { url: relativeDestination, isRelative } = parseRelativeURL(destination.toString(), requestURL.toString());\n        if (!isEdgeRendering && isNextDataRequest && // if the rewrite is external and external rewrite\n        // resolving config is enabled don't add this header\n        // so the upstream app can set it instead\n        !(process.env.__NEXT_EXTERNAL_MIDDLEWARE_REWRITE_RESOLVE && relativeDestination.match(/http(s)?:\\/\\//))) {\n            response.headers.set('x-nextjs-rewrite', relativeDestination);\n        }\n        // Check to see if this is a non-relative rewrite. If it is, we need\n        // to check to see if it's an allowed origin to receive the rewritten\n        // headers.\n        const isAllowedOrigin = !isRelative ? (_params_request_nextConfig = params.request.nextConfig) == null ? void 0 : (_params_request_nextConfig_experimental = _params_request_nextConfig.experimental) == null ? void 0 : (_params_request_nextConfig_experimental_clientParamParsingOrigins = _params_request_nextConfig_experimental.clientParamParsingOrigins) == null ? void 0 : _params_request_nextConfig_experimental_clientParamParsingOrigins.some((origin)=>new RegExp(origin).test(destination.origin)) : false;\n        // If this is an RSC request, and the pathname or search has changed, and\n        // this isn't an external rewrite, we need to set the rewritten pathname and\n        // query headers.\n        if (isRSCRequest && (isRelative || isAllowedOrigin)) {\n            if (requestURL.pathname !== destination.pathname) {\n                response.headers.set(NEXT_REWRITTEN_PATH_HEADER, destination.pathname);\n            }\n            if (requestURL.search !== destination.search) {\n                response.headers.set(NEXT_REWRITTEN_QUERY_HEADER, // remove the leading ? from the search string\n                destination.search.slice(1));\n            }\n        }\n    }\n    /**\n   * Always forward the `_rsc` search parameter to the rewritten URL for RSC requests,\n   * unless it's already present. This is necessary to ensure that RSC hash validation\n   * works correctly after a rewrite. For internal rewrites, the server can validate the\n   * RSC hash using the original URL, so forwarding the `_rsc` parameter is less critical.\n   * However, for external rewrites (where the request is proxied to another Next.js server),\n   * the external server does not have access to the original URL or its search parameters.\n   * In these cases, forwarding the `_rsc` parameter is essential so that the external server\n   * can perform the correct RSC hash validation.\n   */ if (response && rewrite && isRSCRequest && rscHash) {\n        const rewriteURL = new URL(rewrite);\n        if (!rewriteURL.searchParams.has(NEXT_RSC_UNION_QUERY)) {\n            rewriteURL.searchParams.set(NEXT_RSC_UNION_QUERY, rscHash);\n            response.headers.set('x-middleware-rewrite', rewriteURL.toString());\n        }\n    }\n    /**\n   * For redirects we will not include the locale in case when it is the\n   * default and we must also make sure the outgoing URL is a data one if\n   * the incoming request was a data request.\n   */ const redirect = response == null ? void 0 : response.headers.get('Location');\n    if (response && redirect && !isEdgeRendering) {\n        const redirectURL = new NextURL(redirect, {\n            forceLocale: false,\n            headers: params.request.headers,\n            nextConfig: params.request.nextConfig\n        });\n        /**\n     * Responses created from redirects have immutable headers so we have\n     * to clone the response to be able to modify it.\n     */ response = new Response(response.body, response);\n        if (!process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE) {\n            if (redirectURL.host === requestURL.host) {\n                redirectURL.buildId = buildId || redirectURL.buildId;\n                response.headers.set('Location', getRelativeURL(redirectURL, requestURL));\n            }\n        }\n        /**\n     * When the request is a data request we can't use the location header as\n     * it may end up with CORS error. Instead we map to an internal header so\n     * the client knows the destination.\n     */ if (isNextDataRequest) {\n            response.headers.delete('Location');\n            response.headers.set('x-nextjs-redirect', getRelativeURL(redirectURL.toString(), requestURL.toString()));\n        }\n    }\n    const finalResponse = response ? response : NextResponse.next();\n    // Flight headers are not overridable / removable so they are applied at the end.\n    const middlewareOverrideHeaders = finalResponse.headers.get('x-middleware-override-headers');\n    const overwrittenHeaders = [];\n    if (middlewareOverrideHeaders) {\n        for (const [key, value] of flightHeaders){\n            finalResponse.headers.set(`x-middleware-request-${key}`, value);\n            overwrittenHeaders.push(key);\n        }\n        if (overwrittenHeaders.length > 0) {\n            finalResponse.headers.set('x-middleware-override-headers', middlewareOverrideHeaders + ',' + overwrittenHeaders.join(','));\n        }\n    }\n    return {\n        response: finalResponse,\n        waitUntil: getWaitUntilPromiseFromEvent(event) ?? Promise.resolve(),\n        fetchMetrics: request.fetchMetrics\n    };\n}\n\n//# sourceMappingURL=adapter.js.map","import { SYMBOL_CLEARED_COOKIES } from '../api-utils';\nimport { NEXT_REQUEST_META } from '../request-meta';\nimport { BaseNextRequest, BaseNextResponse } from './index';\nlet prop;\nexport class NodeNextRequest extends BaseNextRequest {\n    static #_ = prop = _NEXT_REQUEST_META = NEXT_REQUEST_META;\n    constructor(_req){\n        var _this__req;\n        super(_req.method.toUpperCase(), _req.url, _req), this._req = _req, this.headers = this._req.headers, this.fetchMetrics = (_this__req = this._req) == null ? void 0 : _this__req.fetchMetrics, this[_NEXT_REQUEST_META] = this._req[NEXT_REQUEST_META] || {}, this.streaming = false;\n    }\n    get originalRequest() {\n        // Need to mimic these changes to the original req object for places where we use it:\n        // render.tsx, api/ssg requests\n        this._req[NEXT_REQUEST_META] = this[NEXT_REQUEST_META];\n        this._req.url = this.url;\n        this._req.cookies = this.cookies;\n        return this._req;\n    }\n    set originalRequest(value) {\n        this._req = value;\n    }\n    /**\n   * Returns the request body as a Web Readable Stream. The body here can only\n   * be read once as the body will start flowing as soon as the data handler\n   * is attached.\n   *\n   * @internal\n   */ stream() {\n        if (this.streaming) {\n            throw Object.defineProperty(new Error('Invariant: NodeNextRequest.stream() can only be called once'), \"__NEXT_ERROR_CODE\", {\n                value: \"E467\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        this.streaming = true;\n        return new ReadableStream({\n            start: (controller)=>{\n                this._req.on('data', (chunk)=>{\n                    controller.enqueue(new Uint8Array(chunk));\n                });\n                this._req.on('end', ()=>{\n                    controller.close();\n                });\n                this._req.on('error', (err)=>{\n                    controller.error(err);\n                });\n            }\n        });\n    }\n}\nexport class NodeNextResponse extends BaseNextResponse {\n    get originalResponse() {\n        if (SYMBOL_CLEARED_COOKIES in this) {\n            this._res[SYMBOL_CLEARED_COOKIES] = this[SYMBOL_CLEARED_COOKIES];\n        }\n        return this._res;\n    }\n    constructor(_res){\n        super(_res), this._res = _res, this.textBody = undefined;\n    }\n    get sent() {\n        return this._res.finished || this._res.headersSent;\n    }\n    get statusCode() {\n        return this._res.statusCode;\n    }\n    set statusCode(value) {\n        this._res.statusCode = value;\n    }\n    get statusMessage() {\n        return this._res.statusMessage;\n    }\n    set statusMessage(value) {\n        this._res.statusMessage = value;\n    }\n    setHeader(name, value) {\n        this._res.setHeader(name, value);\n        return this;\n    }\n    removeHeader(name) {\n        this._res.removeHeader(name);\n        return this;\n    }\n    getHeaderValues(name) {\n        const values = this._res.getHeader(name);\n        if (values === undefined) return undefined;\n        return (Array.isArray(values) ? values : [\n            values\n        ]).map((value)=>value.toString());\n    }\n    hasHeader(name) {\n        return this._res.hasHeader(name);\n    }\n    getHeader(name) {\n        const values = this.getHeaderValues(name);\n        return Array.isArray(values) ? values.join(',') : undefined;\n    }\n    getHeaders() {\n        return this._res.getHeaders();\n    }\n    appendHeader(name, value) {\n        const currentValues = this.getHeaderValues(name) ?? [];\n        if (!currentValues.includes(value)) {\n            this._res.setHeader(name, [\n                ...currentValues,\n                value\n            ]);\n        }\n        return this;\n    }\n    body(value) {\n        this.textBody = value;\n        return this;\n    }\n    send() {\n        this._res.end(this.textBody);\n    }\n    onClose(callback) {\n        this.originalResponse.on('close', callback);\n    }\n}\nvar _NEXT_REQUEST_META;\n\n//# sourceMappingURL=node.js.map","import './globals';\nimport { adapter } from './adapter';\nimport { IncrementalCache } from '../lib/incremental-cache';\nimport { RouteMatcher } from '../route-matchers/route-matcher';\nimport { internal_getCurrentFunctionWaitUntil } from './internal-edge-wait-until';\nimport { getServerUtils } from '../server-utils';\nimport { searchParamsToUrlQuery } from '../../shared/lib/router/utils/querystring';\nimport { CloseController, trackStreamConsumed } from './web-on-close';\nimport { getEdgePreviewProps } from './get-edge-preview-props';\nimport { WebNextRequest } from '../../server/base-http/web';\n/**\n * EdgeRouteModuleWrapper is a wrapper around a route module.\n *\n * Note that this class should only be used in the edge runtime.\n */ export class EdgeRouteModuleWrapper {\n    /**\n   * The constructor is wrapped with private to ensure that it can only be\n   * constructed by the static wrap method.\n   *\n   * @param routeModule the route module to wrap\n   */ constructor(routeModule){\n        this.routeModule = routeModule;\n        // TODO: (wyattjoh) possibly allow the module to define it's own matcher\n        this.matcher = new RouteMatcher(routeModule.definition);\n    }\n    /**\n   * This will wrap a module with the EdgeModuleWrapper and return a function\n   * that can be used as a handler for the edge runtime.\n   *\n   * @param module the module to wrap\n   * @param options any options that should be passed to the adapter and\n   *                override the ones passed from the runtime\n   * @returns a function that can be used as a handler for the edge runtime\n   */ static wrap(routeModule, options) {\n        // Create the module wrapper.\n        const wrapper = new EdgeRouteModuleWrapper(routeModule);\n        // Return the wrapping function.\n        return (opts)=>{\n            return adapter({\n                ...opts,\n                IncrementalCache,\n                // Bind the handler method to the wrapper so it still has context.\n                handler: wrapper.handler.bind(wrapper),\n                page: options.page\n            });\n        };\n    }\n    async handler(request, evt) {\n        const utils = getServerUtils({\n            pageIsDynamic: this.matcher.isDynamic,\n            page: this.matcher.definition.pathname,\n            basePath: request.nextUrl.basePath,\n            // We don't need the `handleRewrite` util, so can just pass an empty object\n            rewrites: {},\n            // only used for rewrites, so setting an arbitrary default value here\n            caseSensitive: false\n        });\n        const { nextConfig } = this.routeModule.getNextConfigEdge(new WebNextRequest(request));\n        const { params } = utils.normalizeDynamicRouteParams(searchParamsToUrlQuery(request.nextUrl.searchParams), false);\n        const waitUntil = evt.waitUntil.bind(evt);\n        const closeController = new CloseController();\n        const previewProps = getEdgePreviewProps();\n        // Create the context for the handler. This contains the params from the\n        // match (if any).\n        const context = {\n            params,\n            prerenderManifest: {\n                version: 4,\n                routes: {},\n                dynamicRoutes: {},\n                preview: previewProps,\n                notFoundRoutes: []\n            },\n            renderOpts: {\n                supportsDynamicResponse: true,\n                waitUntil,\n                onClose: closeController.onClose.bind(closeController),\n                onAfterTaskError: undefined,\n                cacheComponents: !!process.env.__NEXT_CACHE_COMPONENTS,\n                experimental: {\n                    authInterrupts: !!process.env.__NEXT_EXPERIMENTAL_AUTH_INTERRUPTS\n                },\n                cacheLifeProfiles: nextConfig.cacheLife\n            },\n            sharedContext: {\n                buildId: ''\n            }\n        };\n        // Get the response from the handler.\n        let res = await this.routeModule.handle(request, context);\n        const waitUntilPromises = [\n            internal_getCurrentFunctionWaitUntil()\n        ];\n        if (context.renderOpts.pendingWaitUntil) {\n            waitUntilPromises.push(context.renderOpts.pendingWaitUntil);\n        }\n        evt.waitUntil(Promise.all(waitUntilPromises));\n        if (!res.body) {\n            // we can delay running it until a bit later --\n            // if it's needed, we'll have a `waitUntil` lock anyway.\n            setTimeout(()=>closeController.dispatchClose(), 0);\n        } else {\n            // NOTE: if this is a streaming response, onClose may be called later,\n            // so we can't rely on `closeController.listeners` -- it might be 0 at this point.\n            const trackedBody = trackStreamConsumed(res.body, ()=>closeController.dispatchClose());\n            res = new Response(trackedBody, {\n                status: res.status,\n                statusText: res.statusText,\n                headers: res.headers\n            });\n        }\n        return res;\n    }\n}\n\n//# sourceMappingURL=edge-route-module-wrapper.js.map","import { isNodeNextResponse } from './base-http/helpers';\nimport { pipeToNodeResponse } from './pipe-readable';\nimport { splitCookiesString } from './web/utils';\n/**\n * Sends the response on the underlying next response object.\n *\n * @param req the underlying request object\n * @param res the underlying response object\n * @param response the response to send\n */ export async function sendResponse(req, res, response, waitUntil) {\n    if (// The type check here ensures that `req` is correctly typed, and the\n    // environment variable check provides dead code elimination.\n    process.env.NEXT_RUNTIME !== 'edge' && isNodeNextResponse(res)) {\n        var // Copy over the response headers.\n        _response_headers;\n        // Copy over the response status.\n        res.statusCode = response.status;\n        res.statusMessage = response.statusText;\n        // TODO: this is not spec-compliant behavior and we should not restrict\n        // headers that are allowed to appear many times.\n        //\n        // See:\n        // https://github.com/vercel/next.js/pull/70127\n        const headersWithMultipleValuesAllowed = [\n            // can add more headers to this list if needed\n            'set-cookie',\n            'www-authenticate',\n            'proxy-authenticate',\n            'vary'\n        ];\n        (_response_headers = response.headers) == null ? void 0 : _response_headers.forEach((value, name)=>{\n            // `x-middleware-set-cookie` is an internal header not needed for the response\n            if (name.toLowerCase() === 'x-middleware-set-cookie') {\n                return;\n            }\n            // The append handling is special cased for `set-cookie`.\n            if (name.toLowerCase() === 'set-cookie') {\n                // TODO: (wyattjoh) replace with native response iteration when we can upgrade undici\n                for (const cookie of splitCookiesString(value)){\n                    res.appendHeader(name, cookie);\n                }\n            } else {\n                // only append the header if it is either not present in the outbound response\n                // or if the header supports multiple values\n                const isHeaderPresent = typeof res.getHeader(name) !== 'undefined';\n                if (headersWithMultipleValuesAllowed.includes(name.toLowerCase()) || !isHeaderPresent) {\n                    res.appendHeader(name, value);\n                }\n            }\n        });\n        /**\n     * The response can't be directly piped to the underlying response. The\n     * following is duplicated from the edge runtime handler.\n     *\n     * See packages/next/server/next-server.ts\n     */ const { originalResponse } = res;\n        // A response body must not be sent for HEAD requests. See https://httpwg.org/specs/rfc9110.html#HEAD\n        if (response.body && req.method !== 'HEAD') {\n            await pipeToNodeResponse(response.body, originalResponse, waitUntil);\n        } else {\n            originalResponse.end();\n        }\n    }\n}\n\n//# sourceMappingURL=send-response.js.map","import { CACHE_ONE_YEAR } from '../../lib/constants';\nexport function getCacheControlHeader({ revalidate, expire }) {\n    const swrHeader = typeof revalidate === 'number' && expire !== undefined && revalidate < expire ? `, stale-while-revalidate=${expire - revalidate}` : '';\n    if (revalidate === 0) {\n        return 'private, no-cache, no-store, max-age=0, must-revalidate';\n    } else if (typeof revalidate === 'number') {\n        return `s-maxage=${revalidate}${swrHeader}`;\n    }\n    return `s-maxage=${CACHE_ONE_YEAR}${swrHeader}`;\n}\n\n//# sourceMappingURL=cache-control.js.map","function __classPrivateFieldSet(receiver, state, value, kind, f) {\n    if (kind === \"m\")\n        throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f)\n        throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver))\n        throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return kind === \"a\" ? f.call(receiver, value) : f ? (f.value = value) : state.set(receiver, value), value;\n}\nfunction __classPrivateFieldGet(receiver, state, kind, f) {\n    if (kind === \"a\" && !f)\n        throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver))\n        throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\nexport { __classPrivateFieldSet, __classPrivateFieldGet };\n","import { NEXT_RSC_UNION_QUERY } from '../client/components/app-router-headers';\nconst INTERNAL_QUERY_NAMES = [\n    NEXT_RSC_UNION_QUERY\n];\nexport function stripInternalQueries(query) {\n    for (const name of INTERNAL_QUERY_NAMES){\n        delete query[name];\n    }\n}\nexport function stripInternalSearchParams(url) {\n    const isStringUrl = typeof url === 'string';\n    const instance = isStringUrl ? new URL(url) : url;\n    instance.searchParams.delete(NEXT_RSC_UNION_QUERY);\n    return isStringUrl ? instance.toString() : instance;\n}\n\n//# sourceMappingURL=internal-utils.js.map","import { stringifyCookie } from '../../web/spec-extension/cookies';\nimport { NextURL } from '../next-url';\nimport { toNodeOutgoingHttpHeaders, validateURL } from '../utils';\nimport { ReflectAdapter } from './adapters/reflect';\nimport { ResponseCookies } from './cookies';\nconst INTERNALS = Symbol('internal response');\nconst REDIRECTS = new Set([\n    301,\n    302,\n    303,\n    307,\n    308\n]);\nfunction handleMiddlewareField(init, headers) {\n    var _init_request;\n    if (init == null ? void 0 : (_init_request = init.request) == null ? void 0 : _init_request.headers) {\n        if (!(init.request.headers instanceof Headers)) {\n            throw Object.defineProperty(new Error('request.headers must be an instance of Headers'), \"__NEXT_ERROR_CODE\", {\n                value: \"E119\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        const keys = [];\n        for (const [key, value] of init.request.headers){\n            headers.set('x-middleware-request-' + key, value);\n            keys.push(key);\n        }\n        headers.set('x-middleware-override-headers', keys.join(','));\n    }\n}\n/**\n * This class extends the [Web `Response` API](https://developer.mozilla.org/docs/Web/API/Response) with additional convenience methods.\n *\n * Read more: [Next.js Docs: `NextResponse`](https://nextjs.org/docs/app/api-reference/functions/next-response)\n */ export class NextResponse extends Response {\n    constructor(body, init = {}){\n        super(body, init);\n        const headers = this.headers;\n        const cookies = new ResponseCookies(headers);\n        const cookiesProxy = new Proxy(cookies, {\n            get (target, prop, receiver) {\n                switch(prop){\n                    case 'delete':\n                    case 'set':\n                        {\n                            return (...args)=>{\n                                const result = Reflect.apply(target[prop], target, args);\n                                const newHeaders = new Headers(headers);\n                                if (result instanceof ResponseCookies) {\n                                    headers.set('x-middleware-set-cookie', result.getAll().map((cookie)=>stringifyCookie(cookie)).join(','));\n                                }\n                                handleMiddlewareField(init, newHeaders);\n                                return result;\n                            };\n                        }\n                    default:\n                        return ReflectAdapter.get(target, prop, receiver);\n                }\n            }\n        });\n        this[INTERNALS] = {\n            cookies: cookiesProxy,\n            url: init.url ? new NextURL(init.url, {\n                headers: toNodeOutgoingHttpHeaders(headers),\n                nextConfig: init.nextConfig\n            }) : undefined\n        };\n    }\n    [Symbol.for('edge-runtime.inspect.custom')]() {\n        return {\n            cookies: this.cookies,\n            url: this.url,\n            // rest of props come from Response\n            body: this.body,\n            bodyUsed: this.bodyUsed,\n            headers: Object.fromEntries(this.headers),\n            ok: this.ok,\n            redirected: this.redirected,\n            status: this.status,\n            statusText: this.statusText,\n            type: this.type\n        };\n    }\n    get cookies() {\n        return this[INTERNALS].cookies;\n    }\n    static json(body, init) {\n        const response = Response.json(body, init);\n        return new NextResponse(response.body, response);\n    }\n    static redirect(url, init) {\n        const status = typeof init === 'number' ? init : (init == null ? void 0 : init.status) ?? 307;\n        if (!REDIRECTS.has(status)) {\n            throw Object.defineProperty(new RangeError('Failed to execute \"redirect\" on \"response\": Invalid status code'), \"__NEXT_ERROR_CODE\", {\n                value: \"E529\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        const initObj = typeof init === 'object' ? init : {};\n        const headers = new Headers(initObj == null ? void 0 : initObj.headers);\n        headers.set('Location', validateURL(url));\n        return new NextResponse(null, {\n            ...initObj,\n            headers,\n            status\n        });\n    }\n    static rewrite(destination, init) {\n        const headers = new Headers(init == null ? void 0 : init.headers);\n        headers.set('x-middleware-rewrite', validateURL(destination));\n        handleMiddlewareField(init, headers);\n        return new NextResponse(null, {\n            ...init,\n            headers\n        });\n    }\n    static next(init) {\n        const headers = new Headers(init == null ? void 0 : init.headers);\n        headers.set('x-middleware-next', '1');\n        handleMiddlewareField(init, headers);\n        return new NextResponse(null, {\n            ...init,\n            headers\n        });\n    }\n}\n\n//# sourceMappingURL=response.js.map","import { createAsyncLocalStorage } from '../app-render/async-local-storage';\nexport function getBuiltinRequestContext() {\n    const _globalThis = globalThis;\n    const ctx = _globalThis[NEXT_REQUEST_CONTEXT_SYMBOL];\n    return ctx == null ? void 0 : ctx.get();\n}\nconst NEXT_REQUEST_CONTEXT_SYMBOL = Symbol.for('@next/request-context');\n/** \"@next/request-context\" has a different signature from AsyncLocalStorage,\n * matching [AsyncContext.Variable](https://github.com/tc39/proposal-async-context).\n * We don't need a full AsyncContext adapter here, just having `.get()` is enough\n */ export function createLocalRequestContext() {\n    const storage = createAsyncLocalStorage();\n    return {\n        get: ()=>storage.getStore(),\n        run: (value, callback)=>storage.run(value, callback)\n    };\n}\n\n//# sourceMappingURL=builtin-request-context.js.map","const STR = 0b000000001;\nconst NUM = 0b000000010;\nconst ARR = 0b000000100;\nconst OBJ = 0b000001000;\nconst NULL = 0b000010000;\nconst BOOL = 0b000100000;\nconst NAN = 0b001000000;\nconst INFINITY = 0b010000000;\nconst MINUS_INFINITY = 0b100000000;\n\nconst INF = INFINITY | MINUS_INFINITY;\nconst SPECIAL = NULL | BOOL | INF | NAN;\nconst ATOM = STR | NUM | SPECIAL;\nconst COLLECTION = ARR | OBJ;\nconst ALL = ATOM | COLLECTION;\n\nconst Allow = {\n  STR,\n  NUM,\n  ARR,\n  OBJ,\n  NULL,\n  BOOL,\n  NAN,\n  INFINITY,\n  MINUS_INFINITY,\n  INF,\n  SPECIAL,\n  ATOM,\n  COLLECTION,\n  ALL,\n};\n\n// The JSON string segment was unable to be parsed completely\nclass PartialJSON extends Error {}\n\nclass MalformedJSON extends Error {}\n\n/**\n * Parse incomplete JSON\n * @param {string} jsonString Partial JSON to be parsed\n * @param {number} allowPartial Specify what types are allowed to be partial, see {@link Allow} for details\n * @returns The parsed JSON\n * @throws {PartialJSON} If the JSON is incomplete (related to the `allow` parameter)\n * @throws {MalformedJSON} If the JSON is malformed\n */\nfunction parseJSON(jsonString: string, allowPartial: number = Allow.ALL): any {\n  if (typeof jsonString !== 'string') {\n    throw new TypeError(`expecting str, got ${typeof jsonString}`);\n  }\n  if (!jsonString.trim()) {\n    throw new Error(`${jsonString} is empty`);\n  }\n  return _parseJSON(jsonString.trim(), allowPartial);\n}\n\nconst _parseJSON = (jsonString: string, allow: number) => {\n  const length = jsonString.length;\n  let index = 0;\n\n  const markPartialJSON = (msg: string) => {\n    throw new PartialJSON(`${msg} at position ${index}`);\n  };\n\n  const throwMalformedError = (msg: string) => {\n    throw new MalformedJSON(`${msg} at position ${index}`);\n  };\n\n  const parseAny: () => any = () => {\n    skipBlank();\n    if (index >= length) markPartialJSON('Unexpected end of input');\n    if (jsonString[index] === '\"') return parseStr();\n    if (jsonString[index] === '{') return parseObj();\n    if (jsonString[index] === '[') return parseArr();\n    if (\n      jsonString.substring(index, index + 4) === 'null' ||\n      (Allow.NULL & allow && length - index < 4 && 'null'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return null;\n    }\n    if (\n      jsonString.substring(index, index + 4) === 'true' ||\n      (Allow.BOOL & allow && length - index < 4 && 'true'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return true;\n    }\n    if (\n      jsonString.substring(index, index + 5) === 'false' ||\n      (Allow.BOOL & allow && length - index < 5 && 'false'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 5;\n      return false;\n    }\n    if (\n      jsonString.substring(index, index + 8) === 'Infinity' ||\n      (Allow.INFINITY & allow && length - index < 8 && 'Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 8;\n      return Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 9) === '-Infinity' ||\n      (Allow.MINUS_INFINITY & allow &&\n        1 < length - index &&\n        length - index < 9 &&\n        '-Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 9;\n      return -Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 3) === 'NaN' ||\n      (Allow.NAN & allow && length - index < 3 && 'NaN'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 3;\n      return NaN;\n    }\n    return parseNum();\n  };\n\n  const parseStr: () => string = () => {\n    const start = index;\n    let escape = false;\n    index++; // skip initial quote\n    while (index < length && (jsonString[index] !== '\"' || (escape && jsonString[index - 1] === '\\\\'))) {\n      escape = jsonString[index] === '\\\\' ? !escape : false;\n      index++;\n    }\n    if (jsonString.charAt(index) == '\"') {\n      try {\n        return JSON.parse(jsonString.substring(start, ++index - Number(escape)));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    } else if (Allow.STR & allow) {\n      try {\n        return JSON.parse(jsonString.substring(start, index - Number(escape)) + '\"');\n      } catch (e) {\n        // SyntaxError: Invalid escape sequence\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('\\\\')) + '\"');\n      }\n    }\n    markPartialJSON('Unterminated string literal');\n  };\n\n  const parseObj = () => {\n    index++; // skip initial brace\n    skipBlank();\n    const obj: Record<string, any> = {};\n    try {\n      while (jsonString[index] !== '}') {\n        skipBlank();\n        if (index >= length && Allow.OBJ & allow) return obj;\n        const key = parseStr();\n        skipBlank();\n        index++; // skip colon\n        try {\n          const value = parseAny();\n          Object.defineProperty(obj, key, { value, writable: true, enumerable: true, configurable: true });\n        } catch (e) {\n          if (Allow.OBJ & allow) return obj;\n          else throw e;\n        }\n        skipBlank();\n        if (jsonString[index] === ',') index++; // skip comma\n      }\n    } catch (e) {\n      if (Allow.OBJ & allow) return obj;\n      else markPartialJSON(\"Expected '}' at end of object\");\n    }\n    index++; // skip final brace\n    return obj;\n  };\n\n  const parseArr = () => {\n    index++; // skip initial bracket\n    const arr = [];\n    try {\n      while (jsonString[index] !== ']') {\n        arr.push(parseAny());\n        skipBlank();\n        if (jsonString[index] === ',') {\n          index++; // skip comma\n        }\n      }\n    } catch (e) {\n      if (Allow.ARR & allow) {\n        return arr;\n      }\n      markPartialJSON(\"Expected ']' at end of array\");\n    }\n    index++; // skip final bracket\n    return arr;\n  };\n\n  const parseNum = () => {\n    if (index === 0) {\n      if (jsonString === '-' && Allow.NUM & allow) markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString);\n      } catch (e) {\n        if (Allow.NUM & allow) {\n          try {\n            if ('.' === jsonString[jsonString.length - 1])\n              return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('.')));\n            return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('e')));\n          } catch (e) {}\n        }\n        throwMalformedError(String(e));\n      }\n    }\n\n    const start = index;\n\n    if (jsonString[index] === '-') index++;\n    while (jsonString[index] && !',]}'.includes(jsonString[index]!)) index++;\n\n    if (index == length && !(Allow.NUM & allow)) markPartialJSON('Unterminated number literal');\n\n    try {\n      return JSON.parse(jsonString.substring(start, index));\n    } catch (e) {\n      if (jsonString.substring(start, index) === '-' && Allow.NUM & allow)\n        markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('e')));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    }\n  };\n\n  const skipBlank = () => {\n    while (index < length && ' \\n\\r\\t'.includes(jsonString[index]!)) {\n      index++;\n    }\n  };\n\n  return parseAny();\n};\n\n// using this function with malformed JSON is undefined behavior\nconst partialParse = (input: string) => parseJSON(input, Allow.ALL ^ Allow.NUM);\n\nexport { partialParse, PartialJSON, MalformedJSON };\n","export class NoFallbackError extends Error {\n    constructor(){\n        super();\n        this.message = 'Internal: NoFallbackError';\n    }\n}\n\n//# sourceMappingURL=no-fallback-error.external.js.map","export function getRevalidateReason(params) {\n    if (params.isOnDemandRevalidate) {\n        return 'on-demand';\n    }\n    if (params.isStaticGeneration) {\n        return 'stale';\n    }\n    return undefined;\n}\n\n//# sourceMappingURL=utils.js.map","import type { Format } from './types';\n\nexport const default_format: Format = 'RFC3986';\nexport const default_formatter = (v: PropertyKey) => String(v);\nexport const formatters: Record<Format, (str: PropertyKey) => string> = {\n  RFC1738: (v: PropertyKey) => String(v).replace(/%20/g, '+'),\n  RFC3986: default_formatter,\n};\nexport const RFC1738 = 'RFC1738';\nexport const RFC3986 = 'RFC3986';\n","export const VERSION = '6.17.0'; // x-release-please-version\n","import {\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionMessageParam,\n  type ChatCompletionToolMessageParam,\n} from '../resources';\n\nexport const isAssistantMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionAssistantMessageParam => {\n  return message?.role === 'assistant';\n};\n\nexport const isToolMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionToolMessageParam => {\n  return message?.role === 'tool';\n};\n\nexport function isPresent<T>(obj: T | null | undefined): obj is T {\n  return obj != null;\n}\n","import { PageSignatureError } from '../error';\nconst responseSymbol = Symbol('response');\nconst passThroughSymbol = Symbol('passThrough');\nconst waitUntilSymbol = Symbol('waitUntil');\nclass FetchEvent {\n    constructor(_request, waitUntil){\n        this[passThroughSymbol] = false;\n        this[waitUntilSymbol] = waitUntil ? {\n            kind: 'external',\n            function: waitUntil\n        } : {\n            kind: 'internal',\n            promises: []\n        };\n    }\n    // TODO: is this dead code? NextFetchEvent never lets this get called\n    respondWith(response) {\n        if (!this[responseSymbol]) {\n            this[responseSymbol] = Promise.resolve(response);\n        }\n    }\n    // TODO: is this dead code? passThroughSymbol is unused\n    passThroughOnException() {\n        this[passThroughSymbol] = true;\n    }\n    waitUntil(promise) {\n        if (this[waitUntilSymbol].kind === 'external') {\n            // if we received an external waitUntil, we delegate to it\n            // TODO(after): this will make us not go through `getServerError(error, 'edge-server')` in `sandbox`\n            const waitUntil = this[waitUntilSymbol].function;\n            return waitUntil(promise);\n        } else {\n            // if we didn't receive an external waitUntil, we make it work on our own\n            // (and expect the caller to do something with the promises)\n            this[waitUntilSymbol].promises.push(promise);\n        }\n    }\n}\nexport function getWaitUntilPromiseFromEvent(event) {\n    return event[waitUntilSymbol].kind === 'internal' ? Promise.all(event[waitUntilSymbol].promises).then(()=>{}) : undefined;\n}\nexport class NextFetchEvent extends FetchEvent {\n    constructor(params){\n        var _params_context;\n        super(params.request, (_params_context = params.context) == null ? void 0 : _params_context.waitUntil);\n        this.sourcePage = params.page;\n    }\n    /**\n   * @deprecated The `request` is now the first parameter and the API is now async.\n   *\n   * Read more: https://nextjs.org/docs/messages/middleware-new-signature\n   */ get request() {\n        throw Object.defineProperty(new PageSignatureError({\n            page: this.sourcePage\n        }), \"__NEXT_ERROR_CODE\", {\n            value: \"E394\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n    /**\n   * @deprecated Using `respondWith` is no longer needed.\n   *\n   * Read more: https://nextjs.org/docs/messages/middleware-new-signature\n   */ respondWith() {\n        throw Object.defineProperty(new PageSignatureError({\n            page: this.sourcePage\n        }), \"__NEXT_ERROR_CODE\", {\n            value: \"E394\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n}\n\n//# sourceMappingURL=fetch-event.js.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { NullableHeaders } from './headers';\n\nimport type { BodyInit } from './builtin-types';\nimport { Stream } from '../core/streaming';\nimport type { HTTPMethod, MergedRequestInit } from './types';\nimport { type HeadersLike } from './headers';\n\nexport type FinalRequestOptions = RequestOptions & { method: HTTPMethod; path: string };\n\nexport type RequestOptions = {\n  /**\n   * The HTTP method for the request (e.g., 'get', 'post', 'put', 'delete').\n   */\n  method?: HTTPMethod;\n\n  /**\n   * The URL path for the request.\n   *\n   * @example \"/v1/foo\"\n   */\n  path?: string;\n\n  /**\n   * Query parameters to include in the request URL.\n   */\n  query?: object | undefined | null;\n\n  /**\n   * The request body. Can be a string, JSON object, FormData, or other supported types.\n   */\n  body?: unknown;\n\n  /**\n   * HTTP headers to include with the request. Can be a Headers object, plain object, or array of tuples.\n   */\n  headers?: HeadersLike;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number;\n\n  stream?: boolean | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * @unit milliseconds\n   */\n  timeout?: number;\n\n  /**\n   * Additional `RequestInit` options to be passed to the underlying `fetch` call.\n   * These options will be merged with the client's default fetch options.\n   */\n  fetchOptions?: MergedRequestInit;\n\n  /**\n   * An AbortSignal that can be used to cancel the request.\n   */\n  signal?: AbortSignal | undefined | null;\n\n  /**\n   * A unique key for this request to enable idempotency.\n   */\n  idempotencyKey?: string;\n\n  /**\n   * Override the default base URL for this specific request.\n   */\n  defaultBaseURL?: string | undefined;\n\n  __metadata?: Record<string, unknown>;\n  __binaryResponse?: boolean | undefined;\n  __streamClass?: typeof Stream;\n};\n\nexport type EncodedContent = { bodyHeaders: HeadersLike; body: BodyInit };\nexport type RequestEncoder = (request: { headers: NullableHeaders; body: unknown }) => EncodedContent;\n\nexport const FallbackEncoder: RequestEncoder = ({ headers, body }) => {\n  return {\n    bodyHeaders: {\n      'content-type': 'application/json',\n    },\n    body: JSON.stringify(body),\n  };\n};\n","export function concatBytes(buffers: Uint8Array[]): Uint8Array {\n  let length = 0;\n  for (const buffer of buffers) {\n    length += buffer.length;\n  }\n  const output = new Uint8Array(length);\n  let index = 0;\n  for (const buffer of buffers) {\n    output.set(buffer, index);\n    index += buffer.length;\n  }\n\n  return output;\n}\n\nlet encodeUTF8_: (str: string) => Uint8Array;\nexport function encodeUTF8(str: string) {\n  let encoder;\n  return (\n    encodeUTF8_ ??\n    ((encoder = new (globalThis as any).TextEncoder()), (encodeUTF8_ = encoder.encode.bind(encoder)))\n  )(str);\n}\n\nlet decodeUTF8_: (bytes: Uint8Array) => string;\nexport function decodeUTF8(bytes: Uint8Array) {\n  let decoder;\n  return (\n    decodeUTF8_ ??\n    ((decoder = new (globalThis as any).TextDecoder()), (decodeUTF8_ = decoder.decode.bind(decoder)))\n  )(bytes);\n}\n","import { type ChatCompletionRunner } from './ChatCompletionRunner';\nimport { type ChatCompletionStreamingRunner } from './ChatCompletionStreamingRunner';\nimport { JSONSchema } from './jsonschema';\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\nexport type RunnableFunctionWithParse<Args extends object> = {\n  /**\n   * @param args the return value from `parse`.\n   * @param runner the runner evaluating this callback.\n   * @returns a string to send back to OpenAI.\n   */\n  function: (\n    args: Args,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * @param input the raw args from the OpenAI function call.\n   * @returns the parsed arguments to pass to `function`\n   */\n  parse: (input: string) => PromiseOrValue<Args>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunctionWithoutParse = {\n  /**\n   * @param args the raw args from the OpenAI function call.\n   * @returns a string to send back to OpenAI\n   */\n  function: (\n    args: string,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunction<Args extends object | string> =\n  Args extends string ? RunnableFunctionWithoutParse\n  : Args extends object ? RunnableFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunction<Args extends object | string> =\n  Args extends string ? RunnableToolFunctionWithoutParse\n  : Args extends object ? RunnableToolFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunctionWithoutParse = {\n  type: 'function';\n  function: RunnableFunctionWithoutParse;\n};\nexport type RunnableToolFunctionWithParse<Args extends object> = {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n};\n\nexport function isRunnableFunctionWithParse<Args extends object>(\n  fn: any,\n): fn is RunnableFunctionWithParse<Args> {\n  return typeof (fn as any).parse === 'function';\n}\n\nexport type BaseFunctionsArgs = readonly (object | string)[];\n\nexport type RunnableFunctions<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\nexport type RunnableTools<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableToolFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableToolFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n */\nexport class ParsingToolFunction<Args extends object> {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.type = 'function';\n    this.function = input;\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport const sleep = (ms: number) => new Promise<void>((resolve) => setTimeout(resolve, ms));\n","import { ContentFilterFinishReasonError, LengthFinishReasonError, OpenAIError } from '../error';\nimport {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsBase,\n  ChatCompletionFunctionTool,\n  ChatCompletionMessage,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionStreamingToolRunnerParams,\n  ChatCompletionStreamParams,\n  ChatCompletionToolRunnerParams,\n  ParsedChatCompletion,\n  ParsedChoice,\n  ParsedFunctionToolCall,\n} from '../resources/chat/completions';\nimport { type ResponseFormatTextJSONSchemaConfig } from '../resources/responses/responses';\nimport { ResponseFormatJSONSchema } from '../resources/shared';\n\ntype AnyChatCompletionCreateParams =\n  | ChatCompletionCreateParams\n  | ChatCompletionToolRunnerParams<any>\n  | ChatCompletionStreamingToolRunnerParams<any>\n  | ChatCompletionStreamParams;\n\ntype Unpacked<T> = T extends (infer U)[] ? U : T;\n\ntype ToolCall = Unpacked<ChatCompletionCreateParamsBase['tools']>;\n\nexport function isChatCompletionFunctionTool(tool: ToolCall): tool is ChatCompletionFunctionTool {\n  return tool !== undefined && 'function' in tool && tool.function !== undefined;\n}\n\nexport type ExtractParsedContentFromParams<Params extends AnyChatCompletionCreateParams> =\n  Params['response_format'] extends AutoParseableResponseFormat<infer P> ? P : null;\n\nexport type AutoParseableResponseFormat<ParsedT> = ResponseFormatJSONSchema & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableResponseFormat<ParsedT>(\n  response_format: ResponseFormatJSONSchema,\n  parser: (content: string) => ParsedT,\n): AutoParseableResponseFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseFormat<ParsedT>;\n}\n\nexport type AutoParseableTextFormat<ParsedT> = ResponseFormatTextJSONSchemaConfig & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableTextFormat<ParsedT>(\n  response_format: ResponseFormatTextJSONSchemaConfig,\n  parser: (content: string) => ParsedT,\n): AutoParseableTextFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTextFormat<ParsedT>;\n}\n\nexport function isAutoParsableResponseFormat<ParsedT>(\n  response_format: any,\n): response_format is AutoParseableResponseFormat<ParsedT> {\n  return response_format?.['$brand'] === 'auto-parseable-response-format';\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = ChatCompletionFunctionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n  __hasFunction: HasFunction; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableTool<OptionsT extends ToolOptions>(\n  tool: ChatCompletionFunctionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nexport function maybeParseChatCompletion<\n  Params extends ChatCompletionCreateParams | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...completion,\n      choices: completion.choices.map((choice) => {\n        assertToolCallsAreChatCompletionFunctionToolCalls(choice.message.tool_calls);\n\n        return {\n          ...choice,\n          message: {\n            ...choice.message,\n            parsed: null,\n            ...(choice.message.tool_calls ?\n              {\n                tool_calls: choice.message.tool_calls,\n              }\n            : undefined),\n          },\n        };\n      }),\n    } as ParsedChatCompletion<ParsedT>;\n  }\n\n  return parseChatCompletion(completion, params);\n}\n\nexport function parseChatCompletion<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  const choices: Array<ParsedChoice<ParsedT>> = completion.choices.map((choice): ParsedChoice<ParsedT> => {\n    if (choice.finish_reason === 'length') {\n      throw new LengthFinishReasonError();\n    }\n\n    if (choice.finish_reason === 'content_filter') {\n      throw new ContentFilterFinishReasonError();\n    }\n\n    assertToolCallsAreChatCompletionFunctionToolCalls(choice.message.tool_calls);\n\n    return {\n      ...choice,\n      message: {\n        ...choice.message,\n        ...(choice.message.tool_calls ?\n          {\n            tool_calls:\n              choice.message.tool_calls?.map((toolCall) => parseToolCall(params, toolCall)) ?? undefined,\n          }\n        : undefined),\n        parsed:\n          choice.message.content && !choice.message.refusal ?\n            parseResponseFormat(params, choice.message.content)\n          : null,\n      },\n    } as ParsedChoice<ParsedT>;\n  });\n\n  return { ...completion, choices };\n}\n\nfunction parseResponseFormat<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.response_format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if (params.response_format?.type === 'json_schema') {\n    if ('$parseRaw' in params.response_format) {\n      const response_format = params.response_format as AutoParseableResponseFormat<ParsedT>;\n\n      return response_format.$parseRaw(content);\n    }\n\n    return JSON.parse(content);\n  }\n\n  return null;\n}\n\nfunction parseToolCall<Params extends ChatCompletionCreateParams>(\n  params: Params,\n  toolCall: ChatCompletionMessageFunctionToolCall,\n): ParsedFunctionToolCall {\n  const inputTool = params.tools?.find(\n    (inputTool) =>\n      isChatCompletionFunctionTool(inputTool) && inputTool.function?.name === toolCall.function.name,\n  ) as ChatCompletionFunctionTool | undefined; // TS doesn't narrow based on isChatCompletionTool\n  return {\n    ...toolCall,\n    function: {\n      ...toolCall.function,\n      parsed_arguments:\n        isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.function.arguments)\n        : inputTool?.function.strict ? JSON.parse(toolCall.function.arguments)\n        : null,\n    },\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ChatCompletionCreateParams | null | undefined,\n  toolCall: ChatCompletionMessageFunctionToolCall,\n): boolean {\n  if (!params || !('tools' in params) || !params.tools) {\n    return false;\n  }\n\n  const inputTool = params.tools?.find(\n    (inputTool) =>\n      isChatCompletionFunctionTool(inputTool) && inputTool.function?.name === toolCall.function.name,\n  );\n  return (\n    isChatCompletionFunctionTool(inputTool) &&\n    (isAutoParsableTool(inputTool) || inputTool?.function.strict || false)\n  );\n}\n\nexport function hasAutoParseableInput(params: AnyChatCompletionCreateParams): boolean {\n  if (isAutoParsableResponseFormat(params.response_format)) {\n    return true;\n  }\n\n  return (\n    params.tools?.some(\n      (t) => isAutoParsableTool(t) || (t.type === 'function' && t.function.strict === true),\n    ) ?? false\n  );\n}\n\nexport function assertToolCallsAreChatCompletionFunctionToolCalls(\n  toolCalls: ChatCompletionMessage['tool_calls'],\n): asserts toolCalls is ChatCompletionMessageFunctionToolCall[] {\n  for (const toolCall of toolCalls || []) {\n    if (toolCall.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool calls are supported; Received \\`${toolCall.type}\\``,\n      );\n    }\n  }\n}\n\nexport function validateInputTools(tools: ChatCompletionCreateParamsBase['tools']) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n","import {\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParamsStreaming,\n} from '../resources/chat/completions';\nimport { RunnerOptions, type AbstractChatCompletionRunnerEvents } from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from '../internal/shim-types';\nimport { RunnableTools, type BaseFunctionsArgs } from './RunnableFunction';\nimport { ChatCompletionSnapshot, ChatCompletionStream } from './ChatCompletionStream';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n}\n\nexport type ChatCompletionStreamingToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionStreamingRunner<ParsedT = null>\n  extends ChatCompletionStream<ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  static override fromReadableStream(stream: ReadableStream): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static runTools<T extends (string | object)[], ParsedT = null>(\n    client: OpenAI,\n    params: ChatCompletionStreamingToolRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<ParsedT> {\n    const runner = new ChatCompletionStreamingRunner<ParsedT>(\n      // @ts-expect-error TODO these types are incompatible\n      params,\n    );\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n}\n","import { encode, is_buffer, maybe_map, has } from './utils';\nimport { default_format, default_formatter, formatters } from './formats';\nimport type { NonNullableProperties, StringifyOptions } from './types';\nimport { isArray } from '../utils/values';\n\nconst array_prefix_generators = {\n  brackets(prefix: PropertyKey) {\n    return String(prefix) + '[]';\n  },\n  comma: 'comma',\n  indices(prefix: PropertyKey, key: string) {\n    return String(prefix) + '[' + key + ']';\n  },\n  repeat(prefix: PropertyKey) {\n    return String(prefix);\n  },\n};\n\nconst push_to_array = function (arr: any[], value_or_array: any) {\n  Array.prototype.push.apply(arr, isArray(value_or_array) ? value_or_array : [value_or_array]);\n};\n\nlet toISOString;\n\nconst defaults = {\n  addQueryPrefix: false,\n  allowDots: false,\n  allowEmptyArrays: false,\n  arrayFormat: 'indices',\n  charset: 'utf-8',\n  charsetSentinel: false,\n  delimiter: '&',\n  encode: true,\n  encodeDotInKeys: false,\n  encoder: encode,\n  encodeValuesOnly: false,\n  format: default_format,\n  formatter: default_formatter,\n  /** @deprecated */\n  indices: false,\n  serializeDate(date) {\n    return (toISOString ??= Function.prototype.call.bind(Date.prototype.toISOString))(date);\n  },\n  skipNulls: false,\n  strictNullHandling: false,\n} as NonNullableProperties<StringifyOptions & { formatter: (typeof formatters)['RFC1738'] }>;\n\nfunction is_non_nullish_primitive(v: unknown): v is string | number | boolean | symbol | bigint {\n  return (\n    typeof v === 'string' ||\n    typeof v === 'number' ||\n    typeof v === 'boolean' ||\n    typeof v === 'symbol' ||\n    typeof v === 'bigint'\n  );\n}\n\nconst sentinel = {};\n\nfunction inner_stringify(\n  object: any,\n  prefix: PropertyKey,\n  generateArrayPrefix: StringifyOptions['arrayFormat'] | ((prefix: string, key: string) => string),\n  commaRoundTrip: boolean,\n  allowEmptyArrays: boolean,\n  strictNullHandling: boolean,\n  skipNulls: boolean,\n  encodeDotInKeys: boolean,\n  encoder: StringifyOptions['encoder'],\n  filter: StringifyOptions['filter'],\n  sort: StringifyOptions['sort'],\n  allowDots: StringifyOptions['allowDots'],\n  serializeDate: StringifyOptions['serializeDate'],\n  format: StringifyOptions['format'],\n  formatter: StringifyOptions['formatter'],\n  encodeValuesOnly: boolean,\n  charset: StringifyOptions['charset'],\n  sideChannel: WeakMap<any, any>,\n) {\n  let obj = object;\n\n  let tmp_sc = sideChannel;\n  let step = 0;\n  let find_flag = false;\n  while ((tmp_sc = tmp_sc.get(sentinel)) !== void undefined && !find_flag) {\n    // Where object last appeared in the ref tree\n    const pos = tmp_sc.get(object);\n    step += 1;\n    if (typeof pos !== 'undefined') {\n      if (pos === step) {\n        throw new RangeError('Cyclic object value');\n      } else {\n        find_flag = true; // Break while\n      }\n    }\n    if (typeof tmp_sc.get(sentinel) === 'undefined') {\n      step = 0;\n    }\n  }\n\n  if (typeof filter === 'function') {\n    obj = filter(prefix, obj);\n  } else if (obj instanceof Date) {\n    obj = serializeDate?.(obj);\n  } else if (generateArrayPrefix === 'comma' && isArray(obj)) {\n    obj = maybe_map(obj, function (value) {\n      if (value instanceof Date) {\n        return serializeDate?.(value);\n      }\n      return value;\n    });\n  }\n\n  if (obj === null) {\n    if (strictNullHandling) {\n      return encoder && !encodeValuesOnly ?\n          // @ts-expect-error\n          encoder(prefix, defaults.encoder, charset, 'key', format)\n        : prefix;\n    }\n\n    obj = '';\n  }\n\n  if (is_non_nullish_primitive(obj) || is_buffer(obj)) {\n    if (encoder) {\n      const key_value =\n        encodeValuesOnly ? prefix\n          // @ts-expect-error\n        : encoder(prefix, defaults.encoder, charset, 'key', format);\n      return [\n        formatter?.(key_value) +\n          '=' +\n          // @ts-expect-error\n          formatter?.(encoder(obj, defaults.encoder, charset, 'value', format)),\n      ];\n    }\n    return [formatter?.(prefix) + '=' + formatter?.(String(obj))];\n  }\n\n  const values: string[] = [];\n\n  if (typeof obj === 'undefined') {\n    return values;\n  }\n\n  let obj_keys;\n  if (generateArrayPrefix === 'comma' && isArray(obj)) {\n    // we need to join elements in\n    if (encodeValuesOnly && encoder) {\n      // @ts-expect-error values only\n      obj = maybe_map(obj, encoder);\n    }\n    obj_keys = [{ value: obj.length > 0 ? obj.join(',') || null : void undefined }];\n  } else if (isArray(filter)) {\n    obj_keys = filter;\n  } else {\n    const keys = Object.keys(obj);\n    obj_keys = sort ? keys.sort(sort) : keys;\n  }\n\n  const encoded_prefix = encodeDotInKeys ? String(prefix).replace(/\\./g, '%2E') : String(prefix);\n\n  const adjusted_prefix =\n    commaRoundTrip && isArray(obj) && obj.length === 1 ? encoded_prefix + '[]' : encoded_prefix;\n\n  if (allowEmptyArrays && isArray(obj) && obj.length === 0) {\n    return adjusted_prefix + '[]';\n  }\n\n  for (let j = 0; j < obj_keys.length; ++j) {\n    const key = obj_keys[j];\n    const value =\n      // @ts-ignore\n      typeof key === 'object' && typeof key.value !== 'undefined' ? key.value : obj[key as any];\n\n    if (skipNulls && value === null) {\n      continue;\n    }\n\n    // @ts-ignore\n    const encoded_key = allowDots && encodeDotInKeys ? (key as any).replace(/\\./g, '%2E') : key;\n    const key_prefix =\n      isArray(obj) ?\n        typeof generateArrayPrefix === 'function' ?\n          generateArrayPrefix(adjusted_prefix, encoded_key)\n        : adjusted_prefix\n      : adjusted_prefix + (allowDots ? '.' + encoded_key : '[' + encoded_key + ']');\n\n    sideChannel.set(object, step);\n    const valueSideChannel = new WeakMap();\n    valueSideChannel.set(sentinel, sideChannel);\n    push_to_array(\n      values,\n      inner_stringify(\n        value,\n        key_prefix,\n        generateArrayPrefix,\n        commaRoundTrip,\n        allowEmptyArrays,\n        strictNullHandling,\n        skipNulls,\n        encodeDotInKeys,\n        // @ts-ignore\n        generateArrayPrefix === 'comma' && encodeValuesOnly && isArray(obj) ? null : encoder,\n        filter,\n        sort,\n        allowDots,\n        serializeDate,\n        format,\n        formatter,\n        encodeValuesOnly,\n        charset,\n        valueSideChannel,\n      ),\n    );\n  }\n\n  return values;\n}\n\nfunction normalize_stringify_options(\n  opts: StringifyOptions = defaults,\n): NonNullableProperties<Omit<StringifyOptions, 'indices'>> & { indices?: boolean } {\n  if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n    throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n  }\n\n  if (typeof opts.encodeDotInKeys !== 'undefined' && typeof opts.encodeDotInKeys !== 'boolean') {\n    throw new TypeError('`encodeDotInKeys` option can only be `true` or `false`, when provided');\n  }\n\n  if (opts.encoder !== null && typeof opts.encoder !== 'undefined' && typeof opts.encoder !== 'function') {\n    throw new TypeError('Encoder has to be a function.');\n  }\n\n  const charset = opts.charset || defaults.charset;\n  if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n    throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n  }\n\n  let format = default_format;\n  if (typeof opts.format !== 'undefined') {\n    if (!has(formatters, opts.format)) {\n      throw new TypeError('Unknown format option provided.');\n    }\n    format = opts.format;\n  }\n  const formatter = formatters[format];\n\n  let filter = defaults.filter;\n  if (typeof opts.filter === 'function' || isArray(opts.filter)) {\n    filter = opts.filter;\n  }\n\n  let arrayFormat: StringifyOptions['arrayFormat'];\n  if (opts.arrayFormat && opts.arrayFormat in array_prefix_generators) {\n    arrayFormat = opts.arrayFormat;\n  } else if ('indices' in opts) {\n    arrayFormat = opts.indices ? 'indices' : 'repeat';\n  } else {\n    arrayFormat = defaults.arrayFormat;\n  }\n\n  if ('commaRoundTrip' in opts && typeof opts.commaRoundTrip !== 'boolean') {\n    throw new TypeError('`commaRoundTrip` must be a boolean, or absent');\n  }\n\n  const allowDots =\n    typeof opts.allowDots === 'undefined' ?\n      !!opts.encodeDotInKeys === true ?\n        true\n      : defaults.allowDots\n    : !!opts.allowDots;\n\n  return {\n    addQueryPrefix: typeof opts.addQueryPrefix === 'boolean' ? opts.addQueryPrefix : defaults.addQueryPrefix,\n    // @ts-ignore\n    allowDots: allowDots,\n    allowEmptyArrays:\n      typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n    arrayFormat: arrayFormat,\n    charset: charset,\n    charsetSentinel:\n      typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n    commaRoundTrip: !!opts.commaRoundTrip,\n    delimiter: typeof opts.delimiter === 'undefined' ? defaults.delimiter : opts.delimiter,\n    encode: typeof opts.encode === 'boolean' ? opts.encode : defaults.encode,\n    encodeDotInKeys:\n      typeof opts.encodeDotInKeys === 'boolean' ? opts.encodeDotInKeys : defaults.encodeDotInKeys,\n    encoder: typeof opts.encoder === 'function' ? opts.encoder : defaults.encoder,\n    encodeValuesOnly:\n      typeof opts.encodeValuesOnly === 'boolean' ? opts.encodeValuesOnly : defaults.encodeValuesOnly,\n    filter: filter,\n    format: format,\n    formatter: formatter,\n    serializeDate: typeof opts.serializeDate === 'function' ? opts.serializeDate : defaults.serializeDate,\n    skipNulls: typeof opts.skipNulls === 'boolean' ? opts.skipNulls : defaults.skipNulls,\n    // @ts-ignore\n    sort: typeof opts.sort === 'function' ? opts.sort : null,\n    strictNullHandling:\n      typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling,\n  };\n}\n\nexport function stringify(object: any, opts: StringifyOptions = {}) {\n  let obj = object;\n  const options = normalize_stringify_options(opts);\n\n  let obj_keys: PropertyKey[] | undefined;\n  let filter;\n\n  if (typeof options.filter === 'function') {\n    filter = options.filter;\n    obj = filter('', obj);\n  } else if (isArray(options.filter)) {\n    filter = options.filter;\n    obj_keys = filter;\n  }\n\n  const keys: string[] = [];\n\n  if (typeof obj !== 'object' || obj === null) {\n    return '';\n  }\n\n  const generateArrayPrefix = array_prefix_generators[options.arrayFormat];\n  const commaRoundTrip = generateArrayPrefix === 'comma' && options.commaRoundTrip;\n\n  if (!obj_keys) {\n    obj_keys = Object.keys(obj);\n  }\n\n  if (options.sort) {\n    obj_keys.sort(options.sort);\n  }\n\n  const sideChannel = new WeakMap();\n  for (let i = 0; i < obj_keys.length; ++i) {\n    const key = obj_keys[i]!;\n\n    if (options.skipNulls && obj[key] === null) {\n      continue;\n    }\n    push_to_array(\n      keys,\n      inner_stringify(\n        obj[key],\n        key,\n        // @ts-expect-error\n        generateArrayPrefix,\n        commaRoundTrip,\n        options.allowEmptyArrays,\n        options.strictNullHandling,\n        options.skipNulls,\n        options.encodeDotInKeys,\n        options.encode ? options.encoder : null,\n        options.filter,\n        options.sort,\n        options.allowDots,\n        options.serializeDate,\n        options.format,\n        options.formatter,\n        options.encodeValuesOnly,\n        options.charset,\n        sideChannel,\n      ),\n    );\n  }\n\n  const joined = keys.join(options.delimiter);\n  let prefix = options.addQueryPrefix === true ? '?' : '';\n\n  if (options.charsetSentinel) {\n    if (options.charset === 'iso-8859-1') {\n      // encodeURIComponent('&#10003;'), the \"numeric entity\" representation of a checkmark\n      prefix += 'utf8=%26%2310003%3B&';\n    } else {\n      // encodeURIComponent('')\n      prefix += 'utf8=%E2%9C%93&';\n    }\n  }\n\n  return joined.length > 0 ? prefix + joined : '';\n}\n","import type { RouteMatch } from '../route-matches/route-match'\nimport type { RouteDefinition } from '../route-definitions/route-definition'\nimport type { Params } from '../request/params'\n\nimport { isDynamicRoute } from '../../shared/lib/router/utils'\nimport {\n  getRouteMatcher,\n  type RouteMatchFn,\n} from '../../shared/lib/router/utils/route-matcher'\nimport { getRouteRegex } from '../../shared/lib/router/utils/route-regex'\n\ntype RouteMatchResult = {\n  params?: Params\n}\n\nexport class RouteMatcher<D extends RouteDefinition = RouteDefinition> {\n  private readonly dynamic?: RouteMatchFn\n\n  /**\n   * When set, this is an array of all the other matchers that are duplicates of\n   * this one. This is used by the managers to warn the users about possible\n   * duplicate matches on routes.\n   */\n  public duplicated?: Array<RouteMatcher>\n\n  constructor(public readonly definition: D) {\n    if (isDynamicRoute(definition.pathname)) {\n      this.dynamic = getRouteMatcher(getRouteRegex(definition.pathname))\n    }\n  }\n\n  /**\n   * Identity returns the identity part of the matcher. This is used to compare\n   * a unique matcher to another. This is also used when sorting dynamic routes,\n   * so it must contain the pathname part.\n   */\n  public get identity(): string {\n    return this.definition.pathname\n  }\n\n  public get isDynamic() {\n    return this.dynamic !== undefined\n  }\n\n  public match(pathname: string): RouteMatch<D> | null {\n    const result = this.test(pathname)\n    if (!result) return null\n\n    return { definition: this.definition, params: result.params }\n  }\n\n  public test(pathname: string): RouteMatchResult | null {\n    if (this.dynamic) {\n      const params = this.dynamic(pathname)\n      if (!params) return null\n\n      return { params }\n    }\n\n    if (pathname === this.definition.pathname) {\n      return {}\n    }\n\n    return null\n  }\n}\n","import type { RequestData, FetchEventResult } from './types'\nimport type { RequestInit } from './spec-extension/request'\nimport { PageSignatureError } from './error'\nimport { fromNodeOutgoingHttpHeaders, normalizeNextQueryParam } from './utils'\nimport {\n  NextFetchEvent,\n  getWaitUntilPromiseFromEvent,\n} from './spec-extension/fetch-event'\nimport { NextRequest } from './spec-extension/request'\nimport { NextResponse } from './spec-extension/response'\nimport {\n  parseRelativeURL,\n  getRelativeURL,\n} from '../../shared/lib/router/utils/relativize-url'\nimport { NextURL } from './next-url'\nimport { stripInternalSearchParams } from '../internal-utils'\nimport { normalizeRscURL } from '../../shared/lib/router/utils/app-paths'\nimport {\n  FLIGHT_HEADERS,\n  NEXT_REWRITTEN_PATH_HEADER,\n  NEXT_REWRITTEN_QUERY_HEADER,\n  NEXT_RSC_UNION_QUERY,\n  RSC_HEADER,\n} from '../../client/components/app-router-headers'\nimport { ensureInstrumentationRegistered } from './globals'\nimport { createRequestStoreForAPI } from '../async-storage/request-store'\nimport { workUnitAsyncStorage } from '../app-render/work-unit-async-storage.external'\nimport { createWorkStore } from '../async-storage/work-store'\nimport { workAsyncStorage } from '../app-render/work-async-storage.external'\nimport { NEXT_ROUTER_PREFETCH_HEADER } from '../../client/components/app-router-headers'\nimport { getTracer } from '../lib/trace/tracer'\nimport type { TextMapGetter } from 'next/dist/compiled/@opentelemetry/api'\nimport { MiddlewareSpan } from '../lib/trace/constants'\nimport { CloseController } from './web-on-close'\nimport { getEdgePreviewProps } from './get-edge-preview-props'\nimport { getBuiltinRequestContext } from '../after/builtin-request-context'\nimport { getImplicitTags } from '../lib/implicit-tags'\n\nexport class NextRequestHint extends NextRequest {\n  sourcePage: string\n  fetchMetrics: FetchEventResult['fetchMetrics'] | undefined\n\n  constructor(params: {\n    init: RequestInit\n    input: Request | string\n    page: string\n  }) {\n    super(params.input, params.init)\n    this.sourcePage = params.page\n  }\n\n  get request() {\n    throw new PageSignatureError({ page: this.sourcePage })\n  }\n\n  respondWith() {\n    throw new PageSignatureError({ page: this.sourcePage })\n  }\n\n  waitUntil() {\n    throw new PageSignatureError({ page: this.sourcePage })\n  }\n}\n\nconst headersGetter: TextMapGetter<Headers> = {\n  keys: (headers) => Array.from(headers.keys()),\n  get: (headers, key) => headers.get(key) ?? undefined,\n}\n\nexport type AdapterOptions = {\n  handler: (req: NextRequestHint, event: NextFetchEvent) => Promise<Response>\n  page: string\n  request: RequestData\n  IncrementalCache?: typeof import('../lib/incremental-cache').IncrementalCache\n  incrementalCacheHandler?: typeof import('../lib/incremental-cache').CacheHandler\n  bypassNextUrl?: boolean\n}\n\n// This has to be compatible with what the Vercel builder does as well:\n// https://github.com/vercel/vercel/blob/0e0a6eb9f12216202ae2f5ee37e4ada1796361fd/packages/next/src/edge-function-source/get-edge-function.ts#L112-L136\nexport type EdgeHandler = (opts: {\n  request: AdapterOptions['request']\n}) => Promise<FetchEventResult>\n\nlet propagator: <T>(request: NextRequestHint, fn: () => T) => T = (\n  request,\n  fn\n) => {\n  const tracer = getTracer()\n  return tracer.withPropagatedContext(request.headers, fn, headersGetter)\n}\n\nlet testApisIntercepted = false\n\nfunction ensureTestApisIntercepted() {\n  if (!testApisIntercepted) {\n    testApisIntercepted = true\n    if (process.env.NEXT_PRIVATE_TEST_PROXY === 'true') {\n      const { interceptTestApis, wrapRequestHandler } =\n        // eslint-disable-next-line @next/internal/typechecked-require -- experimental/testmode is not built ins next/dist/esm\n        require('next/dist/experimental/testmode/server-edge') as typeof import('../../experimental/testmode/server-edge')\n      interceptTestApis()\n      propagator = wrapRequestHandler(propagator)\n    }\n  }\n}\n\nexport async function adapter(\n  params: AdapterOptions\n): Promise<FetchEventResult> {\n  ensureTestApisIntercepted()\n  await ensureInstrumentationRegistered()\n\n  // TODO-APP: use explicit marker for this\n  const isEdgeRendering =\n    typeof (globalThis as any).__BUILD_MANIFEST !== 'undefined'\n\n  params.request.url = normalizeRscURL(params.request.url)\n\n  const requestURL = params.bypassNextUrl\n    ? new URL(params.request.url)\n    : new NextURL(params.request.url, {\n        headers: params.request.headers,\n        nextConfig: params.request.nextConfig,\n      })\n\n  // Iterator uses an index to keep track of the current iteration. Because of deleting and appending below we can't just use the iterator.\n  // Instead we use the keys before iteration.\n  const keys = [...requestURL.searchParams.keys()]\n  for (const key of keys) {\n    const value = requestURL.searchParams.getAll(key)\n\n    const normalizedKey = normalizeNextQueryParam(key)\n    if (normalizedKey) {\n      requestURL.searchParams.delete(normalizedKey)\n      for (const val of value) {\n        requestURL.searchParams.append(normalizedKey, val)\n      }\n      requestURL.searchParams.delete(key)\n    }\n  }\n\n  // Ensure users only see page requests, never data requests.\n  let buildId = process.env.__NEXT_BUILD_ID || ''\n  if ('buildId' in requestURL) {\n    buildId = (requestURL as NextURL).buildId || ''\n    requestURL.buildId = ''\n  }\n\n  const requestHeaders = fromNodeOutgoingHttpHeaders(params.request.headers)\n  const isNextDataRequest = requestHeaders.has('x-nextjs-data')\n  const isRSCRequest = requestHeaders.get(RSC_HEADER) === '1'\n\n  if (isNextDataRequest && requestURL.pathname === '/index') {\n    requestURL.pathname = '/'\n  }\n\n  const flightHeaders = new Map()\n\n  // Headers should only be stripped for middleware\n  if (!isEdgeRendering) {\n    for (const header of FLIGHT_HEADERS) {\n      const value = requestHeaders.get(header)\n      if (value !== null) {\n        flightHeaders.set(header, value)\n        requestHeaders.delete(header)\n      }\n    }\n  }\n\n  const normalizeURL = process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE\n    ? new URL(params.request.url)\n    : requestURL\n\n  const rscHash = normalizeURL.searchParams.get(NEXT_RSC_UNION_QUERY)\n\n  const request = new NextRequestHint({\n    page: params.page,\n    // Strip internal query parameters off the request.\n    input: stripInternalSearchParams(normalizeURL).toString(),\n    init: {\n      body: params.request.body,\n      headers: requestHeaders,\n      method: params.request.method,\n      nextConfig: params.request.nextConfig,\n      signal: params.request.signal,\n    },\n  })\n\n  /**\n   * This allows to identify the request as a data request. The user doesn't\n   * need to know about this property neither use it. We add it for testing\n   * purposes.\n   */\n  if (isNextDataRequest) {\n    Object.defineProperty(request, '__isData', {\n      enumerable: false,\n      value: true,\n    })\n  }\n\n  if (\n    // If we are inside of the next start sandbox\n    // leverage the shared instance if not we need\n    // to create a fresh cache instance each time\n    !(globalThis as any).__incrementalCacheShared &&\n    (params as any).IncrementalCache\n  ) {\n    ;(globalThis as any).__incrementalCache = new (\n      params as {\n        IncrementalCache: typeof import('../lib/incremental-cache').IncrementalCache\n      }\n    ).IncrementalCache({\n      CurCacheHandler: params.incrementalCacheHandler,\n      minimalMode: process.env.NODE_ENV !== 'development',\n      fetchCacheKeyPrefix: process.env.__NEXT_FETCH_CACHE_KEY_PREFIX,\n      dev: process.env.NODE_ENV === 'development',\n      requestHeaders: params.request.headers as any,\n\n      getPrerenderManifest: () => {\n        return {\n          version: -1 as any, // letting us know this doesn't conform to spec\n          routes: {},\n          dynamicRoutes: {},\n          notFoundRoutes: [],\n          preview: getEdgePreviewProps(),\n        }\n      },\n    })\n  }\n\n  // if we're in an edge runtime sandbox, we should use the waitUntil\n  // that we receive from the enclosing NextServer\n  const outerWaitUntil =\n    params.request.waitUntil ?? getBuiltinRequestContext()?.waitUntil\n\n  const event = new NextFetchEvent({\n    request,\n    page: params.page,\n    context: outerWaitUntil ? { waitUntil: outerWaitUntil } : undefined,\n  })\n  let response\n  let cookiesFromResponse\n\n  response = await propagator(request, () => {\n    // we only care to make async storage available for middleware\n    const isMiddleware =\n      params.page === '/middleware' ||\n      params.page === '/src/middleware' ||\n      params.page === '/proxy' ||\n      params.page === '/src/proxy'\n\n    if (isMiddleware) {\n      // if we're in an edge function, we only get a subset of `nextConfig` (no `experimental`),\n      // so we have to inject it via DefinePlugin.\n      // in `next start` this will be passed normally (see `NextNodeServer.runMiddleware`).\n\n      const waitUntil = event.waitUntil.bind(event)\n      const closeController = new CloseController()\n\n      return getTracer().trace(\n        MiddlewareSpan.execute,\n        {\n          spanName: `middleware ${request.method}`,\n          attributes: {\n            'http.target': request.nextUrl.pathname,\n            'http.method': request.method,\n          },\n        },\n        async () => {\n          try {\n            const onUpdateCookies = (cookies: Array<string>) => {\n              cookiesFromResponse = cookies\n            }\n            const previewProps = getEdgePreviewProps()\n            const page = '/' // Fake Work\n            const fallbackRouteParams = null\n\n            const implicitTags = await getImplicitTags(\n              page,\n              request.nextUrl,\n              fallbackRouteParams\n            )\n\n            const requestStore = createRequestStoreForAPI(\n              request,\n              request.nextUrl,\n              implicitTags,\n              onUpdateCookies,\n              previewProps\n            )\n\n            const workStore = createWorkStore({\n              page,\n              renderOpts: {\n                cacheLifeProfiles:\n                  params.request.nextConfig?.experimental?.cacheLife,\n                cacheComponents: false,\n                experimental: {\n                  isRoutePPREnabled: false,\n                  authInterrupts:\n                    !!params.request.nextConfig?.experimental?.authInterrupts,\n                },\n                supportsDynamicResponse: true,\n                waitUntil,\n                onClose: closeController.onClose.bind(closeController),\n                onAfterTaskError: undefined,\n              },\n              isPrefetchRequest:\n                request.headers.get(NEXT_ROUTER_PREFETCH_HEADER) === '1',\n              buildId: buildId ?? '',\n              previouslyRevalidatedTags: [],\n            })\n\n            return await workAsyncStorage.run(workStore, () =>\n              workUnitAsyncStorage.run(\n                requestStore,\n                params.handler,\n                request,\n                event\n              )\n            )\n          } finally {\n            // middleware cannot stream, so we can consider the response closed\n            // as soon as the handler returns.\n            // we can delay running it until a bit later --\n            // if it's needed, we'll have a `waitUntil` lock anyway.\n            setTimeout(() => {\n              closeController.dispatchClose()\n            }, 0)\n          }\n        }\n      )\n    }\n    return params.handler(request, event)\n  })\n\n  // check if response is a Response object\n  if (response && !(response instanceof Response)) {\n    throw new TypeError('Expected an instance of Response to be returned')\n  }\n\n  if (response && cookiesFromResponse) {\n    response.headers.set('set-cookie', cookiesFromResponse)\n  }\n\n  /**\n   * For rewrites we must always include the locale in the final pathname\n   * so we re-create the NextURL forcing it to include it when the it is\n   * an internal rewrite. Also we make sure the outgoing rewrite URL is\n   * a data URL if the request was a data request.\n   */\n  const rewrite = response?.headers.get('x-middleware-rewrite')\n  if (response && rewrite && (isRSCRequest || !isEdgeRendering)) {\n    const destination = new NextURL(rewrite, {\n      forceLocale: true,\n      headers: params.request.headers,\n      nextConfig: params.request.nextConfig,\n    })\n\n    if (!process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE && !isEdgeRendering) {\n      if (destination.host === request.nextUrl.host) {\n        destination.buildId = buildId || destination.buildId\n        response.headers.set('x-middleware-rewrite', String(destination))\n      }\n    }\n\n    /**\n     * When the request is a data request we must show if there was a rewrite\n     * with an internal header so the client knows which component to load\n     * from the data request.\n     */\n    const { url: relativeDestination, isRelative } = parseRelativeURL(\n      destination.toString(),\n      requestURL.toString()\n    )\n\n    if (\n      !isEdgeRendering &&\n      isNextDataRequest &&\n      // if the rewrite is external and external rewrite\n      // resolving config is enabled don't add this header\n      // so the upstream app can set it instead\n      !(\n        process.env.__NEXT_EXTERNAL_MIDDLEWARE_REWRITE_RESOLVE &&\n        relativeDestination.match(/http(s)?:\\/\\//)\n      )\n    ) {\n      response.headers.set('x-nextjs-rewrite', relativeDestination)\n    }\n\n    // Check to see if this is a non-relative rewrite. If it is, we need\n    // to check to see if it's an allowed origin to receive the rewritten\n    // headers.\n    const isAllowedOrigin = !isRelative\n      ? params.request.nextConfig?.experimental?.clientParamParsingOrigins?.some(\n          (origin) => new RegExp(origin).test(destination.origin)\n        )\n      : false\n\n    // If this is an RSC request, and the pathname or search has changed, and\n    // this isn't an external rewrite, we need to set the rewritten pathname and\n    // query headers.\n    if (isRSCRequest && (isRelative || isAllowedOrigin)) {\n      if (requestURL.pathname !== destination.pathname) {\n        response.headers.set(NEXT_REWRITTEN_PATH_HEADER, destination.pathname)\n      }\n      if (requestURL.search !== destination.search) {\n        response.headers.set(\n          NEXT_REWRITTEN_QUERY_HEADER,\n          // remove the leading ? from the search string\n          destination.search.slice(1)\n        )\n      }\n    }\n  }\n\n  /**\n   * Always forward the `_rsc` search parameter to the rewritten URL for RSC requests,\n   * unless it's already present. This is necessary to ensure that RSC hash validation\n   * works correctly after a rewrite. For internal rewrites, the server can validate the\n   * RSC hash using the original URL, so forwarding the `_rsc` parameter is less critical.\n   * However, for external rewrites (where the request is proxied to another Next.js server),\n   * the external server does not have access to the original URL or its search parameters.\n   * In these cases, forwarding the `_rsc` parameter is essential so that the external server\n   * can perform the correct RSC hash validation.\n   */\n  if (response && rewrite && isRSCRequest && rscHash) {\n    const rewriteURL = new URL(rewrite)\n    if (!rewriteURL.searchParams.has(NEXT_RSC_UNION_QUERY)) {\n      rewriteURL.searchParams.set(NEXT_RSC_UNION_QUERY, rscHash)\n      response.headers.set('x-middleware-rewrite', rewriteURL.toString())\n    }\n  }\n\n  /**\n   * For redirects we will not include the locale in case when it is the\n   * default and we must also make sure the outgoing URL is a data one if\n   * the incoming request was a data request.\n   */\n  const redirect = response?.headers.get('Location')\n  if (response && redirect && !isEdgeRendering) {\n    const redirectURL = new NextURL(redirect, {\n      forceLocale: false,\n      headers: params.request.headers,\n      nextConfig: params.request.nextConfig,\n    })\n\n    /**\n     * Responses created from redirects have immutable headers so we have\n     * to clone the response to be able to modify it.\n     */\n    response = new Response(response.body, response)\n\n    if (!process.env.__NEXT_NO_MIDDLEWARE_URL_NORMALIZE) {\n      if (redirectURL.host === requestURL.host) {\n        redirectURL.buildId = buildId || redirectURL.buildId\n        response.headers.set(\n          'Location',\n          getRelativeURL(redirectURL, requestURL)\n        )\n      }\n    }\n\n    /**\n     * When the request is a data request we can't use the location header as\n     * it may end up with CORS error. Instead we map to an internal header so\n     * the client knows the destination.\n     */\n    if (isNextDataRequest) {\n      response.headers.delete('Location')\n      response.headers.set(\n        'x-nextjs-redirect',\n        getRelativeURL(redirectURL.toString(), requestURL.toString())\n      )\n    }\n  }\n\n  const finalResponse = response ? response : NextResponse.next()\n\n  // Flight headers are not overridable / removable so they are applied at the end.\n  const middlewareOverrideHeaders = finalResponse.headers.get(\n    'x-middleware-override-headers'\n  )\n  const overwrittenHeaders: string[] = []\n  if (middlewareOverrideHeaders) {\n    for (const [key, value] of flightHeaders) {\n      finalResponse.headers.set(`x-middleware-request-${key}`, value)\n      overwrittenHeaders.push(key)\n    }\n\n    if (overwrittenHeaders.length > 0) {\n      finalResponse.headers.set(\n        'x-middleware-override-headers',\n        middlewareOverrideHeaders + ',' + overwrittenHeaders.join(',')\n      )\n    }\n  }\n\n  return {\n    response: finalResponse,\n    waitUntil: getWaitUntilPromiseFromEvent(event) ?? Promise.resolve(),\n    fetchMetrics: request.fetchMetrics,\n  }\n}\n","import { toNodeOutgoingHttpHeaders } from '../web/utils';\nimport { BaseNextRequest, BaseNextResponse } from './index';\nimport { DetachedPromise } from '../../lib/detached-promise';\nimport { CloseController, trackBodyConsumed } from '../web/web-on-close';\nimport { InvariantError } from '../../shared/lib/invariant-error';\nexport class WebNextRequest extends BaseNextRequest {\n    constructor(request){\n        const url = new URL(request.url);\n        super(request.method, url.href.slice(url.origin.length), request.clone().body);\n        this.request = request;\n        this.fetchMetrics = request.fetchMetrics;\n        this.headers = {};\n        for (const [name, value] of request.headers.entries()){\n            this.headers[name] = value;\n        }\n    }\n    async parseBody(_limit) {\n        throw Object.defineProperty(new Error('parseBody is not implemented in the web runtime'), \"__NEXT_ERROR_CODE\", {\n            value: \"E213\",\n            enumerable: false,\n            configurable: true\n        });\n    }\n}\nexport class WebNextResponse extends BaseNextResponse {\n    constructor(transformStream = new TransformStream()){\n        super(transformStream.writable), this.transformStream = transformStream, this.headers = new Headers(), this.textBody = undefined, this.closeController = new CloseController(), this.sendPromise = new DetachedPromise(), this._sent = false;\n    }\n    setHeader(name, value) {\n        this.headers.delete(name);\n        for (const val of Array.isArray(value) ? value : [\n            value\n        ]){\n            this.headers.append(name, val);\n        }\n        return this;\n    }\n    removeHeader(name) {\n        this.headers.delete(name);\n        return this;\n    }\n    getHeaderValues(name) {\n        var _this_getHeader;\n        // https://developer.mozilla.org/docs/Web/API/Headers/get#example\n        return (_this_getHeader = this.getHeader(name)) == null ? void 0 : _this_getHeader.split(',').map((v)=>v.trimStart());\n    }\n    getHeader(name) {\n        return this.headers.get(name) ?? undefined;\n    }\n    getHeaders() {\n        return toNodeOutgoingHttpHeaders(this.headers);\n    }\n    hasHeader(name) {\n        return this.headers.has(name);\n    }\n    appendHeader(name, value) {\n        this.headers.append(name, value);\n        return this;\n    }\n    body(value) {\n        this.textBody = value;\n        return this;\n    }\n    send() {\n        this.sendPromise.resolve();\n        this._sent = true;\n    }\n    get sent() {\n        return this._sent;\n    }\n    async toResponse() {\n        // If we haven't called `send` yet, wait for it to be called.\n        if (!this.sent) await this.sendPromise.promise;\n        const body = this.textBody ?? this.transformStream.readable;\n        let bodyInit = body;\n        // if the response is streaming, onClose() can still be called after this point.\n        const canAddListenersLater = typeof bodyInit !== 'string';\n        const shouldTrackBody = canAddListenersLater ? true : this.closeController.listeners > 0;\n        if (shouldTrackBody) {\n            bodyInit = trackBodyConsumed(body, ()=>{\n                this.closeController.dispatchClose();\n            });\n        }\n        return new Response(bodyInit, {\n            headers: this.headers,\n            status: this.statusCode,\n            statusText: this.statusMessage\n        });\n    }\n    onClose(callback) {\n        if (this.closeController.isClosed) {\n            throw Object.defineProperty(new InvariantError('Cannot call onClose on a WebNextResponse that is already closed'), \"__NEXT_ERROR_CODE\", {\n                value: \"E599\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        return this.closeController.onClose(callback);\n    }\n}\n\n//# sourceMappingURL=web.js.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n/**\n * This module provides internal shims and utility functions for environments where certain Node.js or global types may not be available.\n *\n * These are used to ensure we can provide a consistent behaviour between different JavaScript environments and good error\n * messages in cases where an environment isn't fully supported.\n */\n\nimport type { Fetch } from './builtin-types';\nimport type { ReadableStream } from './shim-types';\n\nexport function getDefaultFetch(): Fetch {\n  if (typeof fetch !== 'undefined') {\n    return fetch as any;\n  }\n\n  throw new Error(\n    '`fetch` is not defined as a global; Either pass `fetch` to the client, `new OpenAI({ fetch })` or polyfill the global, `globalThis.fetch = fetch`',\n  );\n}\n\ntype ReadableStreamArgs = ConstructorParameters<typeof ReadableStream>;\n\nexport function makeReadableStream(...args: ReadableStreamArgs): ReadableStream {\n  const ReadableStream = (globalThis as any).ReadableStream;\n  if (typeof ReadableStream === 'undefined') {\n    // Note: All of the platforms / runtimes we officially support already define\n    // `ReadableStream` as a global, so this should only ever be hit on unsupported runtimes.\n    throw new Error(\n      '`ReadableStream` is not defined as a global; You will need to polyfill it, `globalThis.ReadableStream = ReadableStream`',\n    );\n  }\n\n  return new ReadableStream(...args);\n}\n\nexport function ReadableStreamFrom<T>(iterable: Iterable<T> | AsyncIterable<T>): ReadableStream<T> {\n  let iter: AsyncIterator<T> | Iterator<T> =\n    Symbol.asyncIterator in iterable ? iterable[Symbol.asyncIterator]() : iterable[Symbol.iterator]();\n\n  return makeReadableStream({\n    start() {},\n    async pull(controller: any) {\n      const { done, value } = await iter.next();\n      if (done) {\n        controller.close();\n      } else {\n        controller.enqueue(value);\n      }\n    },\n    async cancel() {\n      await iter.return?.();\n    },\n  });\n}\n\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function ReadableStreamToAsyncIterable<T>(stream: any): AsyncIterableIterator<T> {\n  if (stream[Symbol.asyncIterator]) return stream;\n\n  const reader = stream.getReader();\n  return {\n    async next() {\n      try {\n        const result = await reader.read();\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\n        return result;\n      } catch (e) {\n        reader.releaseLock(); // release lock when stream becomes errored\n        throw e;\n      }\n    },\n    async return() {\n      const cancelPromise = reader.cancel();\n      reader.releaseLock();\n      await cancelPromise;\n      return { done: true, value: undefined };\n    },\n    [Symbol.asyncIterator]() {\n      return this;\n    },\n  };\n}\n\n/**\n * Cancels a ReadableStream we don't need to consume.\n * See https://undici.nodejs.org/#/?id=garbage-collection\n */\nexport async function CancelReadableStream(stream: any): Promise<void> {\n  if (stream === null || typeof stream !== 'object') return;\n\n  if (stream[Symbol.asyncIterator]) {\n    await stream[Symbol.asyncIterator]().return?.();\n    return;\n  }\n\n  const reader = stream.getReader();\n  const cancelPromise = reader.cancel();\n  reader.releaseLock();\n  await cancelPromise;\n}\n","/** Monitor when the consumer finishes reading the response body.\nthat's as close as we can get to `res.on('close')` using web APIs.\n*/ export function trackBodyConsumed(body, onEnd) {\n    if (typeof body === 'string') {\n        const generator = async function* generate() {\n            const encoder = new TextEncoder();\n            yield encoder.encode(body);\n            onEnd();\n        };\n        // @ts-expect-error BodyInit typings doesn't seem to include AsyncIterables even though it's supported in practice\n        return generator();\n    } else {\n        return trackStreamConsumed(body, onEnd);\n    }\n}\nexport function trackStreamConsumed(stream, onEnd) {\n    // NOTE: This function must handle `stream` being aborted or cancelled,\n    // so it can't just be this:\n    //\n    //   return stream.pipeThrough(new TransformStream({ flush() { onEnd() } }))\n    //\n    // because that doesn't handle cancellations.\n    // (and cancellation handling via `Transformer.cancel` is only available in node >20)\n    const dest = new TransformStream();\n    const runOnEnd = ()=>onEnd();\n    stream.pipeTo(dest.writable).then(runOnEnd, runOnEnd);\n    return dest.readable;\n}\nexport class CloseController {\n    onClose(callback) {\n        if (this.isClosed) {\n            throw Object.defineProperty(new Error('Cannot subscribe to a closed CloseController'), \"__NEXT_ERROR_CODE\", {\n                value: \"E365\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        this.target.addEventListener('close', callback);\n        this.listeners++;\n    }\n    dispatchClose() {\n        if (this.isClosed) {\n            throw Object.defineProperty(new Error('Cannot close a CloseController multiple times'), \"__NEXT_ERROR_CODE\", {\n                value: \"E229\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        if (this.listeners > 0) {\n            this.target.dispatchEvent(new Event('close'));\n        }\n        this.isClosed = true;\n    }\n    constructor(){\n        this.target = new EventTarget();\n        this.listeners = 0;\n        this.isClosed = false;\n    }\n}\n\n//# sourceMappingURL=web-on-close.js.map","/**\n * The result of parsing a URL relative to a base URL.\n */ export function parseRelativeURL(url, base) {\n    const baseURL = typeof base === 'string' ? new URL(base) : base;\n    const relative = new URL(url, base);\n    // The URL is relative if the origin is the same as the base URL.\n    const isRelative = relative.origin === baseURL.origin;\n    return {\n        url: isRelative ? relative.toString().slice(baseURL.origin.length) : relative.toString(),\n        isRelative\n    };\n}\n/**\n * Given a URL as a string and a base URL it will make the URL relative\n * if the parsed protocol and host is the same as the one in the base\n * URL. Otherwise it returns the same URL string.\n */ export function getRelativeURL(url, base) {\n    const relative = parseRelativeURL(url, base);\n    return relative.url;\n}\n\n//# sourceMappingURL=relativize-url.js.map","import { RFC1738 } from './formats';\nimport type { DefaultEncoder, Format } from './types';\nimport { isArray } from '../utils/values';\n\nexport let has = (obj: object, key: PropertyKey): boolean => (\n  (has = (Object as any).hasOwn ?? Function.prototype.call.bind(Object.prototype.hasOwnProperty)),\n  has(obj, key)\n);\n\nconst hex_table = /* @__PURE__ */ (() => {\n  const array = [];\n  for (let i = 0; i < 256; ++i) {\n    array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n  }\n\n  return array;\n})();\n\nfunction compact_queue<T extends Record<string, any>>(queue: Array<{ obj: T; prop: string }>) {\n  while (queue.length > 1) {\n    const item = queue.pop();\n    if (!item) continue;\n\n    const obj = item.obj[item.prop];\n\n    if (isArray(obj)) {\n      const compacted: unknown[] = [];\n\n      for (let j = 0; j < obj.length; ++j) {\n        if (typeof obj[j] !== 'undefined') {\n          compacted.push(obj[j]);\n        }\n      }\n\n      // @ts-ignore\n      item.obj[item.prop] = compacted;\n    }\n  }\n}\n\nfunction array_to_object(source: any[], options: { plainObjects: boolean }) {\n  const obj = options && options.plainObjects ? Object.create(null) : {};\n  for (let i = 0; i < source.length; ++i) {\n    if (typeof source[i] !== 'undefined') {\n      obj[i] = source[i];\n    }\n  }\n\n  return obj;\n}\n\nexport function merge(\n  target: any,\n  source: any,\n  options: { plainObjects?: boolean; allowPrototypes?: boolean } = {},\n) {\n  if (!source) {\n    return target;\n  }\n\n  if (typeof source !== 'object') {\n    if (isArray(target)) {\n      target.push(source);\n    } else if (target && typeof target === 'object') {\n      if ((options && (options.plainObjects || options.allowPrototypes)) || !has(Object.prototype, source)) {\n        target[source] = true;\n      }\n    } else {\n      return [target, source];\n    }\n\n    return target;\n  }\n\n  if (!target || typeof target !== 'object') {\n    return [target].concat(source);\n  }\n\n  let mergeTarget = target;\n  if (isArray(target) && !isArray(source)) {\n    // @ts-ignore\n    mergeTarget = array_to_object(target, options);\n  }\n\n  if (isArray(target) && isArray(source)) {\n    source.forEach(function (item, i) {\n      if (has(target, i)) {\n        const targetItem = target[i];\n        if (targetItem && typeof targetItem === 'object' && item && typeof item === 'object') {\n          target[i] = merge(targetItem, item, options);\n        } else {\n          target.push(item);\n        }\n      } else {\n        target[i] = item;\n      }\n    });\n    return target;\n  }\n\n  return Object.keys(source).reduce(function (acc, key) {\n    const value = source[key];\n\n    if (has(acc, key)) {\n      acc[key] = merge(acc[key], value, options);\n    } else {\n      acc[key] = value;\n    }\n    return acc;\n  }, mergeTarget);\n}\n\nexport function assign_single_source(target: any, source: any) {\n  return Object.keys(source).reduce(function (acc, key) {\n    acc[key] = source[key];\n    return acc;\n  }, target);\n}\n\nexport function decode(str: string, _: any, charset: string) {\n  const strWithoutPlus = str.replace(/\\+/g, ' ');\n  if (charset === 'iso-8859-1') {\n    // unescape never throws, no try...catch needed:\n    return strWithoutPlus.replace(/%[0-9a-f]{2}/gi, unescape);\n  }\n  // utf-8\n  try {\n    return decodeURIComponent(strWithoutPlus);\n  } catch (e) {\n    return strWithoutPlus;\n  }\n}\n\nconst limit = 1024;\n\nexport const encode: (\n  str: any,\n  defaultEncoder: DefaultEncoder,\n  charset: string,\n  type: 'key' | 'value',\n  format: Format,\n) => string = (str, _defaultEncoder, charset, _kind, format: Format) => {\n  // This code was originally written by Brian White for the io.js core querystring library.\n  // It has been adapted here for stricter adherence to RFC 3986\n  if (str.length === 0) {\n    return str;\n  }\n\n  let string = str;\n  if (typeof str === 'symbol') {\n    string = Symbol.prototype.toString.call(str);\n  } else if (typeof str !== 'string') {\n    string = String(str);\n  }\n\n  if (charset === 'iso-8859-1') {\n    return escape(string).replace(/%u[0-9a-f]{4}/gi, function ($0) {\n      return '%26%23' + parseInt($0.slice(2), 16) + '%3B';\n    });\n  }\n\n  let out = '';\n  for (let j = 0; j < string.length; j += limit) {\n    const segment = string.length >= limit ? string.slice(j, j + limit) : string;\n    const arr = [];\n\n    for (let i = 0; i < segment.length; ++i) {\n      let c = segment.charCodeAt(i);\n      if (\n        c === 0x2d || // -\n        c === 0x2e || // .\n        c === 0x5f || // _\n        c === 0x7e || // ~\n        (c >= 0x30 && c <= 0x39) || // 0-9\n        (c >= 0x41 && c <= 0x5a) || // a-z\n        (c >= 0x61 && c <= 0x7a) || // A-Z\n        (format === RFC1738 && (c === 0x28 || c === 0x29)) // ( )\n      ) {\n        arr[arr.length] = segment.charAt(i);\n        continue;\n      }\n\n      if (c < 0x80) {\n        arr[arr.length] = hex_table[c];\n        continue;\n      }\n\n      if (c < 0x800) {\n        arr[arr.length] = hex_table[0xc0 | (c >> 6)]! + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      if (c < 0xd800 || c >= 0xe000) {\n        arr[arr.length] =\n          hex_table[0xe0 | (c >> 12)]! + hex_table[0x80 | ((c >> 6) & 0x3f)] + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      i += 1;\n      c = 0x10000 + (((c & 0x3ff) << 10) | (segment.charCodeAt(i) & 0x3ff));\n\n      arr[arr.length] =\n        hex_table[0xf0 | (c >> 18)]! +\n        hex_table[0x80 | ((c >> 12) & 0x3f)] +\n        hex_table[0x80 | ((c >> 6) & 0x3f)] +\n        hex_table[0x80 | (c & 0x3f)];\n    }\n\n    out += arr.join('');\n  }\n\n  return out;\n};\n\nexport function compact(value: any) {\n  const queue = [{ obj: { o: value }, prop: 'o' }];\n  const refs = [];\n\n  for (let i = 0; i < queue.length; ++i) {\n    const item = queue[i];\n    // @ts-ignore\n    const obj = item.obj[item.prop];\n\n    const keys = Object.keys(obj);\n    for (let j = 0; j < keys.length; ++j) {\n      const key = keys[j]!;\n      const val = obj[key];\n      if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {\n        queue.push({ obj: obj, prop: key });\n        refs.push(val);\n      }\n    }\n  }\n\n  compact_queue(queue);\n\n  return value;\n}\n\nexport function is_regexp(obj: any) {\n  return Object.prototype.toString.call(obj) === '[object RegExp]';\n}\n\nexport function is_buffer(obj: any) {\n  if (!obj || typeof obj !== 'object') {\n    return false;\n  }\n\n  return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n}\n\nexport function combine(a: any, b: any) {\n  return [].concat(a, b);\n}\n\nexport function maybe_map<T>(val: T[], fn: (v: T) => T) {\n  if (isArray(val)) {\n    const mapped = [];\n    for (let i = 0; i < val.length; i += 1) {\n      mapped.push(fn(val[i]!));\n    }\n    return mapped;\n  }\n  return fn(val);\n}\n","import { OpenAIError } from '../error';\nimport type { ChatCompletionTool } from '../resources/chat/completions';\nimport {\n  ResponseTextConfig,\n  type FunctionTool,\n  type ParsedContent,\n  type ParsedResponse,\n  type ParsedResponseFunctionToolCall,\n  type ParsedResponseOutputItem,\n  type Response,\n  type ResponseCreateParamsBase,\n  type ResponseCreateParamsNonStreaming,\n  type ResponseFunctionToolCall,\n  type Tool,\n} from '../resources/responses/responses';\nimport { type AutoParseableTextFormat, isAutoParsableResponseFormat } from '../lib/parser';\n\nexport type ParseableToolsParams = Array<Tool> | ChatCompletionTool | null;\n\nexport type ResponseCreateParamsWithTools = ResponseCreateParamsBase & {\n  tools?: ParseableToolsParams;\n};\n\ntype TextConfigParams = { text?: ResponseTextConfig };\n\nexport type ExtractParsedContentFromParams<Params extends TextConfigParams> =\n  NonNullable<Params['text']>['format'] extends AutoParseableTextFormat<infer P> ? P : null;\n\nexport function maybeParseResponse<\n  Params extends ResponseCreateParamsBase | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(response: Response, params: Params): ParsedResponse<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...response,\n      output_parsed: null,\n      output: response.output.map((item) => {\n        if (item.type === 'function_call') {\n          return {\n            ...item,\n            parsed_arguments: null,\n          };\n        }\n\n        if (item.type === 'message') {\n          return {\n            ...item,\n            content: item.content.map((content) => ({\n              ...content,\n              parsed: null,\n            })),\n          };\n        } else {\n          return item;\n        }\n      }),\n    };\n  }\n\n  return parseResponse(response, params);\n}\n\nexport function parseResponse<\n  Params extends ResponseCreateParamsBase,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(response: Response, params: Params): ParsedResponse<ParsedT> {\n  const output: Array<ParsedResponseOutputItem<ParsedT>> = response.output.map(\n    (item): ParsedResponseOutputItem<ParsedT> => {\n      if (item.type === 'function_call') {\n        return {\n          ...item,\n          parsed_arguments: parseToolCall(params, item),\n        };\n      }\n      if (item.type === 'message') {\n        const content: Array<ParsedContent<ParsedT>> = item.content.map((content) => {\n          if (content.type === 'output_text') {\n            return {\n              ...content,\n              parsed: parseTextFormat(params, content.text),\n            };\n          }\n\n          return content;\n        });\n\n        return {\n          ...item,\n          content,\n        };\n      }\n\n      return item;\n    },\n  );\n\n  const parsed: Omit<ParsedResponse<ParsedT>, 'output_parsed'> = Object.assign({}, response, { output });\n  if (!Object.getOwnPropertyDescriptor(response, 'output_text')) {\n    addOutputText(parsed);\n  }\n\n  Object.defineProperty(parsed, 'output_parsed', {\n    enumerable: true,\n    get() {\n      for (const output of parsed.output) {\n        if (output.type !== 'message') {\n          continue;\n        }\n\n        for (const content of output.content) {\n          if (content.type === 'output_text' && content.parsed !== null) {\n            return content.parsed;\n          }\n        }\n      }\n\n      return null;\n    },\n  });\n\n  return parsed as ParsedResponse<ParsedT>;\n}\n\nfunction parseTextFormat<\n  Params extends ResponseCreateParamsBase,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.text?.format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if ('$parseRaw' in params.text?.format) {\n    const text_format = params.text?.format as unknown as AutoParseableTextFormat<ParsedT>;\n    return text_format.$parseRaw(content);\n  }\n\n  return JSON.parse(content);\n}\n\nexport function hasAutoParseableInput(params: ResponseCreateParamsWithTools): boolean {\n  if (isAutoParsableResponseFormat(params.text?.format)) {\n    return true;\n  }\n\n  return false;\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableResponseTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = FunctionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableResponseTool<OptionsT extends ToolOptions>(\n  tool: FunctionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableResponseTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableResponseTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nfunction getInputToolByName(input_tools: Array<Tool>, name: string): FunctionTool | undefined {\n  return input_tools.find((tool) => tool.type === 'function' && tool.name === name) as\n    | FunctionTool\n    | undefined;\n}\n\nfunction parseToolCall<Params extends ResponseCreateParamsBase>(\n  params: Params,\n  toolCall: ResponseFunctionToolCall,\n): ParsedResponseFunctionToolCall {\n  const inputTool = getInputToolByName(params.tools ?? [], toolCall.name);\n\n  return {\n    ...toolCall,\n    ...toolCall,\n    parsed_arguments:\n      isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.arguments)\n      : inputTool?.strict ? JSON.parse(toolCall.arguments)\n      : null,\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ResponseCreateParamsNonStreaming | null | undefined,\n  toolCall: ResponseFunctionToolCall,\n): boolean {\n  if (!params) {\n    return false;\n  }\n\n  const inputTool = getInputToolByName(params.tools ?? [], toolCall.name);\n  return isAutoParsableTool(inputTool) || inputTool?.strict || false;\n}\n\nexport function validateInputTools(tools: ChatCompletionTool[] | undefined) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n\nexport function addOutputText(rsp: Response): void {\n  const texts: string[] = [];\n  for (const output of rsp.output) {\n    if (output.type !== 'message') {\n      continue;\n    }\n\n    for (const content of output.content) {\n      if (content.type === 'output_text') {\n        texts.push(content.text);\n      }\n    }\n  }\n\n  rsp.output_text = texts.join('');\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { OpenAIError } from '../../core/error';\n\n// https://url.spec.whatwg.org/#url-scheme-string\nconst startsWithSchemeRegexp = /^[a-z][a-z0-9+.-]*:/i;\n\nexport const isAbsoluteURL = (url: string): boolean => {\n  return startsWithSchemeRegexp.test(url);\n};\n\nexport let isArray = (val: unknown): val is unknown[] => ((isArray = Array.isArray), isArray(val));\nexport let isReadonlyArray = isArray as (val: unknown) => val is readonly unknown[];\n\n/** Returns an object if the given value isn't an object, otherwise returns as-is */\nexport function maybeObj(x: unknown): object {\n  if (typeof x !== 'object') {\n    return {};\n  }\n\n  return x ?? {};\n}\n\n// https://stackoverflow.com/a/34491287\nexport function isEmptyObj(obj: Object | null | undefined): boolean {\n  if (!obj) return true;\n  for (const _k in obj) return false;\n  return true;\n}\n\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nexport function hasOwn<T extends object = object>(obj: T, key: PropertyKey): key is keyof T {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexport function isObj(obj: unknown): obj is Record<string, unknown> {\n  return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\n\nexport const ensurePresent = <T>(value: T | null | undefined): T => {\n  if (value == null) {\n    throw new OpenAIError(`Expected a value to be given but received ${value} instead.`);\n  }\n\n  return value;\n};\n\nexport const validatePositiveInteger = (name: string, n: unknown): number => {\n  if (typeof n !== 'number' || !Number.isInteger(n)) {\n    throw new OpenAIError(`${name} must be an integer`);\n  }\n  if (n < 0) {\n    throw new OpenAIError(`${name} must be a positive integer`);\n  }\n  return n;\n};\n\nexport const coerceInteger = (value: unknown): number => {\n  if (typeof value === 'number') return Math.round(value);\n  if (typeof value === 'string') return parseInt(value, 10);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceFloat = (value: unknown): number => {\n  if (typeof value === 'number') return value;\n  if (typeof value === 'string') return parseFloat(value);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceBoolean = (value: unknown): boolean => {\n  if (typeof value === 'boolean') return value;\n  if (typeof value === 'string') return value === 'true';\n  return Boolean(value);\n};\n\nexport const maybeCoerceInteger = (value: unknown): number | undefined => {\n  if (value == null) {\n    return undefined;\n  }\n  return coerceInteger(value);\n};\n\nexport const maybeCoerceFloat = (value: unknown): number | undefined => {\n  if (value == null) {\n    return undefined;\n  }\n  return coerceFloat(value);\n};\n\nexport const maybeCoerceBoolean = (value: unknown): boolean | undefined => {\n  if (value == null) {\n    return undefined;\n  }\n  return coerceBoolean(value);\n};\n\nexport const safeJSON = (text: string) => {\n  try {\n    return JSON.parse(text);\n  } catch (err) {\n    return undefined;\n  }\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { isReadonlyArray } from './utils/values';\n\ntype HeaderValue = string | undefined | null;\nexport type HeadersLike =\n  | Headers\n  | readonly HeaderValue[][]\n  | Record<string, HeaderValue | readonly HeaderValue[]>\n  | undefined\n  | null\n  | NullableHeaders;\n\nconst brand_privateNullableHeaders = /* @__PURE__ */ Symbol('brand.privateNullableHeaders');\n\n/**\n * @internal\n * Users can pass explicit nulls to unset default headers. When we parse them\n * into a standard headers type we need to preserve that information.\n */\nexport type NullableHeaders = {\n  /** Brand check, prevent users from creating a NullableHeaders. */\n  [brand_privateNullableHeaders]: true;\n  /** Parsed headers. */\n  values: Headers;\n  /** Set of lowercase header names explicitly set to null. */\n  nulls: Set<string>;\n};\n\nfunction* iterateHeaders(headers: HeadersLike): IterableIterator<readonly [string, string | null]> {\n  if (!headers) return;\n\n  if (brand_privateNullableHeaders in headers) {\n    const { values, nulls } = headers;\n    yield* values.entries();\n    for (const name of nulls) {\n      yield [name, null];\n    }\n    return;\n  }\n\n  let shouldClear = false;\n  let iter: Iterable<readonly (HeaderValue | readonly HeaderValue[])[]>;\n  if (headers instanceof Headers) {\n    iter = headers.entries();\n  } else if (isReadonlyArray(headers)) {\n    iter = headers;\n  } else {\n    shouldClear = true;\n    iter = Object.entries(headers ?? {});\n  }\n  for (let row of iter) {\n    const name = row[0];\n    if (typeof name !== 'string') throw new TypeError('expected header name to be a string');\n    const values = isReadonlyArray(row[1]) ? row[1] : [row[1]];\n    let didClear = false;\n    for (const value of values) {\n      if (value === undefined) continue;\n\n      // Objects keys always overwrite older headers, they never append.\n      // Yield a null to clear the header before adding the new values.\n      if (shouldClear && !didClear) {\n        didClear = true;\n        yield [name, null];\n      }\n      yield [name, value];\n    }\n  }\n}\n\nexport const buildHeaders = (newHeaders: HeadersLike[]): NullableHeaders => {\n  const targetHeaders = new Headers();\n  const nullHeaders = new Set<string>();\n  for (const headers of newHeaders) {\n    const seenHeaders = new Set<string>();\n    for (const [name, value] of iterateHeaders(headers)) {\n      const lowerName = name.toLowerCase();\n      if (!seenHeaders.has(lowerName)) {\n        targetHeaders.delete(name);\n        seenHeaders.add(lowerName);\n      }\n      if (value === null) {\n        targetHeaders.delete(name);\n        nullHeaders.add(lowerName);\n      } else {\n        targetHeaders.append(name, value);\n        nullHeaders.delete(lowerName);\n      }\n    }\n  }\n  return { [brand_privateNullableHeaders]: true, values: targetHeaders, nulls: nullHeaders };\n};\n\nexport const isEmptyHeaders = (headers: HeadersLike) => {\n  for (const _ of iterateHeaders(headers)) return false;\n  return true;\n};\n","import type { IncomingHttpHeaders, OutgoingHttpHeaders } from 'http'\nimport type { FetchMetrics } from './index'\n\nimport { toNodeOutgoingHttpHeaders } from '../web/utils'\nimport { BaseNextRequest, BaseNextResponse } from './index'\nimport { DetachedPromise } from '../../lib/detached-promise'\nimport type { NextRequestHint } from '../web/adapter'\nimport { CloseController, trackBodyConsumed } from '../web/web-on-close'\nimport { InvariantError } from '../../shared/lib/invariant-error'\n\nexport class WebNextRequest extends BaseNextRequest<ReadableStream | null> {\n  public request: Request\n  public headers: IncomingHttpHeaders\n  public fetchMetrics: FetchMetrics | undefined\n\n  constructor(request: NextRequestHint) {\n    const url = new URL(request.url)\n\n    super(\n      request.method,\n      url.href.slice(url.origin.length),\n      request.clone().body\n    )\n    this.request = request\n    this.fetchMetrics = request.fetchMetrics\n\n    this.headers = {}\n    for (const [name, value] of request.headers.entries()) {\n      this.headers[name] = value\n    }\n  }\n\n  async parseBody(_limit: string | number): Promise<any> {\n    throw new Error('parseBody is not implemented in the web runtime')\n  }\n}\n\nexport class WebNextResponse extends BaseNextResponse<WritableStream> {\n  private headers = new Headers()\n  private textBody: string | undefined = undefined\n\n  private closeController = new CloseController()\n\n  public statusCode: number | undefined\n  public statusMessage: string | undefined\n\n  constructor(public transformStream = new TransformStream()) {\n    super(transformStream.writable)\n  }\n\n  setHeader(name: string, value: string | string[]): this {\n    this.headers.delete(name)\n    for (const val of Array.isArray(value) ? value : [value]) {\n      this.headers.append(name, val)\n    }\n    return this\n  }\n\n  removeHeader(name: string): this {\n    this.headers.delete(name)\n    return this\n  }\n\n  getHeaderValues(name: string): string[] | undefined {\n    // https://developer.mozilla.org/docs/Web/API/Headers/get#example\n    return this.getHeader(name)\n      ?.split(',')\n      .map((v) => v.trimStart())\n  }\n\n  getHeader(name: string): string | undefined {\n    return this.headers.get(name) ?? undefined\n  }\n\n  getHeaders(): OutgoingHttpHeaders {\n    return toNodeOutgoingHttpHeaders(this.headers)\n  }\n\n  hasHeader(name: string): boolean {\n    return this.headers.has(name)\n  }\n\n  appendHeader(name: string, value: string): this {\n    this.headers.append(name, value)\n    return this\n  }\n\n  body(value: string) {\n    this.textBody = value\n    return this\n  }\n\n  private readonly sendPromise = new DetachedPromise<void>()\n\n  private _sent = false\n  public send() {\n    this.sendPromise.resolve()\n    this._sent = true\n  }\n\n  get sent() {\n    return this._sent\n  }\n\n  public async toResponse() {\n    // If we haven't called `send` yet, wait for it to be called.\n    if (!this.sent) await this.sendPromise.promise\n\n    const body = this.textBody ?? this.transformStream.readable\n\n    let bodyInit: BodyInit = body\n\n    // if the response is streaming, onClose() can still be called after this point.\n    const canAddListenersLater = typeof bodyInit !== 'string'\n    const shouldTrackBody = canAddListenersLater\n      ? true\n      : this.closeController.listeners > 0\n\n    if (shouldTrackBody) {\n      bodyInit = trackBodyConsumed(body, () => {\n        this.closeController.dispatchClose()\n      })\n    }\n\n    return new Response(bodyInit, {\n      headers: this.headers,\n      status: this.statusCode,\n      statusText: this.statusMessage,\n    })\n  }\n\n  public onClose(callback: () => void) {\n    if (this.closeController.isClosed) {\n      throw new InvariantError(\n        'Cannot call onClose on a WebNextResponse that is already closed'\n      )\n    }\n    return this.closeController.onClose(callback)\n  }\n}\n","import { stringifyCookie } from '../../web/spec-extension/cookies'\nimport type { I18NConfig } from '../../config-shared'\nimport { NextURL } from '../next-url'\nimport { toNodeOutgoingHttpHeaders, validateURL } from '../utils'\nimport { ReflectAdapter } from './adapters/reflect'\n\nimport { ResponseCookies } from './cookies'\n\nconst INTERNALS = Symbol('internal response')\nconst REDIRECTS = new Set([301, 302, 303, 307, 308])\n\nfunction handleMiddlewareField(\n  init: MiddlewareResponseInit | undefined,\n  headers: Headers\n) {\n  if (init?.request?.headers) {\n    if (!(init.request.headers instanceof Headers)) {\n      throw new Error('request.headers must be an instance of Headers')\n    }\n\n    const keys = []\n    for (const [key, value] of init.request.headers) {\n      headers.set('x-middleware-request-' + key, value)\n      keys.push(key)\n    }\n\n    headers.set('x-middleware-override-headers', keys.join(','))\n  }\n}\n\n/**\n * This class extends the [Web `Response` API](https://developer.mozilla.org/docs/Web/API/Response) with additional convenience methods.\n *\n * Read more: [Next.js Docs: `NextResponse`](https://nextjs.org/docs/app/api-reference/functions/next-response)\n */\nexport class NextResponse<Body = unknown> extends Response {\n  [INTERNALS]: {\n    cookies: ResponseCookies\n    url?: NextURL\n    body?: Body\n  }\n\n  constructor(body?: BodyInit | null, init: ResponseInit = {}) {\n    super(body, init)\n\n    const headers = this.headers\n    const cookies = new ResponseCookies(headers)\n\n    const cookiesProxy = new Proxy(cookies, {\n      get(target, prop, receiver) {\n        switch (prop) {\n          case 'delete':\n          case 'set': {\n            return (...args: [string, string]) => {\n              const result = Reflect.apply(target[prop], target, args)\n              const newHeaders = new Headers(headers)\n\n              if (result instanceof ResponseCookies) {\n                headers.set(\n                  'x-middleware-set-cookie',\n                  result\n                    .getAll()\n                    .map((cookie) => stringifyCookie(cookie))\n                    .join(',')\n                )\n              }\n\n              handleMiddlewareField(init, newHeaders)\n              return result\n            }\n          }\n          default:\n            return ReflectAdapter.get(target, prop, receiver)\n        }\n      },\n    })\n\n    this[INTERNALS] = {\n      cookies: cookiesProxy,\n      url: init.url\n        ? new NextURL(init.url, {\n            headers: toNodeOutgoingHttpHeaders(headers),\n            nextConfig: init.nextConfig,\n          })\n        : undefined,\n    }\n  }\n\n  [Symbol.for('edge-runtime.inspect.custom')]() {\n    return {\n      cookies: this.cookies,\n      url: this.url,\n      // rest of props come from Response\n      body: this.body,\n      bodyUsed: this.bodyUsed,\n      headers: Object.fromEntries(this.headers),\n      ok: this.ok,\n      redirected: this.redirected,\n      status: this.status,\n      statusText: this.statusText,\n      type: this.type,\n    }\n  }\n\n  public get cookies() {\n    return this[INTERNALS].cookies\n  }\n\n  static json<JsonBody>(\n    body: JsonBody,\n    init?: ResponseInit\n  ): NextResponse<JsonBody> {\n    const response: Response = Response.json(body, init)\n    return new NextResponse(response.body, response)\n  }\n\n  static redirect(url: string | NextURL | URL, init?: number | ResponseInit) {\n    const status = typeof init === 'number' ? init : (init?.status ?? 307)\n    if (!REDIRECTS.has(status)) {\n      throw new RangeError(\n        'Failed to execute \"redirect\" on \"response\": Invalid status code'\n      )\n    }\n    const initObj = typeof init === 'object' ? init : {}\n    const headers = new Headers(initObj?.headers)\n    headers.set('Location', validateURL(url))\n\n    return new NextResponse(null, {\n      ...initObj,\n      headers,\n      status,\n    })\n  }\n\n  static rewrite(\n    destination: string | NextURL | URL,\n    init?: MiddlewareResponseInit\n  ) {\n    const headers = new Headers(init?.headers)\n    headers.set('x-middleware-rewrite', validateURL(destination))\n\n    handleMiddlewareField(init, headers)\n    return new NextResponse(null, { ...init, headers })\n  }\n\n  static next(init?: MiddlewareResponseInit) {\n    const headers = new Headers(init?.headers)\n    headers.set('x-middleware-next', '1')\n\n    handleMiddlewareField(init, headers)\n    return new NextResponse(null, { ...init, headers })\n  }\n}\n\ninterface ResponseInit extends globalThis.ResponseInit {\n  nextConfig?: {\n    basePath?: string\n    i18n?: I18NConfig\n    trailingSlash?: boolean\n  }\n  url?: string\n}\n\ninterface ModifiedRequest {\n  /**\n   * If this is set, the request headers will be overridden with this value.\n   */\n  headers?: Headers\n}\n\ninterface MiddlewareResponseInit extends globalThis.ResponseInit {\n  /**\n   * These fields will override the request from clients.\n   */\n  request?: ModifiedRequest\n}\n","/**\n * Like `Promise.allSettled()` but throws an error if any promises are rejected.\n */\nexport const allSettledWithThrow = async <R>(promises: Promise<R>[]): Promise<R[]> => {\n  const results = await Promise.allSettled(promises);\n  const rejected = results.filter((result): result is PromiseRejectedResult => result.status === 'rejected');\n  if (rejected.length) {\n    for (const result of rejected) {\n      console.error(result.reason);\n    }\n\n    throw new Error(`${rejected.length} promise(s) failed - see the above errors`);\n  }\n\n  // Note: TS was complaining about using `.filter().map()` here for some reason\n  const values: R[] = [];\n  for (const result of results) {\n    if (result.status === 'fulfilled') {\n      values.push(result.value);\n    }\n  }\n  return values;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport { APIPromise } from '../../core/api-promise';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\n\nexport class Speech extends APIResource {\n  /**\n   * Generates audio from the input text.\n   *\n   * @example\n   * ```ts\n   * const speech = await client.audio.speech.create({\n   *   input: 'input',\n   *   model: 'string',\n   *   voice: 'ash',\n   * });\n   *\n   * const content = await speech.blob();\n   * console.log(content);\n   * ```\n   */\n  create(body: SpeechCreateParams, options?: RequestOptions): APIPromise<Response> {\n    return this._client.post('/audio/speech', {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/octet-stream' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n}\n\nexport type SpeechModel = 'tts-1' | 'tts-1-hd' | 'gpt-4o-mini-tts' | 'gpt-4o-mini-tts-2025-12-15';\n\nexport interface SpeechCreateParams {\n  /**\n   * The text to generate audio for. The maximum length is 4096 characters.\n   */\n  input: string;\n\n  /**\n   * One of the available [TTS models](https://platform.openai.com/docs/models#tts):\n   * `tts-1`, `tts-1-hd`, `gpt-4o-mini-tts`, or `gpt-4o-mini-tts-2025-12-15`.\n   */\n  model: (string & {}) | SpeechModel;\n\n  /**\n   * The voice to use when generating the audio. Supported built-in voices are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`,\n   * `shimmer`, `verse`, `marin`, and `cedar`. Previews of the voices are available\n   * in the\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech#voice-options).\n   */\n  voice:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n\n  /**\n   * Control the voice of your generated audio with additional instructions. Does not\n   * work with `tts-1` or `tts-1-hd`.\n   */\n  instructions?: string;\n\n  /**\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`,\n   * `wav`, and `pcm`.\n   */\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac' | 'wav' | 'pcm';\n\n  /**\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\n   * the default.\n   */\n  speed?: number;\n\n  /**\n   * The format to stream the audio in. Supported formats are `sse` and `audio`.\n   * `sse` is not supported for `tts-1` or `tts-1-hd`.\n   */\n  stream_format?: 'sse' | 'audio';\n}\n\nexport declare namespace Speech {\n  export { type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport * as ImagesAPI from './images';\nimport { APIPromise } from '../core/api-promise';\nimport { Stream } from '../core/streaming';\nimport { type Uploadable } from '../core/uploads';\nimport { RequestOptions } from '../internal/request-options';\nimport { multipartFormRequestOptions } from '../internal/uploads';\n\nexport class Images extends APIResource {\n  /**\n   * Creates a variation of a given image. This endpoint only supports `dall-e-2`.\n   *\n   * @example\n   * ```ts\n   * const imagesResponse = await client.images.createVariation({\n   *   image: fs.createReadStream('otter.png'),\n   * });\n   * ```\n   */\n  createVariation(body: ImageCreateVariationParams, options?: RequestOptions): APIPromise<ImagesResponse> {\n    return this._client.post(\n      '/images/variations',\n      multipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n\n  /**\n   * Creates an edited or extended image given one or more source images and a\n   * prompt. This endpoint supports GPT Image models (`gpt-image-1.5`, `gpt-image-1`,\n   * and `gpt-image-1-mini`) and `dall-e-2`.\n   *\n   * @example\n   * ```ts\n   * const imagesResponse = await client.images.edit({\n   *   image: fs.createReadStream('path/to/file'),\n   *   prompt: 'A cute baby sea otter wearing a beret',\n   * });\n   * ```\n   */\n  edit(body: ImageEditParamsNonStreaming, options?: RequestOptions): APIPromise<ImagesResponse>;\n  edit(body: ImageEditParamsStreaming, options?: RequestOptions): APIPromise<Stream<ImageEditStreamEvent>>;\n  edit(\n    body: ImageEditParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ImageEditStreamEvent> | ImagesResponse>;\n  edit(\n    body: ImageEditParams,\n    options?: RequestOptions,\n  ): APIPromise<ImagesResponse> | APIPromise<Stream<ImageEditStreamEvent>> {\n    return this._client.post(\n      '/images/edits',\n      multipartFormRequestOptions({ body, ...options, stream: body.stream ?? false }, this._client),\n    ) as APIPromise<ImagesResponse> | APIPromise<Stream<ImageEditStreamEvent>>;\n  }\n\n  /**\n   * Creates an image given a prompt.\n   * [Learn more](https://platform.openai.com/docs/guides/images).\n   *\n   * @example\n   * ```ts\n   * const imagesResponse = await client.images.generate({\n   *   prompt: 'A cute baby sea otter',\n   * });\n   * ```\n   */\n  generate(body: ImageGenerateParamsNonStreaming, options?: RequestOptions): APIPromise<ImagesResponse>;\n  generate(\n    body: ImageGenerateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ImageGenStreamEvent>>;\n  generate(\n    body: ImageGenerateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ImageGenStreamEvent> | ImagesResponse>;\n  generate(\n    body: ImageGenerateParams,\n    options?: RequestOptions,\n  ): APIPromise<ImagesResponse> | APIPromise<Stream<ImageGenStreamEvent>> {\n    return this._client.post('/images/generations', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ImagesResponse>\n      | APIPromise<Stream<ImageGenStreamEvent>>;\n  }\n}\n\n/**\n * Represents the content or the URL of an image generated by the OpenAI API.\n */\nexport interface Image {\n  /**\n   * The base64-encoded JSON of the generated image. Returned by default for the GPT\n   * image models, and only present if `response_format` is set to `b64_json` for\n   * `dall-e-2` and `dall-e-3`.\n   */\n  b64_json?: string;\n\n  /**\n   * For `dall-e-3` only, the revised prompt that was used to generate the image.\n   */\n  revised_prompt?: string;\n\n  /**\n   * When using `dall-e-2` or `dall-e-3`, the URL of the generated image if\n   * `response_format` is set to `url` (default value). Unsupported for the GPT image\n   * models.\n   */\n  url?: string;\n}\n\n/**\n * Emitted when image editing has completed and the final image is available.\n */\nexport interface ImageEditCompletedEvent {\n  /**\n   * Base64-encoded final edited image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the edited image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the edited image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * The quality setting for the edited image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the edited image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_edit.completed`.\n   */\n  type: 'image_edit.completed';\n\n  /**\n   * For the GPT image models only, the token usage information for the image\n   * generation.\n   */\n  usage: ImageEditCompletedEvent.Usage;\n}\n\nexport namespace ImageEditCompletedEvent {\n  /**\n   * For the GPT image models only, the token usage information for the image\n   * generation.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens (images and text) in the input prompt.\n     */\n    input_tokens: number;\n\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    input_tokens_details: Usage.InputTokensDetails;\n\n    /**\n     * The number of image tokens in the output image.\n     */\n    output_tokens: number;\n\n    /**\n     * The total number of tokens (images and text) used for the image generation.\n     */\n    total_tokens: number;\n  }\n\n  export namespace Usage {\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    export interface InputTokensDetails {\n      /**\n       * The number of image tokens in the input prompt.\n       */\n      image_tokens: number;\n\n      /**\n       * The number of text tokens in the input prompt.\n       */\n      text_tokens: number;\n    }\n  }\n}\n\n/**\n * Emitted when a partial image is available during image editing streaming.\n */\nexport interface ImageEditPartialImageEvent {\n  /**\n   * Base64-encoded partial image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the requested edited image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the requested edited image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * 0-based index for the partial image (streaming).\n   */\n  partial_image_index: number;\n\n  /**\n   * The quality setting for the requested edited image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the requested edited image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_edit.partial_image`.\n   */\n  type: 'image_edit.partial_image';\n}\n\n/**\n * Emitted when a partial image is available during image editing streaming.\n */\nexport type ImageEditStreamEvent = ImageEditPartialImageEvent | ImageEditCompletedEvent;\n\n/**\n * Emitted when image generation has completed and the final image is available.\n */\nexport interface ImageGenCompletedEvent {\n  /**\n   * Base64-encoded image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the generated image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the generated image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * The quality setting for the generated image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the generated image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_generation.completed`.\n   */\n  type: 'image_generation.completed';\n\n  /**\n   * For the GPT image models only, the token usage information for the image\n   * generation.\n   */\n  usage: ImageGenCompletedEvent.Usage;\n}\n\nexport namespace ImageGenCompletedEvent {\n  /**\n   * For the GPT image models only, the token usage information for the image\n   * generation.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens (images and text) in the input prompt.\n     */\n    input_tokens: number;\n\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    input_tokens_details: Usage.InputTokensDetails;\n\n    /**\n     * The number of image tokens in the output image.\n     */\n    output_tokens: number;\n\n    /**\n     * The total number of tokens (images and text) used for the image generation.\n     */\n    total_tokens: number;\n  }\n\n  export namespace Usage {\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    export interface InputTokensDetails {\n      /**\n       * The number of image tokens in the input prompt.\n       */\n      image_tokens: number;\n\n      /**\n       * The number of text tokens in the input prompt.\n       */\n      text_tokens: number;\n    }\n  }\n}\n\n/**\n * Emitted when a partial image is available during image generation streaming.\n */\nexport interface ImageGenPartialImageEvent {\n  /**\n   * Base64-encoded partial image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the requested image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the requested image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * 0-based index for the partial image (streaming).\n   */\n  partial_image_index: number;\n\n  /**\n   * The quality setting for the requested image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the requested image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_generation.partial_image`.\n   */\n  type: 'image_generation.partial_image';\n}\n\n/**\n * Emitted when a partial image is available during image generation streaming.\n */\nexport type ImageGenStreamEvent = ImageGenPartialImageEvent | ImageGenCompletedEvent;\n\nexport type ImageModel = 'gpt-image-1.5' | 'dall-e-2' | 'dall-e-3' | 'gpt-image-1' | 'gpt-image-1-mini';\n\n/**\n * The response from the image generation endpoint.\n */\nexport interface ImagesResponse {\n  /**\n   * The Unix timestamp (in seconds) of when the image was created.\n   */\n  created: number;\n\n  /**\n   * The background parameter used for the image generation. Either `transparent` or\n   * `opaque`.\n   */\n  background?: 'transparent' | 'opaque';\n\n  /**\n   * The list of generated images.\n   */\n  data?: Array<Image>;\n\n  /**\n   * The output format of the image generation. Either `png`, `webp`, or `jpeg`.\n   */\n  output_format?: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * The quality of the image generated. Either `low`, `medium`, or `high`.\n   */\n  quality?: 'low' | 'medium' | 'high';\n\n  /**\n   * The size of the image generated. Either `1024x1024`, `1024x1536`, or\n   * `1536x1024`.\n   */\n  size?: '1024x1024' | '1024x1536' | '1536x1024';\n\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  usage?: ImagesResponse.Usage;\n}\n\nexport namespace ImagesResponse {\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens (images and text) in the input prompt.\n     */\n    input_tokens: number;\n\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    input_tokens_details: Usage.InputTokensDetails;\n\n    /**\n     * The number of output tokens generated by the model.\n     */\n    output_tokens: number;\n\n    /**\n     * The total number of tokens (images and text) used for the image generation.\n     */\n    total_tokens: number;\n\n    /**\n     * The output token details for the image generation.\n     */\n    output_tokens_details?: Usage.OutputTokensDetails;\n  }\n\n  export namespace Usage {\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    export interface InputTokensDetails {\n      /**\n       * The number of image tokens in the input prompt.\n       */\n      image_tokens: number;\n\n      /**\n       * The number of text tokens in the input prompt.\n       */\n      text_tokens: number;\n    }\n\n    /**\n     * The output token details for the image generation.\n     */\n    export interface OutputTokensDetails {\n      /**\n       * The number of image output tokens generated by the model.\n       */\n      image_tokens: number;\n\n      /**\n       * The number of text output tokens generated by the model.\n       */\n      text_tokens: number;\n    }\n  }\n}\n\nexport interface ImageCreateVariationParams {\n  /**\n   * The image to use as the basis for the variation(s). Must be a valid PNG file,\n   * less than 4MB, and square.\n   */\n  image: Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport type ImageEditParams = ImageEditParamsNonStreaming | ImageEditParamsStreaming;\n\nexport interface ImageEditParamsBase {\n  /**\n   * The image(s) to edit. Must be a supported image file or an array of images.\n   *\n   * For the GPT image models (`gpt-image-1`, `gpt-image-1-mini`, and\n   * `gpt-image-1.5`), each image should be a `png`, `webp`, or `jpg` file less than\n   * 50MB. You can provide up to 16 images.\n   *\n   * For `dall-e-2`, you can only provide one image, and it should be a square `png`\n   * file less than 4MB.\n   */\n  image: Uploadable | Array<Uploadable>;\n\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters for `dall-e-2`, and 32000 characters for the GPT image models.\n   */\n  prompt: string;\n\n  /**\n   * Allows to set transparency for the background of the generated image(s). This\n   * parameter is only supported for the GPT image models. Must be one of\n   * `transparent`, `opaque` or `auto` (default value). When `auto` is used, the\n   * model will automatically determine the best background for the image.\n   *\n   * If `transparent`, the output format needs to support transparency, so it should\n   * be set to either `png` (default value) or `webp`.\n   */\n  background?: 'transparent' | 'opaque' | 'auto' | null;\n\n  /**\n   * Control how much effort the model will exert to match the style and features,\n   * especially facial features, of input images. This parameter is only supported\n   * for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and\n   * `low`. Defaults to `low`.\n   */\n  input_fidelity?: 'high' | 'low' | null;\n\n  /**\n   * An additional image whose fully transparent areas (e.g. where alpha is zero)\n   * indicate where `image` should be edited. If there are multiple images provided,\n   * the mask will be applied on the first image. Must be a valid PNG file, less than\n   * 4MB, and have the same dimensions as `image`.\n   */\n  mask?: Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` and the GPT image models\n   * are supported. Defaults to `dall-e-2` unless a parameter specific to the GPT\n   * image models is used.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The compression level (0-100%) for the generated images. This parameter is only\n   * supported for the GPT image models with the `webp` or `jpeg` output formats, and\n   * defaults to 100.\n   */\n  output_compression?: number | null;\n\n  /**\n   * The format in which the generated images are returned. This parameter is only\n   * supported for the GPT image models. Must be one of `png`, `jpeg`, or `webp`. The\n   * default value is `png`.\n   */\n  output_format?: 'png' | 'jpeg' | 'webp' | null;\n\n  /**\n   * The number of partial images to generate. This parameter is used for streaming\n   * responses that return partial images. Value must be between 0 and 3. When set to\n   * 0, the response will be a single image sent in one streaming event.\n   *\n   * Note that the final image may be sent before the full number of partial images\n   * are generated if the full image is generated more quickly.\n   */\n  partial_images?: number | null;\n\n  /**\n   * The quality of the image that will be generated. `high`, `medium` and `low` are\n   * only supported for the GPT image models. `dall-e-2` only supports `standard`\n   * quality. Defaults to `auto`.\n   */\n  quality?: 'standard' | 'low' | 'medium' | 'high' | 'auto' | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated. This parameter is only supported for `dall-e-2`, as the GPT image\n   * models always return base64-encoded images.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `1024x1024`, `1536x1024`\n   * (landscape), `1024x1536` (portrait), or `auto` (default value) for the GPT image\n   * models, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | '1536x1024' | '1024x1536' | 'auto' | null;\n\n  /**\n   * Edit the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information.\n   */\n  stream?: boolean | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ImageEditParams {\n  export type ImageEditParamsNonStreaming = ImagesAPI.ImageEditParamsNonStreaming;\n  export type ImageEditParamsStreaming = ImagesAPI.ImageEditParamsStreaming;\n}\n\nexport interface ImageEditParamsNonStreaming extends ImageEditParamsBase {\n  /**\n   * Edit the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information.\n   */\n  stream?: false | null;\n}\n\nexport interface ImageEditParamsStreaming extends ImageEditParamsBase {\n  /**\n   * Edit the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information.\n   */\n  stream: true;\n}\n\nexport type ImageGenerateParams = ImageGenerateParamsNonStreaming | ImageGenerateParamsStreaming;\n\nexport interface ImageGenerateParamsBase {\n  /**\n   * A text description of the desired image(s). The maximum length is 32000\n   * characters for the GPT image models, 1000 characters for `dall-e-2` and 4000\n   * characters for `dall-e-3`.\n   */\n  prompt: string;\n\n  /**\n   * Allows to set transparency for the background of the generated image(s). This\n   * parameter is only supported for the GPT image models. Must be one of\n   * `transparent`, `opaque` or `auto` (default value). When `auto` is used, the\n   * model will automatically determine the best background for the image.\n   *\n   * If `transparent`, the output format needs to support transparency, so it should\n   * be set to either `png` (default value) or `webp`.\n   */\n  background?: 'transparent' | 'opaque' | 'auto' | null;\n\n  /**\n   * The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or a GPT\n   * image model (`gpt-image-1`, `gpt-image-1-mini`, `gpt-image-1.5`). Defaults to\n   * `dall-e-2` unless a parameter specific to the GPT image models is used.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * Control the content-moderation level for images generated by the GPT image\n   * models. Must be either `low` for less restrictive filtering or `auto` (default\n   * value).\n   */\n  moderation?: 'low' | 'auto' | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The compression level (0-100%) for the generated images. This parameter is only\n   * supported for the GPT image models with the `webp` or `jpeg` output formats, and\n   * defaults to 100.\n   */\n  output_compression?: number | null;\n\n  /**\n   * The format in which the generated images are returned. This parameter is only\n   * supported for the GPT image models. Must be one of `png`, `jpeg`, or `webp`.\n   */\n  output_format?: 'png' | 'jpeg' | 'webp' | null;\n\n  /**\n   * The number of partial images to generate. This parameter is used for streaming\n   * responses that return partial images. Value must be between 0 and 3. When set to\n   * 0, the response will be a single image sent in one streaming event.\n   *\n   * Note that the final image may be sent before the full number of partial images\n   * are generated if the full image is generated more quickly.\n   */\n  partial_images?: number | null;\n\n  /**\n   * The quality of the image that will be generated.\n   *\n   * - `auto` (default value) will automatically select the best quality for the\n   *   given model.\n   * - `high`, `medium` and `low` are supported for the GPT image models.\n   * - `hd` and `standard` are supported for `dall-e-3`.\n   * - `standard` is the only option for `dall-e-2`.\n   */\n  quality?: 'standard' | 'hd' | 'low' | 'medium' | 'high' | 'auto' | null;\n\n  /**\n   * The format in which generated images with `dall-e-2` and `dall-e-3` are\n   * returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes\n   * after the image has been generated. This parameter isn't supported for the GPT\n   * image models, which always return base64-encoded images.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `1024x1024`, `1536x1024`\n   * (landscape), `1024x1536` (portrait), or `auto` (default value) for the GPT image\n   * models, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of\n   * `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.\n   */\n  size?:\n    | 'auto'\n    | '1024x1024'\n    | '1536x1024'\n    | '1024x1536'\n    | '256x256'\n    | '512x512'\n    | '1792x1024'\n    | '1024x1792'\n    | null;\n\n  /**\n   * Generate the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information. This parameter is only supported for the GPT image models.\n   */\n  stream?: boolean | null;\n\n  /**\n   * The style of the generated images. This parameter is only supported for\n   * `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean\n   * towards generating hyper-real and dramatic images. Natural causes the model to\n   * produce more natural, less hyper-real looking images.\n   */\n  style?: 'vivid' | 'natural' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ImageGenerateParams {\n  export type ImageGenerateParamsNonStreaming = ImagesAPI.ImageGenerateParamsNonStreaming;\n  export type ImageGenerateParamsStreaming = ImagesAPI.ImageGenerateParamsStreaming;\n}\n\nexport interface ImageGenerateParamsNonStreaming extends ImageGenerateParamsBase {\n  /**\n   * Generate the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information. This parameter is only supported for the GPT image models.\n   */\n  stream?: false | null;\n}\n\nexport interface ImageGenerateParamsStreaming extends ImageGenerateParamsBase {\n  /**\n   * Generate the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information. This parameter is only supported for the GPT image models.\n   */\n  stream: true;\n}\n\nexport declare namespace Images {\n  export {\n    type Image as Image,\n    type ImageEditCompletedEvent as ImageEditCompletedEvent,\n    type ImageEditPartialImageEvent as ImageEditPartialImageEvent,\n    type ImageEditStreamEvent as ImageEditStreamEvent,\n    type ImageGenCompletedEvent as ImageGenCompletedEvent,\n    type ImageGenPartialImageEvent as ImageGenPartialImageEvent,\n    type ImageGenStreamEvent as ImageGenStreamEvent,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageEditParamsNonStreaming as ImageEditParamsNonStreaming,\n    type ImageEditParamsStreaming as ImageEditParamsStreaming,\n    type ImageGenerateParams as ImageGenerateParams,\n    type ImageGenerateParamsNonStreaming as ImageGenerateParamsNonStreaming,\n    type ImageGenerateParamsStreaming as ImageGenerateParamsStreaming,\n  };\n}\n","import {\n  TextContentBlock,\n  ImageFileContentBlock,\n  Message,\n  MessageContentDelta,\n  Text,\n  ImageFile,\n  TextDelta,\n  MessageDelta,\n  MessageContent,\n} from '../resources/beta/threads/messages';\nimport { RequestOptions } from '../internal/request-options';\nimport {\n  Run,\n  RunCreateParamsBase,\n  RunCreateParamsStreaming,\n  Runs,\n  RunSubmitToolOutputsParamsBase,\n  RunSubmitToolOutputsParamsStreaming,\n} from '../resources/beta/threads/runs/runs';\nimport { type ReadableStream } from '../internal/shim-types';\nimport { Stream } from '../streaming';\nimport { APIUserAbortError, OpenAIError } from '../error';\nimport {\n  AssistantStreamEvent,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n} from '../resources/beta/assistants';\nimport { RunStep, RunStepDelta, ToolCall, ToolCallDelta } from '../resources/beta/threads/runs/steps';\nimport { ThreadCreateAndRunParamsBase, Threads } from '../resources/beta/threads/threads';\nimport { BaseEvents, EventStream } from './EventStream';\nimport { isObj } from '../internal/utils';\n\nexport interface AssistantStreamEvents extends BaseEvents {\n  run: (run: Run) => void;\n\n  //New event structure\n  messageCreated: (message: Message) => void;\n  messageDelta: (message: MessageDelta, snapshot: Message) => void;\n  messageDone: (message: Message) => void;\n\n  runStepCreated: (runStep: RunStep) => void;\n  runStepDelta: (delta: RunStepDelta, snapshot: Runs.RunStep) => void;\n  runStepDone: (runStep: Runs.RunStep, snapshot: Runs.RunStep) => void;\n\n  toolCallCreated: (toolCall: ToolCall) => void;\n  toolCallDelta: (delta: ToolCallDelta, snapshot: ToolCall) => void;\n  toolCallDone: (toolCall: ToolCall) => void;\n\n  textCreated: (content: Text) => void;\n  textDelta: (delta: TextDelta, snapshot: Text) => void;\n  textDone: (content: Text, snapshot: Message) => void;\n\n  //No created or delta as this is not streamed\n  imageFileDone: (content: ImageFile, snapshot: Message) => void;\n\n  event: (event: AssistantStreamEvent) => void;\n}\n\nexport type ThreadCreateAndRunParamsBaseStream = Omit<ThreadCreateAndRunParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunCreateParamsBaseStream = Omit<RunCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunSubmitToolOutputsParamsStream = Omit<RunSubmitToolOutputsParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class AssistantStream\n  extends EventStream<AssistantStreamEvents>\n  implements AsyncIterable<AssistantStreamEvent>\n{\n  //Track all events in a single list for reference\n  #events: AssistantStreamEvent[] = [];\n\n  //Used to accumulate deltas\n  //We are accumulating many types so the value here is not strict\n  #runStepSnapshots: { [id: string]: Runs.RunStep } = {};\n  #messageSnapshots: { [id: string]: Message } = {};\n  #messageSnapshot: Message | undefined;\n  #finalRun: Run | undefined;\n  #currentContentIndex: number | undefined;\n  #currentContent: MessageContent | undefined;\n  #currentToolCallIndex: number | undefined;\n  #currentToolCall: ToolCall | undefined;\n\n  //For current snapshot methods\n  #currentEvent: AssistantStreamEvent | undefined;\n  #currentRunSnapshot: Run | undefined;\n  #currentRunStepSnapshot: Runs.RunStep | undefined;\n\n  [Symbol.asyncIterator](): AsyncIterator<AssistantStreamEvent> {\n    const pushQueue: AssistantStreamEvent[] = [];\n    const readQueue: {\n      resolve: (chunk: AssistantStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    //Catch all for passing along all events\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<AssistantStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<AssistantStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  static fromReadableStream(stream: ReadableStream): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this._connected();\n    const stream = Stream.fromReadableStream<AssistantStreamEvent>(readableStream, this.controller);\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addRun(this.#endRequest());\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n\n  static createToolAssistantStream(\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options: RequestOptions | undefined,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runToolAssistantStream(runId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  protected async _createToolAssistantStream(\n    run: Runs,\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunSubmitToolOutputsParamsStreaming = { ...params, stream: true };\n    const stream = await run.submitToolOutputs(runId, body, {\n      ...options,\n      signal: this.controller.signal,\n    });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  static createThreadAssistantStream(\n    params: ThreadCreateAndRunParamsBaseStream,\n    thread: Threads,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._threadAssistantStream(params, thread, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  static createAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runAssistantStream(threadId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  currentEvent(): AssistantStreamEvent | undefined {\n    return this.#currentEvent;\n  }\n\n  currentRun(): Run | undefined {\n    return this.#currentRunSnapshot;\n  }\n\n  currentMessageSnapshot(): Message | undefined {\n    return this.#messageSnapshot;\n  }\n\n  currentRunStepSnapshot(): Runs.RunStep | undefined {\n    return this.#currentRunStepSnapshot;\n  }\n\n  async finalRunSteps(): Promise<Runs.RunStep[]> {\n    await this.done();\n\n    return Object.values(this.#runStepSnapshots);\n  }\n\n  async finalMessages(): Promise<Message[]> {\n    await this.done();\n\n    return Object.values(this.#messageSnapshots);\n  }\n\n  async finalRun(): Promise<Run> {\n    await this.done();\n    if (!this.#finalRun) throw Error('Final run was not received.');\n\n    return this.#finalRun;\n  }\n\n  protected async _createThreadAssistantStream(\n    thread: Threads,\n    params: ThreadCreateAndRunParamsBase,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  protected async _createAssistantStream(\n    run: Runs,\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  #addEvent(event: AssistantStreamEvent) {\n    if (this.ended) return;\n\n    this.#currentEvent = event;\n\n    this.#handleEvent(event);\n\n    switch (event.event) {\n      case 'thread.created':\n        //No action on this event.\n        break;\n\n      case 'thread.run.created':\n      case 'thread.run.queued':\n      case 'thread.run.in_progress':\n      case 'thread.run.requires_action':\n      case 'thread.run.completed':\n      case 'thread.run.incomplete':\n      case 'thread.run.failed':\n      case 'thread.run.cancelling':\n      case 'thread.run.cancelled':\n      case 'thread.run.expired':\n        this.#handleRun(event);\n        break;\n\n      case 'thread.run.step.created':\n      case 'thread.run.step.in_progress':\n      case 'thread.run.step.delta':\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#handleRunStep(event);\n        break;\n\n      case 'thread.message.created':\n      case 'thread.message.in_progress':\n      case 'thread.message.delta':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        this.#handleMessage(event);\n        break;\n\n      case 'error':\n        //This is included for completeness, but errors are processed in the SSE event processing so this should not occur\n        throw new Error(\n          'Encountered an error event in event processing - errors should be processed earlier',\n        );\n      default:\n        assertNever(event);\n    }\n  }\n\n  #endRequest(): Run {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n\n    if (!this.#finalRun) throw Error('Final run has not been received');\n\n    return this.#finalRun;\n  }\n\n  #handleMessage(this: AssistantStream, event: MessageStreamEvent) {\n    const [accumulatedMessage, newContent] = this.#accumulateMessage(event, this.#messageSnapshot);\n    this.#messageSnapshot = accumulatedMessage;\n    this.#messageSnapshots[accumulatedMessage.id] = accumulatedMessage;\n\n    for (const content of newContent) {\n      const snapshotContent = accumulatedMessage.content[content.index];\n      if (snapshotContent?.type == 'text') {\n        this._emit('textCreated', snapshotContent.text);\n      }\n    }\n\n    switch (event.event) {\n      case 'thread.message.created':\n        this._emit('messageCreated', event.data);\n        break;\n\n      case 'thread.message.in_progress':\n        break;\n\n      case 'thread.message.delta':\n        this._emit('messageDelta', event.data.delta, accumulatedMessage);\n\n        if (event.data.delta.content) {\n          for (const content of event.data.delta.content) {\n            //If it is text delta, emit a text delta event\n            if (content.type == 'text' && content.text) {\n              let textDelta = content.text;\n              let snapshot = accumulatedMessage.content[content.index];\n              if (snapshot && snapshot.type == 'text') {\n                this._emit('textDelta', textDelta, snapshot.text);\n              } else {\n                throw Error('The snapshot associated with this text delta is not text or missing');\n              }\n            }\n\n            if (content.index != this.#currentContentIndex) {\n              //See if we have in progress content\n              if (this.#currentContent) {\n                switch (this.#currentContent.type) {\n                  case 'text':\n                    this._emit('textDone', this.#currentContent.text, this.#messageSnapshot);\n                    break;\n                  case 'image_file':\n                    this._emit('imageFileDone', this.#currentContent.image_file, this.#messageSnapshot);\n                    break;\n                }\n              }\n\n              this.#currentContentIndex = content.index;\n            }\n\n            this.#currentContent = accumulatedMessage.content[content.index];\n          }\n        }\n\n        break;\n\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //We emit the latest content we were working on on completion (including incomplete)\n        if (this.#currentContentIndex !== undefined) {\n          const currentContent = event.data.content[this.#currentContentIndex];\n          if (currentContent) {\n            switch (currentContent.type) {\n              case 'image_file':\n                this._emit('imageFileDone', currentContent.image_file, this.#messageSnapshot);\n                break;\n              case 'text':\n                this._emit('textDone', currentContent.text, this.#messageSnapshot);\n                break;\n            }\n          }\n        }\n\n        if (this.#messageSnapshot) {\n          this._emit('messageDone', event.data);\n        }\n\n        this.#messageSnapshot = undefined;\n    }\n  }\n\n  #handleRunStep(this: AssistantStream, event: RunStepStreamEvent) {\n    const accumulatedRunStep = this.#accumulateRunStep(event);\n    this.#currentRunStepSnapshot = accumulatedRunStep;\n\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this._emit('runStepCreated', event.data);\n        break;\n      case 'thread.run.step.delta':\n        const delta = event.data.delta;\n        if (\n          delta.step_details &&\n          delta.step_details.type == 'tool_calls' &&\n          delta.step_details.tool_calls &&\n          accumulatedRunStep.step_details.type == 'tool_calls'\n        ) {\n          for (const toolCall of delta.step_details.tool_calls) {\n            if (toolCall.index == this.#currentToolCallIndex) {\n              this._emit(\n                'toolCallDelta',\n                toolCall,\n                accumulatedRunStep.step_details.tool_calls[toolCall.index] as ToolCall,\n              );\n            } else {\n              if (this.#currentToolCall) {\n                this._emit('toolCallDone', this.#currentToolCall);\n              }\n\n              this.#currentToolCallIndex = toolCall.index;\n              this.#currentToolCall = accumulatedRunStep.step_details.tool_calls[toolCall.index];\n              if (this.#currentToolCall) this._emit('toolCallCreated', this.#currentToolCall);\n            }\n          }\n        }\n\n        this._emit('runStepDelta', event.data.delta, accumulatedRunStep);\n        break;\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#currentRunStepSnapshot = undefined;\n        const details = event.data.step_details;\n        if (details.type == 'tool_calls') {\n          if (this.#currentToolCall) {\n            this._emit('toolCallDone', this.#currentToolCall as ToolCall);\n            this.#currentToolCall = undefined;\n          }\n        }\n        this._emit('runStepDone', event.data, accumulatedRunStep);\n        break;\n      case 'thread.run.step.in_progress':\n        break;\n    }\n  }\n\n  #handleEvent(this: AssistantStream, event: AssistantStreamEvent) {\n    this.#events.push(event);\n    this._emit('event', event);\n  }\n\n  #accumulateRunStep(event: RunStepStreamEvent): Runs.RunStep {\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        return event.data;\n\n      case 'thread.run.step.delta':\n        let snapshot = this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n        if (!snapshot) {\n          throw Error('Received a RunStepDelta before creation of a snapshot');\n        }\n\n        let data = event.data;\n\n        if (data.delta) {\n          const accumulated = AssistantStream.accumulateDelta(snapshot, data.delta) as Runs.RunStep;\n          this.#runStepSnapshots[event.data.id] = accumulated;\n        }\n\n        return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n      case 'thread.run.step.in_progress':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        break;\n    }\n\n    if (this.#runStepSnapshots[event.data.id]) return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n    throw new Error('No snapshot available');\n  }\n\n  #accumulateMessage(\n    event: AssistantStreamEvent,\n    snapshot: Message | undefined,\n  ): [Message, MessageContentDelta[]] {\n    let newContent: MessageContentDelta[] = [];\n\n    switch (event.event) {\n      case 'thread.message.created':\n        //On creation the snapshot is just the initial message\n        return [event.data, newContent];\n\n      case 'thread.message.delta':\n        if (!snapshot) {\n          throw Error(\n            'Received a delta with no existing snapshot (there should be one from message creation)',\n          );\n        }\n\n        let data = event.data;\n\n        //If this delta does not have content, nothing to process\n        if (data.delta.content) {\n          for (const contentElement of data.delta.content) {\n            if (contentElement.index in snapshot.content) {\n              let currentContent = snapshot.content[contentElement.index];\n              snapshot.content[contentElement.index] = this.#accumulateContent(\n                contentElement,\n                currentContent,\n              );\n            } else {\n              snapshot.content[contentElement.index] = contentElement as MessageContent;\n              // This is a new element\n              newContent.push(contentElement);\n            }\n          }\n        }\n\n        return [snapshot, newContent];\n\n      case 'thread.message.in_progress':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //No changes on other thread events\n        if (snapshot) {\n          return [snapshot, newContent];\n        } else {\n          throw Error('Received thread message event with no existing snapshot');\n        }\n    }\n    throw Error('Tried to accumulate a non-message event');\n  }\n\n  #accumulateContent(\n    contentElement: MessageContentDelta,\n    currentContent: MessageContent | undefined,\n  ): TextContentBlock | ImageFileContentBlock {\n    return AssistantStream.accumulateDelta(currentContent as unknown as Record<any, any>, contentElement) as\n      | TextContentBlock\n      | ImageFileContentBlock;\n  }\n\n  static accumulateDelta(acc: Record<string, any>, delta: Record<string, any>): Record<string, any> {\n    for (const [key, deltaValue] of Object.entries(delta)) {\n      if (!acc.hasOwnProperty(key)) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      let accValue = acc[key];\n      if (accValue === null || accValue === undefined) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // We don't accumulate these special properties\n      if (key === 'index' || key === 'type') {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // Type-specific accumulation logic\n      if (typeof accValue === 'string' && typeof deltaValue === 'string') {\n        accValue += deltaValue;\n      } else if (typeof accValue === 'number' && typeof deltaValue === 'number') {\n        accValue += deltaValue;\n      } else if (isObj(accValue) && isObj(deltaValue)) {\n        accValue = this.accumulateDelta(accValue as Record<string, any>, deltaValue as Record<string, any>);\n      } else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {\n        if (accValue.every((x) => typeof x === 'string' || typeof x === 'number')) {\n          accValue.push(...deltaValue); // Use spread syntax for efficient addition\n          continue;\n        }\n\n        for (const deltaEntry of deltaValue) {\n          if (!isObj(deltaEntry)) {\n            throw new Error(`Expected array delta entry to be an object but got: ${deltaEntry}`);\n          }\n\n          const index = deltaEntry['index'];\n          if (index == null) {\n            console.error(deltaEntry);\n            throw new Error('Expected array delta entry to have an `index` property');\n          }\n\n          if (typeof index !== 'number') {\n            throw new Error(`Expected array delta entry \\`index\\` property to be a number but got ${index}`);\n          }\n\n          const accEntry = accValue[index];\n          if (accEntry == null) {\n            accValue.push(deltaEntry);\n          } else {\n            accValue[index] = this.accumulateDelta(accEntry, deltaEntry);\n          }\n        }\n        continue;\n      } else {\n        throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);\n      }\n      acc[key] = accValue;\n    }\n\n    return acc;\n  }\n\n  #handleRun(this: AssistantStream, event: RunStreamEvent) {\n    this.#currentRunSnapshot = event.data;\n\n    switch (event.event) {\n      case 'thread.run.created':\n        break;\n      case 'thread.run.queued':\n        break;\n      case 'thread.run.in_progress':\n        break;\n      case 'thread.run.requires_action':\n      case 'thread.run.cancelled':\n      case 'thread.run.failed':\n      case 'thread.run.completed':\n      case 'thread.run.expired':\n      case 'thread.run.incomplete':\n        this.#finalRun = event.data;\n        if (this.#currentToolCall) {\n          this._emit('toolCallDone', this.#currentToolCall);\n          this.#currentToolCall = undefined;\n        }\n        break;\n      case 'thread.run.cancelling':\n        break;\n    }\n  }\n\n  protected _addRun(run: Run): Run {\n    return run;\n  }\n\n  protected async _threadAssistantStream(\n    params: ThreadCreateAndRunParamsBase,\n    thread: Threads,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    return await this._createThreadAssistantStream(thread, params, options);\n  }\n\n  protected async _runAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBase,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    return await this._createAssistantStream(runs, threadId, params, options);\n  }\n\n  protected async _runToolAssistantStream(\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    return await this._createToolAssistantStream(runs, runId, params, options);\n  }\n}\n\nfunction assertNever(_x: never) {}\n","import { type RequestOptions } from './request-options';\nimport type { FilePropertyBag, Fetch } from './builtin-types';\nimport type { OpenAI } from '../client';\nimport { ReadableStreamFrom } from './shims';\n\nexport type BlobPart = string | ArrayBuffer | ArrayBufferView | Blob | DataView;\ntype FsReadStream = AsyncIterable<Uint8Array> & { path: string | { toString(): string } };\n\n// https://github.com/oven-sh/bun/issues/5980\ninterface BunFile extends Blob {\n  readonly name?: string | undefined;\n}\n\nexport const checkFileSupport = () => {\n  if (typeof File === 'undefined') {\n    const { process } = globalThis as any;\n    const isOldNode =\n      typeof process?.versions?.node === 'string' && parseInt(process.versions.node.split('.')) < 20;\n    throw new Error(\n      '`File` is not defined as a global, which is required for file uploads.' +\n        (isOldNode ?\n          \" Update to Node 20 LTS or newer, or set `globalThis.File` to `import('node:buffer').File`.\"\n        : ''),\n    );\n  }\n};\n\n/**\n * Typically, this is a native \"File\" class.\n *\n * We provide the {@link toFile} utility to convert a variety of objects\n * into the File class.\n *\n * For convenience, you can also pass a fetch Response, or in Node,\n * the result of fs.createReadStream().\n */\nexport type Uploadable = File | Response | FsReadStream | BunFile;\n\n/**\n * Construct a `File` instance. This is used to ensure a helpful error is thrown\n * for environments that don't define a global `File` yet.\n */\nexport function makeFile(\n  fileBits: BlobPart[],\n  fileName: string | undefined,\n  options?: FilePropertyBag,\n): File {\n  checkFileSupport();\n  return new File(fileBits as any, fileName ?? 'unknown_file', options);\n}\n\nexport function getName(value: any): string | undefined {\n  return (\n    (\n      (typeof value === 'object' &&\n        value !== null &&\n        (('name' in value && value.name && String(value.name)) ||\n          ('url' in value && value.url && String(value.url)) ||\n          ('filename' in value && value.filename && String(value.filename)) ||\n          ('path' in value && value.path && String(value.path)))) ||\n      ''\n    )\n      .split(/[\\\\/]/)\n      .pop() || undefined\n  );\n}\n\nexport const isAsyncIterable = (value: any): value is AsyncIterable<any> =>\n  value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\n\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nexport const maybeMultipartFormRequestOptions = async (\n  opts: RequestOptions,\n  fetch: OpenAI | Fetch,\n): Promise<RequestOptions> => {\n  if (!hasUploadableValue(opts.body)) return opts;\n\n  return { ...opts, body: await createForm(opts.body, fetch) };\n};\n\ntype MultipartFormRequestOptions = Omit<RequestOptions, 'body'> & { body: unknown };\n\nexport const multipartFormRequestOptions = async (\n  opts: MultipartFormRequestOptions,\n  fetch: OpenAI | Fetch,\n): Promise<RequestOptions> => {\n  return { ...opts, body: await createForm(opts.body, fetch) };\n};\n\nconst supportsFormDataMap = /* @__PURE__ */ new WeakMap<Fetch, Promise<boolean>>();\n\n/**\n * node-fetch doesn't support the global FormData object in recent node versions. Instead of sending\n * properly-encoded form data, it just stringifies the object, resulting in a request body of \"[object FormData]\".\n * This function detects if the fetch function provided supports the global FormData object to avoid\n * confusing error messages later on.\n */\nfunction supportsFormData(fetchObject: OpenAI | Fetch): Promise<boolean> {\n  const fetch: Fetch = typeof fetchObject === 'function' ? fetchObject : (fetchObject as any).fetch;\n  const cached = supportsFormDataMap.get(fetch);\n  if (cached) return cached;\n  const promise = (async () => {\n    try {\n      const FetchResponse = (\n        'Response' in fetch ?\n          fetch.Response\n        : (await fetch('data:,')).constructor) as typeof Response;\n      const data = new FormData();\n      if (data.toString() === (await new FetchResponse(data).text())) {\n        return false;\n      }\n      return true;\n    } catch {\n      // avoid false negatives\n      return true;\n    }\n  })();\n  supportsFormDataMap.set(fetch, promise);\n  return promise;\n}\n\nexport const createForm = async <T = Record<string, unknown>>(\n  body: T | undefined,\n  fetch: OpenAI | Fetch,\n): Promise<FormData> => {\n  if (!(await supportsFormData(fetch))) {\n    throw new TypeError(\n      'The provided fetch function does not support file uploads with the current global FormData class.',\n    );\n  }\n  const form = new FormData();\n  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n  return form;\n};\n\n// We check for Blob not File because Bun.File doesn't inherit from File,\n// but they both inherit from Blob and have a `name` property at runtime.\nconst isNamedBlob = (value: unknown) => value instanceof Blob && 'name' in value;\n\nconst isUploadable = (value: unknown) =>\n  typeof value === 'object' &&\n  value !== null &&\n  (value instanceof Response || isAsyncIterable(value) || isNamedBlob(value));\n\nconst hasUploadableValue = (value: unknown): boolean => {\n  if (isUploadable(value)) return true;\n  if (Array.isArray(value)) return value.some(hasUploadableValue);\n  if (value && typeof value === 'object') {\n    for (const k in value) {\n      if (hasUploadableValue((value as any)[k])) return true;\n    }\n  }\n  return false;\n};\n\nconst addFormValue = async (form: FormData, key: string, value: unknown): Promise<void> => {\n  if (value === undefined) return;\n  if (value == null) {\n    throw new TypeError(\n      `Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`,\n    );\n  }\n\n  // TODO: make nested formats configurable\n  if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n    form.append(key, String(value));\n  } else if (value instanceof Response) {\n    form.append(key, makeFile([await value.blob()], getName(value)));\n  } else if (isAsyncIterable(value)) {\n    form.append(key, makeFile([await new Response(ReadableStreamFrom(value)).blob()], getName(value)));\n  } else if (isNamedBlob(value)) {\n    form.append(key, value, getName(value));\n  } else if (Array.isArray(value)) {\n    await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n  } else if (typeof value === 'object') {\n    await Promise.all(\n      Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)),\n    );\n  } else {\n    throw new TypeError(\n      `Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`,\n    );\n  }\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { InvalidWebhookSignatureError } from '../error';\nimport { APIResource } from '../core/resource';\nimport { buildHeaders, HeadersLike } from '../internal/headers';\n\nexport class Webhooks extends APIResource {\n  /**\n   * Validates that the given payload was sent by OpenAI and parses the payload.\n   */\n  async unwrap(\n    payload: string,\n    headers: HeadersLike,\n    secret: string | undefined | null = this._client.webhookSecret,\n    tolerance: number = 300,\n  ): Promise<UnwrapWebhookEvent> {\n    await this.verifySignature(payload, headers, secret, tolerance);\n\n    return JSON.parse(payload) as UnwrapWebhookEvent;\n  }\n\n  /**\n   * Validates whether or not the webhook payload was sent by OpenAI.\n   *\n   * An error will be raised if the webhook payload was not sent by OpenAI.\n   *\n   * @param payload - The webhook payload\n   * @param headers - The webhook headers\n   * @param secret - The webhook secret (optional, will use client secret if not provided)\n   * @param tolerance - Maximum age of the webhook in seconds (default: 300 = 5 minutes)\n   */\n  async verifySignature(\n    payload: string,\n    headers: HeadersLike,\n    secret: string | undefined | null = this._client.webhookSecret,\n    tolerance: number = 300,\n  ): Promise<void> {\n    if (\n      typeof crypto === 'undefined' ||\n      typeof crypto.subtle.importKey !== 'function' ||\n      typeof crypto.subtle.verify !== 'function'\n    ) {\n      throw new Error('Webhook signature verification is only supported when the `crypto` global is defined');\n    }\n\n    this.#validateSecret(secret);\n\n    const headersObj = buildHeaders([headers]).values;\n    const signatureHeader = this.#getRequiredHeader(headersObj, 'webhook-signature');\n    const timestamp = this.#getRequiredHeader(headersObj, 'webhook-timestamp');\n    const webhookId = this.#getRequiredHeader(headersObj, 'webhook-id');\n\n    // Validate timestamp to prevent replay attacks\n    const timestampSeconds = parseInt(timestamp, 10);\n    if (isNaN(timestampSeconds)) {\n      throw new InvalidWebhookSignatureError('Invalid webhook timestamp format');\n    }\n\n    const nowSeconds = Math.floor(Date.now() / 1000);\n\n    if (nowSeconds - timestampSeconds > tolerance) {\n      throw new InvalidWebhookSignatureError('Webhook timestamp is too old');\n    }\n\n    if (timestampSeconds > nowSeconds + tolerance) {\n      throw new InvalidWebhookSignatureError('Webhook timestamp is too new');\n    }\n\n    // Extract signatures from v1,<base64> format\n    // The signature header can have multiple values, separated by spaces.\n    // Each value is in the format v1,<base64>. We should accept if any match.\n    const signatures = signatureHeader\n      .split(' ')\n      .map((part) => (part.startsWith('v1,') ? part.substring(3) : part));\n\n    // Decode the secret if it starts with whsec_\n    const decodedSecret =\n      secret.startsWith('whsec_') ?\n        Buffer.from(secret.replace('whsec_', ''), 'base64')\n      : Buffer.from(secret, 'utf-8');\n\n    // Create the signed payload: {webhook_id}.{timestamp}.{payload}\n    const signedPayload = webhookId ? `${webhookId}.${timestamp}.${payload}` : `${timestamp}.${payload}`;\n\n    // Import the secret as a cryptographic key for HMAC\n    const key = await crypto.subtle.importKey(\n      'raw',\n      decodedSecret,\n      { name: 'HMAC', hash: 'SHA-256' },\n      false,\n      ['verify'],\n    );\n\n    // Check if any signature matches using timing-safe WebCrypto verify\n    for (const signature of signatures) {\n      try {\n        const signatureBytes = Buffer.from(signature, 'base64');\n        const isValid = await crypto.subtle.verify(\n          'HMAC',\n          key,\n          signatureBytes,\n          new TextEncoder().encode(signedPayload),\n        );\n\n        if (isValid) {\n          return; // Valid signature found\n        }\n      } catch {\n        // Invalid base64 or signature format, continue to next signature\n        continue;\n      }\n    }\n\n    throw new InvalidWebhookSignatureError(\n      'The given webhook signature does not match the expected signature',\n    );\n  }\n\n  #validateSecret(secret: string | null | undefined): asserts secret is string {\n    if (typeof secret !== 'string' || secret.length === 0) {\n      throw new Error(\n        `The webhook secret must either be set using the env var, OPENAI_WEBHOOK_SECRET, on the client class, OpenAI({ webhookSecret: '123' }), or passed to this function`,\n      );\n    }\n  }\n\n  #getRequiredHeader(headers: Headers, name: string): string {\n    if (!headers) {\n      throw new Error(`Headers are required`);\n    }\n\n    const value = headers.get(name);\n\n    if (value === null || value === undefined) {\n      throw new Error(`Missing required header: ${name}`);\n    }\n\n    return value;\n  }\n}\n\n/**\n * Sent when a batch API request has been cancelled.\n */\nexport interface BatchCancelledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request was cancelled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchCancelledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.cancelled`.\n   */\n  type: 'batch.cancelled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchCancelledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has been completed.\n */\nexport interface BatchCompletedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request was completed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchCompletedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.completed`.\n   */\n  type: 'batch.completed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchCompletedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has expired.\n */\nexport interface BatchExpiredWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request expired.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchExpiredWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.expired`.\n   */\n  type: 'batch.expired';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchExpiredWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has failed.\n */\nexport interface BatchFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.failed`.\n   */\n  type: 'batch.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when an eval run has been canceled.\n */\nexport interface EvalRunCanceledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the eval run was canceled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: EvalRunCanceledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `eval.run.canceled`.\n   */\n  type: 'eval.run.canceled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace EvalRunCanceledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the eval run.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when an eval run has failed.\n */\nexport interface EvalRunFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the eval run failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: EvalRunFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `eval.run.failed`.\n   */\n  type: 'eval.run.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace EvalRunFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the eval run.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when an eval run has succeeded.\n */\nexport interface EvalRunSucceededWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the eval run succeeded.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: EvalRunSucceededWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `eval.run.succeeded`.\n   */\n  type: 'eval.run.succeeded';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace EvalRunSucceededWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the eval run.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a fine-tuning job has been cancelled.\n */\nexport interface FineTuningJobCancelledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the fine-tuning job was cancelled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: FineTuningJobCancelledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `fine_tuning.job.cancelled`.\n   */\n  type: 'fine_tuning.job.cancelled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace FineTuningJobCancelledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the fine-tuning job.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a fine-tuning job has failed.\n */\nexport interface FineTuningJobFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the fine-tuning job failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: FineTuningJobFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `fine_tuning.job.failed`.\n   */\n  type: 'fine_tuning.job.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace FineTuningJobFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the fine-tuning job.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a fine-tuning job has succeeded.\n */\nexport interface FineTuningJobSucceededWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the fine-tuning job succeeded.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: FineTuningJobSucceededWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `fine_tuning.job.succeeded`.\n   */\n  type: 'fine_tuning.job.succeeded';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace FineTuningJobSucceededWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the fine-tuning job.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when Realtime API Receives a incoming SIP call.\n */\nexport interface RealtimeCallIncomingWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was completed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: RealtimeCallIncomingWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `realtime.call.incoming`.\n   */\n  type: 'realtime.call.incoming';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace RealtimeCallIncomingWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of this call.\n     */\n    call_id: string;\n\n    /**\n     * Headers from the SIP Invite.\n     */\n    sip_headers: Array<Data.SipHeader>;\n  }\n\n  export namespace Data {\n    /**\n     * A header from the SIP Invite.\n     */\n    export interface SipHeader {\n      /**\n       * Name of the SIP Header.\n       */\n      name: string;\n\n      /**\n       * Value of the SIP Header.\n       */\n      value: string;\n    }\n  }\n}\n\n/**\n * Sent when a background response has been cancelled.\n */\nexport interface ResponseCancelledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was cancelled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseCancelledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.cancelled`.\n   */\n  type: 'response.cancelled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseCancelledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a background response has been completed.\n */\nexport interface ResponseCompletedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was completed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseCompletedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.completed`.\n   */\n  type: 'response.completed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseCompletedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a background response has failed.\n */\nexport interface ResponseFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.failed`.\n   */\n  type: 'response.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a background response has been interrupted.\n */\nexport interface ResponseIncompleteWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was interrupted.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseIncompleteWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.incomplete`.\n   */\n  type: 'response.incomplete';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseIncompleteWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has been cancelled.\n */\nexport type UnwrapWebhookEvent =\n  | BatchCancelledWebhookEvent\n  | BatchCompletedWebhookEvent\n  | BatchExpiredWebhookEvent\n  | BatchFailedWebhookEvent\n  | EvalRunCanceledWebhookEvent\n  | EvalRunFailedWebhookEvent\n  | EvalRunSucceededWebhookEvent\n  | FineTuningJobCancelledWebhookEvent\n  | FineTuningJobFailedWebhookEvent\n  | FineTuningJobSucceededWebhookEvent\n  | RealtimeCallIncomingWebhookEvent\n  | ResponseCancelledWebhookEvent\n  | ResponseCompletedWebhookEvent\n  | ResponseFailedWebhookEvent\n  | ResponseIncompleteWebhookEvent;\n\nexport declare namespace Webhooks {\n  export {\n    type BatchCancelledWebhookEvent as BatchCancelledWebhookEvent,\n    type BatchCompletedWebhookEvent as BatchCompletedWebhookEvent,\n    type BatchExpiredWebhookEvent as BatchExpiredWebhookEvent,\n    type BatchFailedWebhookEvent as BatchFailedWebhookEvent,\n    type EvalRunCanceledWebhookEvent as EvalRunCanceledWebhookEvent,\n    type EvalRunFailedWebhookEvent as EvalRunFailedWebhookEvent,\n    type EvalRunSucceededWebhookEvent as EvalRunSucceededWebhookEvent,\n    type FineTuningJobCancelledWebhookEvent as FineTuningJobCancelledWebhookEvent,\n    type FineTuningJobFailedWebhookEvent as FineTuningJobFailedWebhookEvent,\n    type FineTuningJobSucceededWebhookEvent as FineTuningJobSucceededWebhookEvent,\n    type RealtimeCallIncomingWebhookEvent as RealtimeCallIncomingWebhookEvent,\n    type ResponseCancelledWebhookEvent as ResponseCancelledWebhookEvent,\n    type ResponseCompletedWebhookEvent as ResponseCompletedWebhookEvent,\n    type ResponseFailedWebhookEvent as ResponseFailedWebhookEvent,\n    type ResponseIncompleteWebhookEvent as ResponseIncompleteWebhookEvent,\n    type UnwrapWebhookEvent as UnwrapWebhookEvent,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\n\nexport class Sessions extends APIResource {\n  /**\n   * Create an ephemeral API token for use in client-side applications with the\n   * Realtime API. Can be configured with the same session parameters as the\n   * `session.update` client event.\n   *\n   * It responds with a session object, plus a `client_secret` key which contains a\n   * usable ephemeral API token that can be used to authenticate browser clients for\n   * the Realtime API.\n   *\n   * @example\n   * ```ts\n   * const session =\n   *   await client.beta.realtime.sessions.create();\n   * ```\n   */\n  create(body: SessionCreateParams, options?: RequestOptions): APIPromise<SessionCreateResponse> {\n    return this._client.post('/realtime/sessions', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\n/**\n * Realtime session object configuration.\n */\nexport interface Session {\n  /**\n   * Unique identifier for the session that looks like `sess_1234567890abcdef`.\n   */\n  id?: string;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  input_audio_transcription?: Session.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n   * temperature of 0.8 is highly recommended for best performance.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<Session.Tool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | Session.TracingConfiguration;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  turn_detection?: Session.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace Session {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: 'near_field' | 'far_field';\n  }\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription, current options are `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, and `whisper-1`.\n     */\n    model?: string;\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. For `whisper-1`, the\n     * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n     * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n     * \"expect words related to technology\".\n     */\n    prompt?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection.\n     */\n    type?: 'server_vad' | 'semantic_vad';\n  }\n}\n\n/**\n * A new Realtime session configuration, with an ephemeral key. Default TTL for\n * keys is one minute.\n */\nexport interface SessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  client_secret: SessionCreateResponse.ClientSecret;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  input_audio_format?: string;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously and should be treated as rough guidance rather than the\n   * representation understood by the model.\n   */\n  input_audio_transcription?: SessionCreateResponse.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  output_audio_format?: string;\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<SessionCreateResponse.Tool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | SessionCreateResponse.TracingConfiguration;\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  turn_detection?: SessionCreateResponse.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace SessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  export interface ClientSecret {\n    /**\n     * Timestamp for when the token expires. Currently, all tokens expire after one\n     * minute.\n     */\n    expires_at: number;\n\n    /**\n     * Ephemeral key usable in client environments to authenticate connections to the\n     * Realtime API. Use this in client-side environments rather than a standard API\n     * token, which should only be used server-side.\n     */\n    value: string;\n  }\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously and should be treated as rough guidance rather than the\n   * representation understood by the model.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The model to use for transcription.\n     */\n    model?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  export interface TurnDetection {\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     * Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n     * With shorter values the model will respond more quickly, but may jump in on\n     * short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection, only `server_vad` is currently supported.\n     */\n    type?: string;\n  }\n}\n\nexport interface SessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  client_secret?: SessionCreateParams.ClientSecret;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: SessionCreateParams.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  input_audio_transcription?: SessionCreateParams.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n   * temperature of 0.8 is highly recommended for best performance.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<SessionCreateParams.Tool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | SessionCreateParams.TracingConfiguration;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  turn_detection?: SessionCreateParams.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace SessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  export interface ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    expires_after?: ClientSecret.ExpiresAfter;\n  }\n\n  export namespace ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    export interface ExpiresAfter {\n      /**\n       * The anchor point for the ephemeral token expiration. Only `created_at` is\n       * currently supported.\n       */\n      anchor: 'created_at';\n\n      /**\n       * The number of seconds from the anchor point to the expiration. Select a value\n       * between `10` and `7200`.\n       */\n      seconds?: number;\n    }\n  }\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: 'near_field' | 'far_field';\n  }\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription, current options are `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, and `whisper-1`.\n     */\n    model?: string;\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. For `whisper-1`, the\n     * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n     * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n     * \"expect words related to technology\".\n     */\n    prompt?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection.\n     */\n    type?: 'server_vad' | 'semantic_vad';\n  }\n}\n\nexport declare namespace Sessions {\n  export {\n    type Session as Session,\n    type SessionCreateResponse as SessionCreateResponse,\n    type SessionCreateParams as SessionCreateParams,\n  };\n}\n","import { partialParse } from '../_vendor/partial-json-parser/parser';\nimport {\n  APIUserAbortError,\n  ContentFilterFinishReasonError,\n  LengthFinishReasonError,\n  OpenAIError,\n} from '../error';\nimport OpenAI from '../index';\nimport { RequestOptions } from '../internal/request-options';\nimport { type ReadableStream } from '../internal/shim-types';\nimport {\n  AutoParseableResponseFormat,\n  hasAutoParseableInput,\n  isAutoParsableResponseFormat,\n  isAutoParsableTool,\n  isChatCompletionFunctionTool,\n  maybeParseChatCompletion,\n  shouldParseToolCall,\n} from '../lib/parser';\nimport { ChatCompletionFunctionTool, ParsedChatCompletion } from '../resources/chat/completions';\nimport {\n  ChatCompletionTokenLogprob,\n  type ChatCompletion,\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsBase,\n  type ChatCompletionCreateParamsStreaming,\n  type ChatCompletionRole,\n} from '../resources/chat/completions/completions';\nimport { Stream } from '../streaming';\nimport {\n  AbstractChatCompletionRunner,\n  type AbstractChatCompletionRunnerEvents,\n} from './AbstractChatCompletionRunner';\n\nexport interface ContentDeltaEvent {\n  delta: string;\n  snapshot: string;\n  parsed: unknown | null;\n}\n\nexport interface ContentDoneEvent<ParsedT = null> {\n  content: string;\n  parsed: ParsedT | null;\n}\n\nexport interface RefusalDeltaEvent {\n  delta: string;\n  snapshot: string;\n}\n\nexport interface RefusalDoneEvent {\n  refusal: string;\n}\n\nexport interface FunctionToolCallArgumentsDeltaEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n\n  arguments_delta: string;\n}\n\nexport interface FunctionToolCallArgumentsDoneEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n}\n\nexport interface LogProbsContentDeltaEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsContentDoneEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDeltaEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDoneEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface ChatCompletionStreamEvents<ParsedT = null> extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n\n  'content.delta': (props: ContentDeltaEvent) => void;\n  'content.done': (props: ContentDoneEvent<ParsedT>) => void;\n\n  'refusal.delta': (props: RefusalDeltaEvent) => void;\n  'refusal.done': (props: RefusalDoneEvent) => void;\n\n  'tool_calls.function.arguments.delta': (props: FunctionToolCallArgumentsDeltaEvent) => void;\n  'tool_calls.function.arguments.done': (props: FunctionToolCallArgumentsDoneEvent) => void;\n\n  'logprobs.content.delta': (props: LogProbsContentDeltaEvent) => void;\n  'logprobs.content.done': (props: LogProbsContentDoneEvent) => void;\n\n  'logprobs.refusal.delta': (props: LogProbsRefusalDeltaEvent) => void;\n  'logprobs.refusal.done': (props: LogProbsRefusalDoneEvent) => void;\n}\n\nexport type ChatCompletionStreamParams = Omit<ChatCompletionCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\ninterface ChoiceEventState {\n  content_done: boolean;\n  refusal_done: boolean;\n  logprobs_content_done: boolean;\n  logprobs_refusal_done: boolean;\n  current_tool_call_index: number | null;\n  done_tool_calls: Set<number>;\n}\n\nexport class ChatCompletionStream<ParsedT = null>\n  extends AbstractChatCompletionRunner<ChatCompletionStreamEvents<ParsedT>, ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  #params: ChatCompletionCreateParams | null;\n  #choiceEventStates: ChoiceEventState[];\n  #currentChatCompletionSnapshot: ChatCompletionSnapshot | undefined;\n\n  constructor(params: ChatCompletionCreateParams | null) {\n    super();\n    this.#params = params;\n    this.#choiceEventStates = [];\n  }\n\n  get currentChatCompletionSnapshot(): ChatCompletionSnapshot | undefined {\n    return this.#currentChatCompletionSnapshot;\n  }\n\n  /**\n   * Intended for use on the frontend, consuming a stream produced with\n   * `.toReadableStream()` on the backend.\n   *\n   * Note that messages sent to the model do not appear in `.on('message')`\n   * in this context.\n   */\n  static fromReadableStream(stream: ReadableStream): ChatCompletionStream<null> {\n    const runner = new ChatCompletionStream(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static createChatCompletion<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionStreamParams,\n    options?: RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    const runner = new ChatCompletionStream<ParsedT>(params as ChatCompletionCreateParamsStreaming);\n    runner._run(() =>\n      runner._runChatCompletion(\n        client,\n        { ...params, stream: true },\n        { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } },\n      ),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentChatCompletionSnapshot = undefined;\n  }\n\n  #getChoiceEventState(choice: ChatCompletionSnapshot.Choice): ChoiceEventState {\n    let state = this.#choiceEventStates[choice.index];\n    if (state) {\n      return state;\n    }\n\n    state = {\n      content_done: false,\n      refusal_done: false,\n      logprobs_content_done: false,\n      logprobs_refusal_done: false,\n      done_tool_calls: new Set(),\n      current_tool_call_index: null,\n    };\n    this.#choiceEventStates[choice.index] = state;\n    return state;\n  }\n\n  #addChunk(this: ChatCompletionStream<ParsedT>, chunk: ChatCompletionChunk) {\n    if (this.ended) return;\n\n    const completion = this.#accumulateChatCompletion(chunk);\n    this._emit('chunk', chunk, completion);\n\n    for (const choice of chunk.choices) {\n      const choiceSnapshot = completion.choices[choice.index]!;\n\n      if (\n        choice.delta.content != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.content\n      ) {\n        this._emit('content', choice.delta.content, choiceSnapshot.message.content);\n        this._emit('content.delta', {\n          delta: choice.delta.content,\n          snapshot: choiceSnapshot.message.content,\n          parsed: choiceSnapshot.message.parsed,\n        });\n      }\n\n      if (\n        choice.delta.refusal != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.refusal\n      ) {\n        this._emit('refusal.delta', {\n          delta: choice.delta.refusal,\n          snapshot: choiceSnapshot.message.refusal,\n        });\n      }\n\n      if (choice.logprobs?.content != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.content.delta', {\n          content: choice.logprobs?.content,\n          snapshot: choiceSnapshot.logprobs?.content ?? [],\n        });\n      }\n\n      if (choice.logprobs?.refusal != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.refusal.delta', {\n          refusal: choice.logprobs?.refusal,\n          snapshot: choiceSnapshot.logprobs?.refusal ?? [],\n        });\n      }\n\n      const state = this.#getChoiceEventState(choiceSnapshot);\n\n      if (choiceSnapshot.finish_reason) {\n        this.#emitContentDoneEvents(choiceSnapshot);\n\n        if (state.current_tool_call_index != null) {\n          this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n        }\n      }\n\n      for (const toolCall of choice.delta.tool_calls ?? []) {\n        if (state.current_tool_call_index !== toolCall.index) {\n          this.#emitContentDoneEvents(choiceSnapshot);\n\n          // new tool call started, the previous one is done\n          if (state.current_tool_call_index != null) {\n            this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n          }\n        }\n\n        state.current_tool_call_index = toolCall.index;\n      }\n\n      for (const toolCallDelta of choice.delta.tool_calls ?? []) {\n        const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallDelta.index];\n        if (!toolCallSnapshot?.type) {\n          continue;\n        }\n\n        if (toolCallSnapshot?.type === 'function') {\n          this._emit('tool_calls.function.arguments.delta', {\n            name: toolCallSnapshot.function?.name,\n            index: toolCallDelta.index,\n            arguments: toolCallSnapshot.function.arguments,\n            parsed_arguments: toolCallSnapshot.function.parsed_arguments,\n            arguments_delta: toolCallDelta.function?.arguments ?? '',\n          });\n        } else {\n          assertNever(toolCallSnapshot?.type);\n        }\n      }\n    }\n  }\n\n  #emitToolCallDoneEvent(choiceSnapshot: ChatCompletionSnapshot.Choice, toolCallIndex: number) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n    if (state.done_tool_calls.has(toolCallIndex)) {\n      // we've already fired the done event\n      return;\n    }\n\n    const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallIndex];\n    if (!toolCallSnapshot) {\n      throw new Error('no tool call snapshot');\n    }\n    if (!toolCallSnapshot.type) {\n      throw new Error('tool call snapshot missing `type`');\n    }\n\n    if (toolCallSnapshot.type === 'function') {\n      const inputTool = this.#params?.tools?.find(\n        (tool) => isChatCompletionFunctionTool(tool) && tool.function.name === toolCallSnapshot.function.name,\n      ) as ChatCompletionFunctionTool | undefined; // TS doesn't narrow based on isChatCompletionTool\n\n      this._emit('tool_calls.function.arguments.done', {\n        name: toolCallSnapshot.function.name,\n        index: toolCallIndex,\n        arguments: toolCallSnapshot.function.arguments,\n        parsed_arguments:\n          isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCallSnapshot.function.arguments)\n          : inputTool?.function.strict ? JSON.parse(toolCallSnapshot.function.arguments)\n          : null,\n      });\n    } else {\n      assertNever(toolCallSnapshot.type);\n    }\n  }\n\n  #emitContentDoneEvents(choiceSnapshot: ChatCompletionSnapshot.Choice) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n\n    if (choiceSnapshot.message.content && !state.content_done) {\n      state.content_done = true;\n\n      const responseFormat = this.#getAutoParseableResponseFormat();\n\n      this._emit('content.done', {\n        content: choiceSnapshot.message.content,\n        parsed: responseFormat ? responseFormat.$parseRaw(choiceSnapshot.message.content) : (null as any),\n      });\n    }\n\n    if (choiceSnapshot.message.refusal && !state.refusal_done) {\n      state.refusal_done = true;\n\n      this._emit('refusal.done', { refusal: choiceSnapshot.message.refusal });\n    }\n\n    if (choiceSnapshot.logprobs?.content && !state.logprobs_content_done) {\n      state.logprobs_content_done = true;\n\n      this._emit('logprobs.content.done', { content: choiceSnapshot.logprobs.content });\n    }\n\n    if (choiceSnapshot.logprobs?.refusal && !state.logprobs_refusal_done) {\n      state.logprobs_refusal_done = true;\n\n      this._emit('logprobs.refusal.done', { refusal: choiceSnapshot.logprobs.refusal });\n    }\n  }\n\n  #endRequest(): ParsedChatCompletion<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentChatCompletionSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any chunks`);\n    }\n    this.#currentChatCompletionSnapshot = undefined;\n    this.#choiceEventStates = [];\n    return finalizeChatCompletion(snapshot, this.#params);\n  }\n\n  protected override async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    super._createChatCompletion;\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    const stream = await client.chat.completions.create(\n      { ...params, stream: true },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    for await (const chunk of stream) {\n      this.#addChunk(chunk);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n    this._connected();\n    const stream = Stream.fromReadableStream<ChatCompletionChunk>(readableStream, this.controller);\n    let chatId;\n    for await (const chunk of stream) {\n      if (chatId && chatId !== chunk.id) {\n        // A new request has been made.\n        this._addChatCompletion(this.#endRequest());\n      }\n\n      this.#addChunk(chunk);\n      chatId = chunk.id;\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  #getAutoParseableResponseFormat(): AutoParseableResponseFormat<ParsedT> | null {\n    const responseFormat = this.#params?.response_format;\n    if (isAutoParsableResponseFormat<ParsedT>(responseFormat)) {\n      return responseFormat;\n    }\n\n    return null;\n  }\n\n  #accumulateChatCompletion(chunk: ChatCompletionChunk): ChatCompletionSnapshot {\n    let snapshot = this.#currentChatCompletionSnapshot;\n    const { choices, ...rest } = chunk;\n    if (!snapshot) {\n      snapshot = this.#currentChatCompletionSnapshot = {\n        ...rest,\n        choices: [],\n      };\n    } else {\n      Object.assign(snapshot, rest);\n    }\n\n    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\n      let choice = snapshot.choices[index];\n      if (!choice) {\n        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\n      }\n\n      if (logprobs) {\n        if (!choice.logprobs) {\n          choice.logprobs = Object.assign({}, logprobs);\n        } else {\n          const { content, refusal, ...rest } = logprobs;\n          assertIsEmpty(rest);\n          Object.assign(choice.logprobs, rest);\n\n          if (content) {\n            choice.logprobs.content ??= [];\n            choice.logprobs.content.push(...content);\n          }\n\n          if (refusal) {\n            choice.logprobs.refusal ??= [];\n            choice.logprobs.refusal.push(...refusal);\n          }\n        }\n      }\n\n      if (finish_reason) {\n        choice.finish_reason = finish_reason;\n\n        if (this.#params && hasAutoParseableInput(this.#params)) {\n          if (finish_reason === 'length') {\n            throw new LengthFinishReasonError();\n          }\n\n          if (finish_reason === 'content_filter') {\n            throw new ContentFilterFinishReasonError();\n          }\n        }\n      }\n\n      Object.assign(choice, other);\n\n      if (!delta) continue; // Shouldn't happen; just in case.\n\n      const { content, refusal, function_call, role, tool_calls, ...rest } = delta;\n      assertIsEmpty(rest);\n      Object.assign(choice.message, rest);\n\n      if (refusal) {\n        choice.message.refusal = (choice.message.refusal || '') + refusal;\n      }\n\n      if (role) choice.message.role = role;\n      if (function_call) {\n        if (!choice.message.function_call) {\n          choice.message.function_call = function_call;\n        } else {\n          if (function_call.name) choice.message.function_call.name = function_call.name;\n          if (function_call.arguments) {\n            choice.message.function_call.arguments ??= '';\n            choice.message.function_call.arguments += function_call.arguments;\n          }\n        }\n      }\n      if (content) {\n        choice.message.content = (choice.message.content || '') + content;\n\n        if (!choice.message.refusal && this.#getAutoParseableResponseFormat()) {\n          choice.message.parsed = partialParse(choice.message.content);\n        }\n      }\n\n      if (tool_calls) {\n        if (!choice.message.tool_calls) choice.message.tool_calls = [];\n\n        for (const { index, id, type, function: fn, ...rest } of tool_calls) {\n          const tool_call = (choice.message.tool_calls[index] ??=\n            {} as ChatCompletionSnapshot.Choice.Message.ToolCall);\n          Object.assign(tool_call, rest);\n          if (id) tool_call.id = id;\n          if (type) tool_call.type = type;\n          if (fn) tool_call.function ??= { name: fn.name ?? '', arguments: '' };\n          if (fn?.name) tool_call.function!.name = fn.name;\n          if (fn?.arguments) {\n            tool_call.function!.arguments += fn.arguments;\n\n            if (shouldParseToolCall(this.#params, tool_call)) {\n              tool_call.function!.parsed_arguments = partialParse(tool_call.function!.arguments);\n            }\n          }\n        }\n      }\n    }\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ChatCompletionStream<ParsedT>): AsyncIterator<ChatCompletionChunk> {\n    const pushQueue: ChatCompletionChunk[] = [];\n    const readQueue: {\n      resolve: (chunk: ChatCompletionChunk | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('chunk', (chunk) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(chunk);\n      } else {\n        pushQueue.push(chunk);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ChatCompletionChunk>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ChatCompletionChunk | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n}\n\nfunction finalizeChatCompletion<ParsedT>(\n  snapshot: ChatCompletionSnapshot,\n  params: ChatCompletionCreateParams | null,\n): ParsedChatCompletion<ParsedT> {\n  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\n  const completion: ChatCompletion = {\n    ...rest,\n    id,\n    choices: choices.map(\n      ({ message, finish_reason, index, logprobs, ...choiceRest }): ChatCompletion.Choice => {\n        if (!finish_reason) {\n          throw new OpenAIError(`missing finish_reason for choice ${index}`);\n        }\n\n        const { content = null, function_call, tool_calls, ...messageRest } = message;\n        const role = message.role as 'assistant'; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\n        if (!role) {\n          throw new OpenAIError(`missing role for choice ${index}`);\n        }\n\n        if (function_call) {\n          const { arguments: args, name } = function_call;\n          if (args == null) {\n            throw new OpenAIError(`missing function_call.arguments for choice ${index}`);\n          }\n\n          if (!name) {\n            throw new OpenAIError(`missing function_call.name for choice ${index}`);\n          }\n\n          return {\n            ...choiceRest,\n            message: {\n              content,\n              function_call: { arguments: args, name },\n              role,\n              refusal: message.refusal ?? null,\n            },\n            finish_reason,\n            index,\n            logprobs,\n          };\n        }\n\n        if (tool_calls) {\n          return {\n            ...choiceRest,\n            index,\n            finish_reason,\n            logprobs,\n            message: {\n              ...messageRest,\n              role,\n              content,\n              refusal: message.refusal ?? null,\n              tool_calls: tool_calls.map((tool_call, i) => {\n                const { function: fn, type, id, ...toolRest } = tool_call;\n                const { arguments: args, name, ...fnRest } = fn || {};\n                if (id == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\n                }\n                if (type == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\n                }\n                if (name == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`,\n                  );\n                }\n                if (args == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`,\n                  );\n                }\n\n                return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\n              }),\n            },\n          };\n        }\n        return {\n          ...choiceRest,\n          message: { ...messageRest, content, role, refusal: message.refusal ?? null },\n          finish_reason,\n          index,\n          logprobs,\n        };\n      },\n    ),\n    created,\n    model,\n    object: 'chat.completion',\n    ...(system_fingerprint ? { system_fingerprint } : {}),\n  };\n\n  return maybeParseChatCompletion(completion, params);\n}\n\nfunction str(x: unknown) {\n  return JSON.stringify(x);\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionSnapshot {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletionSnapshot.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  // Note we do not include an \"object\" type on the snapshot,\n  // because the object is not a valid \"chat.completion\" until finalized.\n  // object: 'chat.completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n}\n\nexport namespace ChatCompletionSnapshot {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    message: Choice.Message;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, or `function_call`\n     * if the model called a function.\n     */\n    finish_reason: ChatCompletion.Choice['finish_reason'] | null;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: ChatCompletion.Choice.Logprobs | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Message {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      refusal?: string | null;\n\n      parsed?: unknown | null;\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      function_call?: Message.FunctionCall;\n\n      tool_calls?: Array<Message.ToolCall>;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: ChatCompletionRole;\n    }\n\n    export namespace Message {\n      export interface ToolCall {\n        /**\n         * The ID of the tool call.\n         */\n        id: string;\n\n        function: ToolCall.Function;\n\n        /**\n         * The type of the tool.\n         */\n        type: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments: string;\n\n          parsed_arguments?: unknown;\n\n          /**\n           * The name of the function to call.\n           */\n          name: string;\n        }\n      }\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n    }\n  }\n}\n\ntype AssertIsEmpty<T extends {}> = keyof T extends never ? T : never;\n\n/**\n * Ensures the given argument is an empty object, useful for\n * asserting that all known properties on an object have been\n * destructured.\n */\nfunction assertIsEmpty<T extends {}>(obj: AssertIsEmpty<T>): asserts obj is AssertIsEmpty<T> {\n  return;\n}\n\nfunction assertNever(_x: never) {}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport * as CompletionsAPI from './completions';\nimport * as CompletionsCompletionsAPI from './chat/completions/completions';\nimport { APIPromise } from '../core/api-promise';\nimport { Stream } from '../core/streaming';\nimport { RequestOptions } from '../internal/request-options';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a completion for the provided prompt and parameters.\n   *\n   * @example\n   * ```ts\n   * const completion = await client.completions.create({\n   *   model: 'string',\n   *   prompt: 'This is a test.',\n   * });\n   * ```\n   */\n  create(body: CompletionCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Completion>;\n  create(body: CompletionCreateParamsStreaming, options?: RequestOptions): APIPromise<Stream<Completion>>;\n  create(\n    body: CompletionCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<Completion> | Completion>;\n  create(\n    body: CompletionCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\n    return this._client.post('/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<Completion>\n      | APIPromise<Stream<Completion>>;\n  }\n}\n\n/**\n * Represents a completion response from the API. Note: both the streamed and\n * non-streamed response objects share the same shape (unlike the chat endpoint).\n */\nexport interface Completion {\n  /**\n   * A unique identifier for the completion.\n   */\n  id: string;\n\n  /**\n   * The list of completion choices the model generated for the input prompt.\n   */\n  choices: Array<CompletionChoice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"text_completion\"\n   */\n  object: 'text_completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionUsage;\n}\n\nexport interface CompletionChoice {\n  /**\n   * The reason the model stopped generating tokens. This will be `stop` if the model\n   * hit a natural stop point or a provided stop sequence, `length` if the maximum\n   * number of tokens specified in the request was reached, or `content_filter` if\n   * content was omitted due to a flag from our content filters.\n   */\n  finish_reason: 'stop' | 'length' | 'content_filter';\n\n  index: number;\n\n  logprobs: CompletionChoice.Logprobs | null;\n\n  text: string;\n}\n\nexport namespace CompletionChoice {\n  export interface Logprobs {\n    text_offset?: Array<number>;\n\n    token_logprobs?: Array<number>;\n\n    tokens?: Array<string>;\n\n    top_logprobs?: Array<{ [key: string]: number }>;\n  }\n}\n\n/**\n * Usage statistics for the completion request.\n */\nexport interface CompletionUsage {\n  /**\n   * Number of tokens in the generated completion.\n   */\n  completion_tokens: number;\n\n  /**\n   * Number of tokens in the prompt.\n   */\n  prompt_tokens: number;\n\n  /**\n   * Total number of tokens used in the request (prompt + completion).\n   */\n  total_tokens: number;\n\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  completion_tokens_details?: CompletionUsage.CompletionTokensDetails;\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  prompt_tokens_details?: CompletionUsage.PromptTokensDetails;\n}\n\nexport namespace CompletionUsage {\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  export interface CompletionTokensDetails {\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that\n     * appeared in the completion.\n     */\n    accepted_prediction_tokens?: number;\n\n    /**\n     * Audio input tokens generated by the model.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Tokens generated by the model for reasoning.\n     */\n    reasoning_tokens?: number;\n\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that did\n     * not appear in the completion. However, like reasoning tokens, these tokens are\n     * still counted in the total completion tokens for purposes of billing, output,\n     * and context window limits.\n     */\n    rejected_prediction_tokens?: number;\n  }\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  export interface PromptTokensDetails {\n    /**\n     * Audio input tokens present in the prompt.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Cached tokens present in the prompt.\n     */\n    cached_tokens?: number;\n  }\n}\n\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\n\nexport interface CompletionCreateParamsBase {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | 'gpt-3.5-turbo-instruct' | 'davinci-002' | 'babbage-002';\n\n  /**\n   * The prompt(s) to generate completions for, encoded as a string, array of\n   * strings, array of tokens, or array of token arrays.\n   *\n   * Note that <|endoftext|> is the document separator that the model sees during\n   * training, so if a prompt is not specified the model will generate as if from the\n   * beginning of a new document.\n   */\n  prompt: string | Array<string> | Array<number> | Array<Array<number>> | null;\n\n  /**\n   * Generates `best_of` completions server-side and returns the \"best\" (the one with\n   * the highest log probability per token). Results cannot be streamed.\n   *\n   * When used with `n`, `best_of` controls the number of candidate completions and\n   * `n` specifies how many to return  `best_of` must be greater than `n`.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  best_of?: number | null;\n\n  /**\n   * Echo back the prompt in addition to the completion\n   */\n  echo?: boolean | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the GPT\n   * tokenizer) to an associated bias value from -100 to 100. You can use this\n   * [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs.\n   * Mathematically, the bias is added to the logits generated by the model prior to\n   * sampling. The exact effect will vary per model, but values between -1 and 1\n   * should decrease or increase likelihood of selection; values like -100 or 100\n   * should result in a ban or exclusive selection of the relevant token.\n   *\n   * As an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token\n   * from being generated.\n   */\n  logit_bias?: { [key: string]: number } | null;\n\n  /**\n   * Include the log probabilities on the `logprobs` most likely output tokens, as\n   * well the chosen tokens. For example, if `logprobs` is 5, the API will return a\n   * list of the 5 most likely tokens. The API will always return the `logprob` of\n   * the sampled token, so there may be up to `logprobs+1` elements in the response.\n   *\n   * The maximum value for `logprobs` is 5.\n   */\n  logprobs?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the\n   * completion.\n   *\n   * The token count of your prompt plus `max_tokens` cannot exceed the model's\n   * context length.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  max_tokens?: number | null;\n\n  /**\n   * How many completions to generate for each prompt.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  n?: number | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * If specified, our system will make a best effort to sample deterministically,\n   * such that repeated requests with the same `seed` and parameters should return\n   * the same result.\n   *\n   * Determinism is not guaranteed, and you should refer to the `system_fingerprint`\n   * response parameter to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Not supported with latest reasoning models `o3` and `o4-mini`.\n   *\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: CompletionsCompletionsAPI.ChatCompletionStreamOptions | null;\n\n  /**\n   * The suffix that comes after a completion of inserted text.\n   *\n   * This parameter is only supported for `gpt-3.5-turbo-instruct`.\n   */\n  suffix?: string | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace CompletionCreateParams {\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\nexport declare namespace Completions {\n  export {\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { FinalRequestOptions } from './request-options';\nimport { Stream } from '../core/streaming';\nimport { type OpenAI } from '../client';\nimport { formatRequestDetails, loggerFor } from './utils/log';\nimport type { AbstractPage } from '../pagination';\n\nexport type APIResponseProps = {\n  response: Response;\n  options: FinalRequestOptions;\n  controller: AbortController;\n  requestLogID: string;\n  retryOfRequestLogID: string | undefined;\n  startTime: number;\n};\n\nexport async function defaultParseResponse<T>(\n  client: OpenAI,\n  props: APIResponseProps,\n): Promise<WithRequestID<T>> {\n  const { response, requestLogID, retryOfRequestLogID, startTime } = props;\n  const body = await (async () => {\n    if (props.options.stream) {\n      loggerFor(client).debug('response', response.status, response.url, response.headers, response.body);\n\n      // Note: there is an invariant here that isn't represented in the type system\n      // that if you set `stream: true` the response type must also be `Stream<T>`\n\n      if (props.options.__streamClass) {\n        return props.options.__streamClass.fromSSEResponse(response, props.controller, client) as any;\n      }\n\n      return Stream.fromSSEResponse(response, props.controller, client) as any;\n    }\n\n    // fetch refuses to read the body when the status code is 204.\n    if (response.status === 204) {\n      return null as T;\n    }\n\n    if (props.options.__binaryResponse) {\n      return response as unknown as T;\n    }\n\n    const contentType = response.headers.get('content-type');\n    const mediaType = contentType?.split(';')[0]?.trim();\n    const isJSON = mediaType?.includes('application/json') || mediaType?.endsWith('+json');\n    if (isJSON) {\n      const json = await response.json();\n      return addRequestID(json as T, response);\n    }\n\n    const text = await response.text();\n    return text as unknown as T;\n  })();\n  loggerFor(client).debug(\n    `[${requestLogID}] response parsed`,\n    formatRequestDetails({\n      retryOfRequestLogID,\n      url: response.url,\n      status: response.status,\n      body,\n      durationMs: Date.now() - startTime,\n    }),\n  );\n  return body;\n}\n\nexport type WithRequestID<T> =\n  T extends Array<any> | Response | AbstractPage<any> ? T\n  : T extends Record<string, any> ? T & { _request_id?: string | null }\n  : T;\n\nexport function addRequestID<T>(value: T, response: Response): WithRequestID<T> {\n  if (!value || typeof value !== 'object' || Array.isArray(value)) {\n    return value as WithRequestID<T>;\n  }\n\n  return Object.defineProperty(value, '_request_id', {\n    value: response.headers.get('x-request-id'),\n    enumerable: false,\n  }) as WithRequestID<T>;\n}\n","import { BlobPart, getName, makeFile, isAsyncIterable } from './uploads';\nimport type { FilePropertyBag } from './builtin-types';\nimport { checkFileSupport } from './uploads';\n\ntype BlobLikePart = string | ArrayBuffer | ArrayBufferView | BlobLike | DataView;\n\n/**\n * Intended to match DOM Blob, node-fetch Blob, node:buffer Blob, etc.\n * Don't add arrayBuffer here, node-fetch doesn't have it\n */\ninterface BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */\n  readonly size: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */\n  readonly type: string;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */\n  text(): Promise<string>;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */\n  slice(start?: number, end?: number): BlobLike;\n}\n\n/**\n * This check adds the arrayBuffer() method type because it is available and used at runtime\n */\nconst isBlobLike = (value: any): value is BlobLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.size === 'number' &&\n  typeof value.type === 'string' &&\n  typeof value.text === 'function' &&\n  typeof value.slice === 'function' &&\n  typeof value.arrayBuffer === 'function';\n\n/**\n * Intended to match DOM File, node:buffer File, undici File, etc.\n */\ninterface FileLike extends BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */\n  readonly lastModified: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */\n  readonly name?: string | undefined;\n}\n\n/**\n * This check adds the arrayBuffer() method type because it is available and used at runtime\n */\nconst isFileLike = (value: any): value is FileLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.name === 'string' &&\n  typeof value.lastModified === 'number' &&\n  isBlobLike(value);\n\n/**\n * Intended to match DOM Response, node-fetch Response, undici Response, etc.\n */\nexport interface ResponseLike {\n  url: string;\n  blob(): Promise<BlobLike>;\n}\n\nconst isResponseLike = (value: any): value is ResponseLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.url === 'string' &&\n  typeof value.blob === 'function';\n\nexport type ToFileInput =\n  | FileLike\n  | ResponseLike\n  | Exclude<BlobLikePart, string>\n  | AsyncIterable<BlobLikePart>;\n\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file. Can be an {@link Uploadable}, BlobLikePart, or AsyncIterable of BlobLikeParts\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nexport async function toFile(\n  value: ToFileInput | PromiseLike<ToFileInput>,\n  name?: string | null | undefined,\n  options?: FilePropertyBag | undefined,\n): Promise<File> {\n  checkFileSupport();\n\n  // If it's a promise, resolve it.\n  value = await value;\n\n  // If we've been given a `File` we don't need to do anything\n  if (isFileLike(value)) {\n    if (value instanceof File) {\n      return value;\n    }\n    return makeFile([await value.arrayBuffer()], value.name);\n  }\n\n  if (isResponseLike(value)) {\n    const blob = await value.blob();\n    name ||= new URL(value.url).pathname.split(/[\\\\/]/).pop();\n\n    return makeFile(await getBytes(blob), name, options);\n  }\n\n  const parts = await getBytes(value);\n\n  name ||= getName(value);\n\n  if (!options?.type) {\n    const type = parts.find((part) => typeof part === 'object' && 'type' in part && part.type);\n    if (typeof type === 'string') {\n      options = { ...options, type };\n    }\n  }\n\n  return makeFile(parts, name, options);\n}\n\nasync function getBytes(value: BlobLikePart | AsyncIterable<BlobLikePart>): Promise<Array<BlobPart>> {\n  let parts: Array<BlobPart> = [];\n  if (\n    typeof value === 'string' ||\n    ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n    value instanceof ArrayBuffer\n  ) {\n    parts.push(value);\n  } else if (isBlobLike(value)) {\n    parts.push(value instanceof Blob ? value : await value.arrayBuffer());\n  } else if (\n    isAsyncIterable(value) // includes Readable, ReadableStream, etc.\n  ) {\n    for await (const chunk of value) {\n      parts.push(...(await getBytes(chunk as BlobLikePart))); // TODO, consider validating?\n    }\n  } else {\n    const constructor = value?.constructor?.name;\n    throw new Error(\n      `Unexpected data type: ${typeof value}${\n        constructor ? `; constructor: ${constructor}` : ''\n      }${propsForError(value)}`,\n    );\n  }\n\n  return parts;\n}\n\nfunction propsForError(value: unknown): string {\n  if (typeof value !== 'object' || value === null) return '';\n  const props = Object.getOwnPropertyNames(value);\n  return `; props: [${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as TranscriptionsAPI from './transcriptions';\nimport * as AudioAPI from './audio';\nimport { APIPromise } from '../../core/api-promise';\nimport { Stream } from '../../core/streaming';\nimport { type Uploadable } from '../../core/uploads';\nimport { RequestOptions } from '../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../internal/uploads';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   *\n   * @example\n   * ```ts\n   * const transcription =\n   *   await client.audio.transcriptions.create({\n   *     file: fs.createReadStream('speech.mp3'),\n   *     model: 'gpt-4o-transcribe',\n   *   });\n   * ```\n   */\n  create(\n    body: TranscriptionCreateParamsNonStreaming<'json' | undefined>,\n    options?: RequestOptions,\n  ): APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParamsNonStreaming<'verbose_json'>,\n    options?: RequestOptions,\n  ): APIPromise<TranscriptionVerbose>;\n  create(\n    body: TranscriptionCreateParamsNonStreaming<'srt' | 'vtt' | 'text'>,\n    options?: RequestOptions,\n  ): APIPromise<string>;\n  create(body: TranscriptionCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<TranscriptionStreamEvent>>;\n  create(\n    body: TranscriptionCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<TranscriptionCreateResponse | string | Stream<TranscriptionStreamEvent>>;\n  create(\n    body: TranscriptionCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<TranscriptionCreateResponse | string | Stream<TranscriptionStreamEvent>> {\n    return this._client.post(\n      '/audio/transcriptions',\n      multipartFormRequestOptions(\n        {\n          body,\n          ...options,\n          stream: body.stream ?? false,\n          __metadata: { model: body.model },\n        },\n        this._client,\n      ),\n    );\n  }\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport interface Transcription {\n  /**\n   * The transcribed text.\n   */\n  text: string;\n\n  /**\n   * The log probabilities of the tokens in the transcription. Only returned with the\n   * models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe` if `logprobs` is added\n   * to the `include` array.\n   */\n  logprobs?: Array<Transcription.Logprob>;\n\n  /**\n   * Token usage statistics for the request.\n   */\n  usage?: Transcription.Tokens | Transcription.Duration;\n}\n\nexport namespace Transcription {\n  export interface Logprob {\n    /**\n     * The token in the transcription.\n     */\n    token?: string;\n\n    /**\n     * The bytes of the token.\n     */\n    bytes?: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob?: number;\n  }\n\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface Tokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: Tokens.InputTokenDetails;\n  }\n\n  export namespace Tokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface Duration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\n/**\n * Represents a diarized transcription response returned by the model, including\n * the combined transcript and speaker-segment annotations.\n */\nexport interface TranscriptionDiarized {\n  /**\n   * Duration of the input audio in seconds.\n   */\n  duration: number;\n\n  /**\n   * Segments of the transcript annotated with timestamps and speaker labels.\n   */\n  segments: Array<TranscriptionDiarizedSegment>;\n\n  /**\n   * The type of task that was run. Always `transcribe`.\n   */\n  task: 'transcribe';\n\n  /**\n   * The concatenated transcript text for the entire audio input.\n   */\n  text: string;\n\n  /**\n   * Token or duration usage statistics for the request.\n   */\n  usage?: TranscriptionDiarized.Tokens | TranscriptionDiarized.Duration;\n}\n\nexport namespace TranscriptionDiarized {\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface Tokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: Tokens.InputTokenDetails;\n  }\n\n  export namespace Tokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface Duration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\n/**\n * A segment of diarized transcript text with speaker metadata.\n */\nexport interface TranscriptionDiarizedSegment {\n  /**\n   * Unique identifier for the segment.\n   */\n  id: string;\n\n  /**\n   * End timestamp of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Speaker label for this segment. When known speakers are provided, the label\n   * matches `known_speaker_names[]`. Otherwise speakers are labeled sequentially\n   * using capital letters (`A`, `B`, ...).\n   */\n  speaker: string;\n\n  /**\n   * Start timestamp of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Transcript text for this segment.\n   */\n  text: string;\n\n  /**\n   * The type of the segment. Always `transcript.text.segment`.\n   */\n  type: 'transcript.text.segment';\n}\n\nexport type TranscriptionInclude = 'logprobs';\n\nexport interface TranscriptionSegment {\n  /**\n   * Unique identifier of the segment.\n   */\n  id: number;\n\n  /**\n   * Average logprob of the segment. If the value is lower than -1, consider the\n   * logprobs failed.\n   */\n  avg_logprob: number;\n\n  /**\n   * Compression ratio of the segment. If the value is greater than 2.4, consider the\n   * compression failed.\n   */\n  compression_ratio: number;\n\n  /**\n   * End time of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Probability of no speech in the segment. If the value is higher than 1.0 and the\n   * `avg_logprob` is below -1, consider this segment silent.\n   */\n  no_speech_prob: number;\n\n  /**\n   * Seek offset of the segment.\n   */\n  seek: number;\n\n  /**\n   * Start time of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Temperature parameter used for generating the segment.\n   */\n  temperature: number;\n\n  /**\n   * Text content of the segment.\n   */\n  text: string;\n\n  /**\n   * Array of token IDs for the text content.\n   */\n  tokens: Array<number>;\n}\n\n/**\n * Emitted when a diarized transcription returns a completed segment with speaker\n * information. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with `stream` set to `true` and `response_format` set to `diarized_json`.\n */\nexport type TranscriptionStreamEvent =\n  | TranscriptionTextSegmentEvent\n  | TranscriptionTextDeltaEvent\n  | TranscriptionTextDoneEvent;\n\n/**\n * Emitted when there is an additional text delta. This is also the first event\n * emitted when the transcription starts. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with the `Stream` parameter set to `true`.\n */\nexport interface TranscriptionTextDeltaEvent {\n  /**\n   * The text delta that was additionally transcribed.\n   */\n  delta: string;\n\n  /**\n   * The type of the event. Always `transcript.text.delta`.\n   */\n  type: 'transcript.text.delta';\n\n  /**\n   * The log probabilities of the delta. Only included if you\n   * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n   * with the `include[]` parameter set to `logprobs`.\n   */\n  logprobs?: Array<TranscriptionTextDeltaEvent.Logprob>;\n\n  /**\n   * Identifier of the diarized segment that this delta belongs to. Only present when\n   * using `gpt-4o-transcribe-diarize`.\n   */\n  segment_id?: string;\n}\n\nexport namespace TranscriptionTextDeltaEvent {\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token?: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes?: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob?: number;\n  }\n}\n\n/**\n * Emitted when the transcription is complete. Contains the complete transcription\n * text. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with the `Stream` parameter set to `true`.\n */\nexport interface TranscriptionTextDoneEvent {\n  /**\n   * The text that was transcribed.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `transcript.text.done`.\n   */\n  type: 'transcript.text.done';\n\n  /**\n   * The log probabilities of the individual tokens in the transcription. Only\n   * included if you\n   * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n   * with the `include[]` parameter set to `logprobs`.\n   */\n  logprobs?: Array<TranscriptionTextDoneEvent.Logprob>;\n\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  usage?: TranscriptionTextDoneEvent.Usage;\n}\n\nexport namespace TranscriptionTextDoneEvent {\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token?: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes?: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob?: number;\n  }\n\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface Usage {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: Usage.InputTokenDetails;\n  }\n\n  export namespace Usage {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n}\n\n/**\n * Emitted when a diarized transcription returns a completed segment with speaker\n * information. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with `stream` set to `true` and `response_format` set to `diarized_json`.\n */\nexport interface TranscriptionTextSegmentEvent {\n  /**\n   * Unique identifier for the segment.\n   */\n  id: string;\n\n  /**\n   * End timestamp of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Speaker label for this segment.\n   */\n  speaker: string;\n\n  /**\n   * Start timestamp of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Transcript text for this segment.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `transcript.text.segment`.\n   */\n  type: 'transcript.text.segment';\n}\n\n/**\n * Represents a verbose json transcription response returned by model, based on the\n * provided input.\n */\nexport interface TranscriptionVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: number;\n\n  /**\n   * The language of the input audio.\n   */\n  language: string;\n\n  /**\n   * The transcribed text.\n   */\n  text: string;\n\n  /**\n   * Segments of the transcribed text and their corresponding details.\n   */\n  segments?: Array<TranscriptionSegment>;\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  usage?: TranscriptionVerbose.Usage;\n\n  /**\n   * Extracted words and their corresponding timestamps.\n   */\n  words?: Array<TranscriptionWord>;\n}\n\nexport namespace TranscriptionVerbose {\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface Usage {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\nexport interface TranscriptionWord {\n  /**\n   * End time of the word in seconds.\n   */\n  end: number;\n\n  /**\n   * Start time of the word in seconds.\n   */\n  start: number;\n\n  /**\n   * The text content of the word.\n   */\n  word: string;\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport type TranscriptionCreateResponse = Transcription | TranscriptionDiarized | TranscriptionVerbose;\n\nexport type TranscriptionCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> = TranscriptionCreateParamsNonStreaming<ResponseFormat> | TranscriptionCreateParamsStreaming;\n\nexport interface TranscriptionCreateParamsBase<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. The options are `gpt-4o-transcribe`,\n   * `gpt-4o-mini-transcribe`, `gpt-4o-mini-transcribe-2025-12-15`, `whisper-1`\n   * (which is powered by our open source Whisper V2 model), and\n   * `gpt-4o-transcribe-diarize`.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * Controls how the audio is cut into chunks. When set to `\"auto\"`, the server\n   * first normalizes loudness and then uses voice activity detection (VAD) to choose\n   * boundaries. `server_vad` object can be provided to tweak VAD detection\n   * parameters manually. If unset, the audio is transcribed as a single block.\n   * Required when using `gpt-4o-transcribe-diarize` for inputs longer than 30\n   * seconds.\n   */\n  chunking_strategy?: 'auto' | TranscriptionCreateParams.VadConfig | null;\n\n  /**\n   * Additional information to include in the transcription response. `logprobs` will\n   * return the log probabilities of the tokens in the response to understand the\n   * model's confidence in the transcription. `logprobs` only works with\n   * response_format set to `json` and only with the models `gpt-4o-transcribe`,\n   * `gpt-4o-mini-transcribe`, and `gpt-4o-mini-transcribe-2025-12-15`. This field is\n   * not supported when using `gpt-4o-transcribe-diarize`.\n   */\n  include?: Array<TranscriptionInclude>;\n\n  /**\n   * Optional list of speaker names that correspond to the audio samples provided in\n   * `known_speaker_references[]`. Each entry should be a short identifier (for\n   * example `customer` or `agent`). Up to 4 speakers are supported.\n   */\n  known_speaker_names?: Array<string>;\n\n  /**\n   * Optional list of audio samples (as\n   * [data URLs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs))\n   * that contain known speaker references matching `known_speaker_names[]`. Each\n   * sample must be between 2 and 10 seconds, and can use any of the same input audio\n   * formats supported by `file`.\n   */\n  known_speaker_references?: Array<string>;\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n   * format will improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should match the audio language. This field is not supported when using\n   * `gpt-4o-transcribe-diarize`.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, `vtt`, or `diarized_json`. For `gpt-4o-transcribe` and\n   * `gpt-4o-mini-transcribe`, the only supported format is `json`. For\n   * `gpt-4o-transcribe-diarize`, the supported formats are `json`, `text`, and\n   * `diarized_json`, with `diarized_json` required to receive speaker annotations.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section of the Speech-to-Text guide](https://platform.openai.com/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n   * for more information.\n   *\n   * Note: Streaming is not supported for the `whisper-1` model and will be ignored.\n   */\n  stream?: boolean | null;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * `response_format` must be set `verbose_json` to use timestamp granularities.\n   * Either or both of these options are supported: `word`, or `segment`. Note: There\n   * is no additional latency for segment timestamps, but generating word timestamps\n   * incurs additional latency. This option is not available for\n   * `gpt-4o-transcribe-diarize`.\n   */\n  timestamp_granularities?: Array<'word' | 'segment'>;\n}\n\nexport namespace TranscriptionCreateParams {\n  export interface VadConfig {\n    /**\n     * Must be set to `server_vad` to enable manual chunking using server side VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). With shorter values\n     * the model will respond more quickly, but may jump in on short pauses from the\n     * user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Sensitivity threshold (0.0 to 1.0) for voice activity detection. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  export type TranscriptionCreateParamsNonStreaming = TranscriptionsAPI.TranscriptionCreateParamsNonStreaming;\n  export type TranscriptionCreateParamsStreaming = TranscriptionsAPI.TranscriptionCreateParamsStreaming;\n}\n\nexport interface TranscriptionCreateParamsNonStreaming<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> extends TranscriptionCreateParamsBase<ResponseFormat> {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section of the Speech-to-Text guide](https://platform.openai.com/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n   * for more information.\n   *\n   * Note: Streaming is not supported for the `whisper-1` model and will be ignored.\n   */\n  stream?: false | null;\n}\n\nexport interface TranscriptionCreateParamsStreaming extends TranscriptionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section of the Speech-to-Text guide](https://platform.openai.com/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n   * for more information.\n   *\n   * Note: Streaming is not supported for the `whisper-1` model and will be ignored.\n   */\n  stream: true;\n}\n\nexport declare namespace Transcriptions {\n  export {\n    type Transcription as Transcription,\n    type TranscriptionDiarized as TranscriptionDiarized,\n    type TranscriptionDiarizedSegment as TranscriptionDiarizedSegment,\n    type TranscriptionInclude as TranscriptionInclude,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionStreamEvent as TranscriptionStreamEvent,\n    type TranscriptionTextDeltaEvent as TranscriptionTextDeltaEvent,\n    type TranscriptionTextDoneEvent as TranscriptionTextDoneEvent,\n    type TranscriptionTextSegmentEvent as TranscriptionTextSegmentEvent,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n    type TranscriptionCreateParamsNonStreaming as TranscriptionCreateParamsNonStreaming,\n    type TranscriptionCreateParamsStreaming as TranscriptionCreateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as AudioAPI from './audio';\nimport * as TranscriptionsAPI from './transcriptions';\nimport { APIPromise } from '../../core/api-promise';\nimport { type Uploadable } from '../../core/uploads';\nimport { RequestOptions } from '../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../internal/uploads';\n\nexport class Translations extends APIResource {\n  /**\n   * Translates audio into English.\n   *\n   * @example\n   * ```ts\n   * const translation = await client.audio.translations.create({\n   *   file: fs.createReadStream('speech.mp3'),\n   *   model: 'whisper-1',\n   * });\n   * ```\n   */\n  create(\n    body: TranslationCreateParams<'json' | undefined>,\n    options?: RequestOptions,\n  ): APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams<'verbose_json'>,\n    options?: RequestOptions,\n  ): APIPromise<TranslationVerbose>;\n  create(body: TranslationCreateParams<'text' | 'srt' | 'vtt'>, options?: RequestOptions): APIPromise<string>;\n  create(body: TranslationCreateParams, options?: RequestOptions): APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<TranslationCreateResponse | string> {\n    return this._client.post(\n      '/audio/translations',\n      multipartFormRequestOptions({ body, ...options, __metadata: { model: body.model } }, this._client),\n    );\n  }\n}\n\nexport interface Translation {\n  text: string;\n}\n\nexport interface TranslationVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: number;\n\n  /**\n   * The language of the output translation (always `english`).\n   */\n  language: string;\n\n  /**\n   * The translated text.\n   */\n  text: string;\n\n  /**\n   * Segments of the translated text and their corresponding details.\n   */\n  segments?: Array<TranscriptionsAPI.TranscriptionSegment>;\n}\n\nexport type TranslationCreateResponse = Translation | TranslationVerbose;\n\nexport interface TranslationCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) translate, in one of these formats: flac,\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should be in English.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport declare namespace Translations {\n  export {\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { castToError } from '../internal/errors';\n\nexport class OpenAIError extends Error {}\n\nexport class APIError<\n  TStatus extends number | undefined = number | undefined,\n  THeaders extends Headers | undefined = Headers | undefined,\n  TError extends Object | undefined = Object | undefined,\n> extends OpenAIError {\n  /** HTTP status for the response that caused the error */\n  readonly status: TStatus;\n  /** HTTP headers for the response that caused the error */\n  readonly headers: THeaders;\n  /** JSON body of the response that caused the error */\n  readonly error: TError;\n\n  readonly code: string | null | undefined;\n  readonly param: string | null | undefined;\n  readonly type: string | undefined;\n\n  readonly requestID: string | null | undefined;\n\n  constructor(status: TStatus, error: TError, message: string | undefined, headers: THeaders) {\n    super(`${APIError.makeMessage(status, error, message)}`);\n    this.status = status;\n    this.headers = headers;\n    this.requestID = headers?.get('x-request-id');\n    this.error = error;\n\n    const data = error as Record<string, any>;\n    this.code = data?.['code'];\n    this.param = data?.['param'];\n    this.type = data?.['type'];\n  }\n\n  private static makeMessage(status: number | undefined, error: any, message: string | undefined) {\n    const msg =\n      error?.message ?\n        typeof error.message === 'string' ?\n          error.message\n        : JSON.stringify(error.message)\n      : error ? JSON.stringify(error)\n      : message;\n\n    if (status && msg) {\n      return `${status} ${msg}`;\n    }\n    if (status) {\n      return `${status} status code (no body)`;\n    }\n    if (msg) {\n      return msg;\n    }\n    return '(no status code or body)';\n  }\n\n  static generate(\n    status: number | undefined,\n    errorResponse: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ): APIError {\n    if (!status || !headers) {\n      return new APIConnectionError({ message, cause: castToError(errorResponse) });\n    }\n\n    const error = (errorResponse as Record<string, any>)?.['error'];\n\n    if (status === 400) {\n      return new BadRequestError(status, error, message, headers);\n    }\n\n    if (status === 401) {\n      return new AuthenticationError(status, error, message, headers);\n    }\n\n    if (status === 403) {\n      return new PermissionDeniedError(status, error, message, headers);\n    }\n\n    if (status === 404) {\n      return new NotFoundError(status, error, message, headers);\n    }\n\n    if (status === 409) {\n      return new ConflictError(status, error, message, headers);\n    }\n\n    if (status === 422) {\n      return new UnprocessableEntityError(status, error, message, headers);\n    }\n\n    if (status === 429) {\n      return new RateLimitError(status, error, message, headers);\n    }\n\n    if (status >= 500) {\n      return new InternalServerError(status, error, message, headers);\n    }\n\n    return new APIError(status, error, message, headers);\n  }\n}\n\nexport class APIUserAbortError extends APIError<undefined, undefined, undefined> {\n  constructor({ message }: { message?: string } = {}) {\n    super(undefined, undefined, message || 'Request was aborted.', undefined);\n  }\n}\n\nexport class APIConnectionError extends APIError<undefined, undefined, undefined> {\n  constructor({ message, cause }: { message?: string | undefined; cause?: Error | undefined }) {\n    super(undefined, undefined, message || 'Connection error.', undefined);\n    // in some environments the 'cause' property is already declared\n    // @ts-ignore\n    if (cause) this.cause = cause;\n  }\n}\n\nexport class APIConnectionTimeoutError extends APIConnectionError {\n  constructor({ message }: { message?: string } = {}) {\n    super({ message: message ?? 'Request timed out.' });\n  }\n}\n\nexport class BadRequestError extends APIError<400, Headers> {}\n\nexport class AuthenticationError extends APIError<401, Headers> {}\n\nexport class PermissionDeniedError extends APIError<403, Headers> {}\n\nexport class NotFoundError extends APIError<404, Headers> {}\n\nexport class ConflictError extends APIError<409, Headers> {}\n\nexport class UnprocessableEntityError extends APIError<422, Headers> {}\n\nexport class RateLimitError extends APIError<429, Headers> {}\n\nexport class InternalServerError extends APIError<number, Headers> {}\n\nexport class LengthFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the length limit was reached`);\n  }\n}\n\nexport class ContentFilterFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the request was rejected by the content filter`);\n  }\n}\n\nexport class InvalidWebhookSignatureError extends Error {\n  constructor(message: string) {\n    super(message);\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport { OpenAI as default } from './client';\n\nexport { type Uploadable, toFile } from './core/uploads';\nexport { APIPromise } from './core/api-promise';\nexport { OpenAI, type ClientOptions } from './client';\nexport { PagePromise } from './core/pagination';\nexport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n  NotFoundError,\n  ConflictError,\n  RateLimitError,\n  BadRequestError,\n  AuthenticationError,\n  InternalServerError,\n  PermissionDeniedError,\n  UnprocessableEntityError,\n  InvalidWebhookSignatureError,\n} from './core/error';\n\nexport { AzureOpenAI } from './azure';\n","import type {\n  AppRouteRouteHandlerContext,\n  AppRouteRouteModule,\n} from '../route-modules/app-route/module'\n\nimport './globals'\n\nimport { adapter, type NextRequestHint, type EdgeHandler } from './adapter'\nimport { IncrementalCache } from '../lib/incremental-cache'\nimport { RouteMatcher } from '../route-matchers/route-matcher'\nimport type { NextFetchEvent } from './spec-extension/fetch-event'\nimport { internal_getCurrentFunctionWaitUntil } from './internal-edge-wait-until'\nimport { getServerUtils } from '../server-utils'\nimport { searchParamsToUrlQuery } from '../../shared/lib/router/utils/querystring'\nimport { CloseController, trackStreamConsumed } from './web-on-close'\nimport { getEdgePreviewProps } from './get-edge-preview-props'\nimport { WebNextRequest } from '../../server/base-http/web'\n\nexport interface WrapOptions {\n  page: string\n}\n\n/**\n * EdgeRouteModuleWrapper is a wrapper around a route module.\n *\n * Note that this class should only be used in the edge runtime.\n */\nexport class EdgeRouteModuleWrapper {\n  private readonly matcher: RouteMatcher\n\n  /**\n   * The constructor is wrapped with private to ensure that it can only be\n   * constructed by the static wrap method.\n   *\n   * @param routeModule the route module to wrap\n   */\n  private constructor(private readonly routeModule: AppRouteRouteModule) {\n    // TODO: (wyattjoh) possibly allow the module to define it's own matcher\n    this.matcher = new RouteMatcher(routeModule.definition)\n  }\n\n  /**\n   * This will wrap a module with the EdgeModuleWrapper and return a function\n   * that can be used as a handler for the edge runtime.\n   *\n   * @param module the module to wrap\n   * @param options any options that should be passed to the adapter and\n   *                override the ones passed from the runtime\n   * @returns a function that can be used as a handler for the edge runtime\n   */\n  public static wrap(\n    routeModule: AppRouteRouteModule,\n    options: WrapOptions\n  ): EdgeHandler {\n    // Create the module wrapper.\n    const wrapper = new EdgeRouteModuleWrapper(routeModule)\n\n    // Return the wrapping function.\n    return (opts) => {\n      return adapter({\n        ...opts,\n        IncrementalCache,\n        // Bind the handler method to the wrapper so it still has context.\n        handler: wrapper.handler.bind(wrapper),\n        page: options.page,\n      })\n    }\n  }\n\n  private async handler(\n    request: NextRequestHint,\n    evt: NextFetchEvent\n  ): Promise<Response> {\n    const utils = getServerUtils({\n      pageIsDynamic: this.matcher.isDynamic,\n      page: this.matcher.definition.pathname,\n      basePath: request.nextUrl.basePath,\n      // We don't need the `handleRewrite` util, so can just pass an empty object\n      rewrites: {},\n      // only used for rewrites, so setting an arbitrary default value here\n      caseSensitive: false,\n    })\n\n    const { nextConfig } = this.routeModule.getNextConfigEdge(\n      new WebNextRequest(request)\n    )\n\n    const { params } = utils.normalizeDynamicRouteParams(\n      searchParamsToUrlQuery(request.nextUrl.searchParams),\n      false\n    )\n\n    const waitUntil = evt.waitUntil.bind(evt)\n    const closeController = new CloseController()\n\n    const previewProps = getEdgePreviewProps()\n\n    // Create the context for the handler. This contains the params from the\n    // match (if any).\n    const context: AppRouteRouteHandlerContext = {\n      params,\n      prerenderManifest: {\n        version: 4,\n        routes: {},\n        dynamicRoutes: {},\n        preview: previewProps,\n        notFoundRoutes: [],\n      },\n      renderOpts: {\n        supportsDynamicResponse: true,\n        waitUntil,\n        onClose: closeController.onClose.bind(closeController),\n        onAfterTaskError: undefined,\n        cacheComponents: !!process.env.__NEXT_CACHE_COMPONENTS,\n        experimental: {\n          authInterrupts: !!process.env.__NEXT_EXPERIMENTAL_AUTH_INTERRUPTS,\n        },\n        cacheLifeProfiles: nextConfig.cacheLife,\n      },\n      sharedContext: {\n        buildId: '', // TODO: Populate this properly.\n      },\n    }\n\n    // Get the response from the handler.\n    let res = await this.routeModule.handle(request, context)\n\n    const waitUntilPromises = [internal_getCurrentFunctionWaitUntil()]\n    if (context.renderOpts.pendingWaitUntil) {\n      waitUntilPromises.push(context.renderOpts.pendingWaitUntil)\n    }\n    evt.waitUntil(Promise.all(waitUntilPromises))\n\n    if (!res.body) {\n      // we can delay running it until a bit later --\n      // if it's needed, we'll have a `waitUntil` lock anyway.\n      setTimeout(() => closeController.dispatchClose(), 0)\n    } else {\n      // NOTE: if this is a streaming response, onClose may be called later,\n      // so we can't rely on `closeController.listeners` -- it might be 0 at this point.\n      const trackedBody = trackStreamConsumed(res.body, () =>\n        closeController.dispatchClose()\n      )\n      res = new Response(trackedBody, {\n        status: res.status,\n        statusText: res.statusText,\n        headers: res.headers,\n      })\n    }\n\n    return res\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { OpenAIError } from '../../core/error';\nimport { encodeUTF8 } from './bytes';\n\nexport const toBase64 = (data: string | Uint8Array | null | undefined): string => {\n  if (!data) return '';\n\n  if (typeof (globalThis as any).Buffer !== 'undefined') {\n    return (globalThis as any).Buffer.from(data).toString('base64');\n  }\n\n  if (typeof data === 'string') {\n    data = encodeUTF8(data);\n  }\n\n  if (typeof btoa !== 'undefined') {\n    return btoa(String.fromCharCode.apply(null, data as any));\n  }\n\n  throw new OpenAIError('Cannot generate base64 string; Expected `Buffer` or `btoa` to be defined');\n};\n\nexport const fromBase64 = (str: string): Uint8Array => {\n  if (typeof (globalThis as any).Buffer !== 'undefined') {\n    const buf = (globalThis as any).Buffer.from(str, 'base64');\n    return new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength);\n  }\n\n  if (typeof atob !== 'undefined') {\n    const bstr = atob(str);\n    const buf = new Uint8Array(bstr.length);\n    for (let i = 0; i < bstr.length; i++) {\n      buf[i] = bstr.charCodeAt(i);\n    }\n    return buf;\n  }\n\n  throw new OpenAIError('Cannot decode base64 string; Expected `Buffer` or `atob` to be defined');\n};\n\n/**\n * Converts a Base64 encoded string to a Float32Array.\n * @param base64Str - The Base64 encoded string.\n * @returns An Array of numbers interpreted as Float32 values.\n */\nexport const toFloat32Array = (base64Str: string): Array<number> => {\n  if (typeof Buffer !== 'undefined') {\n    // for Node.js environment\n    const buf = Buffer.from(base64Str, 'base64');\n    return Array.from(\n      new Float32Array(buf.buffer, buf.byteOffset, buf.length / Float32Array.BYTES_PER_ELEMENT),\n    );\n  } else {\n    // for legacy web platform APIs\n    const binaryStr = atob(base64Str);\n    const len = binaryStr.length;\n    const bytes = new Uint8Array(len);\n    for (let i = 0; i < len; i++) {\n      bytes[i] = binaryStr.charCodeAt(i);\n    }\n    return Array.from(new Float32Array(bytes.buffer));\n  }\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as GradersAPI from './graders';\nimport {\n  GraderRunParams,\n  GraderRunResponse,\n  GraderValidateParams,\n  GraderValidateResponse,\n  Graders,\n} from './graders';\n\nexport class Alpha extends APIResource {\n  graders: GradersAPI.Graders = new GradersAPI.Graders(this._client);\n}\n\nAlpha.Graders = Graders;\n\nexport declare namespace Alpha {\n  export {\n    Graders as Graders,\n    type GraderRunResponse as GraderRunResponse,\n    type GraderValidateResponse as GraderValidateResponse,\n    type GraderRunParams as GraderRunParams,\n    type GraderValidateParams as GraderValidateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as GraderModelsAPI from './grader-models';\nimport {\n  GraderInputs,\n  GraderModels,\n  LabelModelGrader,\n  MultiGrader,\n  PythonGrader,\n  ScoreModelGrader,\n  StringCheckGrader,\n  TextSimilarityGrader,\n} from './grader-models';\n\nexport class Graders extends APIResource {\n  graderModels: GraderModelsAPI.GraderModels = new GraderModelsAPI.GraderModels(this._client);\n}\n\nGraders.GraderModels = GraderModels;\n\nexport declare namespace Graders {\n  export {\n    GraderModels as GraderModels,\n    type GraderInputs as GraderInputs,\n    type LabelModelGrader as LabelModelGrader,\n    type MultiGrader as MultiGrader,\n    type PythonGrader as PythonGrader,\n    type ScoreModelGrader as ScoreModelGrader,\n    type StringCheckGrader as StringCheckGrader,\n    type TextSimilarityGrader as TextSimilarityGrader,\n  };\n}\n","import {\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParamsNonStreaming,\n} from '../resources/chat/completions';\nimport { type BaseFunctionsArgs, RunnableTools } from './RunnableFunction';\nimport {\n  AbstractChatCompletionRunner,\n  AbstractChatCompletionRunnerEvents,\n  RunnerOptions,\n} from './AbstractChatCompletionRunner';\nimport { isAssistantMessage } from './chatCompletionUtils';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionRunnerEvents extends AbstractChatCompletionRunnerEvents {\n  content: (content: string) => void;\n}\n\nexport type ChatCompletionToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionRunner<ParsedT = null> extends AbstractChatCompletionRunner<\n  ChatCompletionRunnerEvents,\n  ParsedT\n> {\n  static runTools<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionToolRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> {\n    const runner = new ChatCompletionRunner<ParsedT>();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n\n  override _addMessage(\n    this: ChatCompletionRunner<ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit: boolean = true,\n  ) {\n    super._addMessage(message, emit);\n    if (isAssistantMessage(message) && message.content) {\n      this._emit('content', message.content as string);\n    }\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport function isAbortError(err: unknown) {\n  return (\n    typeof err === 'object' &&\n    err !== null &&\n    // Spec-compliant fetch implementations\n    (('name' in err && (err as any).name === 'AbortError') ||\n      // Expo fetch\n      ('message' in err && String((err as any).message).includes('FetchRequestCanceledException')))\n  );\n}\n\nexport const castToError = (err: any): Error => {\n  if (err instanceof Error) return err;\n  if (typeof err === 'object' && err !== null) {\n    try {\n      if (Object.prototype.toString.call(err) === '[object Error]') {\n        // @ts-ignore - not all envs have native support for cause yet\n        const error = new Error(err.message, err.cause ? { cause: err.cause } : {});\n        if (err.stack) error.stack = err.stack;\n        // @ts-ignore - not all envs have native support for cause yet\n        if (err.cause && !error.cause) error.cause = err.cause;\n        if (err.name) error.name = err.name;\n        return error;\n      }\n    } catch {}\n    try {\n      return new Error(JSON.stringify(err));\n    } catch {}\n  }\n  return new Error(err);\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { OpenAIError } from './error';\nimport { FinalRequestOptions } from '../internal/request-options';\nimport { defaultParseResponse, WithRequestID } from '../internal/parse';\nimport { APIPromise } from './api-promise';\nimport { type OpenAI } from '../client';\nimport { type APIResponseProps } from '../internal/parse';\nimport { maybeObj } from '../internal/utils/values';\n\nexport type PageRequestOptions = Pick<FinalRequestOptions, 'query' | 'headers' | 'body' | 'path' | 'method'>;\n\nexport abstract class AbstractPage<Item> implements AsyncIterable<Item> {\n  #client: OpenAI;\n  protected options: FinalRequestOptions;\n\n  protected response: Response;\n  protected body: unknown;\n\n  constructor(client: OpenAI, response: Response, body: unknown, options: FinalRequestOptions) {\n    this.#client = client;\n    this.options = options;\n    this.response = response;\n    this.body = body;\n  }\n\n  abstract nextPageRequestOptions(): PageRequestOptions | null;\n\n  abstract getPaginatedItems(): Item[];\n\n  hasNextPage(): boolean {\n    const items = this.getPaginatedItems();\n    if (!items.length) return false;\n    return this.nextPageRequestOptions() != null;\n  }\n\n  async getNextPage(): Promise<this> {\n    const nextOptions = this.nextPageRequestOptions();\n    if (!nextOptions) {\n      throw new OpenAIError(\n        'No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.',\n      );\n    }\n\n    return await this.#client.requestAPIList(this.constructor as any, nextOptions);\n  }\n\n  async *iterPages(): AsyncGenerator<this> {\n    let page: this = this;\n    yield page;\n    while (page.hasNextPage()) {\n      page = await page.getNextPage();\n      yield page;\n    }\n  }\n\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    for await (const page of this.iterPages()) {\n      for (const item of page.getPaginatedItems()) {\n        yield item;\n      }\n    }\n  }\n}\n\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nexport class PagePromise<\n    PageClass extends AbstractPage<Item>,\n    Item = ReturnType<PageClass['getPaginatedItems']>[number],\n  >\n  extends APIPromise<PageClass>\n  implements AsyncIterable<Item>\n{\n  constructor(\n    client: OpenAI,\n    request: Promise<APIResponseProps>,\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n  ) {\n    super(\n      client,\n      request,\n      async (client, props) =>\n        new Page(\n          client,\n          props.response,\n          await defaultParseResponse(client, props),\n          props.options,\n        ) as WithRequestID<PageClass>,\n    );\n  }\n\n  /**\n   * Allow auto-paginating iteration on an unawaited list call, eg:\n   *\n   *    for await (const item of client.items.list()) {\n   *      console.log(item)\n   *    }\n   */\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    const page = await this;\n    for await (const item of page) {\n      yield item;\n    }\n  }\n}\n\nexport interface PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class Page<Item> extends AbstractPage<Item> implements PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n\n  constructor(client: OpenAI, response: Response, body: PageResponse<Item>, options: FinalRequestOptions) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.object = body.object;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  nextPageRequestOptions(): PageRequestOptions | null {\n    return null;\n  }\n}\n\nexport interface CursorPageResponse<Item> {\n  data: Array<Item>;\n\n  has_more: boolean;\n}\n\nexport interface CursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class CursorPage<Item extends { id: string }>\n  extends AbstractPage<Item>\n  implements CursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  has_more: boolean;\n\n  constructor(\n    client: OpenAI,\n    response: Response,\n    body: CursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.has_more = body.has_more || false;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  override hasNextPage(): boolean {\n    if (this.has_more === false) {\n      return false;\n    }\n\n    return super.hasNextPage();\n  }\n\n  nextPageRequestOptions(): PageRequestOptions | null {\n    const data = this.getPaginatedItems();\n    const id = data[data.length - 1]?.id;\n    if (!id) {\n      return null;\n    }\n\n    return {\n      ...this.options,\n      query: {\n        ...maybeObj(this.options.query),\n        after: id,\n      },\n    };\n  }\n}\n\nexport interface ConversationCursorPageResponse<Item> {\n  data: Array<Item>;\n\n  has_more: boolean;\n\n  last_id: string;\n}\n\nexport interface ConversationCursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class ConversationCursorPage<Item>\n  extends AbstractPage<Item>\n  implements ConversationCursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  has_more: boolean;\n\n  last_id: string;\n\n  constructor(\n    client: OpenAI,\n    response: Response,\n    body: ConversationCursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.has_more = body.has_more || false;\n    this.last_id = body.last_id || '';\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  override hasNextPage(): boolean {\n    if (this.has_more === false) {\n      return false;\n    }\n\n    return super.hasNextPage();\n  }\n\n  nextPageRequestOptions(): PageRequestOptions | null {\n    const cursor = this.last_id;\n    if (!cursor) {\n      return null;\n    }\n\n    return {\n      ...this.options,\n      query: {\n        ...maybeObj(this.options.query),\n        after: cursor,\n      },\n    };\n  }\n}\n","import { OpenAIError } from '../error';\nimport type OpenAI from '../index';\nimport type { RequestOptions } from '../internal/request-options';\nimport { isAutoParsableTool, parseChatCompletion } from '../lib/parser';\nimport type {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionMessageParam,\n  ChatCompletionTool,\n  ParsedChatCompletion,\n} from '../resources/chat/completions';\nimport type { CompletionUsage } from '../resources/completions';\nimport type { ChatCompletionToolRunnerParams } from './ChatCompletionRunner';\nimport type { ChatCompletionStreamingToolRunnerParams } from './ChatCompletionStreamingRunner';\nimport { isAssistantMessage, isToolMessage } from './chatCompletionUtils';\nimport { BaseEvents, EventStream } from './EventStream';\nimport {\n  isRunnableFunctionWithParse,\n  type BaseFunctionsArgs,\n  type RunnableFunction,\n  type RunnableToolFunction,\n} from './RunnableFunction';\n\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\nexport interface RunnerOptions extends RequestOptions {\n  /** How many requests to make before canceling. Default 10. */\n  maxChatCompletions?: number;\n}\n\nexport class AbstractChatCompletionRunner<\n  EventTypes extends AbstractChatCompletionRunnerEvents,\n  ParsedT,\n> extends EventStream<EventTypes> {\n  protected _chatCompletions: ParsedChatCompletion<ParsedT>[] = [];\n  messages: ChatCompletionMessageParam[] = [];\n\n  protected _addChatCompletion(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    chatCompletion: ParsedChatCompletion<ParsedT>,\n  ): ParsedChatCompletion<ParsedT> {\n    this._chatCompletions.push(chatCompletion);\n    this._emit('chatCompletion', chatCompletion);\n    const message = chatCompletion.choices[0]?.message;\n    if (message) this._addMessage(message as ChatCompletionMessageParam);\n    return chatCompletion;\n  }\n\n  protected _addMessage(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit = true,\n  ) {\n    if (!('content' in message)) message.content = null;\n\n    this.messages.push(message);\n\n    if (emit) {\n      this._emit('message', message);\n      if (isToolMessage(message) && message.content) {\n        // Note, this assumes that {role: 'tool', content: } is always the result of a call of tool of type=function.\n        this._emit('functionToolCallResult', message.content as string);\n      } else if (isAssistantMessage(message) && message.tool_calls) {\n        for (const tool_call of message.tool_calls) {\n          if (tool_call.type === 'function') {\n            this._emit('functionToolCall', tool_call.function);\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * @returns a promise that resolves with the final ChatCompletion, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\n   */\n  async finalChatCompletion(): Promise<ParsedChatCompletion<ParsedT>> {\n    await this.done();\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (!completion) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return completion;\n  }\n\n  #getFinalContent(): string | null {\n    return this.#getFinalMessage().content ?? null;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalContent(): Promise<string | null> {\n    await this.done();\n    return this.#getFinalContent();\n  }\n\n  #getFinalMessage(): ChatCompletionMessage {\n    let i = this.messages.length;\n    while (i-- > 0) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message)) {\n        // TODO: support audio here\n        const ret: Omit<ChatCompletionMessage, 'audio'> = {\n          ...message,\n          content: (message as ChatCompletionMessage).content ?? null,\n          refusal: (message as ChatCompletionMessage).refusal ?? null,\n        };\n        return ret;\n      }\n    }\n    throw new OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\n  }\n\n  /**\n   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\n   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalMessage(): Promise<ChatCompletionMessage> {\n    await this.done();\n    return this.#getFinalMessage();\n  }\n\n  #getFinalFunctionToolCall(): ChatCompletionMessageFunctionToolCall.Function | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message) && message?.tool_calls?.length) {\n        return message.tool_calls.filter((x) => x.type === 'function').at(-1)?.function;\n      }\n    }\n\n    return;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final FunctionCall, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalFunctionToolCall(): Promise<ChatCompletionMessageFunctionToolCall.Function | undefined> {\n    await this.done();\n    return this.#getFinalFunctionToolCall();\n  }\n\n  #getFinalFunctionToolCallResult(): string | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (\n        isToolMessage(message) &&\n        message.content != null &&\n        typeof message.content === 'string' &&\n        this.messages.some(\n          (x) =>\n            x.role === 'assistant' &&\n            x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id),\n        )\n      ) {\n        return message.content;\n      }\n    }\n\n    return;\n  }\n\n  async finalFunctionToolCallResult(): Promise<string | undefined> {\n    await this.done();\n    return this.#getFinalFunctionToolCallResult();\n  }\n\n  #calculateTotalUsage(): CompletionUsage {\n    const total: CompletionUsage = {\n      completion_tokens: 0,\n      prompt_tokens: 0,\n      total_tokens: 0,\n    };\n    for (const { usage } of this._chatCompletions) {\n      if (usage) {\n        total.completion_tokens += usage.completion_tokens;\n        total.prompt_tokens += usage.prompt_tokens;\n        total.total_tokens += usage.total_tokens;\n      }\n    }\n    return total;\n  }\n\n  async totalUsage(): Promise<CompletionUsage> {\n    await this.done();\n    return this.#calculateTotalUsage();\n  }\n\n  allChatCompletions(): ChatCompletion[] {\n    return [...this._chatCompletions];\n  }\n\n  protected override _emitFinal(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n  ) {\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (completion) this._emit('finalChatCompletion', completion);\n    const finalMessage = this.#getFinalMessage();\n    if (finalMessage) this._emit('finalMessage', finalMessage);\n    const finalContent = this.#getFinalContent();\n    if (finalContent) this._emit('finalContent', finalContent);\n\n    const finalFunctionCall = this.#getFinalFunctionToolCall();\n    if (finalFunctionCall) this._emit('finalFunctionToolCall', finalFunctionCall);\n\n    const finalFunctionCallResult = this.#getFinalFunctionToolCallResult();\n    if (finalFunctionCallResult != null) this._emit('finalFunctionToolCallResult', finalFunctionCallResult);\n\n    if (this._chatCompletions.some((c) => c.usage)) {\n      this._emit('totalUsage', this.#calculateTotalUsage());\n    }\n  }\n\n  #validateParams(params: ChatCompletionCreateParams): void {\n    if (params.n != null && params.n > 1) {\n      throw new OpenAIError(\n        'ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.',\n      );\n    }\n  }\n\n  protected async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#validateParams(params);\n\n    const chatCompletion = await client.chat.completions.create(\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addChatCompletion(parseChatCompletion(chatCompletion, params));\n  }\n\n  protected async _runChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): Promise<ChatCompletion> {\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n    return await this._createChatCompletion(client, params, options);\n  }\n\n  protected async _runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'tool' as const;\n    const { tool_choice = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall =\n      typeof tool_choice !== 'string' && tool_choice.type === 'function' && tool_choice?.function?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    // TODO(someday): clean this logic up\n    const inputTools = params.tools.map((tool): RunnableToolFunction<any> => {\n      if (isAutoParsableTool(tool)) {\n        if (!tool.$callback) {\n          throw new OpenAIError('Tool given to `.runTools()` that does not have an associated function');\n        }\n\n        return {\n          type: 'function',\n          function: {\n            function: tool.$callback,\n            name: tool.function.name,\n            description: tool.function.description || '',\n            parameters: tool.function.parameters as any,\n            parse: tool.$parseRaw,\n            strict: true,\n          },\n        };\n      }\n\n      return tool as any as RunnableToolFunction<any>;\n    });\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of inputTools) {\n      if (f.type === 'function') {\n        functionsByName[f.function.name || f.function.function.name] = f.function;\n      }\n    }\n\n    const tools: ChatCompletionTool[] =\n      'tools' in params ?\n        inputTools.map((t) =>\n          t.type === 'function' ?\n            {\n              type: 'function',\n              function: {\n                name: t.function.name || t.function.function.name,\n                parameters: t.function.parameters as Record<string, unknown>,\n                description: t.function.description,\n                strict: t.function.strict,\n              },\n            }\n          : (t as unknown as ChatCompletionTool),\n        )\n      : (undefined as any);\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          tool_choice,\n          tools,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.tool_calls?.length) {\n        return;\n      }\n\n      for (const tool_call of message.tool_calls) {\n        if (tool_call.type !== 'function') continue;\n        const tool_call_id = tool_call.id;\n        const { name, arguments: args } = tool_call.function;\n        const fn = functionsByName[name];\n\n        if (!fn) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${Object.keys(\n            functionsByName,\n          )\n            .map((name) => JSON.stringify(name))\n            .join(', ')}. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(\n            singleFunctionToCall,\n          )} requested. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        let parsed;\n        try {\n          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n        } catch (error) {\n          const content = error instanceof Error ? error.message : String(error);\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        // @ts-expect-error it can't rule out `never` type.\n        const rawContent = await fn.function(parsed, this);\n        const content = this.#stringifyFunctionCallResult(rawContent);\n        this._addMessage({ role, tool_call_id, content });\n\n        if (singleFunctionToCall) {\n          return;\n        }\n      }\n    }\n\n    return;\n  }\n\n  #stringifyFunctionCallResult(rawContent: unknown): string {\n    return (\n      typeof rawContent === 'string' ? rawContent\n      : rawContent === undefined ? 'undefined'\n      : JSON.stringify(rawContent)\n    );\n  }\n}\n\nexport interface AbstractChatCompletionRunnerEvents extends BaseEvents {\n  functionToolCall: (functionCall: ChatCompletionMessageFunctionToolCall.Function) => void;\n  message: (message: ChatCompletionMessageParam) => void;\n  chatCompletion: (completion: ChatCompletion) => void;\n  finalContent: (contentSnapshot: string) => void;\n  finalMessage: (message: ChatCompletionMessageParam) => void;\n  finalChatCompletion: (completion: ChatCompletion) => void;\n  finalFunctionToolCall: (functionCall: ChatCompletionMessageFunctionToolCall.Function) => void;\n  functionToolCallResult: (content: string) => void;\n  finalFunctionToolCallResult: (content: string) => void;\n  totalUsage: (usage: CompletionUsage) => void;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { RequestOptions } from '../internal/request-options';\n\nexport class Moderations extends APIResource {\n  /**\n   * Classifies if text and/or image inputs are potentially harmful. Learn more in\n   * the [moderation guide](https://platform.openai.com/docs/guides/moderation).\n   */\n  create(body: ModerationCreateParams, options?: RequestOptions): APIPromise<ModerationCreateResponse> {\n    return this._client.post('/moderations', { body, ...options });\n  }\n}\n\nexport interface Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  categories: Moderation.Categories;\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  category_applied_input_types: Moderation.CategoryAppliedInputTypes;\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  category_scores: Moderation.CategoryScores;\n\n  /**\n   * Whether any of the below categories are flagged.\n   */\n  flagged: boolean;\n}\n\nexport namespace Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  export interface Categories {\n    /**\n     * Content that expresses, incites, or promotes harassing language towards any\n     * target.\n     */\n    harassment: boolean;\n\n    /**\n     * Harassment content that also includes violence or serious harm towards any\n     * target.\n     */\n    'harassment/threatening': boolean;\n\n    /**\n     * Content that expresses, incites, or promotes hate based on race, gender,\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\n     * harassment.\n     */\n    hate: boolean;\n\n    /**\n     * Hateful content that also includes violence or serious harm towards the targeted\n     * group based on race, gender, ethnicity, religion, nationality, sexual\n     * orientation, disability status, or caste.\n     */\n    'hate/threatening': boolean;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing, or that gives advice or instruction on how to commit\n     * illicit acts. For example, \"how to shoplift\" would fit this category.\n     */\n    illicit: boolean | null;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing that also includes violence, or that gives advice or\n     * instruction on the procurement of any weapon.\n     */\n    'illicit/violent': boolean | null;\n\n    /**\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\n     * suicide, cutting, and eating disorders.\n     */\n    'self-harm': boolean;\n\n    /**\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\n     * and eating disorders, or that gives instructions or advice on how to commit such\n     * acts.\n     */\n    'self-harm/instructions': boolean;\n\n    /**\n     * Content where the speaker expresses that they are engaging or intend to engage\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\n     */\n    'self-harm/intent': boolean;\n\n    /**\n     * Content meant to arouse sexual excitement, such as the description of sexual\n     * activity, or that promotes sexual services (excluding sex education and\n     * wellness).\n     */\n    sexual: boolean;\n\n    /**\n     * Sexual content that includes an individual who is under 18 years old.\n     */\n    'sexual/minors': boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury.\n     */\n    violence: boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury in graphic detail.\n     */\n    'violence/graphic': boolean;\n  }\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  export interface CategoryAppliedInputTypes {\n    /**\n     * The applied input type(s) for the category 'harassment'.\n     */\n    harassment: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate'.\n     */\n    hate: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate/threatening'.\n     */\n    'hate/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit'.\n     */\n    illicit: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit/violent'.\n     */\n    'illicit/violent': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm'.\n     */\n    'self-harm': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual'.\n     */\n    sexual: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual/minors'.\n     */\n    'sexual/minors': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'violence'.\n     */\n    violence: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'violence/graphic'.\n     */\n    'violence/graphic': Array<'text' | 'image'>;\n  }\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  export interface CategoryScores {\n    /**\n     * The score for the category 'harassment'.\n     */\n    harassment: number;\n\n    /**\n     * The score for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': number;\n\n    /**\n     * The score for the category 'hate'.\n     */\n    hate: number;\n\n    /**\n     * The score for the category 'hate/threatening'.\n     */\n    'hate/threatening': number;\n\n    /**\n     * The score for the category 'illicit'.\n     */\n    illicit: number;\n\n    /**\n     * The score for the category 'illicit/violent'.\n     */\n    'illicit/violent': number;\n\n    /**\n     * The score for the category 'self-harm'.\n     */\n    'self-harm': number;\n\n    /**\n     * The score for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': number;\n\n    /**\n     * The score for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': number;\n\n    /**\n     * The score for the category 'sexual'.\n     */\n    sexual: number;\n\n    /**\n     * The score for the category 'sexual/minors'.\n     */\n    'sexual/minors': number;\n\n    /**\n     * The score for the category 'violence'.\n     */\n    violence: number;\n\n    /**\n     * The score for the category 'violence/graphic'.\n     */\n    'violence/graphic': number;\n  }\n}\n\n/**\n * An object describing an image to classify.\n */\nexport interface ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  image_url: ModerationImageURLInput.ImageURL;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n}\n\nexport namespace ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n  }\n}\n\nexport type ModerationModel =\n  | 'omni-moderation-latest'\n  | 'omni-moderation-2024-09-26'\n  | 'text-moderation-latest'\n  | 'text-moderation-stable';\n\n/**\n * An object describing an image to classify.\n */\nexport type ModerationMultiModalInput = ModerationImageURLInput | ModerationTextInput;\n\n/**\n * An object describing text to classify.\n */\nexport interface ModerationTextInput {\n  /**\n   * A string of text to classify.\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * Represents if a given text input is potentially harmful.\n */\nexport interface ModerationCreateResponse {\n  /**\n   * The unique identifier for the moderation request.\n   */\n  id: string;\n\n  /**\n   * The model used to generate the moderation results.\n   */\n  model: string;\n\n  /**\n   * A list of moderation objects.\n   */\n  results: Array<Moderation>;\n}\n\nexport interface ModerationCreateParams {\n  /**\n   * Input (or inputs) to classify. Can be a single string, an array of strings, or\n   * an array of multi-modal input objects similar to other models.\n   */\n  input: string | Array<string> | Array<ModerationMultiModalInput>;\n\n  /**\n   * The content moderation model you would like to use. Learn more in\n   * [the moderation guide](https://platform.openai.com/docs/guides/moderation), and\n   * learn about available models\n   * [here](https://platform.openai.com/docs/models#moderation).\n   */\n  model?: (string & {}) | ModerationModel;\n}\n\nexport declare namespace Moderations {\n  export {\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as RealtimeAPI from './realtime';\nimport * as Shared from '../shared';\nimport * as CallsAPI from './calls';\nimport { CallAcceptParams, CallReferParams, CallRejectParams, Calls } from './calls';\nimport * as ClientSecretsAPI from './client-secrets';\nimport {\n  ClientSecretCreateParams,\n  ClientSecretCreateResponse,\n  ClientSecrets,\n  RealtimeSessionClientSecret,\n  RealtimeSessionCreateResponse,\n  RealtimeTranscriptionSessionCreateResponse,\n  RealtimeTranscriptionSessionTurnDetection,\n} from './client-secrets';\nimport * as ResponsesAPI from '../responses/responses';\n\nexport class Realtime extends APIResource {\n  clientSecrets: ClientSecretsAPI.ClientSecrets = new ClientSecretsAPI.ClientSecrets(this._client);\n  calls: CallsAPI.Calls = new CallsAPI.Calls(this._client);\n}\n\nexport interface AudioTranscription {\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n   * format will improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * The model to use for transcription. Current options are `whisper-1`,\n   * `gpt-4o-mini-transcribe`, `gpt-4o-mini-transcribe-2025-12-15`,\n   * `gpt-4o-transcribe`, and `gpt-4o-transcribe-diarize`. Use\n   * `gpt-4o-transcribe-diarize` when you need diarization with speaker labels.\n   */\n  model?:\n    | (string & {})\n    | 'whisper-1'\n    | 'gpt-4o-mini-transcribe'\n    | 'gpt-4o-mini-transcribe-2025-12-15'\n    | 'gpt-4o-transcribe'\n    | 'gpt-4o-transcribe-diarize';\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. For `whisper-1`, the\n   * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n   * For `gpt-4o-transcribe` models (excluding `gpt-4o-transcribe-diarize`), the\n   * prompt is a free text string, for example \"expect words related to technology\".\n   */\n  prompt?: string;\n}\n\n/**\n * Returned when a conversation is created. Emitted right after session creation.\n */\nexport interface ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  conversation: ConversationCreatedEvent.Conversation;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `conversation.created`.\n   */\n  type: 'conversation.created';\n}\n\nexport namespace ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  export interface Conversation {\n    /**\n     * The unique ID of the conversation.\n     */\n    id?: string;\n\n    /**\n     * The object type, must be `realtime.conversation`.\n     */\n    object?: 'realtime.conversation';\n  }\n}\n\n/**\n * A single item within a Realtime conversation.\n */\nexport type ConversationItem =\n  | RealtimeConversationItemSystemMessage\n  | RealtimeConversationItemUserMessage\n  | RealtimeConversationItemAssistantMessage\n  | RealtimeConversationItemFunctionCall\n  | RealtimeConversationItemFunctionCallOutput\n  | RealtimeMcpApprovalResponse\n  | RealtimeMcpListTools\n  | RealtimeMcpToolCall\n  | RealtimeMcpApprovalRequest;\n\n/**\n * Sent by the server when an Item is added to the default Conversation. This can\n * happen in several cases:\n *\n * - When the client sends a `conversation.item.create` event.\n * - When the input audio buffer is committed. In this case the item will be a user\n *   message containing the audio from the buffer.\n * - When the model is generating a Response. In this case the\n *   `conversation.item.added` event will be sent when the model starts generating\n *   a specific Item, and thus it will not yet have any content (and `status` will\n *   be `in_progress`).\n *\n * The event will include the full content of the Item (except when model is\n * generating a Response) except for audio data, which can be retrieved separately\n * with a `conversation.item.retrieve` event if necessary.\n */\nexport interface ConversationItemAdded {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.added`.\n   */\n  type: 'conversation.item.added';\n\n  /**\n   * The ID of the item that precedes this one, if any. This is used to maintain\n   * ordering when items are inserted.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Add a new Item to the Conversation's context, including messages, function\n * calls, and function call responses. This event can be used both to populate a\n * \"history\" of the conversation and to add new items mid-stream, but has the\n * current limitation that it cannot populate assistant audio messages.\n *\n * If successful, the server will respond with a `conversation.item.created` event,\n * otherwise an `error` event will be sent.\n */\nexport interface ConversationItemCreateEvent {\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.create`.\n   */\n  type: 'conversation.item.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. If not\n   * set, the new item will be appended to the end of the conversation.\n   *\n   * If set to `root`, the new item will be added to the beginning of the\n   * conversation.\n   *\n   * If set to an existing ID, it allows an item to be inserted mid-conversation. If\n   * the ID cannot be found, an error will be returned and the item will not be\n   * added.\n   */\n  previous_item_id?: string;\n}\n\n/**\n * Returned when a conversation item is created. There are several scenarios that\n * produce this event:\n *\n * - The server is generating a Response, which if successful will produce either\n *   one or two Items, which will be of type `message` (role `assistant`) or type\n *   `function_call`.\n * - The input audio buffer has been committed, either by the client or the server\n *   (in `server_vad` mode). The server will take the content of the input audio\n *   buffer and add it to a new user message Item.\n * - The client has sent a `conversation.item.create` event to add a new Item to\n *   the Conversation.\n */\nexport interface ConversationItemCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.created`.\n   */\n  type: 'conversation.item.created';\n\n  /**\n   * The ID of the preceding item in the Conversation context, allows the client to\n   * understand the order of the conversation. Can be `null` if the item has no\n   * predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Send this event when you want to remove any item from the conversation history.\n * The server will respond with a `conversation.item.deleted` event, unless the\n * item does not exist in the conversation history, in which case the server will\n * respond with an error.\n */\nexport interface ConversationItemDeleteEvent {\n  /**\n   * The ID of the item to delete.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.delete`.\n   */\n  type: 'conversation.item.delete';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an item in the conversation is deleted by the client with a\n * `conversation.item.delete` event. This event is used to synchronize the server's\n * understanding of the conversation history with the client's view.\n */\nexport interface ConversationItemDeletedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item that was deleted.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.deleted`.\n   */\n  type: 'conversation.item.deleted';\n}\n\n/**\n * Returned when a conversation item is finalized.\n *\n * The event will include the full content of the Item except for audio data, which\n * can be retrieved separately with a `conversation.item.retrieve` event if needed.\n */\nexport interface ConversationItemDone {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.done`.\n   */\n  type: 'conversation.item.done';\n\n  /**\n   * The ID of the item that precedes this one, if any. This is used to maintain\n   * ordering when items are inserted.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * This event is the output of audio transcription for user audio written to the\n * user audio buffer. Transcription begins when the input audio buffer is committed\n * by the client or server (when VAD is enabled). Transcription runs asynchronously\n * with Response creation, so this event may come before or after the Response\n * events.\n *\n * Realtime API models accept audio natively, and thus input transcription is a\n * separate process run on a separate ASR (Automatic Speech Recognition) model. The\n * transcript may diverge somewhat from the model's interpretation, and should be\n * treated as a rough guide.\n */\nexport interface ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item containing the audio that is being transcribed.\n   */\n  item_id: string;\n\n  /**\n   * The transcribed text.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.completed`.\n   */\n  type: 'conversation.item.input_audio_transcription.completed';\n\n  /**\n   * Usage statistics for the transcription, this is billed according to the ASR\n   * model's pricing rather than the realtime model's pricing.\n   */\n  usage:\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageTokens\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageDuration;\n\n  /**\n   * The log probabilities of the transcription.\n   */\n  logprobs?: Array<LogProbProperties> | null;\n}\n\nexport namespace ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface TranscriptTextUsageTokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: TranscriptTextUsageTokens.InputTokenDetails;\n  }\n\n  export namespace TranscriptTextUsageTokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface TranscriptTextUsageDuration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\n/**\n * Returned when the text value of an input audio transcription content part is\n * updated with incremental transcription results.\n */\nexport interface ConversationItemInputAudioTranscriptionDeltaEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item containing the audio that is being transcribed.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.delta`.\n   */\n  type: 'conversation.item.input_audio_transcription.delta';\n\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index?: number;\n\n  /**\n   * The text delta.\n   */\n  delta?: string;\n\n  /**\n   * The log probabilities of the transcription. These can be enabled by\n   * configurating the session with\n   * `\"include\": [\"item.input_audio_transcription.logprobs\"]`. Each entry in the\n   * array corresponds a log probability of which token would be selected for this\n   * chunk of transcription. This can help to identify if it was possible there were\n   * multiple valid options for a given chunk of transcription.\n   */\n  logprobs?: Array<LogProbProperties> | null;\n}\n\n/**\n * Returned when input audio transcription is configured, and a transcription\n * request for a user message failed. These events are separate from other `error`\n * events so that the client can identify the related Item.\n */\nexport interface ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * Details of the transcription error.\n   */\n  error: ConversationItemInputAudioTranscriptionFailedEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.failed`.\n   */\n  type: 'conversation.item.input_audio_transcription.failed';\n}\n\nexport namespace ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * Details of the transcription error.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message?: string;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Returned when an input audio transcription segment is identified for an item.\n */\nexport interface ConversationItemInputAudioTranscriptionSegment {\n  /**\n   * The segment identifier.\n   */\n  id: string;\n\n  /**\n   * The index of the input audio content part within the item.\n   */\n  content_index: number;\n\n  /**\n   * End time of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item containing the input audio content.\n   */\n  item_id: string;\n\n  /**\n   * The detected speaker label for this segment.\n   */\n  speaker: string;\n\n  /**\n   * Start time of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * The text for this segment.\n   */\n  text: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.segment`.\n   */\n  type: 'conversation.item.input_audio_transcription.segment';\n}\n\n/**\n * Send this event when you want to retrieve the server's representation of a\n * specific item in the conversation history. This is useful, for example, to\n * inspect user audio after noise cancellation and VAD. The server will respond\n * with a `conversation.item.retrieved` event, unless the item does not exist in\n * the conversation history, in which case the server will respond with an error.\n */\nexport interface ConversationItemRetrieveEvent {\n  /**\n   * The ID of the item to retrieve.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.retrieve`.\n   */\n  type: 'conversation.item.retrieve';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to truncate a previous assistant messages audio. The server\n * will produce audio faster than realtime, so this event is useful when the user\n * interrupts to truncate audio that has already been sent to the client but not\n * yet played. This will synchronize the server's understanding of the audio with\n * the client's playback.\n *\n * Truncating audio will delete the server-side text transcript to ensure there is\n * not text in the context that hasn't been heard by the user.\n *\n * If successful, the server will respond with a `conversation.item.truncated`\n * event.\n */\nexport interface ConversationItemTruncateEvent {\n  /**\n   * Inclusive duration up to which audio is truncated, in milliseconds. If the\n   * audio_end_ms is greater than the actual audio duration, the server will respond\n   * with an error.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part to truncate. Set this to `0`.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the assistant message item to truncate. Only assistant message items\n   * can be truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncate`.\n   */\n  type: 'conversation.item.truncate';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an earlier assistant audio message item is truncated by the client\n * with a `conversation.item.truncate` event. This event is used to synchronize the\n * server's understanding of the audio with the client's playback.\n *\n * This action will truncate the audio and remove the server-side text transcript\n * to ensure there is no text in the context that hasn't been heard by the user.\n */\nexport interface ConversationItemTruncatedEvent {\n  /**\n   * The duration up to which the audio was truncated, in milliseconds.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part that was truncated.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the assistant message item that was truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncated`.\n   */\n  type: 'conversation.item.truncated';\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItemWithReference {\n  /**\n   * For an item of type (`message` | `function_call` | `function_call_output`) this\n   * field allows the client to assign the unique ID of the item. It is not required\n   * because the server will generate one if not provided.\n   *\n   * For an item of type `item_reference`, this field is required and is a reference\n   * to any item that has previously existed in the conversation.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemWithReference.Content>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`, `in_progress`). These have no\n   * effect on the conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`,\n   * `item_reference`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output' | 'item_reference';\n}\n\nexport namespace ConversationItemWithReference {\n  export interface Content {\n    /**\n     * ID of a previous conversation item to reference (for `item_reference` content\n     * types in `response.create` events). These can reference both client and server\n     * created items.\n     */\n    id?: string;\n\n    /**\n     * Base64-encoded audio bytes, used for `input_audio` content type.\n     */\n    audio?: string;\n\n    /**\n     * The text content, used for `input_text` and `text` content types.\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio, used for `input_audio` content type.\n     */\n    transcript?: string;\n\n    /**\n     * The content type (`input_text`, `input_audio`, `item_reference`, `text`).\n     */\n    type?: 'input_text' | 'input_audio' | 'item_reference' | 'text';\n  }\n}\n\n/**\n * Send this event to append audio bytes to the input audio buffer. The audio\n * buffer is temporary storage you can write to and later commit. A \"commit\" will\n * create a new user message item in the conversation history from the buffer\n * content and clear the buffer. Input audio transcription (if enabled) will be\n * generated when the buffer is committed.\n *\n * If VAD is enabled the audio buffer is used to detect speech and the server will\n * decide when to commit. When Server VAD is disabled, you must commit the audio\n * buffer manually. Input audio noise reduction operates on writes to the audio\n * buffer.\n *\n * The client may choose how much audio to place in each event up to a maximum of\n * 15 MiB, for example streaming smaller chunks from the client may allow the VAD\n * to be more responsive. Unlike most other client events, the server will not send\n * a confirmation response to this event.\n */\nexport interface InputAudioBufferAppendEvent {\n  /**\n   * Base64-encoded audio bytes. This must be in the format specified by the\n   * `input_audio_format` field in the session configuration.\n   */\n  audio: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.append`.\n   */\n  type: 'input_audio_buffer.append';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to clear the audio bytes in the buffer. The server will respond\n * with an `input_audio_buffer.cleared` event.\n */\nexport interface InputAudioBufferClearEvent {\n  /**\n   * The event type, must be `input_audio_buffer.clear`.\n   */\n  type: 'input_audio_buffer.clear';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when the input audio buffer is cleared by the client with a\n * `input_audio_buffer.clear` event.\n */\nexport interface InputAudioBufferClearedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.cleared`.\n   */\n  type: 'input_audio_buffer.cleared';\n}\n\n/**\n * Send this event to commit the user input audio buffer, which will create a new\n * user message item in the conversation. This event will produce an error if the\n * input audio buffer is empty. When in Server VAD mode, the client does not need\n * to send this event, the server will commit the audio buffer automatically.\n *\n * Committing the input audio buffer will trigger input audio transcription (if\n * enabled in session configuration), but it will not create a response from the\n * model. The server will respond with an `input_audio_buffer.committed` event.\n */\nexport interface InputAudioBufferCommitEvent {\n  /**\n   * The event type, must be `input_audio_buffer.commit`.\n   */\n  type: 'input_audio_buffer.commit';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an input audio buffer is committed, either by the client or\n * automatically in server VAD mode. The `item_id` property is the ID of the user\n * message item that will be created, thus a `conversation.item.created` event will\n * also be sent to the client.\n */\nexport interface InputAudioBufferCommittedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.committed`.\n   */\n  type: 'input_audio_buffer.committed';\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. Can be\n   * `null` if the item has no predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * **SIP Only:** Returned when an DTMF event is received. A DTMF event is a message\n * that represents a telephone keypad press (09, \\*, #, AD). The `event` property\n * is the keypad that the user press. The `received_at` is the UTC Unix Timestamp\n * that the server received the event.\n */\nexport interface InputAudioBufferDtmfEventReceivedEvent {\n  /**\n   * The telephone keypad that was pressed by the user.\n   */\n  event: string;\n\n  /**\n   * UTC Unix Timestamp when DTMF Event was received by server.\n   */\n  received_at: number;\n\n  /**\n   * The event type, must be `input_audio_buffer.dtmf_event_received`.\n   */\n  type: 'input_audio_buffer.dtmf_event_received';\n}\n\n/**\n * Sent by the server when in `server_vad` mode to indicate that speech has been\n * detected in the audio buffer. This can happen any time audio is added to the\n * buffer (unless speech is already detected). The client may want to use this\n * event to interrupt audio playback or provide visual feedback to the user.\n *\n * The client should expect to receive a `input_audio_buffer.speech_stopped` event\n * when speech stops. The `item_id` property is the ID of the user message item\n * that will be created when speech stops and will also be included in the\n * `input_audio_buffer.speech_stopped` event (unless the client manually commits\n * the audio buffer during VAD activation).\n */\nexport interface InputAudioBufferSpeechStartedEvent {\n  /**\n   * Milliseconds from the start of all audio written to the buffer during the\n   * session when speech was first detected. This will correspond to the beginning of\n   * audio sent to the model, and thus includes the `prefix_padding_ms` configured in\n   * the Session.\n   */\n  audio_start_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created when speech stops.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_started`.\n   */\n  type: 'input_audio_buffer.speech_started';\n}\n\n/**\n * Returned in `server_vad` mode when the server detects the end of speech in the\n * audio buffer. The server will also send an `conversation.item.created` event\n * with the user message item that is created from the audio buffer.\n */\nexport interface InputAudioBufferSpeechStoppedEvent {\n  /**\n   * Milliseconds since the session started when speech stopped. This will correspond\n   * to the end of audio sent to the model, and thus includes the\n   * `min_silence_duration_ms` configured in the Session.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_stopped`.\n   */\n  type: 'input_audio_buffer.speech_stopped';\n}\n\n/**\n * Returned when the Server VAD timeout is triggered for the input audio buffer.\n * This is configured with `idle_timeout_ms` in the `turn_detection` settings of\n * the session, and it indicates that there hasn't been any speech detected for the\n * configured duration.\n *\n * The `audio_start_ms` and `audio_end_ms` fields indicate the segment of audio\n * after the last model response up to the triggering time, as an offset from the\n * beginning of audio written to the input audio buffer. This means it demarcates\n * the segment of audio that was silent and the difference between the start and\n * end values will roughly match the configured timeout.\n *\n * The empty audio will be committed to the conversation as an `input_audio` item\n * (there will be a `input_audio_buffer.committed` event) and a model response will\n * be generated. There may be speech that didn't trigger VAD but is still detected\n * by the model, so the model may respond with something relevant to the\n * conversation or a prompt to continue speaking.\n */\nexport interface InputAudioBufferTimeoutTriggered {\n  /**\n   * Millisecond offset of audio written to the input audio buffer at the time the\n   * timeout was triggered.\n   */\n  audio_end_ms: number;\n\n  /**\n   * Millisecond offset of audio written to the input audio buffer that was after the\n   * playback time of the last model response.\n   */\n  audio_start_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item associated with this segment.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.timeout_triggered`.\n   */\n  type: 'input_audio_buffer.timeout_triggered';\n}\n\n/**\n * A log probability object.\n */\nexport interface LogProbProperties {\n  /**\n   * The token that was used to generate the log probability.\n   */\n  token: string;\n\n  /**\n   * The bytes that were used to generate the log probability.\n   */\n  bytes: Array<number>;\n\n  /**\n   * The log probability of the token.\n   */\n  logprob: number;\n}\n\n/**\n * Returned when listing MCP tools has completed for an item.\n */\nexport interface McpListToolsCompleted {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP list tools item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `mcp_list_tools.completed`.\n   */\n  type: 'mcp_list_tools.completed';\n}\n\n/**\n * Returned when listing MCP tools has failed for an item.\n */\nexport interface McpListToolsFailed {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP list tools item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `mcp_list_tools.failed`.\n   */\n  type: 'mcp_list_tools.failed';\n}\n\n/**\n * Returned when listing MCP tools is in progress for an item.\n */\nexport interface McpListToolsInProgress {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP list tools item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `mcp_list_tools.in_progress`.\n   */\n  type: 'mcp_list_tools.in_progress';\n}\n\n/**\n * Type of noise reduction. `near_field` is for close-talking microphones such as\n * headphones, `far_field` is for far-field microphones such as laptop or\n * conference room microphones.\n */\nexport type NoiseReductionType = 'near_field' | 'far_field';\n\n/**\n * **WebRTC/SIP Only:** Emit to cut off the current audio response. This will\n * trigger the server to stop generating audio and emit a\n * `output_audio_buffer.cleared` event. This event should be preceded by a\n * `response.cancel` client event to stop the generation of the current response.\n * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n */\nexport interface OutputAudioBufferClearEvent {\n  /**\n   * The event type, must be `output_audio_buffer.clear`.\n   */\n  type: 'output_audio_buffer.clear';\n\n  /**\n   * The unique ID of the client event used for error handling.\n   */\n  event_id?: string;\n}\n\n/**\n * Emitted at the beginning of a Response to indicate the updated rate limits. When\n * a Response is created some tokens will be \"reserved\" for the output tokens, the\n * rate limits shown here reflect that reservation, which is then adjusted\n * accordingly once the Response is completed.\n */\nexport interface RateLimitsUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * List of rate limit information.\n   */\n  rate_limits: Array<RateLimitsUpdatedEvent.RateLimit>;\n\n  /**\n   * The event type, must be `rate_limits.updated`.\n   */\n  type: 'rate_limits.updated';\n}\n\nexport namespace RateLimitsUpdatedEvent {\n  export interface RateLimit {\n    /**\n     * The maximum allowed value for the rate limit.\n     */\n    limit?: number;\n\n    /**\n     * The name of the rate limit (`requests`, `tokens`).\n     */\n    name?: 'requests' | 'tokens';\n\n    /**\n     * The remaining value before the limit is reached.\n     */\n    remaining?: number;\n\n    /**\n     * Seconds until the rate limit resets.\n     */\n    reset_seconds?: number;\n  }\n}\n\n/**\n * Configuration for input and output audio.\n */\nexport interface RealtimeAudioConfig {\n  input?: RealtimeAudioConfigInput;\n\n  output?: RealtimeAudioConfigOutput;\n}\n\nexport interface RealtimeAudioConfigInput {\n  /**\n   * The format of the input audio.\n   */\n  format?: RealtimeAudioFormats;\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  noise_reduction?: RealtimeAudioConfigInput.NoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  transcription?: AudioTranscription;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response.\n   *\n   * Server VAD means that the model will detect the start and end of speech based on\n   * audio volume and respond at the end of user speech.\n   *\n   * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n   * with VAD) to semantically estimate whether the user has finished speaking, then\n   * dynamically sets a timeout based on this probability. For example, if user audio\n   * trails off with \"uhhm\", the model will score a low probability of turn end and\n   * wait longer for the user to continue speaking. This can be useful for more\n   * natural conversations, but may have a higher latency.\n   */\n  turn_detection?: RealtimeAudioInputTurnDetection | null;\n}\n\nexport namespace RealtimeAudioConfigInput {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface NoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: RealtimeAPI.NoiseReductionType;\n  }\n}\n\nexport interface RealtimeAudioConfigOutput {\n  /**\n   * The format of the output audio.\n   */\n  format?: RealtimeAudioFormats;\n\n  /**\n   * The speed of the model's spoken response as a multiple of the original speed.\n   * 1.0 is the default speed. 0.25 is the minimum speed. 1.5 is the maximum speed.\n   * This value can only be changed in between model turns, not while a response is\n   * in progress.\n   *\n   * This parameter is a post-processing adjustment to the audio after it is\n   * generated, it's also possible to prompt the model to speak faster or slower.\n   */\n  speed?: number;\n\n  /**\n   * The voice the model uses to respond. Supported built-in voices are `alloy`,\n   * `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`, and\n   * `cedar`. Voice cannot be changed during the session once the model has responded\n   * with audio at least once. We recommend `marin` and `cedar` for best quality.\n   */\n  voice?:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n}\n\n/**\n * The PCM audio format. Only a 24kHz sample rate is supported.\n */\nexport type RealtimeAudioFormats =\n  | RealtimeAudioFormats.AudioPCM\n  | RealtimeAudioFormats.AudioPCMU\n  | RealtimeAudioFormats.AudioPCMA;\n\nexport namespace RealtimeAudioFormats {\n  /**\n   * The PCM audio format. Only a 24kHz sample rate is supported.\n   */\n  export interface AudioPCM {\n    /**\n     * The sample rate of the audio. Always `24000`.\n     */\n    rate?: 24000;\n\n    /**\n     * The audio format. Always `audio/pcm`.\n     */\n    type?: 'audio/pcm';\n  }\n\n  /**\n   * The G.711 -law format.\n   */\n  export interface AudioPCMU {\n    /**\n     * The audio format. Always `audio/pcmu`.\n     */\n    type?: 'audio/pcmu';\n  }\n\n  /**\n   * The G.711 A-law format.\n   */\n  export interface AudioPCMA {\n    /**\n     * The audio format. Always `audio/pcma`.\n     */\n    type?: 'audio/pcma';\n  }\n}\n\n/**\n * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n * set to `null` to turn off, in which case the client must manually trigger model\n * response.\n *\n * Server VAD means that the model will detect the start and end of speech based on\n * audio volume and respond at the end of user speech.\n *\n * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n * with VAD) to semantically estimate whether the user has finished speaking, then\n * dynamically sets a timeout based on this probability. For example, if user audio\n * trails off with \"uhhm\", the model will score a low probability of turn end and\n * wait longer for the user to continue speaking. This can be useful for more\n * natural conversations, but may have a higher latency.\n */\nexport type RealtimeAudioInputTurnDetection =\n  | RealtimeAudioInputTurnDetection.ServerVad\n  | RealtimeAudioInputTurnDetection.SemanticVad;\n\nexport namespace RealtimeAudioInputTurnDetection {\n  /**\n   * Server-side voice activity detection (VAD) which flips on when user speech is\n   * detected and off after a period of silence.\n   */\n  export interface ServerVad {\n    /**\n     * Type of turn detection, `server_vad` to turn on simple Server VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs. If `interrupt_response` is set to `false` this may fail to create a\n     * response if the model is already responding.\n     *\n     * If both `create_response` and `interrupt_response` are set to `false`, the model\n     * will never respond automatically but VAD events will still be emitted.\n     */\n    create_response?: boolean;\n\n    /**\n     * Optional timeout after which a model response will be triggered automatically.\n     * This is useful for situations in which a long pause from the user is unexpected,\n     * such as a phone call. The model will effectively prompt the user to continue the\n     * conversation based on the current context.\n     *\n     * The timeout value will be applied after the last model response's audio has\n     * finished playing, i.e. it's set to the `response.done` time plus audio playback\n     * duration.\n     *\n     * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n     * Response) will be emitted when the timeout is reached. Idle timeout is currently\n     * only supported for `server_vad` mode.\n     */\n    idle_timeout_ms?: number | null;\n\n    /**\n     * Whether or not to automatically interrupt (cancel) any ongoing response with\n     * output to the default conversation (i.e. `conversation` of `auto`) when a VAD\n     * start event occurs. If `true` then the response will be cancelled, otherwise it\n     * will continue until complete.\n     *\n     * If both `create_response` and `interrupt_response` are set to `false`, the model\n     * will never respond automatically but VAD events will still be emitted.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  /**\n   * Server-side semantic turn detection which uses a model to determine when the\n   * user has finished speaking.\n   */\n  export interface SemanticVad {\n    /**\n     * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n     */\n    type: 'semantic_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n     * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n  }\n}\n\n/**\n * A realtime client event.\n */\nexport type RealtimeClientEvent =\n  | ConversationItemCreateEvent\n  | ConversationItemDeleteEvent\n  | ConversationItemRetrieveEvent\n  | ConversationItemTruncateEvent\n  | InputAudioBufferAppendEvent\n  | InputAudioBufferClearEvent\n  | OutputAudioBufferClearEvent\n  | InputAudioBufferCommitEvent\n  | ResponseCancelEvent\n  | ResponseCreateEvent\n  | SessionUpdateEvent;\n\n/**\n * An assistant message item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemAssistantMessage {\n  /**\n   * The content of the message.\n   */\n  content: Array<RealtimeConversationItemAssistantMessage.Content>;\n\n  /**\n   * The role of the message sender. Always `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * The type of the item. Always `message`.\n   */\n  type: 'message';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\nexport namespace RealtimeConversationItemAssistantMessage {\n  export interface Content {\n    /**\n     * Base64-encoded audio bytes, these will be parsed as the format specified in the\n     * session output audio type configuration. This defaults to PCM 16-bit 24kHz mono\n     * if not specified.\n     */\n    audio?: string;\n\n    /**\n     * The text content.\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio content, this will always be present if the output\n     * type is `audio`.\n     */\n    transcript?: string;\n\n    /**\n     * The content type, `output_text` or `output_audio` depending on the session\n     * `output_modalities` configuration.\n     */\n    type?: 'output_text' | 'output_audio';\n  }\n}\n\n/**\n * A function call item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemFunctionCall {\n  /**\n   * The arguments of the function call. This is a JSON-encoded string representing\n   * the arguments passed to the function, for example\n   * `{\"arg1\": \"value1\", \"arg2\": 42}`.\n   */\n  arguments: string;\n\n  /**\n   * The name of the function being called.\n   */\n  name: string;\n\n  /**\n   * The type of the item. Always `function_call`.\n   */\n  type: 'function_call';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * The ID of the function call.\n   */\n  call_id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\n/**\n * A function call output item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemFunctionCallOutput {\n  /**\n   * The ID of the function call this output is for.\n   */\n  call_id: string;\n\n  /**\n   * The output of the function call, this is free text and can contain any\n   * information or simply be empty.\n   */\n  output: string;\n\n  /**\n   * The type of the item. Always `function_call_output`.\n   */\n  type: 'function_call_output';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\n/**\n * A system message in a Realtime conversation can be used to provide additional\n * context or instructions to the model. This is similar but distinct from the\n * instruction prompt provided at the start of a conversation, as system messages\n * can be added at any point in the conversation. For major changes to the\n * conversation's behavior, use instructions, but for smaller updates (e.g. \"the\n * user is now asking about a different topic\"), use system messages.\n */\nexport interface RealtimeConversationItemSystemMessage {\n  /**\n   * The content of the message.\n   */\n  content: Array<RealtimeConversationItemSystemMessage.Content>;\n\n  /**\n   * The role of the message sender. Always `system`.\n   */\n  role: 'system';\n\n  /**\n   * The type of the item. Always `message`.\n   */\n  type: 'message';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\nexport namespace RealtimeConversationItemSystemMessage {\n  export interface Content {\n    /**\n     * The text content.\n     */\n    text?: string;\n\n    /**\n     * The content type. Always `input_text` for system messages.\n     */\n    type?: 'input_text';\n  }\n}\n\n/**\n * A user message item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemUserMessage {\n  /**\n   * The content of the message.\n   */\n  content: Array<RealtimeConversationItemUserMessage.Content>;\n\n  /**\n   * The role of the message sender. Always `user`.\n   */\n  role: 'user';\n\n  /**\n   * The type of the item. Always `message`.\n   */\n  type: 'message';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\nexport namespace RealtimeConversationItemUserMessage {\n  export interface Content {\n    /**\n     * Base64-encoded audio bytes (for `input_audio`), these will be parsed as the\n     * format specified in the session input audio type configuration. This defaults to\n     * PCM 16-bit 24kHz mono if not specified.\n     */\n    audio?: string;\n\n    /**\n     * The detail level of the image (for `input_image`). `auto` will default to\n     * `high`.\n     */\n    detail?: 'auto' | 'low' | 'high';\n\n    /**\n     * Base64-encoded image bytes (for `input_image`) as a data URI. For example\n     * `data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...`. Supported formats are PNG\n     * and JPEG.\n     */\n    image_url?: string;\n\n    /**\n     * The text content (for `input_text`).\n     */\n    text?: string;\n\n    /**\n     * Transcript of the audio (for `input_audio`). This is not sent to the model, but\n     * will be attached to the message item for reference.\n     */\n    transcript?: string;\n\n    /**\n     * The content type (`input_text`, `input_audio`, or `input_image`).\n     */\n    type?: 'input_text' | 'input_audio' | 'input_image';\n  }\n}\n\n/**\n * Details of the error.\n */\nexport interface RealtimeError {\n  /**\n   * A human-readable error message.\n   */\n  message: string;\n\n  /**\n   * The type of error (e.g., \"invalid_request_error\", \"server_error\").\n   */\n  type: string;\n\n  /**\n   * Error code, if any.\n   */\n  code?: string | null;\n\n  /**\n   * The event_id of the client event that caused the error, if applicable.\n   */\n  event_id?: string | null;\n\n  /**\n   * Parameter related to the error, if any.\n   */\n  param?: string | null;\n}\n\n/**\n * Returned when an error occurs, which could be a client problem or a server\n * problem. Most errors are recoverable and the session will stay open, we\n * recommend to implementors to monitor and log error messages by default.\n */\nexport interface RealtimeErrorEvent {\n  /**\n   * Details of the error.\n   */\n  error: RealtimeError;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `error`.\n   */\n  type: 'error';\n}\n\nexport interface RealtimeFunctionTool {\n  /**\n   * The description of the function, including guidance on when and how to call it,\n   * and guidance about what to tell the user when calling (if anything).\n   */\n  description?: string;\n\n  /**\n   * The name of the function.\n   */\n  name?: string;\n\n  /**\n   * Parameters of the function in JSON Schema.\n   */\n  parameters?: unknown;\n\n  /**\n   * The type of the tool, i.e. `function`.\n   */\n  type?: 'function';\n}\n\n/**\n * A Realtime item requesting human approval of a tool invocation.\n */\nexport interface RealtimeMcpApprovalRequest {\n  /**\n   * The unique ID of the approval request.\n   */\n  id: string;\n\n  /**\n   * A JSON string of arguments for the tool.\n   */\n  arguments: string;\n\n  /**\n   * The name of the tool to run.\n   */\n  name: string;\n\n  /**\n   * The label of the MCP server making the request.\n   */\n  server_label: string;\n\n  /**\n   * The type of the item. Always `mcp_approval_request`.\n   */\n  type: 'mcp_approval_request';\n}\n\n/**\n * A Realtime item responding to an MCP approval request.\n */\nexport interface RealtimeMcpApprovalResponse {\n  /**\n   * The unique ID of the approval response.\n   */\n  id: string;\n\n  /**\n   * The ID of the approval request being answered.\n   */\n  approval_request_id: string;\n\n  /**\n   * Whether the request was approved.\n   */\n  approve: boolean;\n\n  /**\n   * The type of the item. Always `mcp_approval_response`.\n   */\n  type: 'mcp_approval_response';\n\n  /**\n   * Optional reason for the decision.\n   */\n  reason?: string | null;\n}\n\n/**\n * A Realtime item listing tools available on an MCP server.\n */\nexport interface RealtimeMcpListTools {\n  /**\n   * The label of the MCP server.\n   */\n  server_label: string;\n\n  /**\n   * The tools available on the server.\n   */\n  tools: Array<RealtimeMcpListTools.Tool>;\n\n  /**\n   * The type of the item. Always `mcp_list_tools`.\n   */\n  type: 'mcp_list_tools';\n\n  /**\n   * The unique ID of the list.\n   */\n  id?: string;\n}\n\nexport namespace RealtimeMcpListTools {\n  /**\n   * A tool available on an MCP server.\n   */\n  export interface Tool {\n    /**\n     * The JSON schema describing the tool's input.\n     */\n    input_schema: unknown;\n\n    /**\n     * The name of the tool.\n     */\n    name: string;\n\n    /**\n     * Additional annotations about the tool.\n     */\n    annotations?: unknown | null;\n\n    /**\n     * The description of the tool.\n     */\n    description?: string | null;\n  }\n}\n\nexport interface RealtimeMcpProtocolError {\n  code: number;\n\n  message: string;\n\n  type: 'protocol_error';\n}\n\n/**\n * A Realtime item representing an invocation of a tool on an MCP server.\n */\nexport interface RealtimeMcpToolCall {\n  /**\n   * The unique ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * A JSON string of the arguments passed to the tool.\n   */\n  arguments: string;\n\n  /**\n   * The name of the tool that was run.\n   */\n  name: string;\n\n  /**\n   * The label of the MCP server running the tool.\n   */\n  server_label: string;\n\n  /**\n   * The type of the item. Always `mcp_call`.\n   */\n  type: 'mcp_call';\n\n  /**\n   * The ID of an associated approval request, if any.\n   */\n  approval_request_id?: string | null;\n\n  /**\n   * The error from the tool call, if any.\n   */\n  error?: RealtimeMcpProtocolError | RealtimeMcpToolExecutionError | RealtimeMcphttpError | null;\n\n  /**\n   * The output from the tool call.\n   */\n  output?: string | null;\n}\n\nexport interface RealtimeMcpToolExecutionError {\n  message: string;\n\n  type: 'tool_execution_error';\n}\n\nexport interface RealtimeMcphttpError {\n  code: number;\n\n  message: string;\n\n  type: 'http_error';\n}\n\n/**\n * The response resource.\n */\nexport interface RealtimeResponse {\n  /**\n   * The unique ID of the response, will look like `resp_1234`.\n   */\n  id?: string;\n\n  /**\n   * Configuration for audio output.\n   */\n  audio?: RealtimeResponse.Audio;\n\n  /**\n   * Which conversation the response is added to, determined by the `conversation`\n   * field in the `response.create` event. If `auto`, the response will be added to\n   * the default conversation and the value of `conversation_id` will be an id like\n   * `conv_1234`. If `none`, the response will not be added to any conversation and\n   * the value of `conversation_id` will be `null`. If responses are being triggered\n   * automatically by VAD the response will be added to the default conversation\n   */\n  conversation_id?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls, that was used in this response.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The object type, must be `realtime.response`.\n   */\n  object?: 'realtime.response';\n\n  /**\n   * The list of output items generated by the response.\n   */\n  output?: Array<ConversationItem>;\n\n  /**\n   * The set of modalities the model used to respond, currently the only possible\n   * values are `[\\\"audio\\\"]`, `[\\\"text\\\"]`. Audio output always include a text\n   * transcript. Setting the output to mode `text` will disable audio output from the\n   * model.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The final status of the response (`completed`, `cancelled`, `failed`, or\n   * `incomplete`, `in_progress`).\n   */\n  status?: 'completed' | 'cancelled' | 'failed' | 'incomplete' | 'in_progress';\n\n  /**\n   * Additional details about the status.\n   */\n  status_details?: RealtimeResponseStatus;\n\n  /**\n   * Usage statistics for the Response, this will correspond to billing. A Realtime\n   * API session will maintain a conversation context and append new Items to the\n   * Conversation, thus output from previous turns (text and audio tokens) will\n   * become the input for later turns.\n   */\n  usage?: RealtimeResponseUsage;\n}\n\nexport namespace RealtimeResponse {\n  /**\n   * Configuration for audio output.\n   */\n  export interface Audio {\n    output?: Audio.Output;\n  }\n\n  export namespace Audio {\n    export interface Output {\n      /**\n       * The format of the output audio.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * The voice the model uses to respond. Voice cannot be changed during the session\n       * once the model has responded with audio at least once. Current voice options are\n       * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,\n       * and `cedar`. We recommend `marin` and `cedar` for best quality.\n       */\n      voice?:\n        | (string & {})\n        | 'alloy'\n        | 'ash'\n        | 'ballad'\n        | 'coral'\n        | 'echo'\n        | 'sage'\n        | 'shimmer'\n        | 'verse'\n        | 'marin'\n        | 'cedar';\n    }\n  }\n}\n\n/**\n * Configuration for audio input and output.\n */\nexport interface RealtimeResponseCreateAudioOutput {\n  output?: RealtimeResponseCreateAudioOutput.Output;\n}\n\nexport namespace RealtimeResponseCreateAudioOutput {\n  export interface Output {\n    /**\n     * The format of the output audio.\n     */\n    format?: RealtimeAPI.RealtimeAudioFormats;\n\n    /**\n     * The voice the model uses to respond. Supported built-in voices are `alloy`,\n     * `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`, and\n     * `cedar`. Voice cannot be changed during the session once the model has responded\n     * with audio at least once.\n     */\n    voice?:\n      | (string & {})\n      | 'alloy'\n      | 'ash'\n      | 'ballad'\n      | 'coral'\n      | 'echo'\n      | 'sage'\n      | 'shimmer'\n      | 'verse'\n      | 'marin'\n      | 'cedar';\n  }\n}\n\n/**\n * Give the model access to additional tools via remote Model Context Protocol\n * (MCP) servers.\n * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n */\nexport interface RealtimeResponseCreateMcpTool {\n  /**\n   * A label for this MCP server, used to identify it in tool calls.\n   */\n  server_label: string;\n\n  /**\n   * The type of the MCP tool. Always `mcp`.\n   */\n  type: 'mcp';\n\n  /**\n   * List of allowed tool names or a filter object.\n   */\n  allowed_tools?: Array<string> | RealtimeResponseCreateMcpTool.McpToolFilter | null;\n\n  /**\n   * An OAuth access token that can be used with a remote MCP server, either with a\n   * custom MCP server URL or a service connector. Your application must handle the\n   * OAuth authorization flow and provide the token here.\n   */\n  authorization?: string;\n\n  /**\n   * Identifier for service connectors, like those available in ChatGPT. One of\n   * `server_url` or `connector_id` must be provided. Learn more about service\n   * connectors\n   * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n   *\n   * Currently supported `connector_id` values are:\n   *\n   * - Dropbox: `connector_dropbox`\n   * - Gmail: `connector_gmail`\n   * - Google Calendar: `connector_googlecalendar`\n   * - Google Drive: `connector_googledrive`\n   * - Microsoft Teams: `connector_microsoftteams`\n   * - Outlook Calendar: `connector_outlookcalendar`\n   * - Outlook Email: `connector_outlookemail`\n   * - SharePoint: `connector_sharepoint`\n   */\n  connector_id?:\n    | 'connector_dropbox'\n    | 'connector_gmail'\n    | 'connector_googlecalendar'\n    | 'connector_googledrive'\n    | 'connector_microsoftteams'\n    | 'connector_outlookcalendar'\n    | 'connector_outlookemail'\n    | 'connector_sharepoint';\n\n  /**\n   * Optional HTTP headers to send to the MCP server. Use for authentication or other\n   * purposes.\n   */\n  headers?: { [key: string]: string } | null;\n\n  /**\n   * Specify which of the MCP server's tools require approval.\n   */\n  require_approval?: RealtimeResponseCreateMcpTool.McpToolApprovalFilter | 'always' | 'never' | null;\n\n  /**\n   * Optional description of the MCP server, used to provide more context.\n   */\n  server_description?: string;\n\n  /**\n   * The URL for the MCP server. One of `server_url` or `connector_id` must be\n   * provided.\n   */\n  server_url?: string;\n}\n\nexport namespace RealtimeResponseCreateMcpTool {\n  /**\n   * A filter object to specify which tools are allowed.\n   */\n  export interface McpToolFilter {\n    /**\n     * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n     * is\n     * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n     * it will match this filter.\n     */\n    read_only?: boolean;\n\n    /**\n     * List of allowed tool names.\n     */\n    tool_names?: Array<string>;\n  }\n\n  /**\n   * Specify which of the MCP server's tools require approval. Can be `always`,\n   * `never`, or a filter object associated with tools that require approval.\n   */\n  export interface McpToolApprovalFilter {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    always?: McpToolApprovalFilter.Always;\n\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    never?: McpToolApprovalFilter.Never;\n  }\n\n  export namespace McpToolApprovalFilter {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface Always {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface Never {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n  }\n}\n\n/**\n * Create a new Realtime response with these parameters\n */\nexport interface RealtimeResponseCreateParams {\n  /**\n   * Configuration for audio input and output.\n   */\n  audio?: RealtimeResponseCreateAudioOutput;\n\n  /**\n   * Controls which conversation the response is added to. Currently supports `auto`\n   * and `none`, with `auto` as the default value. The `auto` value means that the\n   * contents of the response will be added to the default conversation. Set this to\n   * `none` to create an out-of-band response which will not add items to default\n   * conversation.\n   */\n  conversation?: (string & {}) | 'auto' | 'none';\n\n  /**\n   * Input items to include in the prompt for the model. Using this field creates a\n   * new context for this Response instead of using the default conversation. An\n   * empty array `[]` will clear the context for this Response. Note that this can\n   * include references to items that previously appeared in the session using their\n   * id.\n   */\n  input?: Array<ConversationItem>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior. Note that the server sets default\n   * instructions which will be used if this field is not set and are visible in the\n   * `session.created` event at the start of the session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The set of modalities the model used to respond, currently the only possible\n   * values are `[\\\"audio\\\"]`, `[\\\"text\\\"]`. Audio output always include a text\n   * transcript. Setting the output to mode `text` will disable audio output from the\n   * model.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: ResponsesAPI.ToolChoiceOptions | ResponsesAPI.ToolChoiceFunction | ResponsesAPI.ToolChoiceMcp;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: Array<RealtimeFunctionTool | RealtimeResponseCreateMcpTool>;\n}\n\n/**\n * Additional details about the status.\n */\nexport interface RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  error?: RealtimeResponseStatus.Error;\n\n  /**\n   * The reason the Response did not complete. For a `cancelled` Response, one of\n   * `turn_detected` (the server VAD detected a new start of speech) or\n   * `client_cancelled` (the client sent a cancel event). For an `incomplete`\n   * Response, one of `max_output_tokens` or `content_filter` (the server-side safety\n   * filter activated and cut off the response).\n   */\n  reason?: 'turn_detected' | 'client_cancelled' | 'max_output_tokens' | 'content_filter';\n\n  /**\n   * The type of error that caused the response to fail, corresponding with the\n   * `status` field (`completed`, `cancelled`, `incomplete`, `failed`).\n   */\n  type?: 'completed' | 'cancelled' | 'incomplete' | 'failed';\n}\n\nexport namespace RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Usage statistics for the Response, this will correspond to billing. A Realtime\n * API session will maintain a conversation context and append new Items to the\n * Conversation, thus output from previous turns (text and audio tokens) will\n * become the input for later turns.\n */\nexport interface RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response. Cached tokens are tokens\n   * from previous turns in the conversation that are included as context for the\n   * current response. Cached tokens here are counted as a subset of input tokens,\n   * meaning input tokens will include cached and uncached tokens.\n   */\n  input_token_details?: RealtimeResponseUsageInputTokenDetails;\n\n  /**\n   * The number of input tokens used in the Response, including text and audio\n   * tokens.\n   */\n  input_tokens?: number;\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  output_token_details?: RealtimeResponseUsageOutputTokenDetails;\n\n  /**\n   * The number of output tokens sent in the Response, including text and audio\n   * tokens.\n   */\n  output_tokens?: number;\n\n  /**\n   * The total number of tokens in the Response including input and output text and\n   * audio tokens.\n   */\n  total_tokens?: number;\n}\n\n/**\n * Details about the input tokens used in the Response. Cached tokens are tokens\n * from previous turns in the conversation that are included as context for the\n * current response. Cached tokens here are counted as a subset of input tokens,\n * meaning input tokens will include cached and uncached tokens.\n */\nexport interface RealtimeResponseUsageInputTokenDetails {\n  /**\n   * The number of audio tokens used as input for the Response.\n   */\n  audio_tokens?: number;\n\n  /**\n   * The number of cached tokens used as input for the Response.\n   */\n  cached_tokens?: number;\n\n  /**\n   * Details about the cached tokens used as input for the Response.\n   */\n  cached_tokens_details?: RealtimeResponseUsageInputTokenDetails.CachedTokensDetails;\n\n  /**\n   * The number of image tokens used as input for the Response.\n   */\n  image_tokens?: number;\n\n  /**\n   * The number of text tokens used as input for the Response.\n   */\n  text_tokens?: number;\n}\n\nexport namespace RealtimeResponseUsageInputTokenDetails {\n  /**\n   * Details about the cached tokens used as input for the Response.\n   */\n  export interface CachedTokensDetails {\n    /**\n     * The number of cached audio tokens used as input for the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of cached image tokens used as input for the Response.\n     */\n    image_tokens?: number;\n\n    /**\n     * The number of cached text tokens used as input for the Response.\n     */\n    text_tokens?: number;\n  }\n}\n\n/**\n * Details about the output tokens used in the Response.\n */\nexport interface RealtimeResponseUsageOutputTokenDetails {\n  /**\n   * The number of audio tokens used in the Response.\n   */\n  audio_tokens?: number;\n\n  /**\n   * The number of text tokens used in the Response.\n   */\n  text_tokens?: number;\n}\n\n/**\n * A realtime server event.\n */\nexport type RealtimeServerEvent =\n  | ConversationCreatedEvent\n  | ConversationItemCreatedEvent\n  | ConversationItemDeletedEvent\n  | ConversationItemInputAudioTranscriptionCompletedEvent\n  | ConversationItemInputAudioTranscriptionDeltaEvent\n  | ConversationItemInputAudioTranscriptionFailedEvent\n  | RealtimeServerEvent.ConversationItemRetrieved\n  | ConversationItemTruncatedEvent\n  | RealtimeErrorEvent\n  | InputAudioBufferClearedEvent\n  | InputAudioBufferCommittedEvent\n  | InputAudioBufferDtmfEventReceivedEvent\n  | InputAudioBufferSpeechStartedEvent\n  | InputAudioBufferSpeechStoppedEvent\n  | RateLimitsUpdatedEvent\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseCreatedEvent\n  | ResponseDoneEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | SessionCreatedEvent\n  | SessionUpdatedEvent\n  | RealtimeServerEvent.OutputAudioBufferStarted\n  | RealtimeServerEvent.OutputAudioBufferStopped\n  | RealtimeServerEvent.OutputAudioBufferCleared\n  | ConversationItemAdded\n  | ConversationItemDone\n  | InputAudioBufferTimeoutTriggered\n  | ConversationItemInputAudioTranscriptionSegment\n  | McpListToolsInProgress\n  | McpListToolsCompleted\n  | McpListToolsFailed\n  | ResponseMcpCallArgumentsDelta\n  | ResponseMcpCallArgumentsDone\n  | ResponseMcpCallInProgress\n  | ResponseMcpCallCompleted\n  | ResponseMcpCallFailed;\n\nexport namespace RealtimeServerEvent {\n  /**\n   * Returned when a conversation item is retrieved with\n   * `conversation.item.retrieve`. This is provided as a way to fetch the server's\n   * representation of an item, for example to get access to the post-processed audio\n   * data after noise cancellation and VAD. It includes the full content of the Item,\n   * including audio data.\n   */\n  export interface ConversationItemRetrieved {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * A single item within a Realtime conversation.\n     */\n    item: RealtimeAPI.ConversationItem;\n\n    /**\n     * The event type, must be `conversation.item.retrieved`.\n     */\n    type: 'conversation.item.retrieved';\n  }\n\n  /**\n   * **WebRTC/SIP Only:** Emitted when the server begins streaming audio to the\n   * client. This event is emitted after an audio content part has been added\n   * (`response.content_part.added`) to the response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStarted {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.started`.\n     */\n    type: 'output_audio_buffer.started';\n  }\n\n  /**\n   * **WebRTC/SIP Only:** Emitted when the output audio buffer has been completely\n   * drained on the server, and no more audio is forthcoming. This event is emitted\n   * after the full response data has been sent to the client (`response.done`).\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStopped {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.stopped`.\n     */\n    type: 'output_audio_buffer.stopped';\n  }\n\n  /**\n   * **WebRTC/SIP Only:** Emitted when the output audio buffer is cleared. This\n   * happens either in VAD mode when the user has interrupted\n   * (`input_audio_buffer.speech_started`), or when the client has emitted the\n   * `output_audio_buffer.clear` event to manually cut off the current audio\n   * response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferCleared {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.cleared`.\n     */\n    type: 'output_audio_buffer.cleared';\n  }\n}\n\n/**\n * Realtime session object for the beta interface.\n */\nexport interface RealtimeSession {\n  /**\n   * Unique identifier for the session that looks like `sess_1234567890abcdef`.\n   */\n  id?: string;\n\n  /**\n   * Expiration timestamp for the session, in seconds since epoch.\n   */\n  expires_at?: number;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * - `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   *   transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'> | null;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: RealtimeSession.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  input_audio_transcription?: AudioTranscription | null;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-realtime-mini-2025-12-15'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06'\n    | 'gpt-audio-mini-2025-12-15';\n\n  /**\n   * The object type. Always `realtime.session`.\n   */\n  object?: 'realtime.session';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n   * temperature of 0.8 is highly recommended for best performance.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<RealtimeFunctionTool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | RealtimeSession.TracingConfiguration | null;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response.\n   *\n   * Server VAD means that the model will detect the start and end of speech based on\n   * audio volume and respond at the end of user speech.\n   *\n   * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n   * with VAD) to semantically estimate whether the user has finished speaking, then\n   * dynamically sets a timeout based on this probability. For example, if user audio\n   * trails off with \"uhhm\", the model will score a low probability of turn end and\n   * wait longer for the user to continue speaking. This can be useful for more\n   * natural conversations, but may have a higher latency.\n   */\n  turn_detection?: RealtimeSession.ServerVad | RealtimeSession.SemanticVad | null;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n}\n\nexport namespace RealtimeSession {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: RealtimeAPI.NoiseReductionType;\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Server-side voice activity detection (VAD) which flips on when user speech is\n   * detected and off after a period of silence.\n   */\n  export interface ServerVad {\n    /**\n     * Type of turn detection, `server_vad` to turn on simple Server VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs. If `interrupt_response` is set to `false` this may fail to create a\n     * response if the model is already responding.\n     *\n     * If both `create_response` and `interrupt_response` are set to `false`, the model\n     * will never respond automatically but VAD events will still be emitted.\n     */\n    create_response?: boolean;\n\n    /**\n     * Optional timeout after which a model response will be triggered automatically.\n     * This is useful for situations in which a long pause from the user is unexpected,\n     * such as a phone call. The model will effectively prompt the user to continue the\n     * conversation based on the current context.\n     *\n     * The timeout value will be applied after the last model response's audio has\n     * finished playing, i.e. it's set to the `response.done` time plus audio playback\n     * duration.\n     *\n     * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n     * Response) will be emitted when the timeout is reached. Idle timeout is currently\n     * only supported for `server_vad` mode.\n     */\n    idle_timeout_ms?: number | null;\n\n    /**\n     * Whether or not to automatically interrupt (cancel) any ongoing response with\n     * output to the default conversation (i.e. `conversation` of `auto`) when a VAD\n     * start event occurs. If `true` then the response will be cancelled, otherwise it\n     * will continue until complete.\n     *\n     * If both `create_response` and `interrupt_response` are set to `false`, the model\n     * will never respond automatically but VAD events will still be emitted.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  /**\n   * Server-side semantic turn detection which uses a model to determine when the\n   * user has finished speaking.\n   */\n  export interface SemanticVad {\n    /**\n     * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n     */\n    type: 'semantic_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n     * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n  }\n}\n\n/**\n * Realtime session object configuration.\n */\nexport interface RealtimeSessionCreateRequest {\n  /**\n   * The type of session to create. Always `realtime` for the Realtime API.\n   */\n  type: 'realtime';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeAudioConfig;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-realtime-mini-2025-12-15'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06'\n    | 'gpt-audio-mini-2025-12-15';\n\n  /**\n   * The set of modalities the model can respond with. It defaults to `[\"audio\"]`,\n   * indicating that the model will respond with audio plus a transcript. `[\"text\"]`\n   * can be used to make the model respond with text only. It is not possible to\n   * request both `text` and `audio` at the same time.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: RealtimeToolChoiceConfig;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: RealtimeToolsConfig;\n\n  /**\n   * Realtime API can write session traces to the\n   * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n   * tracing is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: RealtimeTracingConfig | null;\n\n  /**\n   * When the number of tokens in a conversation exceeds the model's input token\n   * limit, the conversation be truncated, meaning messages (starting from the\n   * oldest) will not be included in the model's context. A 32k context model with\n   * 4,096 max output tokens can only include 28,224 tokens in the context before\n   * truncation occurs.\n   *\n   * Clients can configure truncation behavior to truncate with a lower max token\n   * limit, which is an effective way to control token usage and cost.\n   *\n   * Truncation will reduce the number of cached tokens on the next turn (busting the\n   * cache), since messages are dropped from the beginning of the context. However,\n   * clients can also configure truncation to retain messages up to a fraction of the\n   * maximum context size, which will reduce the need for future truncations and thus\n   * improve the cache rate.\n   *\n   * Truncation can be disabled entirely, which means the server will never truncate\n   * but would instead return an error if the conversation exceeds the model's input\n   * token limit.\n   */\n  truncation?: RealtimeTruncation;\n}\n\n/**\n * How the model chooses tools. Provide one of the string modes or force a specific\n * function/MCP tool.\n */\nexport type RealtimeToolChoiceConfig =\n  | ResponsesAPI.ToolChoiceOptions\n  | ResponsesAPI.ToolChoiceFunction\n  | ResponsesAPI.ToolChoiceMcp;\n\n/**\n * Tools available to the model.\n */\nexport type RealtimeToolsConfig = Array<RealtimeToolsConfigUnion>;\n\n/**\n * Give the model access to additional tools via remote Model Context Protocol\n * (MCP) servers.\n * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n */\nexport type RealtimeToolsConfigUnion = RealtimeFunctionTool | RealtimeToolsConfigUnion.Mcp;\n\nexport namespace RealtimeToolsConfigUnion {\n  /**\n   * Give the model access to additional tools via remote Model Context Protocol\n   * (MCP) servers.\n   * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n   */\n  export interface Mcp {\n    /**\n     * A label for this MCP server, used to identify it in tool calls.\n     */\n    server_label: string;\n\n    /**\n     * The type of the MCP tool. Always `mcp`.\n     */\n    type: 'mcp';\n\n    /**\n     * List of allowed tool names or a filter object.\n     */\n    allowed_tools?: Array<string> | Mcp.McpToolFilter | null;\n\n    /**\n     * An OAuth access token that can be used with a remote MCP server, either with a\n     * custom MCP server URL or a service connector. Your application must handle the\n     * OAuth authorization flow and provide the token here.\n     */\n    authorization?: string;\n\n    /**\n     * Identifier for service connectors, like those available in ChatGPT. One of\n     * `server_url` or `connector_id` must be provided. Learn more about service\n     * connectors\n     * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n     *\n     * Currently supported `connector_id` values are:\n     *\n     * - Dropbox: `connector_dropbox`\n     * - Gmail: `connector_gmail`\n     * - Google Calendar: `connector_googlecalendar`\n     * - Google Drive: `connector_googledrive`\n     * - Microsoft Teams: `connector_microsoftteams`\n     * - Outlook Calendar: `connector_outlookcalendar`\n     * - Outlook Email: `connector_outlookemail`\n     * - SharePoint: `connector_sharepoint`\n     */\n    connector_id?:\n      | 'connector_dropbox'\n      | 'connector_gmail'\n      | 'connector_googlecalendar'\n      | 'connector_googledrive'\n      | 'connector_microsoftteams'\n      | 'connector_outlookcalendar'\n      | 'connector_outlookemail'\n      | 'connector_sharepoint';\n\n    /**\n     * Optional HTTP headers to send to the MCP server. Use for authentication or other\n     * purposes.\n     */\n    headers?: { [key: string]: string } | null;\n\n    /**\n     * Specify which of the MCP server's tools require approval.\n     */\n    require_approval?: Mcp.McpToolApprovalFilter | 'always' | 'never' | null;\n\n    /**\n     * Optional description of the MCP server, used to provide more context.\n     */\n    server_description?: string;\n\n    /**\n     * The URL for the MCP server. One of `server_url` or `connector_id` must be\n     * provided.\n     */\n    server_url?: string;\n  }\n\n  export namespace Mcp {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface McpToolFilter {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * Specify which of the MCP server's tools require approval. Can be `always`,\n     * `never`, or a filter object associated with tools that require approval.\n     */\n    export interface McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      always?: McpToolApprovalFilter.Always;\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      never?: McpToolApprovalFilter.Never;\n    }\n\n    export namespace McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Always {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Never {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n    }\n  }\n}\n\n/**\n * Realtime API can write session traces to the\n * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n * tracing is enabled for a session, the configuration cannot be modified.\n *\n * `auto` will create a trace for the session with default values for the workflow\n * name, group id, and metadata.\n */\nexport type RealtimeTracingConfig = 'auto' | RealtimeTracingConfig.TracingConfiguration;\n\nexport namespace RealtimeTracingConfig {\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * Traces Dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the Traces\n     * Dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the Traces Dashboard.\n     */\n    workflow_name?: string;\n  }\n}\n\n/**\n * Configuration for input and output audio.\n */\nexport interface RealtimeTranscriptionSessionAudio {\n  input?: RealtimeTranscriptionSessionAudioInput;\n}\n\nexport interface RealtimeTranscriptionSessionAudioInput {\n  /**\n   * The PCM audio format. Only a 24kHz sample rate is supported.\n   */\n  format?: RealtimeAudioFormats;\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  noise_reduction?: RealtimeTranscriptionSessionAudioInput.NoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  transcription?: AudioTranscription;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response.\n   *\n   * Server VAD means that the model will detect the start and end of speech based on\n   * audio volume and respond at the end of user speech.\n   *\n   * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n   * with VAD) to semantically estimate whether the user has finished speaking, then\n   * dynamically sets a timeout based on this probability. For example, if user audio\n   * trails off with \"uhhm\", the model will score a low probability of turn end and\n   * wait longer for the user to continue speaking. This can be useful for more\n   * natural conversations, but may have a higher latency.\n   */\n  turn_detection?: RealtimeTranscriptionSessionAudioInputTurnDetection | null;\n}\n\nexport namespace RealtimeTranscriptionSessionAudioInput {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface NoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: RealtimeAPI.NoiseReductionType;\n  }\n}\n\n/**\n * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n * set to `null` to turn off, in which case the client must manually trigger model\n * response.\n *\n * Server VAD means that the model will detect the start and end of speech based on\n * audio volume and respond at the end of user speech.\n *\n * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n * with VAD) to semantically estimate whether the user has finished speaking, then\n * dynamically sets a timeout based on this probability. For example, if user audio\n * trails off with \"uhhm\", the model will score a low probability of turn end and\n * wait longer for the user to continue speaking. This can be useful for more\n * natural conversations, but may have a higher latency.\n */\nexport type RealtimeTranscriptionSessionAudioInputTurnDetection =\n  | RealtimeTranscriptionSessionAudioInputTurnDetection.ServerVad\n  | RealtimeTranscriptionSessionAudioInputTurnDetection.SemanticVad;\n\nexport namespace RealtimeTranscriptionSessionAudioInputTurnDetection {\n  /**\n   * Server-side voice activity detection (VAD) which flips on when user speech is\n   * detected and off after a period of silence.\n   */\n  export interface ServerVad {\n    /**\n     * Type of turn detection, `server_vad` to turn on simple Server VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs. If `interrupt_response` is set to `false` this may fail to create a\n     * response if the model is already responding.\n     *\n     * If both `create_response` and `interrupt_response` are set to `false`, the model\n     * will never respond automatically but VAD events will still be emitted.\n     */\n    create_response?: boolean;\n\n    /**\n     * Optional timeout after which a model response will be triggered automatically.\n     * This is useful for situations in which a long pause from the user is unexpected,\n     * such as a phone call. The model will effectively prompt the user to continue the\n     * conversation based on the current context.\n     *\n     * The timeout value will be applied after the last model response's audio has\n     * finished playing, i.e. it's set to the `response.done` time plus audio playback\n     * duration.\n     *\n     * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n     * Response) will be emitted when the timeout is reached. Idle timeout is currently\n     * only supported for `server_vad` mode.\n     */\n    idle_timeout_ms?: number | null;\n\n    /**\n     * Whether or not to automatically interrupt (cancel) any ongoing response with\n     * output to the default conversation (i.e. `conversation` of `auto`) when a VAD\n     * start event occurs. If `true` then the response will be cancelled, otherwise it\n     * will continue until complete.\n     *\n     * If both `create_response` and `interrupt_response` are set to `false`, the model\n     * will never respond automatically but VAD events will still be emitted.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  /**\n   * Server-side semantic turn detection which uses a model to determine when the\n   * user has finished speaking.\n   */\n  export interface SemanticVad {\n    /**\n     * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n     */\n    type: 'semantic_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n     * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n  }\n}\n\n/**\n * Realtime transcription session object configuration.\n */\nexport interface RealtimeTranscriptionSessionCreateRequest {\n  /**\n   * The type of session to create. Always `transcription` for transcription\n   * sessions.\n   */\n  type: 'transcription';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeTranscriptionSessionAudio;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n}\n\n/**\n * When the number of tokens in a conversation exceeds the model's input token\n * limit, the conversation be truncated, meaning messages (starting from the\n * oldest) will not be included in the model's context. A 32k context model with\n * 4,096 max output tokens can only include 28,224 tokens in the context before\n * truncation occurs.\n *\n * Clients can configure truncation behavior to truncate with a lower max token\n * limit, which is an effective way to control token usage and cost.\n *\n * Truncation will reduce the number of cached tokens on the next turn (busting the\n * cache), since messages are dropped from the beginning of the context. However,\n * clients can also configure truncation to retain messages up to a fraction of the\n * maximum context size, which will reduce the need for future truncations and thus\n * improve the cache rate.\n *\n * Truncation can be disabled entirely, which means the server will never truncate\n * but would instead return an error if the conversation exceeds the model's input\n * token limit.\n */\nexport type RealtimeTruncation = 'auto' | 'disabled' | RealtimeTruncationRetentionRatio;\n\n/**\n * Retain a fraction of the conversation tokens when the conversation exceeds the\n * input token limit. This allows you to amortize truncations across multiple\n * turns, which can help improve cached token usage.\n */\nexport interface RealtimeTruncationRetentionRatio {\n  /**\n   * Fraction of post-instruction conversation tokens to retain (`0.0` - `1.0`) when\n   * the conversation exceeds the input token limit. Setting this to `0.8` means that\n   * messages will be dropped until 80% of the maximum allowed tokens are used. This\n   * helps reduce the frequency of truncations and improve cache rates.\n   */\n  retention_ratio: number;\n\n  /**\n   * Use retention ratio truncation.\n   */\n  type: 'retention_ratio';\n\n  /**\n   * Optional custom token limits for this truncation strategy. If not provided, the\n   * model's default token limits will be used.\n   */\n  token_limits?: RealtimeTruncationRetentionRatio.TokenLimits;\n}\n\nexport namespace RealtimeTruncationRetentionRatio {\n  /**\n   * Optional custom token limits for this truncation strategy. If not provided, the\n   * model's default token limits will be used.\n   */\n  export interface TokenLimits {\n    /**\n     * Maximum tokens allowed in the conversation after instructions (which including\n     * tool definitions). For example, setting this to 5,000 would mean that truncation\n     * would occur when the conversation exceeds 5,000 tokens after instructions. This\n     * cannot be higher than the model's context window size minus the maximum output\n     * tokens.\n     */\n    post_instructions?: number;\n  }\n}\n\n/**\n * Returned when the model-generated audio is updated.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * Base64-encoded audio data delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_audio.delta`.\n   */\n  type: 'response.output_audio.delta';\n}\n\n/**\n * Returned when the model-generated audio is done. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_audio.done`.\n   */\n  type: 'response.output_audio.done';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is updated.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The transcript delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_audio_transcript.delta`.\n   */\n  type: 'response.output_audio_transcript.delta';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is done\n * streaming. Also emitted when a Response is interrupted, incomplete, or\n * cancelled.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final transcript of the audio.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `response.output_audio_transcript.done`.\n   */\n  type: 'response.output_audio_transcript.done';\n}\n\n/**\n * Send this event to cancel an in-progress response. The server will respond with\n * a `response.done` event with a status of `response.status=cancelled`. If there\n * is no response to cancel, the server will respond with an error. It's safe to\n * call `response.cancel` even if no response is in progress, an error will be\n * returned the session will remain unaffected.\n */\nexport interface ResponseCancelEvent {\n  /**\n   * The event type, must be `response.cancel`.\n   */\n  type: 'response.cancel';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * A specific response ID to cancel - if not provided, will cancel an in-progress\n   * response in the default conversation.\n   */\n  response_id?: string;\n}\n\n/**\n * Returned when a new content part is added to an assistant message item during\n * response generation.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item to which the content part was added.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseContentPartAddedEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\nexport namespace ResponseContentPartAddedEvent {\n  /**\n   * The content part that was added.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * Returned when a content part is done streaming in an assistant message item.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseContentPartDoneEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\nexport namespace ResponseContentPartDoneEvent {\n  /**\n   * The content part that is done.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * This event instructs the server to create a Response, which means triggering\n * model inference. When in Server VAD mode, the server will create Responses\n * automatically.\n *\n * A Response will include at least one Item, and may have two, in which case the\n * second will be a function call. These Items will be appended to the conversation\n * history by default.\n *\n * The server will respond with a `response.created` event, events for Items and\n * content created, and finally a `response.done` event to indicate the Response is\n * complete.\n *\n * The `response.create` event includes inference configuration like `instructions`\n * and `tools`. If these are set, they will override the Session's configuration\n * for this Response only.\n *\n * Responses can be created out-of-band of the default Conversation, meaning that\n * they can have arbitrary input, and it's possible to disable writing the output\n * to the Conversation. Only one Response can write to the default Conversation at\n * a time, but otherwise multiple Responses can be created in parallel. The\n * `metadata` field is a good way to disambiguate multiple simultaneous Responses.\n *\n * Clients can set `conversation` to `none` to create a Response that does not\n * write to the default Conversation. Arbitrary input can be provided with the\n * `input` field, which is an array accepting raw Items and references to existing\n * Items.\n */\nexport interface ResponseCreateEvent {\n  /**\n   * The event type, must be `response.create`.\n   */\n  type: 'response.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  response?: RealtimeResponseCreateParams;\n}\n\n/**\n * Returned when a new Response is created. The first event of response creation,\n * where the response is in an initial state of `in_progress`.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * Returned when a Response is done streaming. Always emitted, no matter the final\n * state. The Response object included in the `response.done` event will include\n * all output Items in the Response but will omit the raw audio data.\n *\n * Clients should check the `status` field of the Response to determine if it was\n * successful (`completed`) or if there was another outcome: `cancelled`, `failed`,\n * or `incomplete`.\n *\n * A response will contain all output items that were generated during the\n * response, excluding any audio content.\n */\nexport interface ResponseDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.done`.\n   */\n  type: 'response.done';\n}\n\n/**\n * Returned when the model-generated function call arguments are updated.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The arguments delta as a JSON string.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Returned when the model-generated function call arguments are done streaming.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The final arguments as a JSON string.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.done`.\n   */\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * Returned when MCP tool call arguments are updated during response generation.\n */\nexport interface ResponseMcpCallArgumentsDelta {\n  /**\n   * The JSON-encoded arguments delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.mcp_call_arguments.delta`.\n   */\n  type: 'response.mcp_call_arguments.delta';\n\n  /**\n   * If present, indicates the delta text was obfuscated.\n   */\n  obfuscation?: string | null;\n}\n\n/**\n * Returned when MCP tool call arguments are finalized during response generation.\n */\nexport interface ResponseMcpCallArgumentsDone {\n  /**\n   * The final JSON-encoded arguments string.\n   */\n  arguments: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.mcp_call_arguments.done`.\n   */\n  type: 'response.mcp_call_arguments.done';\n}\n\n/**\n * Returned when an MCP tool call has completed successfully.\n */\nexport interface ResponseMcpCallCompleted {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The event type, must be `response.mcp_call.completed`.\n   */\n  type: 'response.mcp_call.completed';\n}\n\n/**\n * Returned when an MCP tool call has failed.\n */\nexport interface ResponseMcpCallFailed {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The event type, must be `response.mcp_call.failed`.\n   */\n  type: 'response.mcp_call.failed';\n}\n\n/**\n * Returned when an MCP tool call has started and is in progress.\n */\nexport interface ResponseMcpCallInProgress {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The event type, must be `response.mcp_call.in_progress`.\n   */\n  type: 'response.mcp_call.in_progress';\n}\n\n/**\n * Returned when a new Item is created during Response generation.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Returned when an Item is done streaming. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * Returned when the text value of an \"output_text\" content part is updated.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The text delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_text.delta`.\n   */\n  type: 'response.output_text.delta';\n}\n\n/**\n * Returned when the text value of an \"output_text\" content part is done streaming.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final text content.\n   */\n  text: string;\n\n  /**\n   * The event type, must be `response.output_text.done`.\n   */\n  type: 'response.output_text.done';\n}\n\n/**\n * Returned when a Session is created. Emitted automatically when a new connection\n * is established as the first server event. This event will contain the default\n * Session configuration.\n */\nexport interface SessionCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The session configuration.\n   */\n  session: RealtimeSessionCreateRequest | RealtimeTranscriptionSessionCreateRequest;\n\n  /**\n   * The event type, must be `session.created`.\n   */\n  type: 'session.created';\n}\n\n/**\n * Send this event to update the sessions configuration. The client may send this\n * event at any time to update any field except for `voice` and `model`. `voice`\n * can be updated only if there have been no other audio outputs yet.\n *\n * When the server receives a `session.update`, it will respond with a\n * `session.updated` event showing the full, effective configuration. Only the\n * fields that are present in the `session.update` are updated. To clear a field\n * like `instructions`, pass an empty string. To clear a field like `tools`, pass\n * an empty array. To clear a field like `turn_detection`, pass `null`.\n */\nexport interface SessionUpdateEvent {\n  /**\n   * Update the Realtime session. Choose either a realtime session or a transcription\n   * session.\n   */\n  session: RealtimeSessionCreateRequest | RealtimeTranscriptionSessionCreateRequest;\n\n  /**\n   * The event type, must be `session.update`.\n   */\n  type: 'session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event. This is an arbitrary\n   * string that a client may assign. It will be passed back if there is an error\n   * with the event, but the corresponding `session.updated` event will not include\n   * it.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when a session is updated with a `session.update` event, unless there\n * is an error.\n */\nexport interface SessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The session configuration.\n   */\n  session: RealtimeSessionCreateRequest | RealtimeTranscriptionSessionCreateRequest;\n\n  /**\n   * The event type, must be `session.updated`.\n   */\n  type: 'session.updated';\n}\n\n/**\n * Send this event to update a transcription session.\n */\nexport interface TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  session: TranscriptionSessionUpdate.Session;\n\n  /**\n   * The event type, must be `transcription_session.update`.\n   */\n  type: 'transcription_session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\nexport namespace TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  export interface Session {\n    /**\n     * The set of items to include in the transcription. Current available items are:\n     * `item.input_audio_transcription.logprobs`\n     */\n    include?: Array<'item.input_audio_transcription.logprobs'>;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n     * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n     * (mono), and little-endian byte order.\n     */\n    input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n    /**\n     * Configuration for input audio transcription. The client can optionally set the\n     * language and prompt for transcription, these offer additional guidance to the\n     * transcription service.\n     */\n    input_audio_transcription?: RealtimeAPI.AudioTranscription;\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    turn_detection?: Session.TurnDetection;\n  }\n\n  export namespace Session {\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    export interface InputAudioNoiseReduction {\n      /**\n       * Type of noise reduction. `near_field` is for close-talking microphones such as\n       * headphones, `far_field` is for far-field microphones such as laptop or\n       * conference room microphones.\n       */\n      type?: RealtimeAPI.NoiseReductionType;\n    }\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    export interface TurnDetection {\n      /**\n       * Amount of audio to include before the VAD detected speech (in milliseconds).\n       * Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n       * With shorter values the model will respond more quickly, but may jump in on\n       * short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n       * threshold will require louder audio to activate the model, and thus might\n       * perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection. Only `server_vad` is currently supported for\n       * transcription sessions.\n       */\n      type?: 'server_vad';\n    }\n  }\n}\n\n/**\n * Returned when a transcription session is updated with a\n * `transcription_session.update` event, unless there is an error.\n */\nexport interface TranscriptionSessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A new Realtime transcription session configuration.\n   *\n   * When a session is created on the server via REST API, the session object also\n   * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n   * not present when a session is updated via the WebSocket API.\n   */\n  session: TranscriptionSessionUpdatedEvent.Session;\n\n  /**\n   * The event type, must be `transcription_session.updated`.\n   */\n  type: 'transcription_session.updated';\n}\n\nexport namespace TranscriptionSessionUpdatedEvent {\n  /**\n   * A new Realtime transcription session configuration.\n   *\n   * When a session is created on the server via REST API, the session object also\n   * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n   * not present when a session is updated via the WebSocket API.\n   */\n  export interface Session {\n    /**\n     * Ephemeral key returned by the API. Only present when the session is created on\n     * the server via REST API.\n     */\n    client_secret: Session.ClientSecret;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     */\n    input_audio_format?: string;\n\n    /**\n     * Configuration of the transcription model.\n     */\n    input_audio_transcription?: RealtimeAPI.AudioTranscription;\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    turn_detection?: Session.TurnDetection;\n  }\n\n  export namespace Session {\n    /**\n     * Ephemeral key returned by the API. Only present when the session is created on\n     * the server via REST API.\n     */\n    export interface ClientSecret {\n      /**\n       * Timestamp for when the token expires. Currently, all tokens expire after one\n       * minute.\n       */\n      expires_at: number;\n\n      /**\n       * Ephemeral key usable in client environments to authenticate connections to the\n       * Realtime API. Use this in client-side environments rather than a standard API\n       * token, which should only be used server-side.\n       */\n      value: string;\n    }\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    export interface TurnDetection {\n      /**\n       * Amount of audio to include before the VAD detected speech (in milliseconds).\n       * Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n       * With shorter values the model will respond more quickly, but may jump in on\n       * short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n       * threshold will require louder audio to activate the model, and thus might\n       * perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection, only `server_vad` is currently supported.\n       */\n      type?: string;\n    }\n  }\n}\n\nRealtime.ClientSecrets = ClientSecrets;\nRealtime.Calls = Calls;\n\nexport declare namespace Realtime {\n  export {\n    type AudioTranscription as AudioTranscription,\n    type ConversationCreatedEvent as ConversationCreatedEvent,\n    type ConversationItem as ConversationItem,\n    type ConversationItemAdded as ConversationItemAdded,\n    type ConversationItemCreateEvent as ConversationItemCreateEvent,\n    type ConversationItemCreatedEvent as ConversationItemCreatedEvent,\n    type ConversationItemDeleteEvent as ConversationItemDeleteEvent,\n    type ConversationItemDeletedEvent as ConversationItemDeletedEvent,\n    type ConversationItemDone as ConversationItemDone,\n    type ConversationItemInputAudioTranscriptionCompletedEvent as ConversationItemInputAudioTranscriptionCompletedEvent,\n    type ConversationItemInputAudioTranscriptionDeltaEvent as ConversationItemInputAudioTranscriptionDeltaEvent,\n    type ConversationItemInputAudioTranscriptionFailedEvent as ConversationItemInputAudioTranscriptionFailedEvent,\n    type ConversationItemInputAudioTranscriptionSegment as ConversationItemInputAudioTranscriptionSegment,\n    type ConversationItemRetrieveEvent as ConversationItemRetrieveEvent,\n    type ConversationItemTruncateEvent as ConversationItemTruncateEvent,\n    type ConversationItemTruncatedEvent as ConversationItemTruncatedEvent,\n    type ConversationItemWithReference as ConversationItemWithReference,\n    type InputAudioBufferAppendEvent as InputAudioBufferAppendEvent,\n    type InputAudioBufferClearEvent as InputAudioBufferClearEvent,\n    type InputAudioBufferClearedEvent as InputAudioBufferClearedEvent,\n    type InputAudioBufferCommitEvent as InputAudioBufferCommitEvent,\n    type InputAudioBufferCommittedEvent as InputAudioBufferCommittedEvent,\n    type InputAudioBufferDtmfEventReceivedEvent as InputAudioBufferDtmfEventReceivedEvent,\n    type InputAudioBufferSpeechStartedEvent as InputAudioBufferSpeechStartedEvent,\n    type InputAudioBufferSpeechStoppedEvent as InputAudioBufferSpeechStoppedEvent,\n    type InputAudioBufferTimeoutTriggered as InputAudioBufferTimeoutTriggered,\n    type LogProbProperties as LogProbProperties,\n    type McpListToolsCompleted as McpListToolsCompleted,\n    type McpListToolsFailed as McpListToolsFailed,\n    type McpListToolsInProgress as McpListToolsInProgress,\n    type NoiseReductionType as NoiseReductionType,\n    type OutputAudioBufferClearEvent as OutputAudioBufferClearEvent,\n    type RateLimitsUpdatedEvent as RateLimitsUpdatedEvent,\n    type RealtimeAudioConfig as RealtimeAudioConfig,\n    type RealtimeAudioConfigInput as RealtimeAudioConfigInput,\n    type RealtimeAudioConfigOutput as RealtimeAudioConfigOutput,\n    type RealtimeAudioFormats as RealtimeAudioFormats,\n    type RealtimeAudioInputTurnDetection as RealtimeAudioInputTurnDetection,\n    type RealtimeClientEvent as RealtimeClientEvent,\n    type RealtimeConversationItemAssistantMessage as RealtimeConversationItemAssistantMessage,\n    type RealtimeConversationItemFunctionCall as RealtimeConversationItemFunctionCall,\n    type RealtimeConversationItemFunctionCallOutput as RealtimeConversationItemFunctionCallOutput,\n    type RealtimeConversationItemSystemMessage as RealtimeConversationItemSystemMessage,\n    type RealtimeConversationItemUserMessage as RealtimeConversationItemUserMessage,\n    type RealtimeError as RealtimeError,\n    type RealtimeErrorEvent as RealtimeErrorEvent,\n    type RealtimeFunctionTool as RealtimeFunctionTool,\n    type RealtimeMcpApprovalRequest as RealtimeMcpApprovalRequest,\n    type RealtimeMcpApprovalResponse as RealtimeMcpApprovalResponse,\n    type RealtimeMcpListTools as RealtimeMcpListTools,\n    type RealtimeMcpProtocolError as RealtimeMcpProtocolError,\n    type RealtimeMcpToolCall as RealtimeMcpToolCall,\n    type RealtimeMcpToolExecutionError as RealtimeMcpToolExecutionError,\n    type RealtimeMcphttpError as RealtimeMcphttpError,\n    type RealtimeResponse as RealtimeResponse,\n    type RealtimeResponseCreateAudioOutput as RealtimeResponseCreateAudioOutput,\n    type RealtimeResponseCreateMcpTool as RealtimeResponseCreateMcpTool,\n    type RealtimeResponseCreateParams as RealtimeResponseCreateParams,\n    type RealtimeResponseStatus as RealtimeResponseStatus,\n    type RealtimeResponseUsage as RealtimeResponseUsage,\n    type RealtimeResponseUsageInputTokenDetails as RealtimeResponseUsageInputTokenDetails,\n    type RealtimeResponseUsageOutputTokenDetails as RealtimeResponseUsageOutputTokenDetails,\n    type RealtimeServerEvent as RealtimeServerEvent,\n    type RealtimeSession as RealtimeSession,\n    type RealtimeSessionCreateRequest as RealtimeSessionCreateRequest,\n    type RealtimeToolChoiceConfig as RealtimeToolChoiceConfig,\n    type RealtimeToolsConfig as RealtimeToolsConfig,\n    type RealtimeToolsConfigUnion as RealtimeToolsConfigUnion,\n    type RealtimeTracingConfig as RealtimeTracingConfig,\n    type RealtimeTranscriptionSessionAudio as RealtimeTranscriptionSessionAudio,\n    type RealtimeTranscriptionSessionAudioInput as RealtimeTranscriptionSessionAudioInput,\n    type RealtimeTranscriptionSessionAudioInputTurnDetection as RealtimeTranscriptionSessionAudioInputTurnDetection,\n    type RealtimeTranscriptionSessionCreateRequest as RealtimeTranscriptionSessionCreateRequest,\n    type RealtimeTruncation as RealtimeTruncation,\n    type RealtimeTruncationRetentionRatio as RealtimeTruncationRetentionRatio,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCancelEvent as ResponseCancelEvent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseCreateEvent as ResponseCreateEvent,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseDoneEvent as ResponseDoneEvent,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseMcpCallArgumentsDelta as ResponseMcpCallArgumentsDelta,\n    type ResponseMcpCallArgumentsDone as ResponseMcpCallArgumentsDone,\n    type ResponseMcpCallCompleted as ResponseMcpCallCompleted,\n    type ResponseMcpCallFailed as ResponseMcpCallFailed,\n    type ResponseMcpCallInProgress as ResponseMcpCallInProgress,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type SessionCreatedEvent as SessionCreatedEvent,\n    type SessionUpdateEvent as SessionUpdateEvent,\n    type SessionUpdatedEvent as SessionUpdatedEvent,\n    type TranscriptionSessionUpdate as TranscriptionSessionUpdate,\n    type TranscriptionSessionUpdatedEvent as TranscriptionSessionUpdatedEvent,\n  };\n\n  export {\n    ClientSecrets as ClientSecrets,\n    type RealtimeSessionClientSecret as RealtimeSessionClientSecret,\n    type RealtimeSessionCreateResponse as RealtimeSessionCreateResponse,\n    type RealtimeTranscriptionSessionCreateResponse as RealtimeTranscriptionSessionCreateResponse,\n    type RealtimeTranscriptionSessionTurnDetection as RealtimeTranscriptionSessionTurnDetection,\n    type ClientSecretCreateResponse as ClientSecretCreateResponse,\n    type ClientSecretCreateParams as ClientSecretCreateParams,\n  };\n\n  export {\n    Calls as Calls,\n    type CallAcceptParams as CallAcceptParams,\n    type CallReferParams as CallReferParams,\n    type CallRejectParams as CallRejectParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport * as BatchesAPI from './batches';\nimport * as Shared from './shared';\nimport { APIPromise } from '../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../core/pagination';\nimport { RequestOptions } from '../internal/request-options';\nimport { path } from '../internal/utils/path';\n\nexport class Batches extends APIResource {\n  /**\n   * Creates and executes a batch from an uploaded file of requests\n   */\n  create(body: BatchCreateParams, options?: RequestOptions): APIPromise<Batch> {\n    return this._client.post('/batches', { body, ...options });\n  }\n\n  /**\n   * Retrieves a batch.\n   */\n  retrieve(batchID: string, options?: RequestOptions): APIPromise<Batch> {\n    return this._client.get(path`/batches/${batchID}`, options);\n  }\n\n  /**\n   * List your organization's batches.\n   */\n  list(\n    query: BatchListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<BatchesPage, Batch> {\n    return this._client.getAPIList('/batches', CursorPage<Batch>, { query, ...options });\n  }\n\n  /**\n   * Cancels an in-progress batch. The batch will be in status `cancelling` for up to\n   * 10 minutes, before changing to `cancelled`, where it will have partial results\n   * (if any) available in the output file.\n   */\n  cancel(batchID: string, options?: RequestOptions): APIPromise<Batch> {\n    return this._client.post(path`/batches/${batchID}/cancel`, options);\n  }\n}\n\nexport type BatchesPage = CursorPage<Batch>;\n\nexport interface Batch {\n  id: string;\n\n  /**\n   * The time frame within which the batch should be processed.\n   */\n  completion_window: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was created.\n   */\n  created_at: number;\n\n  /**\n   * The OpenAI API endpoint used by the batch.\n   */\n  endpoint: string;\n\n  /**\n   * The ID of the input file for the batch.\n   */\n  input_file_id: string;\n\n  /**\n   * The object type, which is always `batch`.\n   */\n  object: 'batch';\n\n  /**\n   * The current status of the batch.\n   */\n  status:\n    | 'validating'\n    | 'failed'\n    | 'in_progress'\n    | 'finalizing'\n    | 'completed'\n    | 'expired'\n    | 'cancelling'\n    | 'cancelled';\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was cancelled.\n   */\n  cancelled_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started cancelling.\n   */\n  cancelling_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was completed.\n   */\n  completed_at?: number;\n\n  /**\n   * The ID of the file containing the outputs of requests with errors.\n   */\n  error_file_id?: string;\n\n  errors?: Batch.Errors;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch expired.\n   */\n  expired_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch failed.\n   */\n  failed_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started finalizing.\n   */\n  finalizing_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started processing.\n   */\n  in_progress_at?: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Model ID used to process the batch, like `gpt-5-2025-08-07`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model?: string;\n\n  /**\n   * The ID of the file containing the outputs of successfully executed requests.\n   */\n  output_file_id?: string;\n\n  /**\n   * The request counts for different statuses within the batch.\n   */\n  request_counts?: BatchRequestCounts;\n\n  /**\n   * Represents token usage details including input tokens, output tokens, a\n   * breakdown of output tokens, and the total tokens used. Only populated on batches\n   * created after September 7, 2025.\n   */\n  usage?: BatchUsage;\n}\n\nexport namespace Batch {\n  export interface Errors {\n    data?: Array<BatchesAPI.BatchError>;\n\n    /**\n     * The object type, which is always `list`.\n     */\n    object?: string;\n  }\n}\n\nexport interface BatchError {\n  /**\n   * An error code identifying the error type.\n   */\n  code?: string;\n\n  /**\n   * The line number of the input file where the error occurred, if applicable.\n   */\n  line?: number | null;\n\n  /**\n   * A human-readable message providing more details about the error.\n   */\n  message?: string;\n\n  /**\n   * The name of the parameter that caused the error, if applicable.\n   */\n  param?: string | null;\n}\n\n/**\n * The request counts for different statuses within the batch.\n */\nexport interface BatchRequestCounts {\n  /**\n   * Number of requests that have been completed successfully.\n   */\n  completed: number;\n\n  /**\n   * Number of requests that have failed.\n   */\n  failed: number;\n\n  /**\n   * Total number of requests in the batch.\n   */\n  total: number;\n}\n\n/**\n * Represents token usage details including input tokens, output tokens, a\n * breakdown of output tokens, and the total tokens used. Only populated on batches\n * created after September 7, 2025.\n */\nexport interface BatchUsage {\n  /**\n   * The number of input tokens.\n   */\n  input_tokens: number;\n\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  input_tokens_details: BatchUsage.InputTokensDetails;\n\n  /**\n   * The number of output tokens.\n   */\n  output_tokens: number;\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  output_tokens_details: BatchUsage.OutputTokensDetails;\n\n  /**\n   * The total number of tokens used.\n   */\n  total_tokens: number;\n}\n\nexport namespace BatchUsage {\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  export interface InputTokensDetails {\n    /**\n     * The number of tokens that were retrieved from the cache.\n     * [More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n     */\n    cached_tokens: number;\n  }\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  export interface OutputTokensDetails {\n    /**\n     * The number of reasoning tokens.\n     */\n    reasoning_tokens: number;\n  }\n}\n\nexport interface BatchCreateParams {\n  /**\n   * The time frame within which the batch should be processed. Currently only `24h`\n   * is supported.\n   */\n  completion_window: '24h';\n\n  /**\n   * The endpoint to be used for all requests in the batch. Currently\n   * `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, `/v1/completions`,\n   * and `/v1/moderations` are supported. Note that `/v1/embeddings` batches are also\n   * restricted to a maximum of 50,000 embedding inputs across all requests in the\n   * batch.\n   */\n  endpoint:\n    | '/v1/responses'\n    | '/v1/chat/completions'\n    | '/v1/embeddings'\n    | '/v1/completions'\n    | '/v1/moderations';\n\n  /**\n   * The ID of an uploaded file that contains requests for the new batch.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your input file must be formatted as a\n   * [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input),\n   * and must be uploaded with the purpose `batch`. The file can contain up to 50,000\n   * requests, and can be up to 200 MB in size.\n   */\n  input_file_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The expiration policy for the output and/or error file that are generated for a\n   * batch.\n   */\n  output_expires_after?: BatchCreateParams.OutputExpiresAfter;\n}\n\nexport namespace BatchCreateParams {\n  /**\n   * The expiration policy for the output and/or error file that are generated for a\n   * batch.\n   */\n  export interface OutputExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `created_at`. Note that the anchor is the file creation time, not the time the\n     * batch is created.\n     */\n    anchor: 'created_at';\n\n    /**\n     * The number of seconds after the anchor time that the file will expire. Must be\n     * between 3600 (1 hour) and 2592000 (30 days).\n     */\n    seconds: number;\n  }\n}\n\nexport interface BatchListParams extends CursorPageParams {}\n\nexport declare namespace Batches {\n  export {\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    type BatchUsage as BatchUsage,\n    type BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as Shared from '../../shared';\nimport * as GraderModelsAPI from '../../graders/grader-models';\nimport * as ResponsesAPI from '../../responses/responses';\nimport * as CompletionsAPI from '../../chat/completions/completions';\nimport * as OutputItemsAPI from './output-items';\nimport {\n  OutputItemListParams,\n  OutputItemListResponse,\n  OutputItemListResponsesPage,\n  OutputItemRetrieveParams,\n  OutputItemRetrieveResponse,\n  OutputItems,\n} from './output-items';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Runs extends APIResource {\n  outputItems: OutputItemsAPI.OutputItems = new OutputItemsAPI.OutputItems(this._client);\n\n  /**\n   * Kicks off a new run for a given evaluation, specifying the data source, and what\n   * model configuration to use to test. The datasource will be validated against the\n   * schema specified in the config of the evaluation.\n   */\n  create(evalID: string, body: RunCreateParams, options?: RequestOptions): APIPromise<RunCreateResponse> {\n    return this._client.post(path`/evals/${evalID}/runs`, { body, ...options });\n  }\n\n  /**\n   * Get an evaluation run by ID.\n   */\n  retrieve(\n    runID: string,\n    params: RunRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<RunRetrieveResponse> {\n    const { eval_id } = params;\n    return this._client.get(path`/evals/${eval_id}/runs/${runID}`, options);\n  }\n\n  /**\n   * Get a list of runs for an evaluation.\n   */\n  list(\n    evalID: string,\n    query: RunListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<RunListResponsesPage, RunListResponse> {\n    return this._client.getAPIList(path`/evals/${evalID}/runs`, CursorPage<RunListResponse>, {\n      query,\n      ...options,\n    });\n  }\n\n  /**\n   * Delete an eval run.\n   */\n  delete(runID: string, params: RunDeleteParams, options?: RequestOptions): APIPromise<RunDeleteResponse> {\n    const { eval_id } = params;\n    return this._client.delete(path`/evals/${eval_id}/runs/${runID}`, options);\n  }\n\n  /**\n   * Cancel an ongoing evaluation run.\n   */\n  cancel(runID: string, params: RunCancelParams, options?: RequestOptions): APIPromise<RunCancelResponse> {\n    const { eval_id } = params;\n    return this._client.post(path`/evals/${eval_id}/runs/${runID}`, options);\n  }\n}\n\nexport type RunListResponsesPage = CursorPage<RunListResponse>;\n\n/**\n * A CompletionsRunDataSource object describing a model sampling configuration.\n */\nexport interface CreateEvalCompletionsRunDataSource {\n  /**\n   * Determines what populates the `item` namespace in this run's data source.\n   */\n  source:\n    | CreateEvalCompletionsRunDataSource.FileContent\n    | CreateEvalCompletionsRunDataSource.FileID\n    | CreateEvalCompletionsRunDataSource.StoredCompletions;\n\n  /**\n   * The type of run data source. Always `completions`.\n   */\n  type: 'completions';\n\n  /**\n   * Used when sampling from a model. Dictates the structure of the messages passed\n   * into the model. Can either be a reference to a prebuilt trajectory (ie,\n   * `item.input_trajectory`), or a template with variable references to the `item`\n   * namespace.\n   */\n  input_messages?:\n    | CreateEvalCompletionsRunDataSource.Template\n    | CreateEvalCompletionsRunDataSource.ItemReference;\n\n  /**\n   * The name of the model to use for generating completions (e.g. \"o3-mini\").\n   */\n  model?: string;\n\n  sampling_params?: CreateEvalCompletionsRunDataSource.SamplingParams;\n}\n\nexport namespace CreateEvalCompletionsRunDataSource {\n  export interface FileContent {\n    /**\n     * The content of the jsonl file.\n     */\n    content: Array<FileContent.Content>;\n\n    /**\n     * The type of jsonl source. Always `file_content`.\n     */\n    type: 'file_content';\n  }\n\n  export namespace FileContent {\n    export interface Content {\n      item: { [key: string]: unknown };\n\n      sample?: { [key: string]: unknown };\n    }\n  }\n\n  export interface FileID {\n    /**\n     * The identifier of the file.\n     */\n    id: string;\n\n    /**\n     * The type of jsonl source. Always `file_id`.\n     */\n    type: 'file_id';\n  }\n\n  /**\n   * A StoredCompletionsRunDataSource configuration describing a set of filters\n   */\n  export interface StoredCompletions {\n    /**\n     * The type of source. Always `stored_completions`.\n     */\n    type: 'stored_completions';\n\n    /**\n     * An optional Unix timestamp to filter items created after this time.\n     */\n    created_after?: number | null;\n\n    /**\n     * An optional Unix timestamp to filter items created before this time.\n     */\n    created_before?: number | null;\n\n    /**\n     * An optional maximum number of items to return.\n     */\n    limit?: number | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * An optional model to filter by (e.g., 'gpt-4o').\n     */\n    model?: string | null;\n  }\n\n  export interface Template {\n    /**\n     * A list of chat messages forming the prompt or context. May include variable\n     * references to the `item` namespace, ie {{item.name}}.\n     */\n    template: Array<ResponsesAPI.EasyInputMessage | Template.EvalItem>;\n\n    /**\n     * The type of input messages. Always `template`.\n     */\n    type: 'template';\n  }\n\n  export namespace Template {\n    /**\n     * A message input to the model with a role indicating instruction following\n     * hierarchy. Instructions given with the `developer` or `system` role take\n     * precedence over instructions given with the `user` role. Messages with the\n     * `assistant` role are presumed to have been generated by the model in previous\n     * interactions.\n     */\n    export interface EvalItem {\n      /**\n       * Inputs to the model - can contain template strings. Supports text, output text,\n       * input images, and input audio, either as a single item or an array of items.\n       */\n      content:\n        | string\n        | ResponsesAPI.ResponseInputText\n        | EvalItem.OutputText\n        | EvalItem.InputImage\n        | ResponsesAPI.ResponseInputAudio\n        | GraderModelsAPI.GraderInputs;\n\n      /**\n       * The role of the message input. One of `user`, `assistant`, `system`, or\n       * `developer`.\n       */\n      role: 'user' | 'assistant' | 'system' | 'developer';\n\n      /**\n       * The type of the message input. Always `message`.\n       */\n      type?: 'message';\n    }\n\n    export namespace EvalItem {\n      /**\n       * A text output from the model.\n       */\n      export interface OutputText {\n        /**\n         * The text output from the model.\n         */\n        text: string;\n\n        /**\n         * The type of the output text. Always `output_text`.\n         */\n        type: 'output_text';\n      }\n\n      /**\n       * An image input block used within EvalItem content arrays.\n       */\n      export interface InputImage {\n        /**\n         * The URL of the image input.\n         */\n        image_url: string;\n\n        /**\n         * The type of the image input. Always `input_image`.\n         */\n        type: 'input_image';\n\n        /**\n         * The detail level of the image to be sent to the model. One of `high`, `low`, or\n         * `auto`. Defaults to `auto`.\n         */\n        detail?: string;\n      }\n    }\n  }\n\n  export interface ItemReference {\n    /**\n     * A reference to a variable in the `item` namespace. Ie, \"item.input_trajectory\"\n     */\n    item_reference: string;\n\n    /**\n     * The type of input messages. Always `item_reference`.\n     */\n    type: 'item_reference';\n  }\n\n  export interface SamplingParams {\n    /**\n     * The maximum number of tokens in the generated output.\n     */\n    max_completion_tokens?: number;\n\n    /**\n     * Constrains effort on reasoning for\n     * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n     * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n     * Reducing reasoning effort can result in faster responses and fewer tokens used\n     * on reasoning in a response.\n     *\n     * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n     *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n     *   calls are supported for all reasoning values in gpt-5.1.\n     * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n     *   support `none`.\n     * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n     * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n     */\n    reasoning_effort?: Shared.ReasoningEffort | null;\n\n    /**\n     * An object specifying the format that the model must output.\n     *\n     * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n     * Outputs which ensures the model will match your supplied JSON schema. Learn more\n     * in the\n     * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n     *\n     * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n     * ensures the message the model generates is valid JSON. Using `json_schema` is\n     * preferred for models that support it.\n     */\n    response_format?:\n      | Shared.ResponseFormatText\n      | Shared.ResponseFormatJSONSchema\n      | Shared.ResponseFormatJSONObject;\n\n    /**\n     * A seed value to initialize the randomness, during sampling.\n     */\n    seed?: number;\n\n    /**\n     * A higher temperature increases randomness in the outputs.\n     */\n    temperature?: number;\n\n    /**\n     * A list of tools the model may call. Currently, only functions are supported as a\n     * tool. Use this to provide a list of functions the model may generate JSON inputs\n     * for. A max of 128 functions are supported.\n     */\n    tools?: Array<CompletionsAPI.ChatCompletionFunctionTool>;\n\n    /**\n     * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n     */\n    top_p?: number;\n  }\n}\n\n/**\n * A JsonlRunDataSource object with that specifies a JSONL file that matches the\n * eval\n */\nexport interface CreateEvalJSONLRunDataSource {\n  /**\n   * Determines what populates the `item` namespace in the data source.\n   */\n  source: CreateEvalJSONLRunDataSource.FileContent | CreateEvalJSONLRunDataSource.FileID;\n\n  /**\n   * The type of data source. Always `jsonl`.\n   */\n  type: 'jsonl';\n}\n\nexport namespace CreateEvalJSONLRunDataSource {\n  export interface FileContent {\n    /**\n     * The content of the jsonl file.\n     */\n    content: Array<FileContent.Content>;\n\n    /**\n     * The type of jsonl source. Always `file_content`.\n     */\n    type: 'file_content';\n  }\n\n  export namespace FileContent {\n    export interface Content {\n      item: { [key: string]: unknown };\n\n      sample?: { [key: string]: unknown };\n    }\n  }\n\n  export interface FileID {\n    /**\n     * The identifier of the file.\n     */\n    id: string;\n\n    /**\n     * The type of jsonl source. Always `file_id`.\n     */\n    type: 'file_id';\n  }\n}\n\n/**\n * An object representing an error response from the Eval API.\n */\nexport interface EvalAPIError {\n  /**\n   * The error code.\n   */\n  code: string;\n\n  /**\n   * The error message.\n   */\n  message: string;\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunCreateResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunCreateResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunCreateResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunCreateResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunCreateResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunCreateResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings. Supports text, output text,\n         * input images, and input audio, either as a single item or an array of items.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | GraderModelsAPI.GraderInputs;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input block used within EvalItem content arrays.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunRetrieveResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunRetrieveResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunRetrieveResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunRetrieveResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunRetrieveResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunRetrieveResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings. Supports text, output text,\n         * input images, and input audio, either as a single item or an array of items.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | GraderModelsAPI.GraderInputs;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input block used within EvalItem content arrays.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunListResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source: CreateEvalJSONLRunDataSource | CreateEvalCompletionsRunDataSource | RunListResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunListResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunListResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunListResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunListResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings. Supports text, output text,\n         * input images, and input audio, either as a single item or an array of items.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | GraderModelsAPI.GraderInputs;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input block used within EvalItem content arrays.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\nexport interface RunDeleteResponse {\n  deleted?: boolean;\n\n  object?: string;\n\n  run_id?: string;\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunCancelResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunCancelResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunCancelResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunCancelResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunCancelResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunCancelResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings. Supports text, output text,\n         * input images, and input audio, either as a single item or an array of items.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | GraderModelsAPI.GraderInputs;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input block used within EvalItem content arrays.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\nexport interface RunCreateParams {\n  /**\n   * Details about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunCreateParams.CreateEvalResponsesRunDataSource;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the run.\n   */\n  name?: string;\n}\n\nexport namespace RunCreateParams {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface CreateEvalResponsesRunDataSource {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source:\n      | CreateEvalResponsesRunDataSource.FileContent\n      | CreateEvalResponsesRunDataSource.FileID\n      | CreateEvalResponsesRunDataSource.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?:\n      | CreateEvalResponsesRunDataSource.Template\n      | CreateEvalResponsesRunDataSource.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: CreateEvalResponsesRunDataSource.SamplingParams;\n  }\n\n  export namespace CreateEvalResponsesRunDataSource {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings. Supports text, output text,\n         * input images, and input audio, either as a single item or an array of items.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | GraderModelsAPI.GraderInputs;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input block used within EvalItem content arrays.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n       * Reducing reasoning effort can result in faster responses and fewer tokens used\n       * on reasoning in a response.\n       *\n       * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n       *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n       *   calls are supported for all reasoning values in gpt-5.1.\n       * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n       *   support `none`.\n       * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n       * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n}\n\nexport interface RunRetrieveParams {\n  /**\n   * The ID of the evaluation to retrieve runs for.\n   */\n  eval_id: string;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * Sort order for runs by timestamp. Use `asc` for ascending order or `desc` for\n   * descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter runs by status. One of `queued` | `in_progress` | `failed` | `completed`\n   * | `canceled`.\n   */\n  status?: 'queued' | 'in_progress' | 'completed' | 'canceled' | 'failed';\n}\n\nexport interface RunDeleteParams {\n  /**\n   * The ID of the evaluation to delete the run from.\n   */\n  eval_id: string;\n}\n\nexport interface RunCancelParams {\n  /**\n   * The ID of the evaluation whose run you want to cancel.\n   */\n  eval_id: string;\n}\n\nRuns.OutputItems = OutputItems;\n\nexport declare namespace Runs {\n  export {\n    type CreateEvalCompletionsRunDataSource as CreateEvalCompletionsRunDataSource,\n    type CreateEvalJSONLRunDataSource as CreateEvalJSONLRunDataSource,\n    type EvalAPIError as EvalAPIError,\n    type RunCreateResponse as RunCreateResponse,\n    type RunRetrieveResponse as RunRetrieveResponse,\n    type RunListResponse as RunListResponse,\n    type RunDeleteResponse as RunDeleteResponse,\n    type RunCancelResponse as RunCancelResponse,\n    type RunListResponsesPage as RunListResponsesPage,\n    type RunCreateParams as RunCreateParams,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunListParams as RunListParams,\n    type RunDeleteParams as RunDeleteParams,\n    type RunCancelParams as RunCancelParams,\n  };\n\n  export {\n    OutputItems as OutputItems,\n    type OutputItemRetrieveResponse as OutputItemRetrieveResponse,\n    type OutputItemListResponse as OutputItemListResponse,\n    type OutputItemListResponsesPage as OutputItemListResponsesPage,\n    type OutputItemRetrieveParams as OutputItemRetrieveParams,\n    type OutputItemListParams as OutputItemListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as Shared from '../../shared';\nimport * as MethodsAPI from '../methods';\nimport * as CheckpointsAPI from './checkpoints';\nimport {\n  CheckpointListParams,\n  Checkpoints,\n  FineTuningJobCheckpoint,\n  FineTuningJobCheckpointsPage,\n} from './checkpoints';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Jobs extends APIResource {\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n\n  /**\n   * Creates a fine-tuning job which begins the process of creating a new model from\n   * a given dataset.\n   *\n   * Response includes details of the enqueued job including job status and the name\n   * of the fine-tuned models once complete.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.create({\n   *   model: 'gpt-4o-mini',\n   *   training_file: 'file-abc123',\n   * });\n   * ```\n   */\n  create(body: JobCreateParams, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post('/fine_tuning/jobs', { body, ...options });\n  }\n\n  /**\n   * Get info about a fine-tuning job.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.retrieve(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  retrieve(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.get(path`/fine_tuning/jobs/${fineTuningJobID}`, options);\n  }\n\n  /**\n   * List your organization's fine-tuning jobs\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const fineTuningJob of client.fineTuning.jobs.list()) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    query: JobListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FineTuningJobsPage, FineTuningJob> {\n    return this._client.getAPIList('/fine_tuning/jobs', CursorPage<FineTuningJob>, { query, ...options });\n  }\n\n  /**\n   * Immediately cancel a fine-tune job.\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.cancel(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  cancel(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/cancel`, options);\n  }\n\n  /**\n   * Get status updates for a fine-tuning job.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const fineTuningJobEvent of client.fineTuning.jobs.listEvents(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  listEvents(\n    fineTuningJobID: string,\n    query: JobListEventsParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FineTuningJobEventsPage, FineTuningJobEvent> {\n    return this._client.getAPIList(\n      path`/fine_tuning/jobs/${fineTuningJobID}/events`,\n      CursorPage<FineTuningJobEvent>,\n      { query, ...options },\n    );\n  }\n\n  /**\n   * Pause a fine-tune job.\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.pause(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  pause(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/pause`, options);\n  }\n\n  /**\n   * Resume a fine-tune job.\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.resume(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  resume(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/resume`, options);\n  }\n}\n\nexport type FineTuningJobsPage = CursorPage<FineTuningJob>;\n\nexport type FineTuningJobEventsPage = CursorPage<FineTuningJobEvent>;\n\n/**\n * The `fine_tuning.job` object represents a fine-tuning job that has been created\n * through the API.\n */\nexport interface FineTuningJob {\n  /**\n   * The object identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  error: FineTuningJob.Error | null;\n\n  /**\n   * The name of the fine-tuned model that is being created. The value will be null\n   * if the fine-tuning job is still running.\n   */\n  fine_tuned_model: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The\n   * value will be null if the fine-tuning job is still running.\n   */\n  finished_at: number | null;\n\n  /**\n   * The hyperparameters used for the fine-tuning job. This value will only be\n   * returned when running `supervised` jobs.\n   */\n  hyperparameters: FineTuningJob.Hyperparameters;\n\n  /**\n   * The base model that is being fine-tuned.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job\".\n   */\n  object: 'fine_tuning.job';\n\n  /**\n   * The organization that owns the fine-tuning job.\n   */\n  organization_id: string;\n\n  /**\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the\n   * results with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  result_files: Array<string>;\n\n  /**\n   * The seed used for the fine-tuning job.\n   */\n  seed: number;\n\n  /**\n   * The current status of the fine-tuning job, which can be either\n   * `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\n   */\n  status: 'validating_files' | 'queued' | 'running' | 'succeeded' | 'failed' | 'cancelled';\n\n  /**\n   * The total number of billable tokens processed by this fine-tuning job. The value\n   * will be null if the fine-tuning job is still running.\n   */\n  trained_tokens: number | null;\n\n  /**\n   * The file ID used for training. You can retrieve the training data with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  training_file: string;\n\n  /**\n   * The file ID used for validation. You can retrieve the validation results with\n   * the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  validation_file: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job is estimated to\n   * finish. The value will be null if the fine-tuning job is not running.\n   */\n  estimated_finish?: number | null;\n\n  /**\n   * A list of integrations to enable for this fine-tuning job.\n   */\n  integrations?: Array<FineTuningJobWandbIntegrationObject> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The method used for fine-tuning.\n   */\n  method?: FineTuningJob.Method;\n}\n\nexport namespace FineTuningJob {\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  export interface Error {\n    /**\n     * A machine-readable error code.\n     */\n    code: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The parameter that was invalid, usually `training_file` or `validation_file`.\n     * This field will be null if the failure was not parameter-specific.\n     */\n    param: string | null;\n  }\n\n  /**\n   * The hyperparameters used for the fine-tuning job. This value will only be\n   * returned when running `supervised` jobs.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number | null;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  /**\n   * The method used for fine-tuning.\n   */\n  export interface Method {\n    /**\n     * The type of method. Is either `supervised`, `dpo`, or `reinforcement`.\n     */\n    type: 'supervised' | 'dpo' | 'reinforcement';\n\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    dpo?: MethodsAPI.DpoMethod;\n\n    /**\n     * Configuration for the reinforcement fine-tuning method.\n     */\n    reinforcement?: MethodsAPI.ReinforcementMethod;\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    supervised?: MethodsAPI.SupervisedMethod;\n  }\n}\n\n/**\n * Fine-tuning job event object\n */\nexport interface FineTuningJobEvent {\n  /**\n   * The object identifier.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * The log level of the event.\n   */\n  level: 'info' | 'warn' | 'error';\n\n  /**\n   * The message of the event.\n   */\n  message: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.event\".\n   */\n  object: 'fine_tuning.job.event';\n\n  /**\n   * The data associated with the event.\n   */\n  data?: unknown;\n\n  /**\n   * The type of event.\n   */\n  type?: 'message' | 'metrics';\n}\n\n/**\n * The settings for your integration with Weights and Biases. This payload\n * specifies the project that metrics will be sent to. Optionally, you can set an\n * explicit display name for your run, add tags to your run, and set a default\n * entity (team, username, etc) to be associated with your run.\n */\nexport interface FineTuningJobWandbIntegration {\n  /**\n   * The name of the project that the new run will be created under.\n   */\n  project: string;\n\n  /**\n   * The entity to use for the run. This allows you to set the team or username of\n   * the WandB user that you would like associated with the run. If not set, the\n   * default entity for the registered WandB API key is used.\n   */\n  entity?: string | null;\n\n  /**\n   * A display name to set for the run. If not set, we will use the Job ID as the\n   * name.\n   */\n  name?: string | null;\n\n  /**\n   * A list of tags to be attached to the newly created run. These tags are passed\n   * through directly to WandB. Some default tags are generated by OpenAI:\n   * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n   */\n  tags?: Array<string>;\n}\n\nexport interface FineTuningJobWandbIntegrationObject {\n  /**\n   * The type of the integration being enabled for the fine-tuning job\n   */\n  type: 'wandb';\n\n  /**\n   * The settings for your integration with Weights and Biases. This payload\n   * specifies the project that metrics will be sent to. Optionally, you can set an\n   * explicit display name for your run, add tags to your run, and set a default\n   * entity (team, username, etc) to be associated with your run.\n   */\n  wandb: FineTuningJobWandbIntegration;\n}\n\nexport type FineTuningJobIntegration = FineTuningJobWandbIntegrationObject;\n\nexport interface JobCreateParams {\n  /**\n   * The name of the model to fine-tune. You can select one of the\n   * [supported models](https://platform.openai.com/docs/guides/fine-tuning#which-models-can-be-fine-tuned).\n   */\n  model: (string & {}) | 'babbage-002' | 'davinci-002' | 'gpt-3.5-turbo' | 'gpt-4o-mini';\n\n  /**\n   * The ID of an uploaded file that contains training data.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your dataset must be formatted as a JSONL file. Additionally, you must upload\n   * your file with the purpose `fine-tune`.\n   *\n   * The contents of the file should differ depending on if the model uses the\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input),\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * format, or if the fine-tuning method uses the\n   * [preference](https://platform.openai.com/docs/api-reference/fine-tuning/preference-input)\n   * format.\n   *\n   * See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization)\n   * for more details.\n   */\n  training_file: string;\n\n  /**\n   * @deprecated The hyperparameters used for the fine-tuning job. This value is now\n   * deprecated in favor of `method`, and should be passed in under the `method`\n   * parameter.\n   */\n  hyperparameters?: JobCreateParams.Hyperparameters;\n\n  /**\n   * A list of integrations to enable for your fine-tuning job.\n   */\n  integrations?: Array<JobCreateParams.Integration> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The method used for fine-tuning.\n   */\n  method?: JobCreateParams.Method;\n\n  /**\n   * The seed controls the reproducibility of the job. Passing in the same seed and\n   * job parameters should produce the same results, but may differ in rare cases. If\n   * a seed is not specified, one will be generated for you.\n   */\n  seed?: number | null;\n\n  /**\n   * A string of up to 64 characters that will be added to your fine-tuned model\n   * name.\n   *\n   * For example, a `suffix` of \"custom-model-name\" would produce a model name like\n   * `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n   */\n  suffix?: string | null;\n\n  /**\n   * The ID of an uploaded file that contains validation data.\n   *\n   * If you provide this file, the data is used to generate validation metrics\n   * periodically during fine-tuning. These metrics can be viewed in the fine-tuning\n   * results file. The same data should not be present in both train and validation\n   * files.\n   *\n   * Your dataset must be formatted as a JSONL file. You must upload your file with\n   * the purpose `fine-tune`.\n   *\n   * See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization)\n   * for more details.\n   */\n  validation_file?: string | null;\n}\n\nexport namespace JobCreateParams {\n  /**\n   * @deprecated The hyperparameters used for the fine-tuning job. This value is now\n   * deprecated in favor of `method`, and should be passed in under the `method`\n   * parameter.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  export interface Integration {\n    /**\n     * The type of integration to enable. Currently, only \"wandb\" (Weights and Biases)\n     * is supported.\n     */\n    type: 'wandb';\n\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    wandb: Integration.Wandb;\n  }\n\n  export namespace Integration {\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    export interface Wandb {\n      /**\n       * The name of the project that the new run will be created under.\n       */\n      project: string;\n\n      /**\n       * The entity to use for the run. This allows you to set the team or username of\n       * the WandB user that you would like associated with the run. If not set, the\n       * default entity for the registered WandB API key is used.\n       */\n      entity?: string | null;\n\n      /**\n       * A display name to set for the run. If not set, we will use the Job ID as the\n       * name.\n       */\n      name?: string | null;\n\n      /**\n       * A list of tags to be attached to the newly created run. These tags are passed\n       * through directly to WandB. Some default tags are generated by OpenAI:\n       * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n       */\n      tags?: Array<string>;\n    }\n  }\n\n  /**\n   * The method used for fine-tuning.\n   */\n  export interface Method {\n    /**\n     * The type of method. Is either `supervised`, `dpo`, or `reinforcement`.\n     */\n    type: 'supervised' | 'dpo' | 'reinforcement';\n\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    dpo?: MethodsAPI.DpoMethod;\n\n    /**\n     * Configuration for the reinforcement fine-tuning method.\n     */\n    reinforcement?: MethodsAPI.ReinforcementMethod;\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    supervised?: MethodsAPI.SupervisedMethod;\n  }\n}\n\nexport interface JobListParams extends CursorPageParams {\n  /**\n   * Optional metadata filter. To filter, use the syntax `metadata[k]=v`.\n   * Alternatively, set `metadata=null` to indicate no metadata.\n   */\n  metadata?: { [key: string]: string } | null;\n}\n\nexport interface JobListEventsParams extends CursorPageParams {}\n\nJobs.Checkpoints = Checkpoints;\n\nexport declare namespace Jobs {\n  export {\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobsPage as FineTuningJobsPage,\n    type FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n\n  export {\n    Checkpoints as Checkpoints,\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    type FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { type OpenAI } from '../client';\n\nimport { type PromiseOrValue } from '../internal/types';\nimport {\n  type APIResponseProps,\n  defaultParseResponse,\n  type WithRequestID,\n  addRequestID,\n} from '../internal/parse';\n\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nexport class APIPromise<T> extends Promise<WithRequestID<T>> {\n  private parsedPromise: Promise<WithRequestID<T>> | undefined;\n  #client: OpenAI;\n\n  constructor(\n    client: OpenAI,\n    private responsePromise: Promise<APIResponseProps>,\n    private parseResponse: (\n      client: OpenAI,\n      props: APIResponseProps,\n    ) => PromiseOrValue<WithRequestID<T>> = defaultParseResponse,\n  ) {\n    super((resolve) => {\n      // this is maybe a bit weird but this has to be a no-op to not implicitly\n      // parse the response body; instead .then, .catch, .finally are overridden\n      // to parse the response\n      resolve(null as any);\n    });\n    this.#client = client;\n  }\n\n  _thenUnwrap<U>(transform: (data: T, props: APIResponseProps) => U): APIPromise<U> {\n    return new APIPromise(this.#client, this.responsePromise, async (client, props) =>\n      addRequestID(transform(await this.parseResponse(client, props), props), props.response),\n    );\n  }\n\n  /**\n   * Gets the raw `Response` instance instead of parsing the response\n   * data.\n   *\n   * If you want to parse the response body but still get the `Response`\n   * instance, you can use {@link withResponse()}.\n   *\n   *  Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` or add `\"lib\": [\"DOM\"]`\n   * to your `tsconfig.json`.\n   */\n  asResponse(): Promise<Response> {\n    return this.responsePromise.then((p) => p.response);\n  }\n\n  /**\n   * Gets the parsed response data, the raw `Response` instance and the ID of the request,\n   * returned via the X-Request-ID header which is useful for debugging requests and reporting\n   * issues to OpenAI.\n   *\n   * If you just want to get the raw `Response` instance without parsing it,\n   * you can use {@link asResponse()}.\n   *\n   *  Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` or add `\"lib\": [\"DOM\"]`\n   * to your `tsconfig.json`.\n   */\n  async withResponse(): Promise<{ data: T; response: Response; request_id: string | null }> {\n    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n    return { data, response, request_id: response.headers.get('x-request-id') };\n  }\n\n  private parse(): Promise<WithRequestID<T>> {\n    if (!this.parsedPromise) {\n      this.parsedPromise = this.responsePromise.then((data) =>\n        this.parseResponse(this.#client, data),\n      ) as any as Promise<WithRequestID<T>>;\n    }\n    return this.parsedPromise;\n  }\n\n  override then<TResult1 = WithRequestID<T>, TResult2 = never>(\n    onfulfilled?: ((value: WithRequestID<T>) => TResult1 | PromiseLike<TResult1>) | undefined | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null,\n  ): Promise<TResult1 | TResult2> {\n    return this.parse().then(onfulfilled, onrejected);\n  }\n\n  override catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null,\n  ): Promise<WithRequestID<T> | TResult> {\n    return this.parse().catch(onrejected);\n  }\n\n  override finally(onfinally?: (() => void) | undefined | null): Promise<WithRequestID<T>> {\n    return this.parse().finally(onfinally);\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as CompletionsAPI from './completions/completions';\nimport {\n  ChatCompletion,\n  ChatCompletionAllowedToolChoice,\n  ChatCompletionAllowedTools,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionCustomTool,\n  ChatCompletionDeleted,\n  ChatCompletionDeveloperMessageParam,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionFunctionTool,\n  ChatCompletionListParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageCustomToolCall,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionNamedToolChoiceCustom,\n  ChatCompletionPredictionContent,\n  ChatCompletionReasoningEffort,\n  ChatCompletionRole,\n  ChatCompletionStoreMessage,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUpdateParams,\n  ChatCompletionUserMessageParam,\n  ChatCompletionsPage,\n  Completions,\n} from './completions/completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport type ChatModel = Shared.ChatModel;\n\nChat.Completions = Completions;\n\nexport declare namespace Chat {\n  export { type ChatModel as ChatModel };\n\n  export {\n    Completions as Completions,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAllowedToolChoice as ChatCompletionAllowedToolChoice,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionCustomTool as ChatCompletionCustomTool,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionFunctionTool as ChatCompletionFunctionTool,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageCustomToolCall as ChatCompletionMessageCustomToolCall,\n    type ChatCompletionMessageFunctionToolCall as ChatCompletionMessageFunctionToolCall,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionNamedToolChoiceCustom as ChatCompletionNamedToolChoiceCustom,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type ChatCompletionAllowedTools as ChatCompletionAllowedTools,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    type ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n  };\n}\n","import { OpenAIError } from '../../core/error';\n\n/**\n * Percent-encode everything that isn't safe to have in a path without encoding safe chars.\n *\n * Taken from https://datatracker.ietf.org/doc/html/rfc3986#section-3.3:\n * > unreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n * > sub-delims  = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\" / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n * > pchar       = unreserved / pct-encoded / sub-delims / \":\" / \"@\"\n */\nexport function encodeURIPath(str: string) {\n  return str.replace(/[^A-Za-z0-9\\-._~!$&'()*+,;=:@]+/g, encodeURIComponent);\n}\n\nconst EMPTY = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.create(null));\n\nexport const createPathTagFunction = (pathEncoder = encodeURIPath) =>\n  function path(statics: readonly string[], ...params: readonly unknown[]): string {\n    // If there are no params, no processing is needed.\n    if (statics.length === 1) return statics[0]!;\n\n    let postPath = false;\n    const invalidSegments = [];\n    const path = statics.reduce((previousValue, currentValue, index) => {\n      if (/[?#]/.test(currentValue)) {\n        postPath = true;\n      }\n      const value = params[index];\n      let encoded = (postPath ? encodeURIComponent : pathEncoder)('' + value);\n      if (\n        index !== params.length &&\n        (value == null ||\n          (typeof value === 'object' &&\n            // handle values from other realms\n            value.toString ===\n              Object.getPrototypeOf(Object.getPrototypeOf((value as any).hasOwnProperty ?? EMPTY) ?? EMPTY)\n                ?.toString))\n      ) {\n        encoded = value + '';\n        invalidSegments.push({\n          start: previousValue.length + currentValue.length,\n          length: encoded.length,\n          error: `Value of type ${Object.prototype.toString\n            .call(value)\n            .slice(8, -1)} is not a valid path parameter`,\n        });\n      }\n      return previousValue + currentValue + (index === params.length ? '' : encoded);\n    }, '');\n\n    const pathOnly = path.split(/[?#]/, 1)[0]!;\n    const invalidSegmentPattern = /(?<=^|\\/)(?:\\.|%2e){1,2}(?=\\/|$)/gi;\n    let match;\n\n    // Find all invalid segments\n    while ((match = invalidSegmentPattern.exec(pathOnly)) !== null) {\n      invalidSegments.push({\n        start: match.index,\n        length: match[0].length,\n        error: `Value \"${match[0]}\" can\\'t be safely passed as a path parameter`,\n      });\n    }\n\n    invalidSegments.sort((a, b) => a.start - b.start);\n\n    if (invalidSegments.length > 0) {\n      let lastEnd = 0;\n      const underline = invalidSegments.reduce((acc, segment) => {\n        const spaces = ' '.repeat(segment.start - lastEnd);\n        const arrows = '^'.repeat(segment.length);\n        lastEnd = segment.start + segment.length;\n        return acc + spaces + arrows;\n      }, '');\n\n      throw new OpenAIError(\n        `Path parameters result in path with invalid segments:\\n${invalidSegments\n          .map((e) => e.error)\n          .join('\\n')}\\n${path}\\n${underline}`,\n      );\n    }\n\n    return path;\n  };\n\n/**\n * URI-encodes path params and ensures no unsafe /./ or /../ path segments are introduced.\n */\nexport const path = /* @__PURE__ */ createPathTagFunction(encodeURIPath);\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as ConversationsAPI from './conversations';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport {\n  ConversationCursorPage,\n  type ConversationCursorPageParams,\n  PagePromise,\n} from '../../core/pagination';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Items extends APIResource {\n  /**\n   * Create items in a conversation with the given ID.\n   */\n  create(\n    conversationID: string,\n    params: ItemCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<ConversationItemList> {\n    const { include, ...body } = params;\n    return this._client.post(path`/conversations/${conversationID}/items`, {\n      query: { include },\n      body,\n      ...options,\n    });\n  }\n\n  /**\n   * Get a single item from a conversation with the given IDs.\n   */\n  retrieve(\n    itemID: string,\n    params: ItemRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<ConversationItem> {\n    const { conversation_id, ...query } = params;\n    return this._client.get(path`/conversations/${conversation_id}/items/${itemID}`, { query, ...options });\n  }\n\n  /**\n   * List all items for a conversation with the given ID.\n   */\n  list(\n    conversationID: string,\n    query: ItemListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ConversationItemsPage, ConversationItem> {\n    return this._client.getAPIList(\n      path`/conversations/${conversationID}/items`,\n      ConversationCursorPage<ConversationItem>,\n      { query, ...options },\n    );\n  }\n\n  /**\n   * Delete an item from a conversation with the given IDs.\n   */\n  delete(\n    itemID: string,\n    params: ItemDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<ConversationsAPI.Conversation> {\n    const { conversation_id } = params;\n    return this._client.delete(path`/conversations/${conversation_id}/items/${itemID}`, options);\n  }\n}\n\nexport type ConversationItemsPage = ConversationCursorPage<ConversationItem>;\n\n/**\n * A single item within a conversation. The set of possible types are the same as\n * the `output` type of a\n * [Response object](https://platform.openai.com/docs/api-reference/responses/object#responses/object-output).\n */\nexport type ConversationItem =\n  | ConversationsAPI.Message\n  | ResponsesAPI.ResponseFunctionToolCallItem\n  | ResponsesAPI.ResponseFunctionToolCallOutputItem\n  | ResponsesAPI.ResponseFileSearchToolCall\n  | ResponsesAPI.ResponseFunctionWebSearch\n  | ConversationItem.ImageGenerationCall\n  | ResponsesAPI.ResponseComputerToolCall\n  | ResponsesAPI.ResponseComputerToolCallOutputItem\n  | ResponsesAPI.ResponseReasoningItem\n  | ResponsesAPI.ResponseCodeInterpreterToolCall\n  | ConversationItem.LocalShellCall\n  | ConversationItem.LocalShellCallOutput\n  | ResponsesAPI.ResponseFunctionShellToolCall\n  | ResponsesAPI.ResponseFunctionShellToolCallOutput\n  | ResponsesAPI.ResponseApplyPatchToolCall\n  | ResponsesAPI.ResponseApplyPatchToolCallOutput\n  | ConversationItem.McpListTools\n  | ConversationItem.McpApprovalRequest\n  | ConversationItem.McpApprovalResponse\n  | ConversationItem.McpCall\n  | ResponsesAPI.ResponseCustomToolCall\n  | ResponsesAPI.ResponseCustomToolCallOutput;\n\nexport namespace ConversationItem {\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * The output of a local shell tool call.\n   */\n  export interface LocalShellCallOutput {\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the output of the local shell tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the local shell tool call output. Always `local_shell_call_output`.\n     */\n    type: 'local_shell_call_output';\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n\n  /**\n   * A response to an MCP approval request.\n   */\n  export interface McpApprovalResponse {\n    /**\n     * The unique ID of the approval response\n     */\n    id: string;\n\n    /**\n     * The ID of the approval request being answered.\n     */\n    approval_request_id: string;\n\n    /**\n     * Whether the request was approved.\n     */\n    approve: boolean;\n\n    /**\n     * The type of the item. Always `mcp_approval_response`.\n     */\n    type: 'mcp_approval_response';\n\n    /**\n     * Optional reason for the decision.\n     */\n    reason?: string | null;\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n}\n\n/**\n * A list of Conversation items.\n */\nexport interface ConversationItemList {\n  /**\n   * A list of conversation items.\n   */\n  data: Array<ConversationItem>;\n\n  /**\n   * The ID of the first item in the list.\n   */\n  first_id: string;\n\n  /**\n   * Whether there are more items available.\n   */\n  has_more: boolean;\n\n  /**\n   * The ID of the last item in the list.\n   */\n  last_id: string;\n\n  /**\n   * The type of object returned, must be `list`.\n   */\n  object: 'list';\n}\n\nexport interface ItemCreateParams {\n  /**\n   * Body param: The items to add to the conversation. You may add up to 20 items at\n   * a time.\n   */\n  items: Array<ResponsesAPI.ResponseInputItem>;\n\n  /**\n   * Query param: Additional fields to include in the response. See the `include`\n   * parameter for\n   * [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include)\n   * for more information.\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n}\n\nexport interface ItemRetrieveParams {\n  /**\n   * Path param: The ID of the conversation that contains the item.\n   */\n  conversation_id: string;\n\n  /**\n   * Query param: Additional fields to include in the response. See the `include`\n   * parameter for\n   * [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include)\n   * for more information.\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n}\n\nexport interface ItemListParams extends ConversationCursorPageParams {\n  /**\n   * Specify additional output data to include in the model response. Currently\n   * supported values are:\n   *\n   * - `web_search_call.action.sources`: Include the sources of the web search tool\n   *   call.\n   * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n   *   in code interpreter tool call items.\n   * - `computer_call_output.output.image_url`: Include image urls from the computer\n   *   call output.\n   * - `file_search_call.results`: Include the search results of the file search tool\n   *   call.\n   * - `message.input_image.image_url`: Include image urls from the input message.\n   * - `message.output_text.logprobs`: Include logprobs with assistant messages.\n   * - `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n   *   tokens in reasoning item outputs. This enables reasoning items to be used in\n   *   multi-turn conversations when using the Responses API statelessly (like when\n   *   the `store` parameter is set to `false`, or when an organization is enrolled\n   *   in the zero data retention program).\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n\n  /**\n   * The order to return the input items in. Default is `desc`.\n   *\n   * - `asc`: Return the input items in ascending order.\n   * - `desc`: Return the input items in descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface ItemDeleteParams {\n  /**\n   * The ID of the conversation that contains the item.\n   */\n  conversation_id: string;\n}\n\nexport declare namespace Items {\n  export {\n    type ConversationItem as ConversationItem,\n    type ConversationItemList as ConversationItemList,\n    type ConversationItemsPage as ConversationItemsPage,\n    type ItemCreateParams as ItemCreateParams,\n    type ItemRetrieveParams as ItemRetrieveParams,\n    type ItemListParams as ItemListParams,\n    type ItemDeleteParams as ItemDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as MethodsAPI from './methods';\nimport {\n  DpoHyperparameters,\n  DpoMethod,\n  Methods,\n  ReinforcementHyperparameters,\n  ReinforcementMethod,\n  SupervisedHyperparameters,\n  SupervisedMethod,\n} from './methods';\nimport * as AlphaAPI from './alpha/alpha';\nimport { Alpha } from './alpha/alpha';\nimport * as CheckpointsAPI from './checkpoints/checkpoints';\nimport { Checkpoints } from './checkpoints/checkpoints';\nimport * as JobsAPI from './jobs/jobs';\nimport {\n  FineTuningJob,\n  FineTuningJobEvent,\n  FineTuningJobEventsPage,\n  FineTuningJobIntegration,\n  FineTuningJobWandbIntegration,\n  FineTuningJobWandbIntegrationObject,\n  FineTuningJobsPage,\n  JobCreateParams,\n  JobListEventsParams,\n  JobListParams,\n  Jobs,\n} from './jobs/jobs';\n\nexport class FineTuning extends APIResource {\n  methods: MethodsAPI.Methods = new MethodsAPI.Methods(this._client);\n  jobs: JobsAPI.Jobs = new JobsAPI.Jobs(this._client);\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n  alpha: AlphaAPI.Alpha = new AlphaAPI.Alpha(this._client);\n}\n\nFineTuning.Methods = Methods;\nFineTuning.Jobs = Jobs;\nFineTuning.Checkpoints = Checkpoints;\nFineTuning.Alpha = Alpha;\n\nexport declare namespace FineTuning {\n  export {\n    Methods as Methods,\n    type DpoHyperparameters as DpoHyperparameters,\n    type DpoMethod as DpoMethod,\n    type ReinforcementHyperparameters as ReinforcementHyperparameters,\n    type ReinforcementMethod as ReinforcementMethod,\n    type SupervisedHyperparameters as SupervisedHyperparameters,\n    type SupervisedMethod as SupervisedMethod,\n  };\n\n  export {\n    Jobs as Jobs,\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobsPage as FineTuningJobsPage,\n    type FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n\n  export { Checkpoints as Checkpoints };\n\n  export { Alpha as Alpha };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as SessionsAPI from './sessions';\nimport { SessionCreateParams, Sessions } from './sessions';\nimport * as ThreadsAPI from './threads';\nimport {\n  ChatKitAttachment,\n  ChatKitResponseOutputText,\n  ChatKitThread,\n  ChatKitThreadAssistantMessageItem,\n  ChatKitThreadItemList,\n  ChatKitThreadItemListDataPage,\n  ChatKitThreadUserMessageItem,\n  ChatKitThreadsPage,\n  ChatKitWidgetItem,\n  ChatSession,\n  ChatSessionAutomaticThreadTitling,\n  ChatSessionChatKitConfiguration,\n  ChatSessionChatKitConfigurationParam,\n  ChatSessionExpiresAfterParam,\n  ChatSessionFileUpload,\n  ChatSessionHistory,\n  ChatSessionRateLimits,\n  ChatSessionRateLimitsParam,\n  ChatSessionStatus,\n  ChatSessionWorkflowParam,\n  ThreadDeleteResponse,\n  ThreadListItemsParams,\n  ThreadListParams,\n  Threads,\n} from './threads';\n\nexport class ChatKit extends APIResource {\n  sessions: SessionsAPI.Sessions = new SessionsAPI.Sessions(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\n/**\n * Workflow metadata and state returned for the session.\n */\nexport interface ChatKitWorkflow {\n  /**\n   * Identifier of the workflow backing the session.\n   */\n  id: string;\n\n  /**\n   * State variable key-value pairs applied when invoking the workflow. Defaults to\n   * null when no overrides were provided.\n   */\n  state_variables: { [key: string]: string | boolean | number } | null;\n\n  /**\n   * Tracing settings applied to the workflow.\n   */\n  tracing: ChatKitWorkflow.Tracing;\n\n  /**\n   * Specific workflow version used for the session. Defaults to null when using the\n   * latest deployment.\n   */\n  version: string | null;\n}\n\nexport namespace ChatKitWorkflow {\n  /**\n   * Tracing settings applied to the workflow.\n   */\n  export interface Tracing {\n    /**\n     * Indicates whether tracing is enabled.\n     */\n    enabled: boolean;\n  }\n}\n\nChatKit.Sessions = Sessions;\nChatKit.Threads = Threads;\n\nexport declare namespace ChatKit {\n  export { type ChatKitWorkflow as ChatKitWorkflow };\n\n  export { Sessions as Sessions, type SessionCreateParams as SessionCreateParams };\n\n  export {\n    Threads as Threads,\n    type ChatSession as ChatSession,\n    type ChatSessionAutomaticThreadTitling as ChatSessionAutomaticThreadTitling,\n    type ChatSessionChatKitConfiguration as ChatSessionChatKitConfiguration,\n    type ChatSessionChatKitConfigurationParam as ChatSessionChatKitConfigurationParam,\n    type ChatSessionExpiresAfterParam as ChatSessionExpiresAfterParam,\n    type ChatSessionFileUpload as ChatSessionFileUpload,\n    type ChatSessionHistory as ChatSessionHistory,\n    type ChatSessionRateLimits as ChatSessionRateLimits,\n    type ChatSessionRateLimitsParam as ChatSessionRateLimitsParam,\n    type ChatSessionStatus as ChatSessionStatus,\n    type ChatSessionWorkflowParam as ChatSessionWorkflowParam,\n    type ChatKitAttachment as ChatKitAttachment,\n    type ChatKitResponseOutputText as ChatKitResponseOutputText,\n    type ChatKitThread as ChatKitThread,\n    type ChatKitThreadAssistantMessageItem as ChatKitThreadAssistantMessageItem,\n    type ChatKitThreadItemList as ChatKitThreadItemList,\n    type ChatKitThreadUserMessageItem as ChatKitThreadUserMessageItem,\n    type ChatKitWidgetItem as ChatKitWidgetItem,\n    type ThreadDeleteResponse as ThreadDeleteResponse,\n    type ChatKitThreadsPage as ChatKitThreadsPage,\n    type ChatKitThreadItemListDataPage as ChatKitThreadItemListDataPage,\n    type ThreadListParams as ThreadListParams,\n    type ThreadListItemsParams as ThreadListItemsParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nexport const readEnv = (env: string): string | undefined => {\n  if (typeof (globalThis as any).process !== 'undefined') {\n    return (globalThis as any).process.env?.[env]?.trim() ?? undefined;\n  }\n  if (typeof (globalThis as any).Deno !== 'undefined') {\n    return (globalThis as any).Deno.env?.get?.(env)?.trim();\n  }\n  return undefined;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Content extends APIResource {\n  /**\n   * Retrieve Container File Content\n   */\n  retrieve(fileID: string, params: ContentRetrieveParams, options?: RequestOptions): APIPromise<Response> {\n    const { container_id } = params;\n    return this._client.get(path`/containers/${container_id}/files/${fileID}/content`, {\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/binary' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n}\n\nexport interface ContentRetrieveParams {\n  container_id: string;\n}\n\nexport declare namespace Content {\n  export { type ContentRetrieveParams as ContentRetrieveParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as RunsAPI from './runs';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class OutputItems extends APIResource {\n  /**\n   * Get an evaluation run output item by ID.\n   */\n  retrieve(\n    outputItemID: string,\n    params: OutputItemRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<OutputItemRetrieveResponse> {\n    const { eval_id, run_id } = params;\n    return this._client.get(path`/evals/${eval_id}/runs/${run_id}/output_items/${outputItemID}`, options);\n  }\n\n  /**\n   * Get a list of output items for an evaluation run.\n   */\n  list(\n    runID: string,\n    params: OutputItemListParams,\n    options?: RequestOptions,\n  ): PagePromise<OutputItemListResponsesPage, OutputItemListResponse> {\n    const { eval_id, ...query } = params;\n    return this._client.getAPIList(\n      path`/evals/${eval_id}/runs/${runID}/output_items`,\n      CursorPage<OutputItemListResponse>,\n      { query, ...options },\n    );\n  }\n}\n\nexport type OutputItemListResponsesPage = CursorPage<OutputItemListResponse>;\n\n/**\n * A schema representing an evaluation run output item.\n */\nexport interface OutputItemRetrieveResponse {\n  /**\n   * Unique identifier for the evaluation run output item.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Details of the input data source item.\n   */\n  datasource_item: { [key: string]: unknown };\n\n  /**\n   * The identifier for the data source item.\n   */\n  datasource_item_id: number;\n\n  /**\n   * The identifier of the evaluation group.\n   */\n  eval_id: string;\n\n  /**\n   * The type of the object. Always \"eval.run.output_item\".\n   */\n  object: 'eval.run.output_item';\n\n  /**\n   * A list of grader results for this output item.\n   */\n  results: Array<OutputItemRetrieveResponse.Result>;\n\n  /**\n   * The identifier of the evaluation run associated with this output item.\n   */\n  run_id: string;\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  sample: OutputItemRetrieveResponse.Sample;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace OutputItemRetrieveResponse {\n  /**\n   * A single grader result for an evaluation run output item.\n   */\n  export interface Result {\n    /**\n     * The name of the grader.\n     */\n    name: string;\n\n    /**\n     * Whether the grader considered the output a pass.\n     */\n    passed: boolean;\n\n    /**\n     * The numeric score produced by the grader.\n     */\n    score: number;\n\n    /**\n     * Optional sample or intermediate data produced by the grader.\n     */\n    sample?: { [key: string]: unknown } | null;\n\n    /**\n     * The grader type (for example, \"string-check-grader\").\n     */\n    type?: string;\n\n    [k: string]: unknown;\n  }\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  export interface Sample {\n    /**\n     * An object representing an error response from the Eval API.\n     */\n    error: RunsAPI.EvalAPIError;\n\n    /**\n     * The reason why the sample generation was finished.\n     */\n    finish_reason: string;\n\n    /**\n     * An array of input messages.\n     */\n    input: Array<Sample.Input>;\n\n    /**\n     * The maximum number of tokens allowed for completion.\n     */\n    max_completion_tokens: number;\n\n    /**\n     * The model used for generating the sample.\n     */\n    model: string;\n\n    /**\n     * An array of output messages.\n     */\n    output: Array<Sample.Output>;\n\n    /**\n     * The seed used for generating the sample.\n     */\n    seed: number;\n\n    /**\n     * The sampling temperature used.\n     */\n    temperature: number;\n\n    /**\n     * The top_p value used for sampling.\n     */\n    top_p: number;\n\n    /**\n     * Token usage details for the sample.\n     */\n    usage: Sample.Usage;\n  }\n\n  export namespace Sample {\n    /**\n     * An input message.\n     */\n    export interface Input {\n      /**\n       * The content of the message.\n       */\n      content: string;\n\n      /**\n       * The role of the message sender (e.g., system, user, developer).\n       */\n      role: string;\n    }\n\n    export interface Output {\n      /**\n       * The content of the message.\n       */\n      content?: string;\n\n      /**\n       * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n       */\n      role?: string;\n    }\n\n    /**\n     * Token usage details for the sample.\n     */\n    export interface Usage {\n      /**\n       * The number of tokens retrieved from cache.\n       */\n      cached_tokens: number;\n\n      /**\n       * The number of completion tokens generated.\n       */\n      completion_tokens: number;\n\n      /**\n       * The number of prompt tokens used.\n       */\n      prompt_tokens: number;\n\n      /**\n       * The total number of tokens used.\n       */\n      total_tokens: number;\n    }\n  }\n}\n\n/**\n * A schema representing an evaluation run output item.\n */\nexport interface OutputItemListResponse {\n  /**\n   * Unique identifier for the evaluation run output item.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Details of the input data source item.\n   */\n  datasource_item: { [key: string]: unknown };\n\n  /**\n   * The identifier for the data source item.\n   */\n  datasource_item_id: number;\n\n  /**\n   * The identifier of the evaluation group.\n   */\n  eval_id: string;\n\n  /**\n   * The type of the object. Always \"eval.run.output_item\".\n   */\n  object: 'eval.run.output_item';\n\n  /**\n   * A list of grader results for this output item.\n   */\n  results: Array<OutputItemListResponse.Result>;\n\n  /**\n   * The identifier of the evaluation run associated with this output item.\n   */\n  run_id: string;\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  sample: OutputItemListResponse.Sample;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace OutputItemListResponse {\n  /**\n   * A single grader result for an evaluation run output item.\n   */\n  export interface Result {\n    /**\n     * The name of the grader.\n     */\n    name: string;\n\n    /**\n     * Whether the grader considered the output a pass.\n     */\n    passed: boolean;\n\n    /**\n     * The numeric score produced by the grader.\n     */\n    score: number;\n\n    /**\n     * Optional sample or intermediate data produced by the grader.\n     */\n    sample?: { [key: string]: unknown } | null;\n\n    /**\n     * The grader type (for example, \"string-check-grader\").\n     */\n    type?: string;\n\n    [k: string]: unknown;\n  }\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  export interface Sample {\n    /**\n     * An object representing an error response from the Eval API.\n     */\n    error: RunsAPI.EvalAPIError;\n\n    /**\n     * The reason why the sample generation was finished.\n     */\n    finish_reason: string;\n\n    /**\n     * An array of input messages.\n     */\n    input: Array<Sample.Input>;\n\n    /**\n     * The maximum number of tokens allowed for completion.\n     */\n    max_completion_tokens: number;\n\n    /**\n     * The model used for generating the sample.\n     */\n    model: string;\n\n    /**\n     * An array of output messages.\n     */\n    output: Array<Sample.Output>;\n\n    /**\n     * The seed used for generating the sample.\n     */\n    seed: number;\n\n    /**\n     * The sampling temperature used.\n     */\n    temperature: number;\n\n    /**\n     * The top_p value used for sampling.\n     */\n    top_p: number;\n\n    /**\n     * Token usage details for the sample.\n     */\n    usage: Sample.Usage;\n  }\n\n  export namespace Sample {\n    /**\n     * An input message.\n     */\n    export interface Input {\n      /**\n       * The content of the message.\n       */\n      content: string;\n\n      /**\n       * The role of the message sender (e.g., system, user, developer).\n       */\n      role: string;\n    }\n\n    export interface Output {\n      /**\n       * The content of the message.\n       */\n      content?: string;\n\n      /**\n       * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n       */\n      role?: string;\n    }\n\n    /**\n     * Token usage details for the sample.\n     */\n    export interface Usage {\n      /**\n       * The number of tokens retrieved from cache.\n       */\n      cached_tokens: number;\n\n      /**\n       * The number of completion tokens generated.\n       */\n      completion_tokens: number;\n\n      /**\n       * The number of prompt tokens used.\n       */\n      prompt_tokens: number;\n\n      /**\n       * The total number of tokens used.\n       */\n      total_tokens: number;\n    }\n  }\n}\n\nexport interface OutputItemRetrieveParams {\n  /**\n   * The ID of the evaluation to retrieve runs for.\n   */\n  eval_id: string;\n\n  /**\n   * The ID of the run to retrieve.\n   */\n  run_id: string;\n}\n\nexport interface OutputItemListParams extends CursorPageParams {\n  /**\n   * Path param: The ID of the evaluation to retrieve runs for.\n   */\n  eval_id: string;\n\n  /**\n   * Query param: Sort order for output items by timestamp. Use `asc` for ascending\n   * order or `desc` for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Query param: Filter output items by status. Use `failed` to filter by failed\n   * output items or `pass` to filter by passed output items.\n   */\n  status?: 'fail' | 'pass';\n}\n\nexport declare namespace OutputItems {\n  export {\n    type OutputItemRetrieveResponse as OutputItemRetrieveResponse,\n    type OutputItemListResponse as OutputItemListResponse,\n    type OutputItemListResponsesPage as OutputItemListResponsesPage,\n    type OutputItemRetrieveParams as OutputItemRetrieveParams,\n    type OutputItemListParams as OutputItemListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as VectorStoresAPI from './vector-stores';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise, Page } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { sleep } from '../../internal/utils';\nimport { Uploadable } from '../../uploads';\nimport { path } from '../../internal/utils/path';\n\nexport class Files extends APIResource {\n  /**\n   * Create a vector store file by attaching a\n   * [File](https://platform.openai.com/docs/api-reference/files) to a\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n   */\n  create(\n    vectorStoreID: string,\n    body: FileCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFile> {\n    return this._client.post(path`/vector_stores/${vectorStoreID}/files`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a vector store file.\n   */\n  retrieve(\n    fileID: string,\n    params: FileRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFile> {\n    const { vector_store_id } = params;\n    return this._client.get(path`/vector_stores/${vector_store_id}/files/${fileID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Update attributes on a vector store file.\n   */\n  update(fileID: string, params: FileUpdateParams, options?: RequestOptions): APIPromise<VectorStoreFile> {\n    const { vector_store_id, ...body } = params;\n    return this._client.post(path`/vector_stores/${vector_store_id}/files/${fileID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of vector store files.\n   */\n  list(\n    vectorStoreID: string,\n    query: FileListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<VectorStoreFilesPage, VectorStoreFile> {\n    return this._client.getAPIList(path`/vector_stores/${vectorStoreID}/files`, CursorPage<VectorStoreFile>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a vector store file. This will remove the file from the vector store but\n   * the file itself will not be deleted. To delete the file, use the\n   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n   * endpoint.\n   */\n  delete(\n    fileID: string,\n    params: FileDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileDeleted> {\n    const { vector_store_id } = params;\n    return this._client.delete(path`/vector_stores/${vector_store_id}/files/${fileID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Attach a file to the given vector store and wait for it to be processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const file = await this.create(vectorStoreId, body, options);\n    return await this.poll(vectorStoreId, file.id, options);\n  }\n  /**\n   * Wait for the vector store file to finish processing.\n   *\n   * Note: this will return even if the file failed to process, you need to check\n   * file.last_error and file.status to handle these cases\n   */\n  async poll(\n    vectorStoreID: string,\n    fileID: string,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const headers = buildHeaders([\n      options?.headers,\n      {\n        'X-Stainless-Poll-Helper': 'true',\n        'X-Stainless-Custom-Poll-Interval': options?.pollIntervalMs?.toString() ?? undefined,\n      },\n    ]);\n\n    while (true) {\n      const fileResponse = await this.retrieve(\n        fileID,\n        {\n          vector_store_id: vectorStoreID,\n        },\n        { ...options, headers },\n      ).withResponse();\n\n      const file = fileResponse.data;\n\n      switch (file.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'completed':\n          return file;\n      }\n    }\n  }\n  /**\n   * Upload a file to the `files` API and then attach it to the given vector store.\n   *\n   * Note the file will be asynchronously processed (you can use the alternative\n   * polling helper method to wait for processing to complete).\n   */\n  async upload(vectorStoreId: string, file: Uploadable, options?: RequestOptions): Promise<VectorStoreFile> {\n    const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n  }\n  /**\n   * Add a file to a vector store and poll until processing is complete.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this.upload(vectorStoreId, file, options);\n    return await this.poll(vectorStoreId, fileInfo.id, options);\n  }\n\n  /**\n   * Retrieve the parsed contents of a vector store file.\n   */\n  content(\n    fileID: string,\n    params: FileContentParams,\n    options?: RequestOptions,\n  ): PagePromise<FileContentResponsesPage, FileContentResponse> {\n    const { vector_store_id } = params;\n    return this._client.getAPIList(\n      path`/vector_stores/${vector_store_id}/files/${fileID}/content`,\n      Page<FileContentResponse>,\n      { ...options, headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]) },\n    );\n  }\n}\n\nexport type VectorStoreFilesPage = CursorPage<VectorStoreFile>;\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type FileContentResponsesPage = Page<FileContentResponse>;\n\n/**\n * A list of files attached to a vector store.\n */\nexport interface VectorStoreFile {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store file was created.\n   */\n  created_at: number;\n\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  last_error: VectorStoreFile.LastError | null;\n\n  /**\n   * The object type, which is always `vector_store.file`.\n   */\n  object: 'vector_store.file';\n\n  /**\n   * The status of the vector store file, which can be either `in_progress`,\n   * `completed`, `cancelled`, or `failed`. The status `completed` indicates that the\n   * vector store file is ready for use.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The total vector store usage in bytes. Note that this may be different from the\n   * original file size.\n   */\n  usage_bytes: number;\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * The strategy used to chunk the file.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategy;\n}\n\nexport namespace VectorStoreFile {\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `unsupported_file`, or `invalid_file`.\n     */\n    code: 'server_error' | 'unsupported_file' | 'invalid_file';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n}\n\nexport interface VectorStoreFileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.file.deleted';\n}\n\nexport interface FileContentResponse {\n  /**\n   * The text content\n   */\n  text?: string;\n\n  /**\n   * The content type (currently only `\"text\"`)\n   */\n  type?: string;\n}\n\nexport interface FileCreateParams {\n  /**\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n   * vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileRetrieveParams {\n  /**\n   * The ID of the vector store that the file belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileUpdateParams {\n  /**\n   * Path param: The ID of the vector store the file belongs to.\n   */\n  vector_store_id: string;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard. Keys are\n   * strings with a maximum length of 64 characters. Values are strings with a\n   * maximum length of 512 characters, booleans, or numbers.\n   */\n  attributes: { [key: string]: string | number | boolean } | null;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface FileDeleteParams {\n  /**\n   * The ID of the vector store that the file belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileContentParams {\n  /**\n   * The ID of the vector store.\n   */\n  vector_store_id: string;\n}\n\nexport declare namespace Files {\n  export {\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    type FileContentResponse as FileContentResponse,\n    type VectorStoreFilesPage as VectorStoreFilesPage,\n    type FileContentResponsesPage as FileContentResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileUpdateParams as FileUpdateParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n    type FileContentParams as FileContentParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as ClientSecretsAPI from './client-secrets';\nimport * as RealtimeAPI from './realtime';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\n\nexport class ClientSecrets extends APIResource {\n  /**\n   * Create a Realtime client secret with an associated session configuration.\n   *\n   * @example\n   * ```ts\n   * const clientSecret =\n   *   await client.realtime.clientSecrets.create();\n   * ```\n   */\n  create(body: ClientSecretCreateParams, options?: RequestOptions): APIPromise<ClientSecretCreateResponse> {\n    return this._client.post('/realtime/client_secrets', { body, ...options });\n  }\n}\n\n/**\n * Ephemeral key returned by the API.\n */\nexport interface RealtimeSessionClientSecret {\n  /**\n   * Timestamp for when the token expires. Currently, all tokens expire after one\n   * minute.\n   */\n  expires_at: number;\n\n  /**\n   * Ephemeral key usable in client environments to authenticate connections to the\n   * Realtime API. Use this in client-side environments rather than a standard API\n   * token, which should only be used server-side.\n   */\n  value: string;\n}\n\n/**\n * A new Realtime session configuration, with an ephemeral key. Default TTL for\n * keys is one minute.\n */\nexport interface RealtimeSessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  client_secret: RealtimeSessionClientSecret;\n\n  /**\n   * The type of session to create. Always `realtime` for the Realtime API.\n   */\n  type: 'realtime';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeSessionCreateResponse.Audio;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-realtime-mini-2025-12-15'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06'\n    | 'gpt-audio-mini-2025-12-15';\n\n  /**\n   * The set of modalities the model can respond with. It defaults to `[\"audio\"]`,\n   * indicating that the model will respond with audio plus a transcript. `[\"text\"]`\n   * can be used to make the model respond with text only. It is not possible to\n   * request both `text` and `audio` at the same time.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: ResponsesAPI.ToolChoiceOptions | ResponsesAPI.ToolChoiceFunction | ResponsesAPI.ToolChoiceMcp;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: Array<RealtimeAPI.RealtimeFunctionTool | RealtimeSessionCreateResponse.McpTool>;\n\n  /**\n   * Realtime API can write session traces to the\n   * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n   * tracing is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | RealtimeSessionCreateResponse.TracingConfiguration | null;\n\n  /**\n   * When the number of tokens in a conversation exceeds the model's input token\n   * limit, the conversation be truncated, meaning messages (starting from the\n   * oldest) will not be included in the model's context. A 32k context model with\n   * 4,096 max output tokens can only include 28,224 tokens in the context before\n   * truncation occurs.\n   *\n   * Clients can configure truncation behavior to truncate with a lower max token\n   * limit, which is an effective way to control token usage and cost.\n   *\n   * Truncation will reduce the number of cached tokens on the next turn (busting the\n   * cache), since messages are dropped from the beginning of the context. However,\n   * clients can also configure truncation to retain messages up to a fraction of the\n   * maximum context size, which will reduce the need for future truncations and thus\n   * improve the cache rate.\n   *\n   * Truncation can be disabled entirely, which means the server will never truncate\n   * but would instead return an error if the conversation exceeds the model's input\n   * token limit.\n   */\n  truncation?: RealtimeAPI.RealtimeTruncation;\n}\n\nexport namespace RealtimeSessionCreateResponse {\n  /**\n   * Configuration for input and output audio.\n   */\n  export interface Audio {\n    input?: Audio.Input;\n\n    output?: Audio.Output;\n  }\n\n  export namespace Audio {\n    export interface Input {\n      /**\n       * The format of the input audio.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * Configuration for input audio noise reduction. This can be set to `null` to turn\n       * off. Noise reduction filters audio added to the input audio buffer before it is\n       * sent to VAD and the model. Filtering the audio can improve VAD and turn\n       * detection accuracy (reducing false positives) and model performance by improving\n       * perception of the input audio.\n       */\n      noise_reduction?: Input.NoiseReduction;\n\n      /**\n       * Configuration for input audio transcription, defaults to off and can be set to\n       * `null` to turn off once on. Input audio transcription is not native to the\n       * model, since the model consumes audio directly. Transcription runs\n       * asynchronously through\n       * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n       * and should be treated as guidance of input audio content rather than precisely\n       * what the model heard. The client can optionally set the language and prompt for\n       * transcription, these offer additional guidance to the transcription service.\n       */\n      transcription?: RealtimeAPI.AudioTranscription;\n\n      /**\n       * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n       * set to `null` to turn off, in which case the client must manually trigger model\n       * response.\n       *\n       * Server VAD means that the model will detect the start and end of speech based on\n       * audio volume and respond at the end of user speech.\n       *\n       * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n       * with VAD) to semantically estimate whether the user has finished speaking, then\n       * dynamically sets a timeout based on this probability. For example, if user audio\n       * trails off with \"uhhm\", the model will score a low probability of turn end and\n       * wait longer for the user to continue speaking. This can be useful for more\n       * natural conversations, but may have a higher latency.\n       */\n      turn_detection?: Input.ServerVad | Input.SemanticVad | null;\n    }\n\n    export namespace Input {\n      /**\n       * Configuration for input audio noise reduction. This can be set to `null` to turn\n       * off. Noise reduction filters audio added to the input audio buffer before it is\n       * sent to VAD and the model. Filtering the audio can improve VAD and turn\n       * detection accuracy (reducing false positives) and model performance by improving\n       * perception of the input audio.\n       */\n      export interface NoiseReduction {\n        /**\n         * Type of noise reduction. `near_field` is for close-talking microphones such as\n         * headphones, `far_field` is for far-field microphones such as laptop or\n         * conference room microphones.\n         */\n        type?: RealtimeAPI.NoiseReductionType;\n      }\n\n      /**\n       * Server-side voice activity detection (VAD) which flips on when user speech is\n       * detected and off after a period of silence.\n       */\n      export interface ServerVad {\n        /**\n         * Type of turn detection, `server_vad` to turn on simple Server VAD.\n         */\n        type: 'server_vad';\n\n        /**\n         * Whether or not to automatically generate a response when a VAD stop event\n         * occurs. If `interrupt_response` is set to `false` this may fail to create a\n         * response if the model is already responding.\n         *\n         * If both `create_response` and `interrupt_response` are set to `false`, the model\n         * will never respond automatically but VAD events will still be emitted.\n         */\n        create_response?: boolean;\n\n        /**\n         * Optional timeout after which a model response will be triggered automatically.\n         * This is useful for situations in which a long pause from the user is unexpected,\n         * such as a phone call. The model will effectively prompt the user to continue the\n         * conversation based on the current context.\n         *\n         * The timeout value will be applied after the last model response's audio has\n         * finished playing, i.e. it's set to the `response.done` time plus audio playback\n         * duration.\n         *\n         * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n         * Response) will be emitted when the timeout is reached. Idle timeout is currently\n         * only supported for `server_vad` mode.\n         */\n        idle_timeout_ms?: number | null;\n\n        /**\n         * Whether or not to automatically interrupt (cancel) any ongoing response with\n         * output to the default conversation (i.e. `conversation` of `auto`) when a VAD\n         * start event occurs. If `true` then the response will be cancelled, otherwise it\n         * will continue until complete.\n         *\n         * If both `create_response` and `interrupt_response` are set to `false`, the model\n         * will never respond automatically but VAD events will still be emitted.\n         */\n        interrupt_response?: boolean;\n\n        /**\n         * Used only for `server_vad` mode. Amount of audio to include before the VAD\n         * detected speech (in milliseconds). Defaults to 300ms.\n         */\n        prefix_padding_ms?: number;\n\n        /**\n         * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n         * milliseconds). Defaults to 500ms. With shorter values the model will respond\n         * more quickly, but may jump in on short pauses from the user.\n         */\n        silence_duration_ms?: number;\n\n        /**\n         * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n         * defaults to 0.5. A higher threshold will require louder audio to activate the\n         * model, and thus might perform better in noisy environments.\n         */\n        threshold?: number;\n      }\n\n      /**\n       * Server-side semantic turn detection which uses a model to determine when the\n       * user has finished speaking.\n       */\n      export interface SemanticVad {\n        /**\n         * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n         */\n        type: 'semantic_vad';\n\n        /**\n         * Whether or not to automatically generate a response when a VAD stop event\n         * occurs.\n         */\n        create_response?: boolean;\n\n        /**\n         * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n         * will wait longer for the user to continue speaking, `high` will respond more\n         * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n         * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n         */\n        eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n        /**\n         * Whether or not to automatically interrupt any ongoing response with output to\n         * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n         * occurs.\n         */\n        interrupt_response?: boolean;\n      }\n    }\n\n    export interface Output {\n      /**\n       * The format of the output audio.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * The speed of the model's spoken response as a multiple of the original speed.\n       * 1.0 is the default speed. 0.25 is the minimum speed. 1.5 is the maximum speed.\n       * This value can only be changed in between model turns, not while a response is\n       * in progress.\n       *\n       * This parameter is a post-processing adjustment to the audio after it is\n       * generated, it's also possible to prompt the model to speak faster or slower.\n       */\n      speed?: number;\n\n      /**\n       * The voice the model uses to respond. Voice cannot be changed during the session\n       * once the model has responded with audio at least once. Current voice options are\n       * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,\n       * and `cedar`. We recommend `marin` and `cedar` for best quality.\n       */\n      voice?:\n        | (string & {})\n        | 'alloy'\n        | 'ash'\n        | 'ballad'\n        | 'coral'\n        | 'echo'\n        | 'sage'\n        | 'shimmer'\n        | 'verse'\n        | 'marin'\n        | 'cedar';\n    }\n  }\n\n  /**\n   * Give the model access to additional tools via remote Model Context Protocol\n   * (MCP) servers.\n   * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n   */\n  export interface McpTool {\n    /**\n     * A label for this MCP server, used to identify it in tool calls.\n     */\n    server_label: string;\n\n    /**\n     * The type of the MCP tool. Always `mcp`.\n     */\n    type: 'mcp';\n\n    /**\n     * List of allowed tool names or a filter object.\n     */\n    allowed_tools?: Array<string> | McpTool.McpToolFilter | null;\n\n    /**\n     * An OAuth access token that can be used with a remote MCP server, either with a\n     * custom MCP server URL or a service connector. Your application must handle the\n     * OAuth authorization flow and provide the token here.\n     */\n    authorization?: string;\n\n    /**\n     * Identifier for service connectors, like those available in ChatGPT. One of\n     * `server_url` or `connector_id` must be provided. Learn more about service\n     * connectors\n     * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n     *\n     * Currently supported `connector_id` values are:\n     *\n     * - Dropbox: `connector_dropbox`\n     * - Gmail: `connector_gmail`\n     * - Google Calendar: `connector_googlecalendar`\n     * - Google Drive: `connector_googledrive`\n     * - Microsoft Teams: `connector_microsoftteams`\n     * - Outlook Calendar: `connector_outlookcalendar`\n     * - Outlook Email: `connector_outlookemail`\n     * - SharePoint: `connector_sharepoint`\n     */\n    connector_id?:\n      | 'connector_dropbox'\n      | 'connector_gmail'\n      | 'connector_googlecalendar'\n      | 'connector_googledrive'\n      | 'connector_microsoftteams'\n      | 'connector_outlookcalendar'\n      | 'connector_outlookemail'\n      | 'connector_sharepoint';\n\n    /**\n     * Optional HTTP headers to send to the MCP server. Use for authentication or other\n     * purposes.\n     */\n    headers?: { [key: string]: string } | null;\n\n    /**\n     * Specify which of the MCP server's tools require approval.\n     */\n    require_approval?: McpTool.McpToolApprovalFilter | 'always' | 'never' | null;\n\n    /**\n     * Optional description of the MCP server, used to provide more context.\n     */\n    server_description?: string;\n\n    /**\n     * The URL for the MCP server. One of `server_url` or `connector_id` must be\n     * provided.\n     */\n    server_url?: string;\n  }\n\n  export namespace McpTool {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface McpToolFilter {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * Specify which of the MCP server's tools require approval. Can be `always`,\n     * `never`, or a filter object associated with tools that require approval.\n     */\n    export interface McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      always?: McpToolApprovalFilter.Always;\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      never?: McpToolApprovalFilter.Never;\n    }\n\n    export namespace McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Always {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Never {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n    }\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * Traces Dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the Traces\n     * Dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the Traces Dashboard.\n     */\n    workflow_name?: string;\n  }\n}\n\n/**\n * A Realtime transcription session configuration object.\n */\nexport interface RealtimeTranscriptionSessionCreateResponse {\n  /**\n   * Unique identifier for the session that looks like `sess_1234567890abcdef`.\n   */\n  id: string;\n\n  /**\n   * The object type. Always `realtime.transcription_session`.\n   */\n  object: string;\n\n  /**\n   * The type of session. Always `transcription` for transcription sessions.\n   */\n  type: 'transcription';\n\n  /**\n   * Configuration for input audio for the session.\n   */\n  audio?: RealtimeTranscriptionSessionCreateResponse.Audio;\n\n  /**\n   * Expiration timestamp for the session, in seconds since epoch.\n   */\n  expires_at?: number;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * - `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   *   transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n}\n\nexport namespace RealtimeTranscriptionSessionCreateResponse {\n  /**\n   * Configuration for input audio for the session.\n   */\n  export interface Audio {\n    input?: Audio.Input;\n  }\n\n  export namespace Audio {\n    export interface Input {\n      /**\n       * The PCM audio format. Only a 24kHz sample rate is supported.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * Configuration for input audio noise reduction.\n       */\n      noise_reduction?: Input.NoiseReduction;\n\n      /**\n       * Configuration of the transcription model.\n       */\n      transcription?: RealtimeAPI.AudioTranscription;\n\n      /**\n       * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n       * means that the model will detect the start and end of speech based on audio\n       * volume and respond at the end of user speech.\n       */\n      turn_detection?: ClientSecretsAPI.RealtimeTranscriptionSessionTurnDetection;\n    }\n\n    export namespace Input {\n      /**\n       * Configuration for input audio noise reduction.\n       */\n      export interface NoiseReduction {\n        /**\n         * Type of noise reduction. `near_field` is for close-talking microphones such as\n         * headphones, `far_field` is for far-field microphones such as laptop or\n         * conference room microphones.\n         */\n        type?: RealtimeAPI.NoiseReductionType;\n      }\n    }\n  }\n}\n\n/**\n * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n * means that the model will detect the start and end of speech based on audio\n * volume and respond at the end of user speech.\n */\nexport interface RealtimeTranscriptionSessionTurnDetection {\n  /**\n   * Amount of audio to include before the VAD detected speech (in milliseconds).\n   * Defaults to 300ms.\n   */\n  prefix_padding_ms?: number;\n\n  /**\n   * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n   * With shorter values the model will respond more quickly, but may jump in on\n   * short pauses from the user.\n   */\n  silence_duration_ms?: number;\n\n  /**\n   * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n   * threshold will require louder audio to activate the model, and thus might\n   * perform better in noisy environments.\n   */\n  threshold?: number;\n\n  /**\n   * Type of turn detection, only `server_vad` is currently supported.\n   */\n  type?: string;\n}\n\n/**\n * Response from creating a session and client secret for the Realtime API.\n */\nexport interface ClientSecretCreateResponse {\n  /**\n   * Expiration timestamp for the client secret, in seconds since epoch.\n   */\n  expires_at: number;\n\n  /**\n   * The session configuration for either a realtime or transcription session.\n   */\n  session: RealtimeSessionCreateResponse | RealtimeTranscriptionSessionCreateResponse;\n\n  /**\n   * The generated client secret value.\n   */\n  value: string;\n}\n\nexport interface ClientSecretCreateParams {\n  /**\n   * Configuration for the client secret expiration. Expiration refers to the time\n   * after which a client secret will no longer be valid for creating sessions. The\n   * session itself may continue after that time once started. A secret can be used\n   * to create multiple sessions until it expires.\n   */\n  expires_after?: ClientSecretCreateParams.ExpiresAfter;\n\n  /**\n   * Session configuration to use for the client secret. Choose either a realtime\n   * session or a transcription session.\n   */\n  session?: RealtimeAPI.RealtimeSessionCreateRequest | RealtimeAPI.RealtimeTranscriptionSessionCreateRequest;\n}\n\nexport namespace ClientSecretCreateParams {\n  /**\n   * Configuration for the client secret expiration. Expiration refers to the time\n   * after which a client secret will no longer be valid for creating sessions. The\n   * session itself may continue after that time once started. A secret can be used\n   * to create multiple sessions until it expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The anchor point for the client secret expiration, meaning that `seconds` will\n     * be added to the `created_at` time of the client secret to produce an expiration\n     * timestamp. Only `created_at` is currently supported.\n     */\n    anchor?: 'created_at';\n\n    /**\n     * The number of seconds from the anchor point to the expiration. Select a value\n     * between `10` and `7200` (2 hours). This default to 600 seconds (10 minutes) if\n     * not specified.\n     */\n    seconds?: number;\n  }\n}\n\nexport declare namespace ClientSecrets {\n  export {\n    type RealtimeSessionClientSecret as RealtimeSessionClientSecret,\n    type RealtimeSessionCreateResponse as RealtimeSessionCreateResponse,\n    type RealtimeTranscriptionSessionCreateResponse as RealtimeTranscriptionSessionCreateResponse,\n    type RealtimeTranscriptionSessionTurnDetection as RealtimeTranscriptionSessionTurnDetection,\n    type ClientSecretCreateResponse as ClientSecretCreateResponse,\n    type ClientSecretCreateParams as ClientSecretCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport * from './chat/index';\nexport * from './shared';\nexport { Audio, type AudioModel, type AudioResponseFormat } from './audio/audio';\nexport {\n  Batches,\n  type Batch,\n  type BatchError,\n  type BatchRequestCounts,\n  type BatchUsage,\n  type BatchCreateParams,\n  type BatchListParams,\n  type BatchesPage,\n} from './batches';\nexport { Beta } from './beta/beta';\nexport {\n  Completions,\n  type Completion,\n  type CompletionChoice,\n  type CompletionUsage,\n  type CompletionCreateParams,\n  type CompletionCreateParamsNonStreaming,\n  type CompletionCreateParamsStreaming,\n} from './completions';\nexport {\n  Containers,\n  type ContainerCreateResponse,\n  type ContainerRetrieveResponse,\n  type ContainerListResponse,\n  type ContainerCreateParams,\n  type ContainerListParams,\n  type ContainerListResponsesPage,\n} from './containers/containers';\nexport { Conversations } from './conversations/conversations';\nexport {\n  Embeddings,\n  type CreateEmbeddingResponse,\n  type Embedding,\n  type EmbeddingModel,\n  type EmbeddingCreateParams,\n} from './embeddings';\nexport {\n  Evals,\n  type EvalCustomDataSourceConfig,\n  type EvalStoredCompletionsDataSourceConfig,\n  type EvalCreateResponse,\n  type EvalRetrieveResponse,\n  type EvalUpdateResponse,\n  type EvalListResponse,\n  type EvalDeleteResponse,\n  type EvalCreateParams,\n  type EvalUpdateParams,\n  type EvalListParams,\n  type EvalListResponsesPage,\n} from './evals/evals';\nexport {\n  Files,\n  type FileContent,\n  type FileDeleted,\n  type FileObject,\n  type FilePurpose,\n  type FileCreateParams,\n  type FileListParams,\n  type FileObjectsPage,\n} from './files';\nexport { FineTuning } from './fine-tuning/fine-tuning';\nexport { Graders } from './graders/graders';\nexport {\n  Images,\n  type Image,\n  type ImageEditCompletedEvent,\n  type ImageEditPartialImageEvent,\n  type ImageEditStreamEvent,\n  type ImageGenCompletedEvent,\n  type ImageGenPartialImageEvent,\n  type ImageGenStreamEvent,\n  type ImageModel,\n  type ImagesResponse,\n  type ImageCreateVariationParams,\n  type ImageEditParams,\n  type ImageEditParamsNonStreaming,\n  type ImageEditParamsStreaming,\n  type ImageGenerateParams,\n  type ImageGenerateParamsNonStreaming,\n  type ImageGenerateParamsStreaming,\n} from './images';\nexport { Models, type Model, type ModelDeleted, type ModelsPage } from './models';\nexport {\n  Moderations,\n  type Moderation,\n  type ModerationImageURLInput,\n  type ModerationModel,\n  type ModerationMultiModalInput,\n  type ModerationTextInput,\n  type ModerationCreateResponse,\n  type ModerationCreateParams,\n} from './moderations';\nexport { Realtime } from './realtime/realtime';\nexport { Responses } from './responses/responses';\nexport { Uploads, type Upload, type UploadCreateParams, type UploadCompleteParams } from './uploads/uploads';\nexport {\n  VectorStores,\n  type AutoFileChunkingStrategyParam,\n  type FileChunkingStrategy,\n  type FileChunkingStrategyParam,\n  type OtherFileChunkingStrategyObject,\n  type StaticFileChunkingStrategy,\n  type StaticFileChunkingStrategyObject,\n  type StaticFileChunkingStrategyObjectParam,\n  type VectorStore,\n  type VectorStoreDeleted,\n  type VectorStoreSearchResponse,\n  type VectorStoreCreateParams,\n  type VectorStoreUpdateParams,\n  type VectorStoreListParams,\n  type VectorStoreSearchParams,\n  type VectorStoresPage,\n  type VectorStoreSearchResponsesPage,\n} from './vector-stores/vector-stores';\nexport {\n  Videos,\n  type Video,\n  type VideoCreateError,\n  type VideoModel,\n  type VideoSeconds,\n  type VideoSize,\n  type VideoDeleteResponse,\n  type VideoCreateParams,\n  type VideoListParams,\n  type VideoDownloadContentParams,\n  type VideoRemixParams,\n  type VideosPage,\n} from './videos';\nexport { Webhooks } from './webhooks';\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { RequestInit, RequestInfo, BodyInit } from './internal/builtin-types';\nimport type { HTTPMethod, PromiseOrValue, MergedRequestInit, FinalizedRequestInit } from './internal/types';\nimport { uuid4 } from './internal/utils/uuid';\nimport { validatePositiveInteger, isAbsoluteURL, safeJSON } from './internal/utils/values';\nimport { sleep } from './internal/utils/sleep';\nexport type { Logger, LogLevel } from './internal/utils/log';\nimport { castToError, isAbortError } from './internal/errors';\nimport type { APIResponseProps } from './internal/parse';\nimport { getPlatformHeaders } from './internal/detect-platform';\nimport * as Shims from './internal/shims';\nimport * as Opts from './internal/request-options';\nimport * as qs from './internal/qs';\nimport { VERSION } from './version';\nimport * as Errors from './core/error';\nimport * as Pagination from './core/pagination';\nimport {\n  AbstractPage,\n  type ConversationCursorPageParams,\n  ConversationCursorPageResponse,\n  type CursorPageParams,\n  CursorPageResponse,\n  PageResponse,\n} from './core/pagination';\nimport * as Uploads from './core/uploads';\nimport * as API from './resources/index';\nimport { APIPromise } from './core/api-promise';\nimport {\n  Batch,\n  BatchCreateParams,\n  BatchError,\n  BatchListParams,\n  BatchRequestCounts,\n  BatchUsage,\n  Batches,\n  BatchesPage,\n} from './resources/batches';\nimport {\n  Completion,\n  CompletionChoice,\n  CompletionCreateParams,\n  CompletionCreateParamsNonStreaming,\n  CompletionCreateParamsStreaming,\n  CompletionUsage,\n  Completions,\n} from './resources/completions';\nimport {\n  CreateEmbeddingResponse,\n  Embedding,\n  EmbeddingCreateParams,\n  EmbeddingModel,\n  Embeddings,\n} from './resources/embeddings';\nimport {\n  FileContent,\n  FileCreateParams,\n  FileDeleted,\n  FileListParams,\n  FileObject,\n  FileObjectsPage,\n  FilePurpose,\n  Files,\n} from './resources/files';\nimport {\n  Image,\n  ImageCreateVariationParams,\n  ImageEditCompletedEvent,\n  ImageEditParams,\n  ImageEditParamsNonStreaming,\n  ImageEditParamsStreaming,\n  ImageEditPartialImageEvent,\n  ImageEditStreamEvent,\n  ImageGenCompletedEvent,\n  ImageGenPartialImageEvent,\n  ImageGenStreamEvent,\n  ImageGenerateParams,\n  ImageGenerateParamsNonStreaming,\n  ImageGenerateParamsStreaming,\n  ImageModel,\n  Images,\n  ImagesResponse,\n} from './resources/images';\nimport { Model, ModelDeleted, Models, ModelsPage } from './resources/models';\nimport {\n  Moderation,\n  ModerationCreateParams,\n  ModerationCreateResponse,\n  ModerationImageURLInput,\n  ModerationModel,\n  ModerationMultiModalInput,\n  ModerationTextInput,\n  Moderations,\n} from './resources/moderations';\nimport {\n  Video,\n  VideoCreateError,\n  VideoCreateParams,\n  VideoDeleteResponse,\n  VideoDownloadContentParams,\n  VideoListParams,\n  VideoModel,\n  VideoRemixParams,\n  VideoSeconds,\n  VideoSize,\n  Videos,\n  VideosPage,\n} from './resources/videos';\nimport { Webhooks } from './resources/webhooks';\nimport { Audio, AudioModel, AudioResponseFormat } from './resources/audio/audio';\nimport { Beta } from './resources/beta/beta';\nimport { Chat } from './resources/chat/chat';\nimport {\n  ContainerCreateParams,\n  ContainerCreateResponse,\n  ContainerListParams,\n  ContainerListResponse,\n  ContainerListResponsesPage,\n  ContainerRetrieveResponse,\n  Containers,\n} from './resources/containers/containers';\nimport { Conversations } from './resources/conversations/conversations';\nimport {\n  EvalCreateParams,\n  EvalCreateResponse,\n  EvalCustomDataSourceConfig,\n  EvalDeleteResponse,\n  EvalListParams,\n  EvalListResponse,\n  EvalListResponsesPage,\n  EvalRetrieveResponse,\n  EvalStoredCompletionsDataSourceConfig,\n  EvalUpdateParams,\n  EvalUpdateResponse,\n  Evals,\n} from './resources/evals/evals';\nimport { FineTuning } from './resources/fine-tuning/fine-tuning';\nimport { Graders } from './resources/graders/graders';\nimport { Realtime } from './resources/realtime/realtime';\nimport { Responses } from './resources/responses/responses';\nimport {\n  Upload,\n  UploadCompleteParams,\n  UploadCreateParams,\n  Uploads as UploadsAPIUploads,\n} from './resources/uploads/uploads';\nimport {\n  AutoFileChunkingStrategyParam,\n  FileChunkingStrategy,\n  FileChunkingStrategyParam,\n  OtherFileChunkingStrategyObject,\n  StaticFileChunkingStrategy,\n  StaticFileChunkingStrategyObject,\n  StaticFileChunkingStrategyObjectParam,\n  VectorStore,\n  VectorStoreCreateParams,\n  VectorStoreDeleted,\n  VectorStoreListParams,\n  VectorStoreSearchParams,\n  VectorStoreSearchResponse,\n  VectorStoreSearchResponsesPage,\n  VectorStoreUpdateParams,\n  VectorStores,\n  VectorStoresPage,\n} from './resources/vector-stores/vector-stores';\nimport {\n  ChatCompletion,\n  ChatCompletionAllowedToolChoice,\n  ChatCompletionAllowedTools,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionCustomTool,\n  ChatCompletionDeleted,\n  ChatCompletionDeveloperMessageParam,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionFunctionTool,\n  ChatCompletionListParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageCustomToolCall,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionNamedToolChoiceCustom,\n  ChatCompletionPredictionContent,\n  ChatCompletionReasoningEffort,\n  ChatCompletionRole,\n  ChatCompletionStoreMessage,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUpdateParams,\n  ChatCompletionUserMessageParam,\n  ChatCompletionsPage,\n} from './resources/chat/completions/completions';\nimport { type Fetch } from './internal/builtin-types';\nimport { isRunningInBrowser } from './internal/detect-platform';\nimport { HeadersLike, NullableHeaders, buildHeaders } from './internal/headers';\nimport { FinalRequestOptions, RequestOptions } from './internal/request-options';\nimport { readEnv } from './internal/utils/env';\nimport {\n  type LogLevel,\n  type Logger,\n  formatRequestDetails,\n  loggerFor,\n  parseLogLevel,\n} from './internal/utils/log';\nimport { isEmptyObj } from './internal/utils/values';\n\nexport type ApiKeySetter = () => Promise<string>;\n\nexport interface ClientOptions {\n  /**\n   * API key used for authentication.\n   *\n   * - Accepts either a static string or an async function that resolves to a string.\n   * - Defaults to process.env['OPENAI_API_KEY'].\n   * - When a function is provided, it is invoked before each request so you can rotate\n   *   or refresh credentials at runtime.\n   * - The function must return a non-empty string; otherwise an OpenAIError is thrown.\n   * - If the function throws, the error is wrapped in an OpenAIError with the original\n   *   error available as `cause`.\n   */\n  apiKey?: string | ApiKeySetter | undefined;\n  /**\n   * Defaults to process.env['OPENAI_ORG_ID'].\n   */\n  organization?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_PROJECT_ID'].\n   */\n  project?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_WEBHOOK_SECRET'].\n   */\n  webhookSecret?: string | null | undefined;\n\n  /**\n   * Override the default base URL for the API, e.g., \"https://api.example.com/v2/\"\n   *\n   * Defaults to process.env['OPENAI_BASE_URL'].\n   */\n  baseURL?: string | null | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * Note that request timeouts are retried by default, so in a worst-case scenario you may wait\n   * much longer than this timeout before the promise succeeds or fails.\n   *\n   * @unit milliseconds\n   */\n  timeout?: number | undefined;\n  /**\n   * Additional `RequestInit` options to be passed to `fetch` calls.\n   * Properties will be overridden by per-request `fetchOptions`.\n   */\n  fetchOptions?: MergedRequestInit | undefined;\n\n  /**\n   * Specify a custom `fetch` function implementation.\n   *\n   * If not provided, we expect that `fetch` is defined globally.\n   */\n  fetch?: Fetch | undefined;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number | undefined;\n\n  /**\n   * Default headers to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * header to `null` in request options.\n   */\n  defaultHeaders?: HeadersLike | undefined;\n\n  /**\n   * Default query parameters to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * param to `undefined` in request options.\n   */\n  defaultQuery?: Record<string, string | undefined> | undefined;\n\n  /**\n   * By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   * Only set this option to `true` if you understand the risks and have appropriate mitigations in place.\n   */\n  dangerouslyAllowBrowser?: boolean | undefined;\n\n  /**\n   * Set the log level.\n   *\n   * Defaults to process.env['OPENAI_LOG'] or 'warn' if it isn't set.\n   */\n  logLevel?: LogLevel | undefined;\n\n  /**\n   * Set the logger.\n   *\n   * Defaults to globalThis.console.\n   */\n  logger?: Logger | undefined;\n}\n\n/**\n * API Client for interfacing with the OpenAI API.\n */\nexport class OpenAI {\n  apiKey: string;\n  organization: string | null;\n  project: string | null;\n  webhookSecret: string | null;\n\n  baseURL: string;\n  maxRetries: number;\n  timeout: number;\n  logger: Logger;\n  logLevel: LogLevel | undefined;\n  fetchOptions: MergedRequestInit | undefined;\n\n  private fetch: Fetch;\n  #encoder: Opts.RequestEncoder;\n  protected idempotencyHeader?: string;\n  protected _options: ClientOptions;\n\n  /**\n   * API Client for interfacing with the OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]\n   * @param {string | null | undefined} [opts.webhookSecret=process.env['OPENAI_WEBHOOK_SECRET'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {MergedRequestInit} [opts.fetchOptions] - Additional `RequestInit` options to be passed to `fetch` calls.\n   * @param {Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {HeadersLike} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Record<string, string | undefined>} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = readEnv('OPENAI_BASE_URL'),\n    apiKey = readEnv('OPENAI_API_KEY'),\n    organization = readEnv('OPENAI_ORG_ID') ?? null,\n    project = readEnv('OPENAI_PROJECT_ID') ?? null,\n    webhookSecret = readEnv('OPENAI_WEBHOOK_SECRET') ?? null,\n    ...opts\n  }: ClientOptions = {}) {\n    if (apiKey === undefined) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass an `apiKey`, or set the `OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    const options: ClientOptions = {\n      apiKey,\n      organization,\n      project,\n      webhookSecret,\n      ...opts,\n      baseURL: baseURL || `https://api.openai.com/v1`,\n    };\n\n    if (!options.dangerouslyAllowBrowser && isRunningInBrowser()) {\n      throw new Errors.OpenAIError(\n        \"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\",\n      );\n    }\n\n    this.baseURL = options.baseURL!;\n    this.timeout = options.timeout ?? OpenAI.DEFAULT_TIMEOUT /* 10 minutes */;\n    this.logger = options.logger ?? console;\n    const defaultLogLevel = 'warn';\n    // Set default logLevel early so that we can log a warning in parseLogLevel.\n    this.logLevel = defaultLogLevel;\n    this.logLevel =\n      parseLogLevel(options.logLevel, 'ClientOptions.logLevel', this) ??\n      parseLogLevel(readEnv('OPENAI_LOG'), \"process.env['OPENAI_LOG']\", this) ??\n      defaultLogLevel;\n    this.fetchOptions = options.fetchOptions;\n    this.maxRetries = options.maxRetries ?? 2;\n    this.fetch = options.fetch ?? Shims.getDefaultFetch();\n    this.#encoder = Opts.FallbackEncoder;\n\n    this._options = options;\n\n    this.apiKey = typeof apiKey === 'string' ? apiKey : 'Missing Key';\n    this.organization = organization;\n    this.project = project;\n    this.webhookSecret = webhookSecret;\n  }\n\n  /**\n   * Create a new client instance re-using the same options given to the current client with optional overriding.\n   */\n  withOptions(options: Partial<ClientOptions>): this {\n    const client = new (this.constructor as any as new (props: ClientOptions) => typeof this)({\n      ...this._options,\n      baseURL: this.baseURL,\n      maxRetries: this.maxRetries,\n      timeout: this.timeout,\n      logger: this.logger,\n      logLevel: this.logLevel,\n      fetch: this.fetch,\n      fetchOptions: this.fetchOptions,\n      apiKey: this.apiKey,\n      organization: this.organization,\n      project: this.project,\n      webhookSecret: this.webhookSecret,\n      ...options,\n    });\n    return client;\n  }\n\n  /**\n   * Check whether the base URL is set to its default.\n   */\n  #baseURLOverridden(): boolean {\n    return this.baseURL !== 'https://api.openai.com/v1';\n  }\n\n  protected defaultQuery(): Record<string, string | undefined> | undefined {\n    return this._options.defaultQuery;\n  }\n\n  protected validateHeaders({ values, nulls }: NullableHeaders) {\n    return;\n  }\n\n  protected async authHeaders(opts: FinalRequestOptions): Promise<NullableHeaders | undefined> {\n    return buildHeaders([{ Authorization: `Bearer ${this.apiKey}` }]);\n  }\n\n  protected stringifyQuery(query: Record<string, unknown>): string {\n    return qs.stringify(query, { arrayFormat: 'brackets' });\n  }\n\n  private getUserAgent(): string {\n    return `${this.constructor.name}/JS ${VERSION}`;\n  }\n\n  protected defaultIdempotencyKey(): string {\n    return `stainless-node-retry-${uuid4()}`;\n  }\n\n  protected makeStatusError(\n    status: number,\n    error: Object,\n    message: string | undefined,\n    headers: Headers,\n  ): Errors.APIError {\n    return Errors.APIError.generate(status, error, message, headers);\n  }\n\n  async _callApiKey(): Promise<boolean> {\n    const apiKey = this._options.apiKey;\n    if (typeof apiKey !== 'function') return false;\n\n    let token: unknown;\n    try {\n      token = await apiKey();\n    } catch (err: any) {\n      if (err instanceof Errors.OpenAIError) throw err;\n      throw new Errors.OpenAIError(\n        `Failed to get token from 'apiKey' function: ${err.message}`,\n        // @ts-ignore\n        { cause: err },\n      );\n    }\n\n    if (typeof token !== 'string' || !token) {\n      throw new Errors.OpenAIError(\n        `Expected 'apiKey' function argument to return a string but it returned ${token}`,\n      );\n    }\n    this.apiKey = token;\n    return true;\n  }\n\n  buildURL(\n    path: string,\n    query: Record<string, unknown> | null | undefined,\n    defaultBaseURL?: string | undefined,\n  ): string {\n    const baseURL = (!this.#baseURLOverridden() && defaultBaseURL) || this.baseURL;\n    const url =\n      isAbsoluteURL(path) ?\n        new URL(path)\n      : new URL(baseURL + (baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n\n    const defaultQuery = this.defaultQuery();\n    if (!isEmptyObj(defaultQuery)) {\n      query = { ...defaultQuery, ...query };\n    }\n\n    if (typeof query === 'object' && query && !Array.isArray(query)) {\n      url.search = this.stringifyQuery(query as Record<string, unknown>);\n    }\n\n    return url.toString();\n  }\n\n  /**\n   * Used as a callback for mutating the given `FinalRequestOptions` object.\n   */\n  protected async prepareOptions(options: FinalRequestOptions): Promise<void> {\n    await this._callApiKey();\n  }\n\n  /**\n   * Used as a callback for mutating the given `RequestInit` object.\n   *\n   * This is useful for cases where you want to add certain headers based off of\n   * the request properties, e.g. `method` or `url`.\n   */\n  protected async prepareRequest(\n    request: RequestInit,\n    { url, options }: { url: string; options: FinalRequestOptions },\n  ): Promise<void> {}\n\n  get<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('get', path, opts);\n  }\n\n  post<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('post', path, opts);\n  }\n\n  patch<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('patch', path, opts);\n  }\n\n  put<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('put', path, opts);\n  }\n\n  delete<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('delete', path, opts);\n  }\n\n  private methodRequest<Rsp>(\n    method: HTTPMethod,\n    path: string,\n    opts?: PromiseOrValue<RequestOptions>,\n  ): APIPromise<Rsp> {\n    return this.request(\n      Promise.resolve(opts).then((opts) => {\n        return { method, path, ...opts };\n      }),\n    );\n  }\n\n  request<Rsp>(\n    options: PromiseOrValue<FinalRequestOptions>,\n    remainingRetries: number | null = null,\n  ): APIPromise<Rsp> {\n    return new APIPromise(this, this.makeRequest(options, remainingRetries, undefined));\n  }\n\n  private async makeRequest(\n    optionsInput: PromiseOrValue<FinalRequestOptions>,\n    retriesRemaining: number | null,\n    retryOfRequestLogID: string | undefined,\n  ): Promise<APIResponseProps> {\n    const options = await optionsInput;\n    const maxRetries = options.maxRetries ?? this.maxRetries;\n    if (retriesRemaining == null) {\n      retriesRemaining = maxRetries;\n    }\n\n    await this.prepareOptions(options);\n\n    const { req, url, timeout } = await this.buildRequest(options, {\n      retryCount: maxRetries - retriesRemaining,\n    });\n\n    await this.prepareRequest(req, { url, options });\n\n    /** Not an API request ID, just for correlating local log entries. */\n    const requestLogID = 'log_' + ((Math.random() * (1 << 24)) | 0).toString(16).padStart(6, '0');\n    const retryLogStr = retryOfRequestLogID === undefined ? '' : `, retryOf: ${retryOfRequestLogID}`;\n    const startTime = Date.now();\n\n    loggerFor(this).debug(\n      `[${requestLogID}] sending request`,\n      formatRequestDetails({\n        retryOfRequestLogID,\n        method: options.method,\n        url,\n        options,\n        headers: req.headers,\n      }),\n    );\n\n    if (options.signal?.aborted) {\n      throw new Errors.APIUserAbortError();\n    }\n\n    const controller = new AbortController();\n    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n    const headersTime = Date.now();\n\n    if (response instanceof globalThis.Error) {\n      const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n      if (options.signal?.aborted) {\n        throw new Errors.APIUserAbortError();\n      }\n      // detect native connection timeout errors\n      // deno throws \"TypeError: error sending request for url (https://example/): client error (Connect): tcp connect error: Operation timed out (os error 60): Operation timed out (os error 60)\"\n      // undici throws \"TypeError: fetch failed\" with cause \"ConnectTimeoutError: Connect Timeout Error (attempted address: example:443, timeout: 1ms)\"\n      // others do not provide enough information to distinguish timeouts from other connection errors\n      const isTimeout =\n        isAbortError(response) ||\n        /timed? ?out/i.test(String(response) + ('cause' in response ? String(response.cause) : ''));\n      if (retriesRemaining) {\n        loggerFor(this).info(\n          `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} - ${retryMessage}`,\n        );\n        loggerFor(this).debug(\n          `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} (${retryMessage})`,\n          formatRequestDetails({\n            retryOfRequestLogID,\n            url,\n            durationMs: headersTime - startTime,\n            message: response.message,\n          }),\n        );\n        return this.retryRequest(options, retriesRemaining, retryOfRequestLogID ?? requestLogID);\n      }\n      loggerFor(this).info(\n        `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} - error; no more retries left`,\n      );\n      loggerFor(this).debug(\n        `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} (error; no more retries left)`,\n        formatRequestDetails({\n          retryOfRequestLogID,\n          url,\n          durationMs: headersTime - startTime,\n          message: response.message,\n        }),\n      );\n      if (isTimeout) {\n        throw new Errors.APIConnectionTimeoutError();\n      }\n      throw new Errors.APIConnectionError({ cause: response });\n    }\n\n    const specialHeaders = [...response.headers.entries()]\n      .filter(([name]) => name === 'x-request-id')\n      .map(([name, value]) => ', ' + name + ': ' + JSON.stringify(value))\n      .join('');\n    const responseInfo = `[${requestLogID}${retryLogStr}${specialHeaders}] ${req.method} ${url} ${\n      response.ok ? 'succeeded' : 'failed'\n    } with status ${response.status} in ${headersTime - startTime}ms`;\n\n    if (!response.ok) {\n      const shouldRetry = await this.shouldRetry(response);\n      if (retriesRemaining && shouldRetry) {\n        const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n\n        // We don't need the body of this response.\n        await Shims.CancelReadableStream(response.body);\n        loggerFor(this).info(`${responseInfo} - ${retryMessage}`);\n        loggerFor(this).debug(\n          `[${requestLogID}] response error (${retryMessage})`,\n          formatRequestDetails({\n            retryOfRequestLogID,\n            url: response.url,\n            status: response.status,\n            headers: response.headers,\n            durationMs: headersTime - startTime,\n          }),\n        );\n        return this.retryRequest(\n          options,\n          retriesRemaining,\n          retryOfRequestLogID ?? requestLogID,\n          response.headers,\n        );\n      }\n\n      const retryMessage = shouldRetry ? `error; no more retries left` : `error; not retryable`;\n\n      loggerFor(this).info(`${responseInfo} - ${retryMessage}`);\n\n      const errText = await response.text().catch((err: any) => castToError(err).message);\n      const errJSON = safeJSON(errText);\n      const errMessage = errJSON ? undefined : errText;\n\n      loggerFor(this).debug(\n        `[${requestLogID}] response error (${retryMessage})`,\n        formatRequestDetails({\n          retryOfRequestLogID,\n          url: response.url,\n          status: response.status,\n          headers: response.headers,\n          message: errMessage,\n          durationMs: Date.now() - startTime,\n        }),\n      );\n\n      const err = this.makeStatusError(response.status, errJSON, errMessage, response.headers);\n      throw err;\n    }\n\n    loggerFor(this).info(responseInfo);\n    loggerFor(this).debug(\n      `[${requestLogID}] response start`,\n      formatRequestDetails({\n        retryOfRequestLogID,\n        url: response.url,\n        status: response.status,\n        headers: response.headers,\n        durationMs: headersTime - startTime,\n      }),\n    );\n\n    return { response, options, controller, requestLogID, retryOfRequestLogID, startTime };\n  }\n\n  getAPIList<Item, PageClass extends Pagination.AbstractPage<Item> = Pagination.AbstractPage<Item>>(\n    path: string,\n    Page: new (...args: any[]) => PageClass,\n    opts?: RequestOptions,\n  ): Pagination.PagePromise<PageClass, Item> {\n    return this.requestAPIList(Page, { method: 'get', path, ...opts });\n  }\n\n  requestAPIList<\n    Item = unknown,\n    PageClass extends Pagination.AbstractPage<Item> = Pagination.AbstractPage<Item>,\n  >(\n    Page: new (...args: ConstructorParameters<typeof Pagination.AbstractPage>) => PageClass,\n    options: FinalRequestOptions,\n  ): Pagination.PagePromise<PageClass, Item> {\n    const request = this.makeRequest(options, null, undefined);\n    return new Pagination.PagePromise<PageClass, Item>(this as any as OpenAI, request, Page);\n  }\n\n  async fetchWithTimeout(\n    url: RequestInfo,\n    init: RequestInit | undefined,\n    ms: number,\n    controller: AbortController,\n  ): Promise<Response> {\n    const { signal, method, ...options } = init || {};\n    if (signal) signal.addEventListener('abort', () => controller.abort());\n\n    const timeout = setTimeout(() => controller.abort(), ms);\n\n    const isReadableBody =\n      ((globalThis as any).ReadableStream && options.body instanceof (globalThis as any).ReadableStream) ||\n      (typeof options.body === 'object' && options.body !== null && Symbol.asyncIterator in options.body);\n\n    const fetchOptions: RequestInit = {\n      signal: controller.signal as any,\n      ...(isReadableBody ? { duplex: 'half' } : {}),\n      method: 'GET',\n      ...options,\n    };\n    if (method) {\n      // Custom methods like 'patch' need to be uppercased\n      // See https://github.com/nodejs/undici/issues/2294\n      fetchOptions.method = method.toUpperCase();\n    }\n\n    try {\n      // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n      return await this.fetch.call(undefined, url, fetchOptions);\n    } finally {\n      clearTimeout(timeout);\n    }\n  }\n\n  private async shouldRetry(response: Response): Promise<boolean> {\n    // Note this is not a standard header.\n    const shouldRetryHeader = response.headers.get('x-should-retry');\n\n    // If the server explicitly says whether or not to retry, obey.\n    if (shouldRetryHeader === 'true') return true;\n    if (shouldRetryHeader === 'false') return false;\n\n    // Retry on request timeouts.\n    if (response.status === 408) return true;\n\n    // Retry on lock timeouts.\n    if (response.status === 409) return true;\n\n    // Retry on rate limits.\n    if (response.status === 429) return true;\n\n    // Retry internal errors.\n    if (response.status >= 500) return true;\n\n    return false;\n  }\n\n  private async retryRequest(\n    options: FinalRequestOptions,\n    retriesRemaining: number,\n    requestLogID: string,\n    responseHeaders?: Headers | undefined,\n  ): Promise<APIResponseProps> {\n    let timeoutMillis: number | undefined;\n\n    // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n    const retryAfterMillisHeader = responseHeaders?.get('retry-after-ms');\n    if (retryAfterMillisHeader) {\n      const timeoutMs = parseFloat(retryAfterMillisHeader);\n      if (!Number.isNaN(timeoutMs)) {\n        timeoutMillis = timeoutMs;\n      }\n    }\n\n    // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n    const retryAfterHeader = responseHeaders?.get('retry-after');\n    if (retryAfterHeader && !timeoutMillis) {\n      const timeoutSeconds = parseFloat(retryAfterHeader);\n      if (!Number.isNaN(timeoutSeconds)) {\n        timeoutMillis = timeoutSeconds * 1000;\n      } else {\n        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n      }\n    }\n\n    // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n    // just do what it says, but otherwise calculate a default\n    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n      const maxRetries = options.maxRetries ?? this.maxRetries;\n      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n    }\n    await sleep(timeoutMillis);\n\n    return this.makeRequest(options, retriesRemaining - 1, requestLogID);\n  }\n\n  private calculateDefaultRetryTimeoutMillis(retriesRemaining: number, maxRetries: number): number {\n    const initialRetryDelay = 0.5;\n    const maxRetryDelay = 8.0;\n\n    const numRetries = maxRetries - retriesRemaining;\n\n    // Apply exponential backoff, but not more than the max.\n    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n\n    // Apply some jitter, take up to at most 25 percent of the retry time.\n    const jitter = 1 - Math.random() * 0.25;\n\n    return sleepSeconds * jitter * 1000;\n  }\n\n  async buildRequest(\n    inputOptions: FinalRequestOptions,\n    { retryCount = 0 }: { retryCount?: number } = {},\n  ): Promise<{ req: FinalizedRequestInit; url: string; timeout: number }> {\n    const options = { ...inputOptions };\n    const { method, path, query, defaultBaseURL } = options;\n\n    const url = this.buildURL(path!, query as Record<string, unknown>, defaultBaseURL);\n    if ('timeout' in options) validatePositiveInteger('timeout', options.timeout);\n    options.timeout = options.timeout ?? this.timeout;\n    const { bodyHeaders, body } = this.buildBody({ options });\n    const reqHeaders = await this.buildHeaders({ options: inputOptions, method, bodyHeaders, retryCount });\n\n    const req: FinalizedRequestInit = {\n      method,\n      headers: reqHeaders,\n      ...(options.signal && { signal: options.signal }),\n      ...((globalThis as any).ReadableStream &&\n        body instanceof (globalThis as any).ReadableStream && { duplex: 'half' }),\n      ...(body && { body }),\n      ...((this.fetchOptions as any) ?? {}),\n      ...((options.fetchOptions as any) ?? {}),\n    };\n\n    return { req, url, timeout: options.timeout };\n  }\n\n  private async buildHeaders({\n    options,\n    method,\n    bodyHeaders,\n    retryCount,\n  }: {\n    options: FinalRequestOptions;\n    method: HTTPMethod;\n    bodyHeaders: HeadersLike;\n    retryCount: number;\n  }): Promise<Headers> {\n    let idempotencyHeaders: HeadersLike = {};\n    if (this.idempotencyHeader && method !== 'get') {\n      if (!options.idempotencyKey) options.idempotencyKey = this.defaultIdempotencyKey();\n      idempotencyHeaders[this.idempotencyHeader] = options.idempotencyKey;\n    }\n\n    const headers = buildHeaders([\n      idempotencyHeaders,\n      {\n        Accept: 'application/json',\n        'User-Agent': this.getUserAgent(),\n        'X-Stainless-Retry-Count': String(retryCount),\n        ...(options.timeout ? { 'X-Stainless-Timeout': String(Math.trunc(options.timeout / 1000)) } : {}),\n        ...getPlatformHeaders(),\n        'OpenAI-Organization': this.organization,\n        'OpenAI-Project': this.project,\n      },\n      await this.authHeaders(options),\n      this._options.defaultHeaders,\n      bodyHeaders,\n      options.headers,\n    ]);\n\n    this.validateHeaders(headers);\n\n    return headers.values;\n  }\n\n  private buildBody({ options: { body, headers: rawHeaders } }: { options: FinalRequestOptions }): {\n    bodyHeaders: HeadersLike;\n    body: BodyInit | undefined;\n  } {\n    if (!body) {\n      return { bodyHeaders: undefined, body: undefined };\n    }\n    const headers = buildHeaders([rawHeaders]);\n    if (\n      // Pass raw type verbatim\n      ArrayBuffer.isView(body) ||\n      body instanceof ArrayBuffer ||\n      body instanceof DataView ||\n      (typeof body === 'string' &&\n        // Preserve legacy string encoding behavior for now\n        headers.values.has('content-type')) ||\n      // `Blob` is superset of `File`\n      ((globalThis as any).Blob && body instanceof (globalThis as any).Blob) ||\n      // `FormData` -> `multipart/form-data`\n      body instanceof FormData ||\n      // `URLSearchParams` -> `application/x-www-form-urlencoded`\n      body instanceof URLSearchParams ||\n      // Send chunked stream (each chunk has own `length`)\n      ((globalThis as any).ReadableStream && body instanceof (globalThis as any).ReadableStream)\n    ) {\n      return { bodyHeaders: undefined, body: body as BodyInit };\n    } else if (\n      typeof body === 'object' &&\n      (Symbol.asyncIterator in body ||\n        (Symbol.iterator in body && 'next' in body && typeof body.next === 'function'))\n    ) {\n      return { bodyHeaders: undefined, body: Shims.ReadableStreamFrom(body as AsyncIterable<Uint8Array>) };\n    } else {\n      return this.#encoder({ body, headers });\n    }\n  }\n\n  static OpenAI = this;\n  static DEFAULT_TIMEOUT = 600000; // 10 minutes\n\n  static OpenAIError = Errors.OpenAIError;\n  static APIError = Errors.APIError;\n  static APIConnectionError = Errors.APIConnectionError;\n  static APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\n  static APIUserAbortError = Errors.APIUserAbortError;\n  static NotFoundError = Errors.NotFoundError;\n  static ConflictError = Errors.ConflictError;\n  static RateLimitError = Errors.RateLimitError;\n  static BadRequestError = Errors.BadRequestError;\n  static AuthenticationError = Errors.AuthenticationError;\n  static InternalServerError = Errors.InternalServerError;\n  static PermissionDeniedError = Errors.PermissionDeniedError;\n  static UnprocessableEntityError = Errors.UnprocessableEntityError;\n  static InvalidWebhookSignatureError = Errors.InvalidWebhookSignatureError;\n\n  static toFile = Uploads.toFile;\n\n  completions: API.Completions = new API.Completions(this);\n  chat: API.Chat = new API.Chat(this);\n  embeddings: API.Embeddings = new API.Embeddings(this);\n  files: API.Files = new API.Files(this);\n  images: API.Images = new API.Images(this);\n  audio: API.Audio = new API.Audio(this);\n  moderations: API.Moderations = new API.Moderations(this);\n  models: API.Models = new API.Models(this);\n  fineTuning: API.FineTuning = new API.FineTuning(this);\n  graders: API.Graders = new API.Graders(this);\n  vectorStores: API.VectorStores = new API.VectorStores(this);\n  webhooks: API.Webhooks = new API.Webhooks(this);\n  beta: API.Beta = new API.Beta(this);\n  batches: API.Batches = new API.Batches(this);\n  uploads: API.Uploads = new API.Uploads(this);\n  responses: API.Responses = new API.Responses(this);\n  realtime: API.Realtime = new API.Realtime(this);\n  conversations: API.Conversations = new API.Conversations(this);\n  evals: API.Evals = new API.Evals(this);\n  containers: API.Containers = new API.Containers(this);\n  videos: API.Videos = new API.Videos(this);\n}\n\nOpenAI.Completions = Completions;\nOpenAI.Chat = Chat;\nOpenAI.Embeddings = Embeddings;\nOpenAI.Files = Files;\nOpenAI.Images = Images;\nOpenAI.Audio = Audio;\nOpenAI.Moderations = Moderations;\nOpenAI.Models = Models;\nOpenAI.FineTuning = FineTuning;\nOpenAI.Graders = Graders;\nOpenAI.VectorStores = VectorStores;\nOpenAI.Webhooks = Webhooks;\nOpenAI.Beta = Beta;\nOpenAI.Batches = Batches;\nOpenAI.Uploads = UploadsAPIUploads;\nOpenAI.Responses = Responses;\nOpenAI.Realtime = Realtime;\nOpenAI.Conversations = Conversations;\nOpenAI.Evals = Evals;\nOpenAI.Containers = Containers;\nOpenAI.Videos = Videos;\n\nexport declare namespace OpenAI {\n  export type RequestOptions = Opts.RequestOptions;\n\n  export import Page = Pagination.Page;\n  export { type PageResponse as PageResponse };\n\n  export import CursorPage = Pagination.CursorPage;\n  export { type CursorPageParams as CursorPageParams, type CursorPageResponse as CursorPageResponse };\n\n  export import ConversationCursorPage = Pagination.ConversationCursorPage;\n  export {\n    type ConversationCursorPageParams as ConversationCursorPageParams,\n    type ConversationCursorPageResponse as ConversationCursorPageResponse,\n  };\n\n  export {\n    Completions as Completions,\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n\n  export {\n    Chat as Chat,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAllowedToolChoice as ChatCompletionAllowedToolChoice,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionCustomTool as ChatCompletionCustomTool,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionFunctionTool as ChatCompletionFunctionTool,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageCustomToolCall as ChatCompletionMessageCustomToolCall,\n    type ChatCompletionMessageFunctionToolCall as ChatCompletionMessageFunctionToolCall,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionNamedToolChoiceCustom as ChatCompletionNamedToolChoiceCustom,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type ChatCompletionAllowedTools as ChatCompletionAllowedTools,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    type ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n  };\n\n  export {\n    Embeddings as Embeddings,\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n\n  export {\n    Files as Files,\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    type FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n\n  export {\n    Images as Images,\n    type Image as Image,\n    type ImageEditCompletedEvent as ImageEditCompletedEvent,\n    type ImageEditPartialImageEvent as ImageEditPartialImageEvent,\n    type ImageEditStreamEvent as ImageEditStreamEvent,\n    type ImageGenCompletedEvent as ImageGenCompletedEvent,\n    type ImageGenPartialImageEvent as ImageGenPartialImageEvent,\n    type ImageGenStreamEvent as ImageGenStreamEvent,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageEditParamsNonStreaming as ImageEditParamsNonStreaming,\n    type ImageEditParamsStreaming as ImageEditParamsStreaming,\n    type ImageGenerateParams as ImageGenerateParams,\n    type ImageGenerateParamsNonStreaming as ImageGenerateParamsNonStreaming,\n    type ImageGenerateParamsStreaming as ImageGenerateParamsStreaming,\n  };\n\n  export { Audio as Audio, type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Moderations as Moderations,\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n\n  export {\n    Models as Models,\n    type Model as Model,\n    type ModelDeleted as ModelDeleted,\n    type ModelsPage as ModelsPage,\n  };\n\n  export { FineTuning as FineTuning };\n\n  export { Graders as Graders };\n\n  export {\n    VectorStores as VectorStores,\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyObjectParam as StaticFileChunkingStrategyObjectParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    type VectorStoreSearchResponse as VectorStoreSearchResponse,\n    type VectorStoresPage as VectorStoresPage,\n    type VectorStoreSearchResponsesPage as VectorStoreSearchResponsesPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n    type VectorStoreSearchParams as VectorStoreSearchParams,\n  };\n\n  export { Webhooks as Webhooks };\n\n  export { Beta as Beta };\n\n  export {\n    Batches as Batches,\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    type BatchUsage as BatchUsage,\n    type BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n\n  export {\n    UploadsAPIUploads as Uploads,\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export { Responses as Responses };\n\n  export { Realtime as Realtime };\n\n  export { Conversations as Conversations };\n\n  export {\n    Evals as Evals,\n    type EvalCustomDataSourceConfig as EvalCustomDataSourceConfig,\n    type EvalStoredCompletionsDataSourceConfig as EvalStoredCompletionsDataSourceConfig,\n    type EvalCreateResponse as EvalCreateResponse,\n    type EvalRetrieveResponse as EvalRetrieveResponse,\n    type EvalUpdateResponse as EvalUpdateResponse,\n    type EvalListResponse as EvalListResponse,\n    type EvalDeleteResponse as EvalDeleteResponse,\n    type EvalListResponsesPage as EvalListResponsesPage,\n    type EvalCreateParams as EvalCreateParams,\n    type EvalUpdateParams as EvalUpdateParams,\n    type EvalListParams as EvalListParams,\n  };\n\n  export {\n    Containers as Containers,\n    type ContainerCreateResponse as ContainerCreateResponse,\n    type ContainerRetrieveResponse as ContainerRetrieveResponse,\n    type ContainerListResponse as ContainerListResponse,\n    type ContainerListResponsesPage as ContainerListResponsesPage,\n    type ContainerCreateParams as ContainerCreateParams,\n    type ContainerListParams as ContainerListParams,\n  };\n\n  export {\n    Videos as Videos,\n    type Video as Video,\n    type VideoCreateError as VideoCreateError,\n    type VideoModel as VideoModel,\n    type VideoSeconds as VideoSeconds,\n    type VideoSize as VideoSize,\n    type VideoDeleteResponse as VideoDeleteResponse,\n    type VideosPage as VideosPage,\n    type VideoCreateParams as VideoCreateParams,\n    type VideoListParams as VideoListParams,\n    type VideoDownloadContentParams as VideoDownloadContentParams,\n    type VideoRemixParams as VideoRemixParams,\n  };\n\n  export type AllModels = API.AllModels;\n  export type ChatModel = API.ChatModel;\n  export type ComparisonFilter = API.ComparisonFilter;\n  export type CompoundFilter = API.CompoundFilter;\n  export type CustomToolInputFormat = API.CustomToolInputFormat;\n  export type ErrorObject = API.ErrorObject;\n  export type FunctionDefinition = API.FunctionDefinition;\n  export type FunctionParameters = API.FunctionParameters;\n  export type Metadata = API.Metadata;\n  export type Reasoning = API.Reasoning;\n  export type ReasoningEffort = API.ReasoningEffort;\n  export type ResponseFormatJSONObject = API.ResponseFormatJSONObject;\n  export type ResponseFormatJSONSchema = API.ResponseFormatJSONSchema;\n  export type ResponseFormatText = API.ResponseFormatText;\n  export type ResponseFormatTextGrammar = API.ResponseFormatTextGrammar;\n  export type ResponseFormatTextPython = API.ResponseFormatTextPython;\n  export type ResponsesModel = API.ResponsesModel;\n}\n","import { OpenAIError } from './error';\nimport { type ReadableStream } from '../internal/shim-types';\nimport { makeReadableStream } from '../internal/shims';\nimport { findDoubleNewlineIndex, LineDecoder } from '../internal/decoders/line';\nimport { ReadableStreamToAsyncIterable } from '../internal/shims';\nimport { isAbortError } from '../internal/errors';\nimport { encodeUTF8 } from '../internal/utils/bytes';\nimport { loggerFor } from '../internal/utils/log';\nimport type { OpenAI } from '../client';\n\nimport { APIError } from './error';\n\ntype Bytes = string | ArrayBuffer | Uint8Array | null | undefined;\n\nexport type ServerSentEvent = {\n  event: string | null;\n  data: string;\n  raw: string[];\n};\n\nexport class Stream<Item> implements AsyncIterable<Item> {\n  controller: AbortController;\n  #client: OpenAI | undefined;\n\n  constructor(\n    private iterator: () => AsyncIterator<Item>,\n    controller: AbortController,\n    client?: OpenAI,\n  ) {\n    this.controller = controller;\n    this.#client = client;\n  }\n\n  static fromSSEResponse<Item>(\n    response: Response,\n    controller: AbortController,\n    client?: OpenAI,\n  ): Stream<Item> {\n    let consumed = false;\n    const logger = client ? loggerFor(client) : console;\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new OpenAIError('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const sse of _iterSSEMessages(response, controller)) {\n          if (done) continue;\n\n          if (sse.data.startsWith('[DONE]')) {\n            done = true;\n            continue;\n          }\n\n          if (sse.event === null || !sse.event.startsWith('thread.')) {\n            let data;\n\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              logger.error(`Could not parse message into JSON:`, sse.data);\n              logger.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n\n            if (data && data.error) {\n              throw new APIError(undefined, data.error, undefined, response.headers);\n            }\n\n            yield data;\n          } else {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            // TODO: Is this where the error should be thrown?\n            if (sse.event == 'error') {\n              throw new APIError(undefined, data.error, data.message, undefined);\n            }\n            yield { event: sse.event, data: data } as any;\n          }\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (isAbortError(e)) return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller, client);\n  }\n\n  /**\n   * Generates a Stream from a newline-separated ReadableStream\n   * where each item is a JSON value.\n   */\n  static fromReadableStream<Item>(\n    readableStream: ReadableStream,\n    controller: AbortController,\n    client?: OpenAI,\n  ): Stream<Item> {\n    let consumed = false;\n\n    async function* iterLines(): AsyncGenerator<string, void, unknown> {\n      const lineDecoder = new LineDecoder();\n\n      const iter = ReadableStreamToAsyncIterable<Bytes>(readableStream);\n      for await (const chunk of iter) {\n        for (const line of lineDecoder.decode(chunk)) {\n          yield line;\n        }\n      }\n\n      for (const line of lineDecoder.flush()) {\n        yield line;\n      }\n    }\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new OpenAIError('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const line of iterLines()) {\n          if (done) continue;\n          if (line) yield JSON.parse(line);\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (isAbortError(e)) return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller, client);\n  }\n\n  [Symbol.asyncIterator](): AsyncIterator<Item> {\n    return this.iterator();\n  }\n\n  /**\n   * Splits the stream into two streams which can be\n   * independently read from at different speeds.\n   */\n  tee(): [Stream<Item>, Stream<Item>] {\n    const left: Array<Promise<IteratorResult<Item>>> = [];\n    const right: Array<Promise<IteratorResult<Item>>> = [];\n    const iterator = this.iterator();\n\n    const teeIterator = (queue: Array<Promise<IteratorResult<Item>>>): AsyncIterator<Item> => {\n      return {\n        next: () => {\n          if (queue.length === 0) {\n            const result = iterator.next();\n            left.push(result);\n            right.push(result);\n          }\n          return queue.shift()!;\n        },\n      };\n    };\n\n    return [\n      new Stream(() => teeIterator(left), this.controller, this.#client),\n      new Stream(() => teeIterator(right), this.controller, this.#client),\n    ];\n  }\n\n  /**\n   * Converts this stream to a newline-separated ReadableStream of\n   * JSON stringified values in the stream\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n   */\n  toReadableStream(): ReadableStream {\n    const self = this;\n    let iter: AsyncIterator<Item>;\n\n    return makeReadableStream({\n      async start() {\n        iter = self[Symbol.asyncIterator]();\n      },\n      async pull(ctrl: any) {\n        try {\n          const { value, done } = await iter.next();\n          if (done) return ctrl.close();\n\n          const bytes = encodeUTF8(JSON.stringify(value) + '\\n');\n\n          ctrl.enqueue(bytes);\n        } catch (err) {\n          ctrl.error(err);\n        }\n      },\n      async cancel() {\n        await iter.return?.();\n      },\n    });\n  }\n}\n\nexport async function* _iterSSEMessages(\n  response: Response,\n  controller: AbortController,\n): AsyncGenerator<ServerSentEvent, void, unknown> {\n  if (!response.body) {\n    controller.abort();\n    if (\n      typeof (globalThis as any).navigator !== 'undefined' &&\n      (globalThis as any).navigator.product === 'ReactNative'\n    ) {\n      throw new OpenAIError(\n        `The default react-native fetch implementation does not support streaming. Please use expo/fetch: https://docs.expo.dev/versions/latest/sdk/expo/#expofetch-api`,\n      );\n    }\n    throw new OpenAIError(`Attempted to iterate over a response with no body`);\n  }\n\n  const sseDecoder = new SSEDecoder();\n  const lineDecoder = new LineDecoder();\n\n  const iter = ReadableStreamToAsyncIterable<Bytes>(response.body);\n  for await (const sseChunk of iterSSEChunks(iter)) {\n    for (const line of lineDecoder.decode(sseChunk)) {\n      const sse = sseDecoder.decode(line);\n      if (sse) yield sse;\n    }\n  }\n\n  for (const line of lineDecoder.flush()) {\n    const sse = sseDecoder.decode(line);\n    if (sse) yield sse;\n  }\n}\n\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator: AsyncIterableIterator<Bytes>): AsyncGenerator<Uint8Array> {\n  let data = new Uint8Array();\n\n  for await (const chunk of iterator) {\n    if (chunk == null) {\n      continue;\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? encodeUTF8(chunk)\n      : chunk;\n\n    let newData = new Uint8Array(data.length + binaryChunk.length);\n    newData.set(data);\n    newData.set(binaryChunk, data.length);\n    data = newData;\n\n    let patternIndex;\n    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n      yield data.slice(0, patternIndex);\n      data = data.slice(patternIndex);\n    }\n  }\n\n  if (data.length > 0) {\n    yield data;\n  }\n}\n\nclass SSEDecoder {\n  private data: string[];\n  private event: string | null;\n  private chunks: string[];\n\n  constructor() {\n    this.event = null;\n    this.data = [];\n    this.chunks = [];\n  }\n\n  decode(line: string) {\n    if (line.endsWith('\\r')) {\n      line = line.substring(0, line.length - 1);\n    }\n\n    if (!line) {\n      // empty line and we didn't previously encounter any messages\n      if (!this.event && !this.data.length) return null;\n\n      const sse: ServerSentEvent = {\n        event: this.event,\n        data: this.data.join('\\n'),\n        raw: this.chunks,\n      };\n\n      this.event = null;\n      this.data = [];\n      this.chunks = [];\n\n      return sse;\n    }\n\n    this.chunks.push(line);\n\n    if (line.startsWith(':')) {\n      return null;\n    }\n\n    let [fieldname, _, value] = partition(line, ':');\n\n    if (value.startsWith(' ')) {\n      value = value.substring(1);\n    }\n\n    if (fieldname === 'event') {\n      this.event = value;\n    } else if (fieldname === 'data') {\n      this.data.push(value);\n    }\n\n    return null;\n  }\n}\n\nfunction partition(str: string, delimiter: string): [string, string, string] {\n  const index = str.indexOf(delimiter);\n  if (index !== -1) {\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n  }\n\n  return [str, '', ''];\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as ResponsesAPI from './responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\n\nexport class InputTokens extends APIResource {\n  /**\n   * Get input token counts\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.inputTokens.count();\n   * ```\n   */\n  count(\n    body: InputTokenCountParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<InputTokenCountResponse> {\n    return this._client.post('/responses/input_tokens', { body, ...options });\n  }\n}\n\nexport interface InputTokenCountResponse {\n  input_tokens: number;\n\n  object: 'response.input_tokens';\n}\n\nexport interface InputTokenCountParams {\n  /**\n   * The conversation that this response belongs to. Items from this conversation are\n   * prepended to `input_items` for this response request. Input items and output\n   * items from this response are automatically added to this conversation after this\n   * response completes.\n   */\n  conversation?: string | ResponsesAPI.ResponseConversationParam | null;\n\n  /**\n   * Text, image, or file inputs to the model, used to generate a response\n   */\n  input?: string | Array<ResponsesAPI.ResponseInputItem> | null;\n\n  /**\n   * A system (or developer) message inserted into the model's context. When used\n   * along with `previous_response_id`, the instructions from a previous response\n   * will not be carried over to the next response. This makes it simple to swap out\n   * system (or developer) messages in new responses.\n   */\n  instructions?: string | null;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model?: string | null;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls?: boolean | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   * Cannot be used in conjunction with `conversation`.\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * **gpt-5 and o-series models only** Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: InputTokenCountParams.Text | null;\n\n  /**\n   * Controls which tool the model should use, if any.\n   */\n  tool_choice?:\n    | ResponsesAPI.ToolChoiceOptions\n    | ResponsesAPI.ToolChoiceAllowed\n    | ResponsesAPI.ToolChoiceTypes\n    | ResponsesAPI.ToolChoiceFunction\n    | ResponsesAPI.ToolChoiceMcp\n    | ResponsesAPI.ToolChoiceCustom\n    | ResponsesAPI.ToolChoiceApplyPatch\n    | ResponsesAPI.ToolChoiceShell\n    | null;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   */\n  tools?: Array<ResponsesAPI.Tool> | null;\n\n  /**\n   * The truncation strategy to use for the model response. - `auto`: If the input to\n   * this Response exceeds the model's context window size, the model will truncate\n   * the response to fit the context window by dropping items from the beginning of\n   * the conversation. - `disabled` (default): If the input size will exceed the\n   * context window size for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled';\n}\n\nexport namespace InputTokenCountParams {\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  export interface Text {\n    /**\n     * An object specifying the format that the model must output.\n     *\n     * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n     * ensures the model will match your supplied JSON schema. Learn more in the\n     * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n     *\n     * The default format is `{ \"type\": \"text\" }` with no additional options.\n     *\n     * **Not recommended for gpt-4o and newer models:**\n     *\n     * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n     * ensures the message the model generates is valid JSON. Using `json_schema` is\n     * preferred for models that support it.\n     */\n    format?: ResponsesAPI.ResponseFormatTextConfig;\n\n    /**\n     * Constrains the verbosity of the model's response. Lower values will result in\n     * more concise responses, while higher values will result in more verbose\n     * responses. Currently supported values are `low`, `medium`, and `high`.\n     */\n    verbosity?: 'low' | 'medium' | 'high' | null;\n  }\n}\n\nexport declare namespace InputTokens {\n  export {\n    type InputTokenCountResponse as InputTokenCountResponse,\n    type InputTokenCountParams as InputTokenCountParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as FilesAPI from './files';\nimport { VectorStoreFilesPage } from './files';\nimport * as VectorStoresAPI from './vector-stores';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { sleep } from '../../internal/utils/sleep';\nimport { type Uploadable } from '../../uploads';\nimport { allSettledWithThrow } from '../../lib/Util';\nimport { path } from '../../internal/utils/path';\n\nexport class FileBatches extends APIResource {\n  /**\n   * Create a vector store file batch.\n   */\n  create(\n    vectorStoreID: string,\n    body: FileBatchCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileBatch> {\n    return this._client.post(path`/vector_stores/${vectorStoreID}/file_batches`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a vector store file batch.\n   */\n  retrieve(\n    batchID: string,\n    params: FileBatchRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileBatch> {\n    const { vector_store_id } = params;\n    return this._client.get(path`/vector_stores/${vector_store_id}/file_batches/${batchID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Cancel a vector store file batch. This attempts to cancel the processing of\n   * files in this batch as soon as possible.\n   */\n  cancel(\n    batchID: string,\n    params: FileBatchCancelParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileBatch> {\n    const { vector_store_id } = params;\n    return this._client.post(path`/vector_stores/${vector_store_id}/file_batches/${batchID}/cancel`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Create a vector store batch and poll until all files have been processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const batch = await this.create(vectorStoreId, body);\n    return await this.poll(vectorStoreId, batch.id, options);\n  }\n\n  /**\n   * Returns a list of vector store files in a batch.\n   */\n  listFiles(\n    batchID: string,\n    params: FileBatchListFilesParams,\n    options?: RequestOptions,\n  ): PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile> {\n    const { vector_store_id, ...query } = params;\n    return this._client.getAPIList(\n      path`/vector_stores/${vector_store_id}/file_batches/${batchID}/files`,\n      CursorPage<FilesAPI.VectorStoreFile>,\n      { query, ...options, headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]) },\n    );\n  }\n\n  /**\n   * Wait for the given file batch to be processed.\n   *\n   * Note: this will return even if one of the files failed to process, you need to\n   * check batch.file_counts.failed_count to handle this case.\n   */\n  async poll(\n    vectorStoreID: string,\n    batchID: string,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const headers = buildHeaders([\n      options?.headers,\n      {\n        'X-Stainless-Poll-Helper': 'true',\n        'X-Stainless-Custom-Poll-Interval': options?.pollIntervalMs?.toString() ?? undefined,\n      },\n    ]);\n\n    while (true) {\n      const { data: batch, response } = await this.retrieve(\n        batchID,\n        { vector_store_id: vectorStoreID },\n        {\n          ...options,\n          headers,\n        },\n      ).withResponse();\n\n      switch (batch.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'cancelled':\n        case 'completed':\n          return batch;\n      }\n    }\n  }\n\n  /**\n   * Uploads the given files concurrently and then creates a vector store file batch.\n   *\n   * The concurrency limit is configurable using the `maxConcurrency` parameter.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    { files, fileIds = [] }: { files: Uploadable[]; fileIds?: string[] },\n    options?: RequestOptions & { pollIntervalMs?: number; maxConcurrency?: number },\n  ): Promise<VectorStoreFileBatch> {\n    if (files == null || files.length == 0) {\n      throw new Error(\n        `No \\`files\\` provided to process. If you've already uploaded files you should use \\`.createAndPoll()\\` instead`,\n      );\n    }\n\n    const configuredConcurrency = options?.maxConcurrency ?? 5;\n\n    // We cap the number of workers at the number of files (so we don't start any unnecessary workers)\n    const concurrencyLimit = Math.min(configuredConcurrency, files.length);\n\n    const client = this._client;\n    const fileIterator = files.values();\n    const allFileIds: string[] = [...fileIds];\n\n    // This code is based on this design. The libraries don't accommodate our environment limits.\n    // https://stackoverflow.com/questions/40639432/what-is-the-best-way-to-limit-concurrency-when-using-es6s-promise-all\n    async function processFiles(iterator: IterableIterator<Uploadable>) {\n      for (let item of iterator) {\n        const fileObj = await client.files.create({ file: item, purpose: 'assistants' }, options);\n        allFileIds.push(fileObj.id);\n      }\n    }\n\n    // Start workers to process results\n    const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);\n\n    // Wait for all processing to complete.\n    await allSettledWithThrow(workers);\n\n    return await this.createAndPoll(vectorStoreId, {\n      file_ids: allFileIds,\n    });\n  }\n}\n\n/**\n * A batch of files attached to a vector store.\n */\nexport interface VectorStoreFileBatch {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store files batch was\n   * created.\n   */\n  created_at: number;\n\n  file_counts: VectorStoreFileBatch.FileCounts;\n\n  /**\n   * The object type, which is always `vector_store.file_batch`.\n   */\n  object: 'vector_store.files_batch';\n\n  /**\n   * The status of the vector store files batch, which can be either `in_progress`,\n   * `completed`, `cancelled` or `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n}\n\nexport namespace VectorStoreFileBatch {\n  export interface FileCounts {\n    /**\n     * The number of files that where cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n}\n\nexport interface FileBatchCreateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files. If `attributes` or `chunking_strategy` are provided, they will be applied\n   * to all files in the batch. Mutually exclusive with `files`.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * A list of objects that each include a `file_id` plus optional `attributes` or\n   * `chunking_strategy`. Use this when you need to override metadata for specific\n   * files. The global `attributes` or `chunking_strategy` will be ignored and must\n   * be specified for each file. Mutually exclusive with `file_ids`.\n   */\n  files?: Array<FileBatchCreateParams.File>;\n}\n\nexport namespace FileBatchCreateParams {\n  export interface File {\n    /**\n     * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n     * vector store should use. Useful for tools like `file_search` that can access\n     * files.\n     */\n    file_id: string;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard. Keys are strings with a maximum\n     * length of 64 characters. Values are strings with a maximum length of 512\n     * characters, booleans, or numbers.\n     */\n    attributes?: { [key: string]: string | number | boolean } | null;\n\n    /**\n     * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n     * strategy. Only applicable if `file_ids` is non-empty.\n     */\n    chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n  }\n}\n\nexport interface FileBatchRetrieveParams {\n  /**\n   * The ID of the vector store that the file batch belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileBatchCancelParams {\n  /**\n   * The ID of the vector store that the file batch belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileBatchListFilesParams extends CursorPageParams {\n  /**\n   * Path param: The ID of the vector store that the files belong to.\n   */\n  vector_store_id: string;\n\n  /**\n   * Query param: A cursor for use in pagination. `before` is an object ID that\n   * defines your place in the list. For instance, if you make a list request and\n   * receive 100 objects, starting with obj_foo, your subsequent call can include\n   * before=obj_foo in order to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Query param: Filter by file status. One of `in_progress`, `completed`, `failed`,\n   * `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Query param: Sort order by the `created_at` timestamp of the objects. `asc` for\n   * ascending order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace FileBatches {\n  export {\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchRetrieveParams as FileBatchRetrieveParams,\n    type FileBatchCancelParams as FileBatchCancelParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n\nexport { type VectorStoreFilesPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as SpeechAPI from './speech';\nimport { Speech, SpeechCreateParams, SpeechModel } from './speech';\nimport * as TranscriptionsAPI from './transcriptions';\nimport {\n  Transcription,\n  TranscriptionCreateParams,\n  TranscriptionCreateParamsNonStreaming,\n  TranscriptionCreateParamsStreaming,\n  TranscriptionCreateResponse,\n  TranscriptionDiarized,\n  TranscriptionDiarizedSegment,\n  TranscriptionInclude,\n  TranscriptionSegment,\n  TranscriptionStreamEvent,\n  TranscriptionTextDeltaEvent,\n  TranscriptionTextDoneEvent,\n  TranscriptionTextSegmentEvent,\n  TranscriptionVerbose,\n  TranscriptionWord,\n  Transcriptions,\n} from './transcriptions';\nimport * as TranslationsAPI from './translations';\nimport {\n  Translation,\n  TranslationCreateParams,\n  TranslationCreateResponse,\n  TranslationVerbose,\n  Translations,\n} from './translations';\n\nexport class Audio extends APIResource {\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\n}\n\nexport type AudioModel =\n  | 'whisper-1'\n  | 'gpt-4o-transcribe'\n  | 'gpt-4o-mini-transcribe'\n  | 'gpt-4o-mini-transcribe-2025-12-15'\n  | 'gpt-4o-transcribe-diarize';\n\n/**\n * The format of the output, in one of these options: `json`, `text`, `srt`,\n * `verbose_json`, `vtt`, or `diarized_json`. For `gpt-4o-transcribe` and\n * `gpt-4o-mini-transcribe`, the only supported format is `json`. For\n * `gpt-4o-transcribe-diarize`, the supported formats are `json`, `text`, and\n * `diarized_json`, with `diarized_json` required to receive speaker annotations.\n */\nexport type AudioResponseFormat = 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt' | 'diarized_json';\n\nAudio.Transcriptions = Transcriptions;\nAudio.Translations = Translations;\nAudio.Speech = Speech;\n\nexport declare namespace Audio {\n  export { type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Transcriptions as Transcriptions,\n    type Transcription as Transcription,\n    type TranscriptionDiarized as TranscriptionDiarized,\n    type TranscriptionDiarizedSegment as TranscriptionDiarizedSegment,\n    type TranscriptionInclude as TranscriptionInclude,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionStreamEvent as TranscriptionStreamEvent,\n    type TranscriptionTextDeltaEvent as TranscriptionTextDeltaEvent,\n    type TranscriptionTextDoneEvent as TranscriptionTextDoneEvent,\n    type TranscriptionTextSegmentEvent as TranscriptionTextSegmentEvent,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n    type TranscriptionCreateParamsNonStreaming as TranscriptionCreateParamsNonStreaming,\n    type TranscriptionCreateParamsStreaming as TranscriptionCreateParamsStreaming,\n  };\n\n  export {\n    Translations as Translations,\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n\n  export { Speech as Speech, type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n/**\n * https://stackoverflow.com/a/2117523\n */\nexport let uuid4 = function () {\n  const { crypto } = globalThis as any;\n  if (crypto?.randomUUID) {\n    uuid4 = crypto.randomUUID.bind(crypto);\n    return crypto.randomUUID();\n  }\n  const u8 = new Uint8Array(1);\n  const randomByte = crypto ? () => crypto.getRandomValues(u8)[0]! : () => (Math.random() * 0xff) & 0xff;\n  return '10000000-1000-4000-8000-100000000000'.replace(/[018]/g, (c) =>\n    (+c ^ (randomByte() & (15 >> (+c / 4)))).toString(16),\n  );\n};\n","import { APIUserAbortError, OpenAIError } from '../error';\n\nexport class EventStream<EventTypes extends BaseEvents> {\n  controller: AbortController = new AbortController();\n\n  #connectedPromise: Promise<void>;\n  #resolveConnectedPromise: () => void = () => {};\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\n\n  #endPromise: Promise<void>;\n  #resolveEndPromise: () => void = () => {};\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\n\n  #listeners: {\n    [Event in keyof EventTypes]?: EventListeners<EventTypes, Event>;\n  } = {};\n\n  #ended = false;\n  #errored = false;\n  #aborted = false;\n  #catchingPromiseCreated = false;\n\n  constructor() {\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveConnectedPromise = resolve;\n      this.#rejectConnectedPromise = reject;\n    });\n\n    this.#endPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveEndPromise = resolve;\n      this.#rejectEndPromise = reject;\n    });\n\n    // Don't let these promises cause unhandled rejection errors.\n    // we will manually cause an unhandled rejection error later\n    // if the user hasn't registered any error listener or called\n    // any promise-returning method.\n    this.#connectedPromise.catch(() => {});\n    this.#endPromise.catch(() => {});\n  }\n\n  protected _run(this: EventStream<EventTypes>, executor: () => Promise<any>) {\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\n    // references to `this` before the `super()` constructor call returns.\n    setTimeout(() => {\n      executor().then(() => {\n        this._emitFinal();\n        this._emit('end');\n      }, this.#handleError.bind(this));\n    }, 0);\n  }\n\n  protected _connected(this: EventStream<EventTypes>) {\n    if (this.ended) return;\n    this.#resolveConnectedPromise();\n    this._emit('connect');\n  }\n\n  get ended(): boolean {\n    return this.#ended;\n  }\n\n  get errored(): boolean {\n    return this.#errored;\n  }\n\n  get aborted(): boolean {\n    return this.#aborted;\n  }\n\n  abort() {\n    this.controller.abort();\n  }\n\n  /**\n   * Adds the listener function to the end of the listeners array for the event.\n   * No checks are made to see if the listener has already been added. Multiple calls passing\n   * the same combination of event and listener will result in the listener being added, and\n   * called, multiple times.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  on<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener });\n    return this;\n  }\n\n  /**\n   * Removes the specified listener from the listener array for the event.\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\n   * listener has been added multiple times to the listener array for the specified event, then\n   * off() must be called multiple times to remove each instance.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  off<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners = this.#listeners[event];\n    if (!listeners) return this;\n    const index = listeners.findIndex((l) => l.listener === listener);\n    if (index >= 0) listeners.splice(index, 1);\n    return this;\n  }\n\n  /**\n   * Adds a one-time listener function for the event. The next time the event is triggered,\n   * this listener is removed and then invoked.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  once<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener, once: true });\n    return this;\n  }\n\n  /**\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\n   * the event is triggered, instead of calling a listener callback.\n   * @returns a Promise that resolves the next time given event is triggered,\n   * or rejects if an error is emitted.  (If you request the 'error' event,\n   * returns a promise that resolves with the error).\n   *\n   * Example:\n   *\n   *   const message = await stream.emitted('message') // rejects if the stream errors\n   */\n  emitted<Event extends keyof EventTypes>(\n    event: Event,\n  ): Promise<\n    EventParameters<EventTypes, Event> extends [infer Param] ? Param\n    : EventParameters<EventTypes, Event> extends [] ? void\n    : EventParameters<EventTypes, Event>\n  > {\n    return new Promise((resolve, reject) => {\n      this.#catchingPromiseCreated = true;\n      if (event !== 'error') this.once('error', reject);\n      this.once(event, resolve as any);\n    });\n  }\n\n  async done(): Promise<void> {\n    this.#catchingPromiseCreated = true;\n    await this.#endPromise;\n  }\n\n  #handleError(this: EventStream<EventTypes>, error: unknown) {\n    this.#errored = true;\n    if (error instanceof Error && error.name === 'AbortError') {\n      error = new APIUserAbortError();\n    }\n    if (error instanceof APIUserAbortError) {\n      this.#aborted = true;\n      return this._emit('abort', error);\n    }\n    if (error instanceof OpenAIError) {\n      return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n      const openAIError: OpenAIError = new OpenAIError(error.message);\n      // @ts-ignore\n      openAIError.cause = error;\n      return this._emit('error', openAIError);\n    }\n    return this._emit('error', new OpenAIError(String(error)));\n  }\n\n  _emit<Event extends keyof BaseEvents>(event: Event, ...args: EventParameters<BaseEvents, Event>): void;\n  _emit<Event extends keyof EventTypes>(event: Event, ...args: EventParameters<EventTypes, Event>): void;\n  _emit<Event extends keyof EventTypes>(\n    this: EventStream<EventTypes>,\n    event: Event,\n    ...args: EventParameters<EventTypes, Event>\n  ) {\n    // make sure we don't emit any events after end\n    if (this.#ended) {\n      return;\n    }\n\n    if (event === 'end') {\n      this.#ended = true;\n      this.#resolveEndPromise();\n    }\n\n    const listeners: EventListeners<EventTypes, Event> | undefined = this.#listeners[event];\n    if (listeners) {\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\n      listeners.forEach(({ listener }: any) => listener(...(args as any)));\n    }\n\n    if (event === 'abort') {\n      const error = args[0] as APIUserAbortError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n      return;\n    }\n\n    if (event === 'error') {\n      // NOTE: _emit('error', error) should only be called from #handleError().\n\n      const error = args[0] as OpenAIError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n        // If you are seeing stack traces here, make sure to handle errors via either:\n        // - runner.on('error', () => ...)\n        // - await runner.done()\n        // - await runner.finalChatCompletion()\n        // - etc.\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n    }\n  }\n\n  protected _emitFinal(): void {}\n}\n\ntype EventListener<Events, EventType extends keyof Events> = Events[EventType];\n\ntype EventListeners<Events, EventType extends keyof Events> = Array<{\n  listener: EventListener<Events, EventType>;\n  once?: boolean;\n}>;\n\nexport type EventParameters<Events, EventType extends keyof Events> = {\n  [Event in EventType]: EventListener<Events, EventType> extends (...args: infer P) => any ? P : never;\n}[EventType];\n\nexport interface BaseEvents {\n  connect: () => void;\n  error: (error: OpenAIError) => void;\n  abort: (error: APIUserAbortError) => void;\n  end: () => void;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ContentAPI from './content';\nimport { Content, ContentRetrieveParams } from './content';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { type Uploadable } from '../../../core/uploads';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../../internal/uploads';\nimport { path } from '../../../internal/utils/path';\n\nexport class Files extends APIResource {\n  content: ContentAPI.Content = new ContentAPI.Content(this._client);\n\n  /**\n   * Create a Container File\n   *\n   * You can send either a multipart/form-data request with the raw file content, or\n   * a JSON request with a file ID.\n   */\n  create(\n    containerID: string,\n    body: FileCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<FileCreateResponse> {\n    return this._client.post(\n      path`/containers/${containerID}/files`,\n      multipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n\n  /**\n   * Retrieve Container File\n   */\n  retrieve(\n    fileID: string,\n    params: FileRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<FileRetrieveResponse> {\n    const { container_id } = params;\n    return this._client.get(path`/containers/${container_id}/files/${fileID}`, options);\n  }\n\n  /**\n   * List Container files\n   */\n  list(\n    containerID: string,\n    query: FileListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FileListResponsesPage, FileListResponse> {\n    return this._client.getAPIList(path`/containers/${containerID}/files`, CursorPage<FileListResponse>, {\n      query,\n      ...options,\n    });\n  }\n\n  /**\n   * Delete Container File\n   */\n  delete(fileID: string, params: FileDeleteParams, options?: RequestOptions): APIPromise<void> {\n    const { container_id } = params;\n    return this._client.delete(path`/containers/${container_id}/files/${fileID}`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n}\n\nexport type FileListResponsesPage = CursorPage<FileListResponse>;\n\nexport interface FileCreateResponse {\n  /**\n   * Unique identifier for the file.\n   */\n  id: string;\n\n  /**\n   * Size of the file in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The container this file belongs to.\n   */\n  container_id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The type of this object (`container.file`).\n   */\n  object: 'container.file';\n\n  /**\n   * Path of the file in the container.\n   */\n  path: string;\n\n  /**\n   * Source of the file (e.g., `user`, `assistant`).\n   */\n  source: string;\n}\n\nexport interface FileRetrieveResponse {\n  /**\n   * Unique identifier for the file.\n   */\n  id: string;\n\n  /**\n   * Size of the file in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The container this file belongs to.\n   */\n  container_id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The type of this object (`container.file`).\n   */\n  object: 'container.file';\n\n  /**\n   * Path of the file in the container.\n   */\n  path: string;\n\n  /**\n   * Source of the file (e.g., `user`, `assistant`).\n   */\n  source: string;\n}\n\nexport interface FileListResponse {\n  /**\n   * Unique identifier for the file.\n   */\n  id: string;\n\n  /**\n   * Size of the file in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The container this file belongs to.\n   */\n  container_id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The type of this object (`container.file`).\n   */\n  object: 'container.file';\n\n  /**\n   * Path of the file in the container.\n   */\n  path: string;\n\n  /**\n   * Source of the file (e.g., `user`, `assistant`).\n   */\n  source: string;\n}\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file?: Uploadable;\n\n  /**\n   * Name of the file to create.\n   */\n  file_id?: string;\n}\n\nexport interface FileRetrieveParams {\n  container_id: string;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface FileDeleteParams {\n  container_id: string;\n}\n\nFiles.Content = Content;\n\nexport declare namespace Files {\n  export {\n    type FileCreateResponse as FileCreateResponse,\n    type FileRetrieveResponse as FileRetrieveResponse,\n    type FileListResponse as FileListResponse,\n    type FileListResponsesPage as FileListResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n  };\n\n  export { Content as Content, type ContentRetrieveParams as ContentRetrieveParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { ConversationCursorPage, type ConversationCursorPageParams, PagePromise } from '../core/pagination';\nimport { type Uploadable } from '../core/uploads';\nimport { buildHeaders } from '../internal/headers';\nimport { RequestOptions } from '../internal/request-options';\nimport { maybeMultipartFormRequestOptions } from '../internal/uploads';\nimport { path } from '../internal/utils/path';\n\nexport class Videos extends APIResource {\n  /**\n   * Create a video\n   */\n  create(body: VideoCreateParams, options?: RequestOptions): APIPromise<Video> {\n    return this._client.post('/videos', maybeMultipartFormRequestOptions({ body, ...options }, this._client));\n  }\n\n  /**\n   * Retrieve a video\n   */\n  retrieve(videoID: string, options?: RequestOptions): APIPromise<Video> {\n    return this._client.get(path`/videos/${videoID}`, options);\n  }\n\n  /**\n   * List videos\n   */\n  list(\n    query: VideoListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<VideosPage, Video> {\n    return this._client.getAPIList('/videos', ConversationCursorPage<Video>, { query, ...options });\n  }\n\n  /**\n   * Delete a video\n   */\n  delete(videoID: string, options?: RequestOptions): APIPromise<VideoDeleteResponse> {\n    return this._client.delete(path`/videos/${videoID}`, options);\n  }\n\n  /**\n   * Download video content\n   */\n  downloadContent(\n    videoID: string,\n    query: VideoDownloadContentParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<Response> {\n    return this._client.get(path`/videos/${videoID}/content`, {\n      query,\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/binary' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n\n  /**\n   * Create a video remix\n   */\n  remix(videoID: string, body: VideoRemixParams, options?: RequestOptions): APIPromise<Video> {\n    return this._client.post(\n      path`/videos/${videoID}/remix`,\n      maybeMultipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n}\n\nexport type VideosPage = ConversationCursorPage<Video>;\n\n/**\n * Structured information describing a generated video job.\n */\nexport interface Video {\n  /**\n   * Unique identifier for the video job.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (seconds) for when the job completed, if finished.\n   */\n  completed_at: number | null;\n\n  /**\n   * Unix timestamp (seconds) for when the job was created.\n   */\n  created_at: number;\n\n  /**\n   * Error payload that explains why generation failed, if applicable.\n   */\n  error: VideoCreateError | null;\n\n  /**\n   * Unix timestamp (seconds) for when the downloadable assets expire, if set.\n   */\n  expires_at: number | null;\n\n  /**\n   * The video generation model that produced the job.\n   */\n  model: VideoModel;\n\n  /**\n   * The object type, which is always `video`.\n   */\n  object: 'video';\n\n  /**\n   * Approximate completion percentage for the generation task.\n   */\n  progress: number;\n\n  /**\n   * The prompt that was used to generate the video.\n   */\n  prompt: string | null;\n\n  /**\n   * Identifier of the source video if this video is a remix.\n   */\n  remixed_from_video_id: string | null;\n\n  /**\n   * Duration of the generated clip in seconds.\n   */\n  seconds: VideoSeconds;\n\n  /**\n   * The resolution of the generated video.\n   */\n  size: VideoSize;\n\n  /**\n   * Current lifecycle status of the video job.\n   */\n  status: 'queued' | 'in_progress' | 'completed' | 'failed';\n}\n\n/**\n * An error that occurred while generating the response.\n */\nexport interface VideoCreateError {\n  /**\n   * A machine-readable error code that was returned.\n   */\n  code: string;\n\n  /**\n   * A human-readable description of the error that was returned.\n   */\n  message: string;\n}\n\nexport type VideoModel =\n  | (string & {})\n  | 'sora-2'\n  | 'sora-2-pro'\n  | 'sora-2-2025-10-06'\n  | 'sora-2-pro-2025-10-06'\n  | 'sora-2-2025-12-08';\n\nexport type VideoSeconds = '4' | '8' | '12';\n\nexport type VideoSize = '720x1280' | '1280x720' | '1024x1792' | '1792x1024';\n\n/**\n * Confirmation payload returned after deleting a video.\n */\nexport interface VideoDeleteResponse {\n  /**\n   * Identifier of the deleted video.\n   */\n  id: string;\n\n  /**\n   * Indicates that the video resource was deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * The object type that signals the deletion response.\n   */\n  object: 'video.deleted';\n}\n\nexport interface VideoCreateParams {\n  /**\n   * Text prompt that describes the video to generate.\n   */\n  prompt: string;\n\n  /**\n   * Optional image reference that guides generation.\n   */\n  input_reference?: Uploadable;\n\n  /**\n   * The video generation model to use (allowed values: sora-2, sora-2-pro). Defaults\n   * to `sora-2`.\n   */\n  model?: VideoModel;\n\n  /**\n   * Clip duration in seconds (allowed values: 4, 8, 12). Defaults to 4 seconds.\n   */\n  seconds?: VideoSeconds;\n\n  /**\n   * Output resolution formatted as width x height (allowed values: 720x1280,\n   * 1280x720, 1024x1792, 1792x1024). Defaults to 720x1280.\n   */\n  size?: VideoSize;\n}\n\nexport interface VideoListParams extends ConversationCursorPageParams {\n  /**\n   * Sort order of results by timestamp. Use `asc` for ascending order or `desc` for\n   * descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface VideoDownloadContentParams {\n  /**\n   * Which downloadable asset to return. Defaults to the MP4 video.\n   */\n  variant?: 'video' | 'thumbnail' | 'spritesheet';\n}\n\nexport interface VideoRemixParams {\n  /**\n   * Updated text prompt that directs the remix generation.\n   */\n  prompt: string;\n}\n\nexport declare namespace Videos {\n  export {\n    type Video as Video,\n    type VideoCreateError as VideoCreateError,\n    type VideoModel as VideoModel,\n    type VideoSeconds as VideoSeconds,\n    type VideoSize as VideoSize,\n    type VideoDeleteResponse as VideoDeleteResponse,\n    type VideosPage as VideosPage,\n    type VideoCreateParams as VideoCreateParams,\n    type VideoListParams as VideoListParams,\n    type VideoDownloadContentParams as VideoDownloadContentParams,\n    type VideoRemixParams as VideoRemixParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as FileBatchesAPI from './file-batches';\nimport {\n  FileBatchCancelParams,\n  FileBatchCreateParams,\n  FileBatchListFilesParams,\n  FileBatchRetrieveParams,\n  FileBatches,\n  VectorStoreFileBatch,\n} from './file-batches';\nimport * as FilesAPI from './files';\nimport {\n  FileContentParams,\n  FileContentResponse,\n  FileContentResponsesPage,\n  FileCreateParams,\n  FileDeleteParams,\n  FileListParams,\n  FileRetrieveParams,\n  FileUpdateParams,\n  Files,\n  VectorStoreFile,\n  VectorStoreFileDeleted,\n  VectorStoreFilesPage,\n} from './files';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, Page, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class VectorStores extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n  fileBatches: FileBatchesAPI.FileBatches = new FileBatchesAPI.FileBatches(this._client);\n\n  /**\n   * Create a vector store.\n   */\n  create(body: VectorStoreCreateParams, options?: RequestOptions): APIPromise<VectorStore> {\n    return this._client.post('/vector_stores', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a vector store.\n   */\n  retrieve(vectorStoreID: string, options?: RequestOptions): APIPromise<VectorStore> {\n    return this._client.get(path`/vector_stores/${vectorStoreID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a vector store.\n   */\n  update(\n    vectorStoreID: string,\n    body: VectorStoreUpdateParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStore> {\n    return this._client.post(path`/vector_stores/${vectorStoreID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of vector stores.\n   */\n  list(\n    query: VectorStoreListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<VectorStoresPage, VectorStore> {\n    return this._client.getAPIList('/vector_stores', CursorPage<VectorStore>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a vector store.\n   */\n  delete(vectorStoreID: string, options?: RequestOptions): APIPromise<VectorStoreDeleted> {\n    return this._client.delete(path`/vector_stores/${vectorStoreID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Search a vector store for relevant chunks based on a query and file attributes\n   * filter.\n   */\n  search(\n    vectorStoreID: string,\n    body: VectorStoreSearchParams,\n    options?: RequestOptions,\n  ): PagePromise<VectorStoreSearchResponsesPage, VectorStoreSearchResponse> {\n    return this._client.getAPIList(\n      path`/vector_stores/${vectorStoreID}/search`,\n      Page<VectorStoreSearchResponse>,\n      {\n        body,\n        method: 'post',\n        ...options,\n        headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      },\n    );\n  }\n}\n\nexport type VectorStoresPage = CursorPage<VectorStore>;\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type VectorStoreSearchResponsesPage = Page<VectorStoreSearchResponse>;\n\n/**\n * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n * `800` and `chunk_overlap_tokens` of `400`.\n */\nexport interface AutoFileChunkingStrategyParam {\n  /**\n   * Always `auto`.\n   */\n  type: 'auto';\n}\n\n/**\n * The strategy used to chunk the file.\n */\nexport type FileChunkingStrategy = StaticFileChunkingStrategyObject | OtherFileChunkingStrategyObject;\n\n/**\n * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n * strategy. Only applicable if `file_ids` is non-empty.\n */\nexport type FileChunkingStrategyParam = AutoFileChunkingStrategyParam | StaticFileChunkingStrategyObjectParam;\n\n/**\n * This is returned when the chunking strategy is unknown. Typically, this is\n * because the file was indexed before the `chunking_strategy` concept was\n * introduced in the API.\n */\nexport interface OtherFileChunkingStrategyObject {\n  /**\n   * Always `other`.\n   */\n  type: 'other';\n}\n\nexport interface StaticFileChunkingStrategy {\n  /**\n   * The number of tokens that overlap between chunks. The default value is `400`.\n   *\n   * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n   */\n  chunk_overlap_tokens: number;\n\n  /**\n   * The maximum number of tokens in each chunk. The default value is `800`. The\n   * minimum value is `100` and the maximum value is `4096`.\n   */\n  max_chunk_size_tokens: number;\n}\n\nexport interface StaticFileChunkingStrategyObject {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * Customize your own chunking strategy by setting chunk size and chunk overlap.\n */\nexport interface StaticFileChunkingStrategyObjectParam {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * A vector store is a collection of processed files can be used by the\n * `file_search` tool.\n */\nexport interface VectorStore {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was created.\n   */\n  created_at: number;\n\n  file_counts: VectorStore.FileCounts;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was last active.\n   */\n  last_active_at: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `vector_store`.\n   */\n  object: 'vector_store';\n\n  /**\n   * The status of the vector store, which can be either `expired`, `in_progress`, or\n   * `completed`. A status of `completed` indicates that the vector store is ready\n   * for use.\n   */\n  status: 'expired' | 'in_progress' | 'completed';\n\n  /**\n   * The total number of bytes used by the files in the vector store.\n   */\n  usage_bytes: number;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStore.ExpiresAfter;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store will expire.\n   */\n  expires_at?: number | null;\n}\n\nexport namespace VectorStore {\n  export interface FileCounts {\n    /**\n     * The number of files that were cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been successfully processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.deleted';\n}\n\nexport interface VectorStoreSearchResponse {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * Content chunks from the file.\n   */\n  content: Array<VectorStoreSearchResponse.Content>;\n\n  /**\n   * The ID of the vector store file.\n   */\n  file_id: string;\n\n  /**\n   * The name of the vector store file.\n   */\n  filename: string;\n\n  /**\n   * The similarity score for the result.\n   */\n  score: number;\n}\n\nexport namespace VectorStoreSearchResponse {\n  export interface Content {\n    /**\n     * The text content returned from search.\n     */\n    text: string;\n\n    /**\n     * The type of content.\n     */\n    type: 'text';\n  }\n}\n\nexport interface VectorStoreCreateParams {\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: FileChunkingStrategyParam;\n\n  /**\n   * A description for the vector store. Can be used to describe the vector store's\n   * purpose.\n   */\n  description?: string;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreCreateParams.ExpiresAfter;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string;\n}\n\nexport namespace VectorStoreCreateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreUpdateParams.ExpiresAfter | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string | null;\n}\n\nexport namespace VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface VectorStoreSearchParams {\n  /**\n   * A query string for a search\n   */\n  query: string | Array<string>;\n\n  /**\n   * A filter to apply based on file attributes.\n   */\n  filters?: Shared.ComparisonFilter | Shared.CompoundFilter;\n\n  /**\n   * The maximum number of results to return. This number should be between 1 and 50\n   * inclusive.\n   */\n  max_num_results?: number;\n\n  /**\n   * Ranking options for search.\n   */\n  ranking_options?: VectorStoreSearchParams.RankingOptions;\n\n  /**\n   * Whether to rewrite the natural language query for vector search.\n   */\n  rewrite_query?: boolean;\n}\n\nexport namespace VectorStoreSearchParams {\n  /**\n   * Ranking options for search.\n   */\n  export interface RankingOptions {\n    /**\n     * Enable re-ranking; set to `none` to disable, which can help reduce latency.\n     */\n    ranker?: 'none' | 'auto' | 'default-2024-11-15';\n\n    score_threshold?: number;\n  }\n}\n\nVectorStores.Files = Files;\nVectorStores.FileBatches = FileBatches;\n\nexport declare namespace VectorStores {\n  export {\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyObjectParam as StaticFileChunkingStrategyObjectParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    type VectorStoreSearchResponse as VectorStoreSearchResponse,\n    type VectorStoresPage as VectorStoresPage,\n    type VectorStoreSearchResponsesPage as VectorStoreSearchResponsesPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n    type VectorStoreSearchParams as VectorStoreSearchParams,\n  };\n\n  export {\n    Files as Files,\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    type FileContentResponse as FileContentResponse,\n    type VectorStoreFilesPage as VectorStoreFilesPage,\n    type FileContentResponsesPage as FileContentResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileUpdateParams as FileUpdateParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n    type FileContentParams as FileContentParams,\n  };\n\n  export {\n    FileBatches as FileBatches,\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchRetrieveParams as FileBatchRetrieveParams,\n    type FileBatchCancelParams as FileBatchCancelParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { hasOwn } from './values';\nimport { type OpenAI } from '../../client';\nimport { RequestOptions } from '../request-options';\n\ntype LogFn = (message: string, ...rest: unknown[]) => void;\nexport type Logger = {\n  error: LogFn;\n  warn: LogFn;\n  info: LogFn;\n  debug: LogFn;\n};\nexport type LogLevel = 'off' | 'error' | 'warn' | 'info' | 'debug';\n\nconst levelNumbers = {\n  off: 0,\n  error: 200,\n  warn: 300,\n  info: 400,\n  debug: 500,\n};\n\nexport const parseLogLevel = (\n  maybeLevel: string | undefined,\n  sourceName: string,\n  client: OpenAI,\n): LogLevel | undefined => {\n  if (!maybeLevel) {\n    return undefined;\n  }\n  if (hasOwn(levelNumbers, maybeLevel)) {\n    return maybeLevel;\n  }\n  loggerFor(client).warn(\n    `${sourceName} was set to ${JSON.stringify(maybeLevel)}, expected one of ${JSON.stringify(\n      Object.keys(levelNumbers),\n    )}`,\n  );\n  return undefined;\n};\n\nfunction noop() {}\n\nfunction makeLogFn(fnLevel: keyof Logger, logger: Logger | undefined, logLevel: LogLevel) {\n  if (!logger || levelNumbers[fnLevel] > levelNumbers[logLevel]) {\n    return noop;\n  } else {\n    // Don't wrap logger functions, we want the stacktrace intact!\n    return logger[fnLevel].bind(logger);\n  }\n}\n\nconst noopLogger = {\n  error: noop,\n  warn: noop,\n  info: noop,\n  debug: noop,\n};\n\nlet cachedLoggers = /* @__PURE__ */ new WeakMap<Logger, [LogLevel, Logger]>();\n\nexport function loggerFor(client: OpenAI): Logger {\n  const logger = client.logger;\n  const logLevel = client.logLevel ?? 'off';\n  if (!logger) {\n    return noopLogger;\n  }\n\n  const cachedLogger = cachedLoggers.get(logger);\n  if (cachedLogger && cachedLogger[0] === logLevel) {\n    return cachedLogger[1];\n  }\n\n  const levelLogger = {\n    error: makeLogFn('error', logger, logLevel),\n    warn: makeLogFn('warn', logger, logLevel),\n    info: makeLogFn('info', logger, logLevel),\n    debug: makeLogFn('debug', logger, logLevel),\n  };\n\n  cachedLoggers.set(logger, [logLevel, levelLogger]);\n\n  return levelLogger;\n}\n\nexport const formatRequestDetails = (details: {\n  options?: RequestOptions | undefined;\n  headers?: Headers | Record<string, string> | undefined;\n  retryOfRequestLogID?: string | undefined;\n  retryOf?: string | undefined;\n  url?: string | undefined;\n  status?: number | undefined;\n  method?: string | undefined;\n  durationMs?: number | undefined;\n  message?: unknown;\n  body?: unknown;\n}) => {\n  if (details.options) {\n    details.options = { ...details.options };\n    delete details.options['headers']; // redundant + leaks internals\n  }\n  if (details.headers) {\n    details.headers = Object.fromEntries(\n      (details.headers instanceof Headers ? [...details.headers] : Object.entries(details.headers)).map(\n        ([name, value]) => [\n          name,\n          (\n            name.toLowerCase() === 'authorization' ||\n            name.toLowerCase() === 'cookie' ||\n            name.toLowerCase() === 'set-cookie'\n          ) ?\n            '***'\n          : value,\n        ],\n      ),\n    );\n  }\n  if ('retryOfRequestLogID' in details) {\n    if (details.retryOfRequestLogID) {\n      details.retryOf = details.retryOfRequestLogID;\n    }\n    delete details.retryOfRequestLogID;\n  }\n  return details;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as CompletionsCompletionsAPI from './completions';\nimport * as CompletionsAPI from '../../completions';\nimport * as Shared from '../../shared';\nimport * as MessagesAPI from './messages';\nimport { MessageListParams, Messages } from './messages';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { Stream } from '../../../core/streaming';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nimport { ChatCompletionRunner } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingRunner } from '../../../lib/ChatCompletionStreamingRunner';\nimport { RunnerOptions } from '../../../lib/AbstractChatCompletionRunner';\nimport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nimport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nimport { ExtractParsedContentFromParams, parseChatCompletion, validateInputTools } from '../../../lib/parser';\n\nexport class Completions extends APIResource {\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * **Starting a new project?** We recommend trying\n   * [Responses](https://platform.openai.com/docs/api-reference/responses) to take\n   * advantage of the latest OpenAI platform features. Compare\n   * [Chat Completions with Responses](https://platform.openai.com/docs/guides/responses-vs-chat-completions?api-mode=responses).\n   *\n   * ---\n   *\n   * Creates a model response for the given chat conversation. Learn more in the\n   * [text generation](https://platform.openai.com/docs/guides/text-generation),\n   * [vision](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio) guides.\n   *\n   * Parameter support can differ depending on the model used to generate the\n   * response, particularly for newer reasoning models. Parameters that are only\n   * supported for reasoning models are noted below. For the current state of\n   * unsupported parameters in reasoning models,\n   * [refer to the reasoning guide](https://platform.openai.com/docs/guides/reasoning).\n   *\n   * @example\n   * ```ts\n   * const chatCompletion = await client.chat.completions.create(\n   *   {\n   *     messages: [{ content: 'string', role: 'developer' }],\n   *     model: 'gpt-4o',\n   *   },\n   * );\n   * ```\n   */\n  create(body: ChatCompletionCreateParamsNonStreaming, options?: RequestOptions): APIPromise<ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk>>;\n  create(\n    body: ChatCompletionCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk> | ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<ChatCompletion> | APIPromise<Stream<ChatCompletionChunk>> {\n    return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ChatCompletion>\n      | APIPromise<Stream<ChatCompletionChunk>>;\n  }\n\n  /**\n   * Get a stored chat completion. Only Chat Completions that have been created with\n   * the `store` parameter set to `true` will be returned.\n   *\n   * @example\n   * ```ts\n   * const chatCompletion =\n   *   await client.chat.completions.retrieve('completion_id');\n   * ```\n   */\n  retrieve(completionID: string, options?: RequestOptions): APIPromise<ChatCompletion> {\n    return this._client.get(path`/chat/completions/${completionID}`, options);\n  }\n\n  /**\n   * Modify a stored chat completion. Only Chat Completions that have been created\n   * with the `store` parameter set to `true` can be modified. Currently, the only\n   * supported modification is to update the `metadata` field.\n   *\n   * @example\n   * ```ts\n   * const chatCompletion = await client.chat.completions.update(\n   *   'completion_id',\n   *   { metadata: { foo: 'string' } },\n   * );\n   * ```\n   */\n  update(\n    completionID: string,\n    body: ChatCompletionUpdateParams,\n    options?: RequestOptions,\n  ): APIPromise<ChatCompletion> {\n    return this._client.post(path`/chat/completions/${completionID}`, { body, ...options });\n  }\n\n  /**\n   * List stored Chat Completions. Only Chat Completions that have been stored with\n   * the `store` parameter set to `true` will be returned.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const chatCompletion of client.chat.completions.list()) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    query: ChatCompletionListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ChatCompletionsPage, ChatCompletion> {\n    return this._client.getAPIList('/chat/completions', CursorPage<ChatCompletion>, { query, ...options });\n  }\n\n  /**\n   * Delete a stored chat completion. Only Chat Completions that have been created\n   * with the `store` parameter set to `true` can be deleted.\n   *\n   * @example\n   * ```ts\n   * const chatCompletionDeleted =\n   *   await client.chat.completions.delete('completion_id');\n   * ```\n   */\n  delete(completionID: string, options?: RequestOptions): APIPromise<ChatCompletionDeleted> {\n    return this._client.delete(path`/chat/completions/${completionID}`, options);\n  }\n\n  parse<Params extends ChatCompletionParseParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): APIPromise<ParsedChatCompletion<ParsedT>> {\n    validateInputTools(body.tools);\n\n    return this._client.chat.completions\n      .create(body, {\n        ...options,\n        headers: {\n          ...options?.headers,\n          'X-Stainless-Helper-Method': 'chat.completions.parse',\n        },\n      })\n      ._thenUnwrap((completion) => parseChatCompletion(completion, body));\n  }\n\n  /**\n   * A convenience helper for using tool calls with the /chat/completions endpoint\n   * which automatically calls the JavaScript functions you provide and sends their\n   * results back to the /chat/completions endpoint, looping as long as the model\n   * requests function calls.\n   *\n   * For more details and examples, see\n   * [the docs](https://github.com/openai/openai-node#automated-function-calls)\n   */\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionStreamingRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any> | ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(\n    body: Params,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> | ChatCompletionStreamingRunner<ParsedT> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runTools(\n        this._client,\n        body as ChatCompletionStreamingToolRunnerParams<any>,\n        options,\n      );\n    }\n\n    return ChatCompletionRunner.runTools(this._client, body as ChatCompletionToolRunnerParams<any>, options);\n  }\n\n  /**\n   * Creates a chat completion stream\n   */\n  stream<Params extends ChatCompletionStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    return ChatCompletionStream.createChatCompletion(this._client, body, options);\n  }\n}\n\nexport interface ParsedFunction extends ChatCompletionMessageFunctionToolCall.Function {\n  parsed_arguments?: unknown;\n}\n\nexport interface ParsedFunctionToolCall extends ChatCompletionMessageFunctionToolCall {\n  function: ParsedFunction;\n}\n\nexport interface ParsedChatCompletionMessage<ParsedT> extends ChatCompletionMessage {\n  parsed: ParsedT | null;\n  tool_calls?: Array<ParsedFunctionToolCall>;\n}\n\nexport interface ParsedChoice<ParsedT> extends ChatCompletion.Choice {\n  message: ParsedChatCompletionMessage<ParsedT>;\n}\n\nexport interface ParsedChatCompletion<ParsedT> extends ChatCompletion {\n  choices: Array<ParsedChoice<ParsedT>>;\n}\n\nexport type ChatCompletionParseParams = ChatCompletionCreateParamsNonStreaming;\n\nexport { ChatCompletionStreamingRunner } from '../../../lib/ChatCompletionStreamingRunner';\nexport {\n  type RunnableFunctionWithParse,\n  type RunnableFunctionWithoutParse,\n  ParsingToolFunction,\n} from '../../../lib/RunnableFunction';\nexport { type ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { type ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nexport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nexport { ChatCompletionRunner } from '../../../lib/ChatCompletionRunner';\n\nexport type ChatCompletionsPage = CursorPage<ChatCompletion>;\n\nexport type ChatCompletionStoreMessagesPage = CursorPage<ChatCompletionStoreMessage>;\n\n/**\n * Represents a chat completion response returned by model, based on the provided\n * input.\n */\nexport interface ChatCompletion {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletion.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for the chat completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion`.\n   */\n  object: 'chat.completion';\n\n  /**\n   * Specifies the processing type used for serving the request.\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When the `service_tier` parameter is set, the response body will include the\n   * `service_tier` value based on the processing mode actually used to serve the\n   * request. This response value may be different from the value set in the\n   * parameter.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * @deprecated This fingerprint represents the backend configuration that the model\n   * runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletion {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: Choice.Logprobs | null;\n\n    /**\n     * A chat completion message generated by the model.\n     */\n    message: CompletionsCompletionsAPI.ChatCompletionMessage;\n  }\n\n  export namespace Choice {\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\n/**\n * Constrains the tools available to the model to a pre-defined set.\n */\nexport interface ChatCompletionAllowedToolChoice {\n  /**\n   * Constrains the tools available to the model to a pre-defined set.\n   */\n  allowed_tools: ChatCompletionAllowedTools;\n\n  /**\n   * Allowed tool configuration type. Always `allowed_tools`.\n   */\n  type: 'allowed_tools';\n}\n\n/**\n * Messages sent by the model in response to user messages.\n */\nexport interface ChatCompletionAssistantMessageParam {\n  /**\n   * The role of the messages author, in this case `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAssistantMessageParam.Audio | null;\n\n  /**\n   * The contents of the assistant message. Required unless `tool_calls` or\n   * `function_call` is specified.\n   */\n  content?: string | Array<ChatCompletionContentPartText | ChatCompletionContentPartRefusal> | null;\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionAssistantMessageParam.FunctionCall | null;\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n\n  /**\n   * The refusal message by the assistant.\n   */\n  refusal?: string | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionAssistantMessageParam {\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  export interface Audio {\n    /**\n     * Unique identifier for a previous audio response from the model.\n     */\n    id: string;\n  }\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * If the audio output modality is requested, this object contains data about the\n * audio response from the model.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudio {\n  /**\n   * Unique identifier for this audio response.\n   */\n  id: string;\n\n  /**\n   * Base64 encoded audio bytes generated by the model, in the format specified in\n   * the request.\n   */\n  data: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when this audio response will no longer be\n   * accessible on the server for use in multi-turn conversations.\n   */\n  expires_at: number;\n\n  /**\n   * Transcript of the audio generated by the model.\n   */\n  transcript: string;\n}\n\n/**\n * Parameters for audio output. Required when audio output is requested with\n * `modalities: [\"audio\"]`.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudioParam {\n  /**\n   * Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`, `opus`,\n   * or `pcm16`.\n   */\n  format: 'wav' | 'aac' | 'mp3' | 'flac' | 'opus' | 'pcm16';\n\n  /**\n   * The voice the model uses to respond. Supported built-in voices are `alloy`,\n   * `ash`, `ballad`, `coral`, `echo`, `fable`, `nova`, `onyx`, `sage`, `shimmer`,\n   * `marin`, and `cedar`.\n   */\n  voice:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by the model,\n * based on the provided input.\n * [Learn more](https://platform.openai.com/docs/guides/streaming-responses).\n */\nexport interface ChatCompletionChunk {\n  /**\n   * A unique identifier for the chat completion. Each chunk has the same ID.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can contain more than one elements if `n` is\n   * greater than 1. Can also be empty for the last chunk if you set\n   * `stream_options: {\"include_usage\": true}`.\n   */\n  choices: Array<ChatCompletionChunk.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created. Each\n   * chunk has the same timestamp.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion.chunk`.\n   */\n  object: 'chat.completion.chunk';\n\n  /**\n   * Specifies the processing type used for serving the request.\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When the `service_tier` parameter is set, the response body will include the\n   * `service_tier` value based on the processing mode actually used to serve the\n   * request. This response value may be different from the value set in the\n   * parameter.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * @deprecated This fingerprint represents the backend configuration that the model\n   * runs with. Can be used in conjunction with the `seed` request parameter to\n   * understand when backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * An optional field that will only be present when you set\n   * `stream_options: {\"include_usage\": true}` in your request. When present, it\n   * contains a null value **except for the last chunk** which contains the token\n   * usage statistics for the entire request.\n   *\n   * **NOTE:** If the stream is interrupted or cancelled, you may not receive the\n   * final usage chunk which contains the total token usage for the request.\n   */\n  usage?: CompletionsAPI.CompletionUsage | null;\n}\n\nexport namespace ChatCompletionChunk {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    delta: Choice.Delta;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call' | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs?: Choice.Logprobs | null;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Delta {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      /**\n       * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n       * function that should be called, as generated by the model.\n       */\n      function_call?: Delta.FunctionCall;\n\n      /**\n       * The refusal message generated by the model.\n       */\n      refusal?: string | null;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'developer' | 'system' | 'user' | 'assistant' | 'tool';\n\n      tool_calls?: Array<Delta.ToolCall>;\n    }\n\n    export namespace Delta {\n      /**\n       * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n       * function that should be called, as generated by the model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n\n      export interface ToolCall {\n        index: number;\n\n        /**\n         * The ID of the tool call.\n         */\n        id?: string;\n\n        function?: ToolCall.Function;\n\n        /**\n         * The type of the tool. Currently, only `function` is supported.\n         */\n        type?: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments?: string;\n\n          /**\n           * The name of the function to call.\n           */\n          name?: string;\n        }\n      }\n    }\n\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport type ChatCompletionContentPart =\n  | ChatCompletionContentPartText\n  | ChatCompletionContentPartImage\n  | ChatCompletionContentPartInputAudio\n  | ChatCompletionContentPart.File;\n\nexport namespace ChatCompletionContentPart {\n  /**\n   * Learn about [file inputs](https://platform.openai.com/docs/guides/text) for text\n   * generation.\n   */\n  export interface File {\n    file: File.File;\n\n    /**\n     * The type of the content part. Always `file`.\n     */\n    type: 'file';\n  }\n\n  export namespace File {\n    export interface File {\n      /**\n       * The base64 encoded file data, used when passing the file to the model as a\n       * string.\n       */\n      file_data?: string;\n\n      /**\n       * The ID of an uploaded file to use as input.\n       */\n      file_id?: string;\n\n      /**\n       * The name of the file, used when passing the file to the model as a string.\n       */\n      filename?: string;\n    }\n  }\n}\n\n/**\n * Learn about [image inputs](https://platform.openai.com/docs/guides/vision).\n */\nexport interface ChatCompletionContentPartImage {\n  image_url: ChatCompletionContentPartImage.ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport namespace ChatCompletionContentPartImage {\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n\n    /**\n     * Specifies the detail level of the image. Learn more in the\n     * [Vision guide](https://platform.openai.com/docs/guides/vision#low-or-high-fidelity-image-understanding).\n     */\n    detail?: 'auto' | 'low' | 'high';\n  }\n}\n\n/**\n * Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionContentPartInputAudio {\n  input_audio: ChatCompletionContentPartInputAudio.InputAudio;\n\n  /**\n   * The type of the content part. Always `input_audio`.\n   */\n  type: 'input_audio';\n}\n\nexport namespace ChatCompletionContentPartInputAudio {\n  export interface InputAudio {\n    /**\n     * Base64 encoded audio data.\n     */\n    data: string;\n\n    /**\n     * The format of the encoded audio data. Currently supports \"wav\" and \"mp3\".\n     */\n    format: 'wav' | 'mp3';\n  }\n}\n\nexport interface ChatCompletionContentPartRefusal {\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'refusal';\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport interface ChatCompletionContentPartText {\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'text';\n}\n\n/**\n * A custom tool that processes input using a specified format.\n */\nexport interface ChatCompletionCustomTool {\n  /**\n   * Properties of the custom tool.\n   */\n  custom: ChatCompletionCustomTool.Custom;\n\n  /**\n   * The type of the custom tool. Always `custom`.\n   */\n  type: 'custom';\n}\n\nexport namespace ChatCompletionCustomTool {\n  /**\n   * Properties of the custom tool.\n   */\n  export interface Custom {\n    /**\n     * The name of the custom tool, used to identify it in tool calls.\n     */\n    name: string;\n\n    /**\n     * Optional description of the custom tool, used to provide more context.\n     */\n    description?: string;\n\n    /**\n     * The input format for the custom tool. Default is unconstrained text.\n     */\n    format?: Custom.Text | Custom.Grammar;\n  }\n\n  export namespace Custom {\n    /**\n     * Unconstrained free-form text.\n     */\n    export interface Text {\n      /**\n       * Unconstrained text format. Always `text`.\n       */\n      type: 'text';\n    }\n\n    /**\n     * A grammar defined by the user.\n     */\n    export interface Grammar {\n      /**\n       * Your chosen grammar.\n       */\n      grammar: Grammar.Grammar;\n\n      /**\n       * Grammar format. Always `grammar`.\n       */\n      type: 'grammar';\n    }\n\n    export namespace Grammar {\n      /**\n       * Your chosen grammar.\n       */\n      export interface Grammar {\n        /**\n         * The grammar definition.\n         */\n        definition: string;\n\n        /**\n         * The syntax of the grammar definition. One of `lark` or `regex`.\n         */\n        syntax: 'lark' | 'regex';\n      }\n    }\n  }\n}\n\nexport interface ChatCompletionDeleted {\n  /**\n   * The ID of the chat completion that was deleted.\n   */\n  id: string;\n\n  /**\n   * Whether the chat completion was deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * The type of object being deleted.\n   */\n  object: 'chat.completion.deleted';\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, `developer` messages\n * replace the previous `system` messages.\n */\nexport interface ChatCompletionDeveloperMessageParam {\n  /**\n   * The contents of the developer message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `developer`.\n   */\n  role: 'developer';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n * to call that function.\n */\nexport interface ChatCompletionFunctionCallOption {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * @deprecated\n */\nexport interface ChatCompletionFunctionMessageParam {\n  /**\n   * The contents of the function message.\n   */\n  content: string | null;\n\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * The role of the messages author, in this case `function`.\n   */\n  role: 'function';\n}\n\n/**\n * A function tool that can be used to generate a response.\n */\nexport interface ChatCompletionFunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionMessage {\n  /**\n   * The contents of the message.\n   */\n  content: string | null;\n\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string | null;\n\n  /**\n   * The role of the author of this message.\n   */\n  role: 'assistant';\n\n  /**\n   * Annotations for the message, when applicable, as when using the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  annotations?: Array<ChatCompletionMessage.Annotation>;\n\n  /**\n   * If the audio output modality is requested, this object contains data about the\n   * audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudio | null;\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionMessage.FunctionCall | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionMessage {\n  /**\n   * A URL citation when using web search.\n   */\n  export interface Annotation {\n    /**\n     * The type of the URL citation. Always `url_citation`.\n     */\n    type: 'url_citation';\n\n    /**\n     * A URL citation when using web search.\n     */\n    url_citation: Annotation.URLCitation;\n  }\n\n  export namespace Annotation {\n    /**\n     * A URL citation when using web search.\n     */\n    export interface URLCitation {\n      /**\n       * The index of the last character of the URL citation in the message.\n       */\n      end_index: number;\n\n      /**\n       * The index of the first character of the URL citation in the message.\n       */\n      start_index: number;\n\n      /**\n       * The title of the web resource.\n       */\n      title: string;\n\n      /**\n       * The URL of the web resource.\n       */\n      url: string;\n    }\n  }\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * A call to a custom tool created by the model.\n */\nexport interface ChatCompletionMessageCustomToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The custom tool that the model called.\n   */\n  custom: ChatCompletionMessageCustomToolCall.Custom;\n\n  /**\n   * The type of the tool. Always `custom`.\n   */\n  type: 'custom';\n}\n\nexport namespace ChatCompletionMessageCustomToolCall {\n  /**\n   * The custom tool that the model called.\n   */\n  export interface Custom {\n    /**\n     * The input for the custom tool call generated by the model.\n     */\n    input: string;\n\n    /**\n     * The name of the custom tool to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * A call to a function tool created by the model.\n */\nexport interface ChatCompletionMessageFunctionToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The function that the model called.\n   */\n  function: ChatCompletionMessageFunctionToolCall.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionMessageFunctionToolCall {\n  /**\n   * The function that the model called.\n   */\n  export interface Function {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, `developer` messages\n * replace the previous `system` messages.\n */\nexport type ChatCompletionMessageParam =\n  | ChatCompletionDeveloperMessageParam\n  | ChatCompletionSystemMessageParam\n  | ChatCompletionUserMessageParam\n  | ChatCompletionAssistantMessageParam\n  | ChatCompletionToolMessageParam\n  | ChatCompletionFunctionMessageParam;\n\n/**\n * A call to a function tool created by the model.\n */\nexport type ChatCompletionMessageToolCall =\n  | ChatCompletionMessageFunctionToolCall\n  | ChatCompletionMessageCustomToolCall;\n\nexport type ChatCompletionModality = 'text' | 'audio';\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * function.\n */\nexport interface ChatCompletionNamedToolChoice {\n  function: ChatCompletionNamedToolChoice.Function;\n\n  /**\n   * For function calling, the type is always `function`.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionNamedToolChoice {\n  export interface Function {\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * custom tool.\n */\nexport interface ChatCompletionNamedToolChoiceCustom {\n  custom: ChatCompletionNamedToolChoiceCustom.Custom;\n\n  /**\n   * For custom tool calling, the type is always `custom`.\n   */\n  type: 'custom';\n}\n\nexport namespace ChatCompletionNamedToolChoiceCustom {\n  export interface Custom {\n    /**\n     * The name of the custom tool to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Static predicted output content, such as the content of a text file that is\n * being regenerated.\n */\nexport interface ChatCompletionPredictionContent {\n  /**\n   * The content that should be matched when generating a model response. If\n   * generated tokens would match this content, the entire model response can be\n   * returned much more quickly.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The type of the predicted content you want to provide. This type is currently\n   * always `content`.\n   */\n  type: 'content';\n}\n\n/**\n * The role of the author of a message\n */\nexport type ChatCompletionRole = 'developer' | 'system' | 'user' | 'assistant' | 'tool' | 'function';\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionStoreMessage extends ChatCompletionMessage {\n  /**\n   * The identifier of the chat message.\n   */\n  id: string;\n\n  /**\n   * If a content parts array was provided, this is an array of `text` and\n   * `image_url` parts. Otherwise, null.\n   */\n  content_parts?: Array<ChatCompletionContentPartText | ChatCompletionContentPartImage> | null;\n}\n\n/**\n * Options for streaming response. Only set this when you set `stream: true`.\n */\nexport interface ChatCompletionStreamOptions {\n  /**\n   * When true, stream obfuscation will be enabled. Stream obfuscation adds random\n   * characters to an `obfuscation` field on streaming delta events to normalize\n   * payload sizes as a mitigation to certain side-channel attacks. These obfuscation\n   * fields are included by default, but add a small amount of overhead to the data\n   * stream. You can set `include_obfuscation` to false to optimize for bandwidth if\n   * you trust the network links between your application and the OpenAI API.\n   */\n  include_obfuscation?: boolean;\n\n  /**\n   * If set, an additional chunk will be streamed before the `data: [DONE]` message.\n   * The `usage` field on this chunk shows the token usage statistics for the entire\n   * request, and the `choices` field will always be an empty array.\n   *\n   * All other chunks will also include a `usage` field, but with a null value.\n   * **NOTE:** If the stream is interrupted, you may not receive the final usage\n   * chunk which contains the total token usage for the request.\n   */\n  include_usage?: boolean;\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, use `developer` messages\n * for this purpose instead.\n */\nexport interface ChatCompletionSystemMessageParam {\n  /**\n   * The contents of the system message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `system`.\n   */\n  role: 'system';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\nexport interface ChatCompletionTokenLogprob {\n  /**\n   * The token.\n   */\n  token: string;\n\n  /**\n   * A list of integers representing the UTF-8 bytes representation of the token.\n   * Useful in instances where characters are represented by multiple tokens and\n   * their byte representations must be combined to generate the correct text\n   * representation. Can be `null` if there is no bytes representation for the token.\n   */\n  bytes: Array<number> | null;\n\n  /**\n   * The log probability of this token, if it is within the top 20 most likely\n   * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n   * unlikely.\n   */\n  logprob: number;\n\n  /**\n   * List of the most likely tokens and their log probability, at this token\n   * position. In rare cases, there may be fewer than the number of requested\n   * `top_logprobs` returned.\n   */\n  top_logprobs: Array<ChatCompletionTokenLogprob.TopLogprob>;\n}\n\nexport namespace ChatCompletionTokenLogprob {\n  export interface TopLogprob {\n    /**\n     * The token.\n     */\n    token: string;\n\n    /**\n     * A list of integers representing the UTF-8 bytes representation of the token.\n     * Useful in instances where characters are represented by multiple tokens and\n     * their byte representations must be combined to generate the correct text\n     * representation. Can be `null` if there is no bytes representation for the token.\n     */\n    bytes: Array<number> | null;\n\n    /**\n     * The log probability of this token, if it is within the top 20 most likely\n     * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n     * unlikely.\n     */\n    logprob: number;\n  }\n}\n\n/**\n * A function tool that can be used to generate a response.\n */\nexport type ChatCompletionTool = ChatCompletionFunctionTool | ChatCompletionCustomTool;\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tool and instead generates a message. `auto` means the model can\n * pick between generating a message or calling one or more tools. `required` means\n * the model must call one or more tools. Specifying a particular tool via\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n *\n * `none` is the default when no tools are present. `auto` is the default if tools\n * are present.\n */\nexport type ChatCompletionToolChoiceOption =\n  | 'none'\n  | 'auto'\n  | 'required'\n  | ChatCompletionAllowedToolChoice\n  | ChatCompletionNamedToolChoice\n  | ChatCompletionNamedToolChoiceCustom;\n\nexport interface ChatCompletionToolMessageParam {\n  /**\n   * The contents of the tool message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `tool`.\n   */\n  role: 'tool';\n\n  /**\n   * Tool call that this message is responding to.\n   */\n  tool_call_id: string;\n}\n\n/**\n * Messages sent by an end user, containing prompts or additional context\n * information.\n */\nexport interface ChatCompletionUserMessageParam {\n  /**\n   * The contents of the user message.\n   */\n  content: string | Array<ChatCompletionContentPart>;\n\n  /**\n   * The role of the messages author, in this case `user`.\n   */\n  role: 'user';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * Constrains the tools available to the model to a pre-defined set.\n */\nexport interface ChatCompletionAllowedTools {\n  /**\n   * Constrains the tools available to the model to a pre-defined set.\n   *\n   * `auto` allows the model to pick from among the allowed tools and generate a\n   * message.\n   *\n   * `required` requires the model to call one or more of the allowed tools.\n   */\n  mode: 'auto' | 'required';\n\n  /**\n   * A list of tool definitions that the model should be allowed to call.\n   *\n   * For the Chat Completions API, the list of tool definitions might look like:\n   *\n   * ```json\n   * [\n   *   { \"type\": \"function\", \"function\": { \"name\": \"get_weather\" } },\n   *   { \"type\": \"function\", \"function\": { \"name\": \"get_time\" } }\n   * ]\n   * ```\n   */\n  tools: Array<{ [key: string]: unknown }>;\n}\n\nexport type ChatCompletionReasoningEffort = Shared.ReasoningEffort | null;\n\nexport type ChatCompletionCreateParams =\n  | ChatCompletionCreateParamsNonStreaming\n  | ChatCompletionCreateParamsStreaming;\n\nexport interface ChatCompletionCreateParamsBase {\n  /**\n   * A list of messages comprising the conversation so far. Depending on the\n   * [model](https://platform.openai.com/docs/models) you use, different message\n   * types (modalities) are supported, like\n   * [text](https://platform.openai.com/docs/guides/text-generation),\n   * [images](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio).\n   */\n  messages: Array<ChatCompletionMessageParam>;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * Parameters for audio output. Required when audio output is requested with\n   * `modalities: [\"audio\"]`.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudioParam | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * @deprecated Deprecated in favor of `tool_choice`.\n   *\n   * Controls which (if any) function is called by the model.\n   *\n   * `none` means the model will not call a function and instead generates a message.\n   *\n   * `auto` means the model can pick between generating a message or calling a\n   * function.\n   *\n   * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n   * to call that function.\n   *\n   * `none` is the default when no functions are present. `auto` is the default if\n   * functions are present.\n   */\n  function_call?: 'none' | 'auto' | ChatCompletionFunctionCallOption;\n\n  /**\n   * @deprecated Deprecated in favor of `tools`.\n   *\n   * A list of functions the model may generate JSON inputs for.\n   */\n  functions?: Array<ChatCompletionCreateParams.Function>;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the\n   * tokenizer) to an associated bias value from -100 to 100. Mathematically, the\n   * bias is added to the logits generated by the model prior to sampling. The exact\n   * effect will vary per model, but values between -1 and 1 should decrease or\n   * increase likelihood of selection; values like -100 or 100 should result in a ban\n   * or exclusive selection of the relevant token.\n   */\n  logit_bias?: { [key: string]: number } | null;\n\n  /**\n   * Whether to return log probabilities of the output tokens or not. If true,\n   * returns the log probabilities of each output token returned in the `content` of\n   * `message`.\n   */\n  logprobs?: boolean | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a completion,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * @deprecated The maximum number of [tokens](/tokenizer) that can be generated in\n   * the chat completion. This value can be used to control\n   * [costs](https://openai.com/api/pricing/) for text generated via API.\n   *\n   * This value is now deprecated in favor of `max_completion_tokens`, and is not\n   * compatible with\n   * [o-series models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Output types that you would like the model to generate. Most models are capable\n   * of generating text, which is the default:\n   *\n   * `[\"text\"]`\n   *\n   * The `gpt-4o-audio-preview` model can also be used to\n   * [generate audio](https://platform.openai.com/docs/guides/audio). To request that\n   * this model generate both text and audio responses, you can use:\n   *\n   * `[\"text\", \"audio\"]`\n   */\n  modalities?: Array<'text' | 'audio'> | null;\n\n  /**\n   * How many chat completion choices to generate for each input message. Note that\n   * you will be charged based on the number of generated tokens across all of the\n   * choices. Keep `n` as `1` to minimize costs.\n   */\n  n?: number | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Static predicted output content, such as the content of a text file that is\n   * being regenerated.\n   */\n  prediction?: ChatCompletionPredictionContent | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * Used by OpenAI to cache responses for similar requests to optimize your cache\n   * hit rates. Replaces the `user` field.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n   */\n  prompt_cache_key?: string;\n\n  /**\n   * The retention policy for the prompt cache. Set to `24h` to enable extended\n   * prompt caching, which keeps cached prefixes active for longer, up to a maximum\n   * of 24 hours.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).\n   */\n  prompt_cache_retention?: 'in-memory' | '24h' | null;\n\n  /**\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n   * Reducing reasoning effort can result in faster responses and fewer tokens used\n   * on reasoning in a response.\n   *\n   * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n   *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n   *   calls are supported for all reasoning values in gpt-5.1.\n   * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n   *   support `none`.\n   * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n   * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * An object specifying the format that the model must output.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n   * ensures the message the model generates is valid JSON. Using `json_schema` is\n   * preferred for models that support it.\n   */\n  response_format?:\n    | Shared.ResponseFormatText\n    | Shared.ResponseFormatJSONSchema\n    | Shared.ResponseFormatJSONObject;\n\n  /**\n   * A stable identifier used to help detect users of your application that may be\n   * violating OpenAI's usage policies. The IDs should be a string that uniquely\n   * identifies each user. We recommend hashing their username or email address, in\n   * order to avoid sending us any identifying information.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  safety_identifier?: string;\n\n  /**\n   * @deprecated This feature is in Beta. If specified, our system will make a best\n   * effort to sample deterministically, such that repeated requests with the same\n   * `seed` and parameters should return the same result. Determinism is not\n   * guaranteed, and you should refer to the `system_fingerprint` response parameter\n   * to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Specifies the processing type used for serving the request.\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When the `service_tier` parameter is set, the response body will include the\n   * `service_tier` value based on the processing mode actually used to serve the\n   * request. This response value may be different from the value set in the\n   * parameter.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * Not supported with latest reasoning models `o3` and `o4-mini`.\n   *\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether or not to store the output of this chat completion request for use in\n   * our [model distillation](https://platform.openai.com/docs/guides/distillation)\n   * or [evals](https://platform.openai.com/docs/guides/evals) products.\n   *\n   * Supports text and image inputs. Note: image inputs over 8MB will be dropped.\n   */\n  store?: boolean | null;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionStreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tool and instead generates a message. `auto` means the model can\n   * pick between generating a message or calling one or more tools. `required` means\n   * the model must call one or more tools. Specifying a particular tool via\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   *\n   * `none` is the default when no tools are present. `auto` is the default if tools\n   * are present.\n   */\n  tool_choice?: ChatCompletionToolChoiceOption;\n\n  /**\n   * A list of tools the model may call. You can provide either\n   * [custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools)\n   * or [function tools](https://platform.openai.com/docs/guides/function-calling).\n   */\n  tools?: Array<ChatCompletionTool>;\n\n  /**\n   * An integer between 0 and 20 specifying the number of most likely tokens to\n   * return at each token position, each with an associated log probability.\n   * `logprobs` must be set to `true` if this parameter is used.\n   */\n  top_logprobs?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * @deprecated This field is being replaced by `safety_identifier` and\n   * `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching\n   * optimizations. A stable identifier for your end-users. Used to boost cache hit\n   * rates by better bucketing similar requests and to help OpenAI detect and prevent\n   * abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  user?: string;\n\n  /**\n   * Constrains the verbosity of the model's response. Lower values will result in\n   * more concise responses, while higher values will result in more verbose\n   * responses. Currently supported values are `low`, `medium`, and `high`.\n   */\n  verbosity?: 'low' | 'medium' | 'high' | null;\n\n  /**\n   * This tool searches the web for relevant results to use in a response. Learn more\n   * about the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  web_search_options?: ChatCompletionCreateParams.WebSearchOptions;\n}\n\nexport namespace ChatCompletionCreateParams {\n  /**\n   * @deprecated\n   */\n  export interface Function {\n    /**\n     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\n     * underscores and dashes, with a maximum length of 64.\n     */\n    name: string;\n\n    /**\n     * A description of what the function does, used by the model to choose when and\n     * how to call the function.\n     */\n    description?: string;\n\n    /**\n     * The parameters the functions accepts, described as a JSON Schema object. See the\n     * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n     * and the\n     * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n     * documentation about the format.\n     *\n     * Omitting `parameters` defines a function with an empty parameter list.\n     */\n    parameters?: Shared.FunctionParameters;\n  }\n\n  /**\n   * This tool searches the web for relevant results to use in a response. Learn more\n   * about the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  export interface WebSearchOptions {\n    /**\n     * High level guidance for the amount of context window space to use for the\n     * search. One of `low`, `medium`, or `high`. `medium` is the default.\n     */\n    search_context_size?: 'low' | 'medium' | 'high';\n\n    /**\n     * Approximate location parameters for the search.\n     */\n    user_location?: WebSearchOptions.UserLocation | null;\n  }\n\n  export namespace WebSearchOptions {\n    /**\n     * Approximate location parameters for the search.\n     */\n    export interface UserLocation {\n      /**\n       * Approximate location parameters for the search.\n       */\n      approximate: UserLocation.Approximate;\n\n      /**\n       * The type of location approximation. Always `approximate`.\n       */\n      type: 'approximate';\n    }\n\n    export namespace UserLocation {\n      /**\n       * Approximate location parameters for the search.\n       */\n      export interface Approximate {\n        /**\n         * Free text input for the city of the user, e.g. `San Francisco`.\n         */\n        city?: string;\n\n        /**\n         * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n         * the user, e.g. `US`.\n         */\n        country?: string;\n\n        /**\n         * Free text input for the region of the user, e.g. `California`.\n         */\n        region?: string;\n\n        /**\n         * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n         * user, e.g. `America/Los_Angeles`.\n         */\n        timezone?: string;\n      }\n    }\n  }\n\n  export type ChatCompletionCreateParamsNonStreaming =\n    CompletionsCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export type ChatCompletionCreateParamsStreaming =\n    CompletionsCompletionsAPI.ChatCompletionCreateParamsStreaming;\n}\n\nexport interface ChatCompletionCreateParamsNonStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream?: false | null;\n}\n\nexport interface ChatCompletionCreateParamsStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream: true;\n}\n\nexport interface ChatCompletionUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n}\n\nexport interface ChatCompletionListParams extends CursorPageParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The model used to generate the Chat Completions.\n   */\n  model?: string;\n\n  /**\n   * Sort order for Chat Completions by timestamp. Use `asc` for ascending order or\n   * `desc` for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\nCompletions.Messages = Messages;\n\nexport declare namespace Completions {\n  export {\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAllowedToolChoice as ChatCompletionAllowedToolChoice,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionCustomTool as ChatCompletionCustomTool,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionFunctionTool as ChatCompletionFunctionTool,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageCustomToolCall as ChatCompletionMessageCustomToolCall,\n    type ChatCompletionMessageFunctionToolCall as ChatCompletionMessageFunctionToolCall,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionNamedToolChoiceCustom as ChatCompletionNamedToolChoiceCustom,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type ChatCompletionAllowedTools as ChatCompletionAllowedTools,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    type ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n  };\n\n  export { Messages as Messages, type MessageListParams as MessageListParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport {\n  type ExtractParsedContentFromParams,\n  parseResponse,\n  type ResponseCreateParamsWithTools,\n  addOutputText,\n} from '../../lib/ResponsesParser';\nimport { ResponseStream, ResponseStreamParams } from '../../lib/responses/ResponseStream';\nimport { APIResource } from '../../core/resource';\nimport * as ResponsesAPI from './responses';\nimport * as Shared from '../shared';\nimport * as InputItemsAPI from './input-items';\nimport { InputItemListParams, InputItems, ResponseItemList } from './input-items';\nimport * as InputTokensAPI from './input-tokens';\nimport { InputTokenCountParams, InputTokenCountResponse, InputTokens } from './input-tokens';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage } from '../../core/pagination';\nimport { Stream } from '../../core/streaming';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport interface ParsedResponseOutputText<ParsedT> extends ResponseOutputText {\n  parsed: ParsedT | null;\n}\n\nexport type ParsedContent<ParsedT> = ParsedResponseOutputText<ParsedT> | ResponseOutputRefusal;\n\nexport interface ParsedResponseOutputMessage<ParsedT> extends ResponseOutputMessage {\n  content: ParsedContent<ParsedT>[];\n}\n\nexport interface ParsedResponseFunctionToolCall extends ResponseFunctionToolCall {\n  parsed_arguments: any;\n}\n\nexport type ParsedResponseOutputItem<ParsedT> =\n  | ParsedResponseOutputMessage<ParsedT>\n  | ParsedResponseFunctionToolCall\n  | ResponseFileSearchToolCall\n  | ResponseFunctionWebSearch\n  | ResponseComputerToolCall\n  | ResponseReasoningItem\n  | ResponseCompactionItem\n  | ResponseOutputItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseOutputItem.LocalShellCall\n  | ResponseFunctionShellToolCall\n  | ResponseFunctionShellToolCallOutput\n  | ResponseApplyPatchToolCall\n  | ResponseApplyPatchToolCallOutput\n  | ResponseOutputItem.McpCall\n  | ResponseOutputItem.McpListTools\n  | ResponseOutputItem.McpApprovalRequest\n  | ResponseCustomToolCall;\n\nexport interface ParsedResponse<ParsedT> extends Response {\n  output: Array<ParsedResponseOutputItem<ParsedT>>;\n\n  output_parsed: ParsedT | null;\n}\n\nexport type ResponseParseParams = ResponseCreateParamsNonStreaming;\n\nexport class Responses extends APIResource {\n  inputItems: InputItemsAPI.InputItems = new InputItemsAPI.InputItems(this._client);\n  inputTokens: InputTokensAPI.InputTokens = new InputTokensAPI.InputTokens(this._client);\n\n  /**\n   * Creates a model response. Provide\n   * [text](https://platform.openai.com/docs/guides/text) or\n   * [image](https://platform.openai.com/docs/guides/images) inputs to generate\n   * [text](https://platform.openai.com/docs/guides/text) or\n   * [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have\n   * the model call your own\n   * [custom code](https://platform.openai.com/docs/guides/function-calling) or use\n   * built-in [tools](https://platform.openai.com/docs/guides/tools) like\n   * [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   * [file search](https://platform.openai.com/docs/guides/tools-file-search) to use\n   * your own data as input for the model's response.\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.create();\n   * ```\n   */\n  create(body: ResponseCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Response>;\n  create(\n    body: ResponseCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent>>;\n  create(\n    body: ResponseCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent> | Response>;\n  create(\n    body: ResponseCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>> {\n    return (\n      this._client.post('/responses', { body, ...options, stream: body.stream ?? false }) as\n        | APIPromise<Response>\n        | APIPromise<Stream<ResponseStreamEvent>>\n    )._thenUnwrap((rsp) => {\n      if ('object' in rsp && rsp.object === 'response') {\n        addOutputText(rsp as Response);\n      }\n\n      return rsp;\n    }) as APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a model response with the given ID.\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.retrieve(\n   *   'resp_677efb5139a88190b512bc3fef8e535d',\n   * );\n   * ```\n   */\n  retrieve(\n    responseID: string,\n    query?: ResponseRetrieveParamsNonStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Response>;\n  retrieve(\n    responseID: string,\n    query: ResponseRetrieveParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent>>;\n  retrieve(\n    responseID: string,\n    query?: ResponseRetrieveParamsBase | undefined,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent> | Response>;\n  retrieve(\n    responseID: string,\n    query: ResponseRetrieveParams | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>> {\n    return (\n      this._client.get(path`/responses/${responseID}`, {\n        query,\n        ...options,\n        stream: query?.stream ?? false,\n      }) as APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>>\n    )._thenUnwrap((rsp) => {\n      if ('object' in rsp && rsp.object === 'response') {\n        addOutputText(rsp as Response);\n      }\n\n      return rsp;\n    }) as APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>>;\n  }\n\n  /**\n   * Deletes a model response with the given ID.\n   *\n   * @example\n   * ```ts\n   * await client.responses.delete(\n   *   'resp_677efb5139a88190b512bc3fef8e535d',\n   * );\n   * ```\n   */\n  delete(responseID: string, options?: RequestOptions): APIPromise<void> {\n    return this._client.delete(path`/responses/${responseID}`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  parse<Params extends ResponseCreateParamsWithTools, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): APIPromise<ParsedResponse<ParsedT>> {\n    return this._client.responses\n      .create(body, options)\n      ._thenUnwrap((response) => parseResponse(response as Response, body));\n  }\n\n  /**\n   * Creates a model response stream\n   */\n  stream<Params extends ResponseStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): ResponseStream<ParsedT> {\n    return ResponseStream.createResponse<ParsedT>(this._client, body, options);\n  }\n\n  /**\n   * Cancels a model response with the given ID. Only responses created with the\n   * `background` parameter set to `true` can be cancelled.\n   * [Learn more](https://platform.openai.com/docs/guides/background).\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.cancel(\n   *   'resp_677efb5139a88190b512bc3fef8e535d',\n   * );\n   * ```\n   */\n  cancel(responseID: string, options?: RequestOptions): APIPromise<Response> {\n    return this._client.post(path`/responses/${responseID}/cancel`, options);\n  }\n\n  /**\n   * Compact conversation\n   *\n   * @example\n   * ```ts\n   * const compactedResponse = await client.responses.compact({\n   *   model: 'gpt-5.2',\n   * });\n   * ```\n   */\n  compact(body: ResponseCompactParams, options?: RequestOptions): APIPromise<CompactedResponse> {\n    return this._client.post('/responses/compact', { body, ...options });\n  }\n}\n\nexport type ResponseItemsPage = CursorPage<ResponseItem>;\n\n/**\n * Allows the assistant to create, delete, or update files using unified diffs.\n */\nexport interface ApplyPatchTool {\n  /**\n   * The type of the tool. Always `apply_patch`.\n   */\n  type: 'apply_patch';\n}\n\nexport interface CompactedResponse {\n  /**\n   * The unique identifier for the compacted response.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the compacted conversation was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type. Always `response.compaction`.\n   */\n  object: 'response.compaction';\n\n  /**\n   * The compacted list of output items. This is a list of all user messages,\n   * followed by a single compaction item.\n   */\n  output: Array<ResponseOutputItem>;\n\n  /**\n   * Token accounting for the compaction pass, including cached, reasoning, and total\n   * tokens.\n   */\n  usage: ResponseUsage;\n}\n\n/**\n * A tool that controls a virtual computer. Learn more about the\n * [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).\n */\nexport interface ComputerTool {\n  /**\n   * The height of the computer display.\n   */\n  display_height: number;\n\n  /**\n   * The width of the computer display.\n   */\n  display_width: number;\n\n  /**\n   * The type of computer environment to control.\n   */\n  environment: 'windows' | 'mac' | 'linux' | 'ubuntu' | 'browser';\n\n  /**\n   * The type of the computer use tool. Always `computer_use_preview`.\n   */\n  type: 'computer_use_preview';\n}\n\n/**\n * A custom tool that processes input using a specified format. Learn more about\n * [custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools)\n */\nexport interface CustomTool {\n  /**\n   * The name of the custom tool, used to identify it in tool calls.\n   */\n  name: string;\n\n  /**\n   * The type of the custom tool. Always `custom`.\n   */\n  type: 'custom';\n\n  /**\n   * Optional description of the custom tool, used to provide more context.\n   */\n  description?: string;\n\n  /**\n   * The input format for the custom tool. Default is unconstrained text.\n   */\n  format?: Shared.CustomToolInputFormat;\n}\n\n/**\n * A message input to the model with a role indicating instruction following\n * hierarchy. Instructions given with the `developer` or `system` role take\n * precedence over instructions given with the `user` role. Messages with the\n * `assistant` role are presumed to have been generated by the model in previous\n * interactions.\n */\nexport interface EasyInputMessage {\n  /**\n   * Text, image, or audio input to the model, used to generate a response. Can also\n   * contain previous assistant responses.\n   */\n  content: string | ResponseInputMessageContentList;\n\n  /**\n   * The role of the message input. One of `user`, `assistant`, `system`, or\n   * `developer`.\n   */\n  role: 'user' | 'assistant' | 'system' | 'developer';\n\n  /**\n   * The type of the message input. Always `message`.\n   */\n  type?: 'message';\n}\n\n/**\n * A tool that searches for relevant content from uploaded files. Learn more about\n * the\n * [file search tool](https://platform.openai.com/docs/guides/tools-file-search).\n */\nexport interface FileSearchTool {\n  /**\n   * The type of the file search tool. Always `file_search`.\n   */\n  type: 'file_search';\n\n  /**\n   * The IDs of the vector stores to search.\n   */\n  vector_store_ids: Array<string>;\n\n  /**\n   * A filter to apply.\n   */\n  filters?: Shared.ComparisonFilter | Shared.CompoundFilter | null;\n\n  /**\n   * The maximum number of results to return. This number should be between 1 and 50\n   * inclusive.\n   */\n  max_num_results?: number;\n\n  /**\n   * Ranking options for search.\n   */\n  ranking_options?: FileSearchTool.RankingOptions;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Ranking options for search.\n   */\n  export interface RankingOptions {\n    /**\n     * Weights that control how reciprocal rank fusion balances semantic embedding\n     * matches versus sparse keyword matches when hybrid search is enabled.\n     */\n    hybrid_search?: RankingOptions.HybridSearch;\n\n    /**\n     * The ranker to use for the file search.\n     */\n    ranker?: 'auto' | 'default-2024-11-15';\n\n    /**\n     * The score threshold for the file search, a number between 0 and 1. Numbers\n     * closer to 1 will attempt to return only the most relevant results, but may\n     * return fewer results.\n     */\n    score_threshold?: number;\n  }\n\n  export namespace RankingOptions {\n    /**\n     * Weights that control how reciprocal rank fusion balances semantic embedding\n     * matches versus sparse keyword matches when hybrid search is enabled.\n     */\n    export interface HybridSearch {\n      /**\n       * The weight of the embedding in the reciprocal ranking fusion.\n       */\n      embedding_weight: number;\n\n      /**\n       * The weight of the text in the reciprocal ranking fusion.\n       */\n      text_weight: number;\n    }\n  }\n}\n\n/**\n * A tool that allows the model to execute shell commands.\n */\nexport interface FunctionShellTool {\n  /**\n   * The type of the shell tool. Always `shell`.\n   */\n  type: 'shell';\n}\n\n/**\n * Defines a function in your own code the model can choose to call. Learn more\n * about\n * [function calling](https://platform.openai.com/docs/guides/function-calling).\n */\nexport interface FunctionTool {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * A JSON schema object describing the parameters of the function.\n   */\n  parameters: { [key: string]: unknown } | null;\n\n  /**\n   * Whether to enforce strict parameter validation. Default `true`.\n   */\n  strict: boolean | null;\n\n  /**\n   * The type of the function tool. Always `function`.\n   */\n  type: 'function';\n\n  /**\n   * A description of the function. Used by the model to determine whether or not to\n   * call the function.\n   */\n  description?: string | null;\n}\n\nexport interface Response {\n  /**\n   * Unique identifier for this Response.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) of when this Response was created.\n   */\n  created_at: number;\n\n  output_text: string;\n\n  /**\n   * An error object returned when the model fails to generate a Response.\n   */\n  error: ResponseError | null;\n\n  /**\n   * Details about why the response is incomplete.\n   */\n  incomplete_details: Response.IncompleteDetails | null;\n\n  /**\n   * A system (or developer) message inserted into the model's context.\n   *\n   * When using along with `previous_response_id`, the instructions from a previous\n   * response will not be carried over to the next response. This makes it simple to\n   * swap out system (or developer) messages in new responses.\n   */\n  instructions: string | Array<ResponseInputItem> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model: Shared.ResponsesModel;\n\n  /**\n   * The object type of this resource - always set to `response`.\n   */\n  object: 'response';\n\n  /**\n   * An array of content items generated by the model.\n   *\n   * - The length and order of items in the `output` array is dependent on the\n   *   model's response.\n   * - Rather than accessing the first item in the `output` array and assuming it's\n   *   an `assistant` message with the content generated by the model, you might\n   *   consider using the `output_text` property where supported in SDKs.\n   */\n  output: Array<ResponseOutputItem>;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature: number | null;\n\n  /**\n   * How the model should select which tool (or tools) to use when generating a\n   * response. See the `tools` parameter to see how to specify which tools the model\n   * can call.\n   */\n  tool_choice:\n    | ToolChoiceOptions\n    | ToolChoiceAllowed\n    | ToolChoiceTypes\n    | ToolChoiceFunction\n    | ToolChoiceMcp\n    | ToolChoiceCustom\n    | ToolChoiceApplyPatch\n    | ToolChoiceShell;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   *\n   * We support the following categories of tools:\n   *\n   * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n   *   capabilities, like\n   *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n   *   Learn more about\n   *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n   * - **MCP Tools**: Integrations with third-party systems via custom MCP servers or\n   *   predefined connectors such as Google Drive and SharePoint. Learn more about\n   *   [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n   * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n   *   the model to call your own code with strongly typed arguments and outputs.\n   *   Learn more about\n   *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n   *   You can also use custom tools to call your own code.\n   */\n  tools: Array<Tool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p: number | null;\n\n  /**\n   * Whether to run the model response in the background.\n   * [Learn more](https://platform.openai.com/docs/guides/background).\n   */\n  background?: boolean | null;\n\n  /**\n   * Unix timestamp (in seconds) of when this Response was completed. Only present\n   * when the status is `completed`.\n   */\n  completed_at?: number | null;\n\n  /**\n   * The conversation that this response belonged to. Input items and output items\n   * from this response were automatically added to this conversation.\n   */\n  conversation?: Response.Conversation | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a response,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_output_tokens?: number | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   * Cannot be used in conjunction with `conversation`.\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsePrompt | null;\n\n  /**\n   * Used by OpenAI to cache responses for similar requests to optimize your cache\n   * hit rates. Replaces the `user` field.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n   */\n  prompt_cache_key?: string;\n\n  /**\n   * The retention policy for the prompt cache. Set to `24h` to enable extended\n   * prompt caching, which keeps cached prefixes active for longer, up to a maximum\n   * of 24 hours.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).\n   */\n  prompt_cache_retention?: 'in-memory' | '24h' | null;\n\n  /**\n   * **gpt-5 and o-series models only**\n   *\n   * Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * A stable identifier used to help detect users of your application that may be\n   * violating OpenAI's usage policies. The IDs should be a string that uniquely\n   * identifies each user. We recommend hashing their username or email address, in\n   * order to avoid sending us any identifying information.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  safety_identifier?: string;\n\n  /**\n   * Specifies the latency tier to use for processing the request. This parameter is\n   * relevant for customers subscribed to the scale tier service:\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When this parameter is set, the response body will include the `service_tier`\n   * utilized.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * The status of the response generation. One of `completed`, `failed`,\n   * `in_progress`, `cancelled`, `queued`, or `incomplete`.\n   */\n  status?: ResponseStatus;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * The truncation strategy to use for the model response.\n   *\n   * - `auto`: If the input to this Response exceeds the model's context window size,\n   *   the model will truncate the response to fit the context window by dropping\n   *   items from the beginning of the conversation.\n   * - `disabled` (default): If the input size will exceed the context window size\n   *   for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled' | null;\n\n  /**\n   * Represents token usage details including input tokens, output tokens, a\n   * breakdown of output tokens, and the total tokens used.\n   */\n  usage?: ResponseUsage;\n\n  /**\n   * @deprecated This field is being replaced by `safety_identifier` and\n   * `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching\n   * optimizations. A stable identifier for your end-users. Used to boost cache hit\n   * rates by better bucketing similar requests and to help OpenAI detect and prevent\n   * abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  user?: string;\n}\n\nexport namespace Response {\n  /**\n   * Details about why the response is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the response is incomplete.\n     */\n    reason?: 'max_output_tokens' | 'content_filter';\n  }\n\n  /**\n   * The conversation that this response belonged to. Input items and output items\n   * from this response were automatically added to this conversation.\n   */\n  export interface Conversation {\n    /**\n     * The unique ID of the conversation that this response was associated with.\n     */\n    id: string;\n  }\n}\n\n/**\n * A tool call that applies file diffs by creating, deleting, or updating files.\n */\nexport interface ResponseApplyPatchToolCall {\n  /**\n   * The unique ID of the apply patch tool call. Populated when this item is returned\n   * via API.\n   */\n  id: string;\n\n  /**\n   * The unique ID of the apply patch tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * One of the create_file, delete_file, or update_file operations applied via\n   * apply_patch.\n   */\n  operation:\n    | ResponseApplyPatchToolCall.CreateFile\n    | ResponseApplyPatchToolCall.DeleteFile\n    | ResponseApplyPatchToolCall.UpdateFile;\n\n  /**\n   * The status of the apply patch tool call. One of `in_progress` or `completed`.\n   */\n  status: 'in_progress' | 'completed';\n\n  /**\n   * The type of the item. Always `apply_patch_call`.\n   */\n  type: 'apply_patch_call';\n\n  /**\n   * The ID of the entity that created this tool call.\n   */\n  created_by?: string;\n}\n\nexport namespace ResponseApplyPatchToolCall {\n  /**\n   * Instruction describing how to create a file via the apply_patch tool.\n   */\n  export interface CreateFile {\n    /**\n     * Diff to apply.\n     */\n    diff: string;\n\n    /**\n     * Path of the file to create.\n     */\n    path: string;\n\n    /**\n     * Create a new file with the provided diff.\n     */\n    type: 'create_file';\n  }\n\n  /**\n   * Instruction describing how to delete a file via the apply_patch tool.\n   */\n  export interface DeleteFile {\n    /**\n     * Path of the file to delete.\n     */\n    path: string;\n\n    /**\n     * Delete the specified file.\n     */\n    type: 'delete_file';\n  }\n\n  /**\n   * Instruction describing how to update a file via the apply_patch tool.\n   */\n  export interface UpdateFile {\n    /**\n     * Diff to apply.\n     */\n    diff: string;\n\n    /**\n     * Path of the file to update.\n     */\n    path: string;\n\n    /**\n     * Update an existing file with the provided diff.\n     */\n    type: 'update_file';\n  }\n}\n\n/**\n * The output emitted by an apply patch tool call.\n */\nexport interface ResponseApplyPatchToolCallOutput {\n  /**\n   * The unique ID of the apply patch tool call output. Populated when this item is\n   * returned via API.\n   */\n  id: string;\n\n  /**\n   * The unique ID of the apply patch tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The status of the apply patch tool call output. One of `completed` or `failed`.\n   */\n  status: 'completed' | 'failed';\n\n  /**\n   * The type of the item. Always `apply_patch_call_output`.\n   */\n  type: 'apply_patch_call_output';\n\n  /**\n   * The ID of the entity that created this tool call output.\n   */\n  created_by?: string;\n\n  /**\n   * Optional textual output returned by the apply patch tool.\n   */\n  output?: string | null;\n}\n\n/**\n * Emitted when there is a partial audio response.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * A chunk of Base64 encoded response audio bytes.\n   */\n  delta: string;\n\n  /**\n   * A sequence number for this chunk of the stream response.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.delta`.\n   */\n  type: 'response.audio.delta';\n}\n\n/**\n * Emitted when the audio response is complete.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The sequence number of the delta.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.done`.\n   */\n  type: 'response.audio.done';\n}\n\n/**\n * Emitted when there is a partial transcript of audio.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The partial transcript of the audio response.\n   */\n  delta: string;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.transcript.delta`.\n   */\n  type: 'response.audio.transcript.delta';\n}\n\n/**\n * Emitted when the full audio transcript is completed.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.transcript.done`.\n   */\n  type: 'response.audio.transcript.done';\n}\n\n/**\n * Emitted when a partial code snippet is streamed by the code interpreter.\n */\nexport interface ResponseCodeInterpreterCallCodeDeltaEvent {\n  /**\n   * The partial code snippet being streamed by the code interpreter.\n   */\n  delta: string;\n\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code is being\n   * streamed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call_code.delta`.\n   */\n  type: 'response.code_interpreter_call_code.delta';\n}\n\n/**\n * Emitted when the code snippet is finalized by the code interpreter.\n */\nexport interface ResponseCodeInterpreterCallCodeDoneEvent {\n  /**\n   * The final code snippet output by the code interpreter.\n   */\n  code: string;\n\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call_code.done`.\n   */\n  type: 'response.code_interpreter_call_code.done';\n}\n\n/**\n * Emitted when the code interpreter call is completed.\n */\nexport interface ResponseCodeInterpreterCallCompletedEvent {\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code interpreter call\n   * is completed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.completed`.\n   */\n  type: 'response.code_interpreter_call.completed';\n}\n\n/**\n * Emitted when a code interpreter call is in progress.\n */\nexport interface ResponseCodeInterpreterCallInProgressEvent {\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code interpreter call\n   * is in progress.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.in_progress`.\n   */\n  type: 'response.code_interpreter_call.in_progress';\n}\n\n/**\n * Emitted when the code interpreter is actively interpreting the code snippet.\n */\nexport interface ResponseCodeInterpreterCallInterpretingEvent {\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code interpreter is\n   * interpreting code.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.interpreting`.\n   */\n  type: 'response.code_interpreter_call.interpreting';\n}\n\n/**\n * A tool call to run code.\n */\nexport interface ResponseCodeInterpreterToolCall {\n  /**\n   * The unique ID of the code interpreter tool call.\n   */\n  id: string;\n\n  /**\n   * The code to run, or null if not available.\n   */\n  code: string | null;\n\n  /**\n   * The ID of the container used to run the code.\n   */\n  container_id: string;\n\n  /**\n   * The outputs generated by the code interpreter, such as logs or images. Can be\n   * null if no outputs are available.\n   */\n  outputs: Array<ResponseCodeInterpreterToolCall.Logs | ResponseCodeInterpreterToolCall.Image> | null;\n\n  /**\n   * The status of the code interpreter tool call. Valid values are `in_progress`,\n   * `completed`, `incomplete`, `interpreting`, and `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete' | 'interpreting' | 'failed';\n\n  /**\n   * The type of the code interpreter tool call. Always `code_interpreter_call`.\n   */\n  type: 'code_interpreter_call';\n}\n\nexport namespace ResponseCodeInterpreterToolCall {\n  /**\n   * The logs output from the code interpreter.\n   */\n  export interface Logs {\n    /**\n     * The logs output from the code interpreter.\n     */\n    logs: string;\n\n    /**\n     * The type of the output. Always `logs`.\n     */\n    type: 'logs';\n  }\n\n  /**\n   * The image output from the code interpreter.\n   */\n  export interface Image {\n    /**\n     * The type of the output. Always `image`.\n     */\n    type: 'image';\n\n    /**\n     * The URL of the image output from the code interpreter.\n     */\n    url: string;\n  }\n}\n\n/**\n * A compaction item generated by the\n * [`v1/responses/compact` API](https://platform.openai.com/docs/api-reference/responses/compact).\n */\nexport interface ResponseCompactionItem {\n  /**\n   * The unique ID of the compaction item.\n   */\n  id: string;\n\n  /**\n   * The encrypted content that was produced by compaction.\n   */\n  encrypted_content: string;\n\n  /**\n   * The type of the item. Always `compaction`.\n   */\n  type: 'compaction';\n\n  /**\n   * The identifier of the actor that created the item.\n   */\n  created_by?: string;\n}\n\n/**\n * A compaction item generated by the\n * [`v1/responses/compact` API](https://platform.openai.com/docs/api-reference/responses/compact).\n */\nexport interface ResponseCompactionItemParam {\n  /**\n   * The encrypted content of the compaction summary.\n   */\n  encrypted_content: string;\n\n  /**\n   * The type of the item. Always `compaction`.\n   */\n  type: 'compaction';\n\n  /**\n   * The ID of the compaction item.\n   */\n  id?: string | null;\n}\n\n/**\n * Emitted when the model response is complete.\n */\nexport interface ResponseCompletedEvent {\n  /**\n   * Properties of the completed response.\n   */\n  response: Response;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.completed`.\n   */\n  type: 'response.completed';\n}\n\n/**\n * A tool call to a computer use tool. See the\n * [computer use guide](https://platform.openai.com/docs/guides/tools-computer-use)\n * for more information.\n */\nexport interface ResponseComputerToolCall {\n  /**\n   * The unique ID of the computer call.\n   */\n  id: string;\n\n  /**\n   * A click action.\n   */\n  action:\n    | ResponseComputerToolCall.Click\n    | ResponseComputerToolCall.DoubleClick\n    | ResponseComputerToolCall.Drag\n    | ResponseComputerToolCall.Keypress\n    | ResponseComputerToolCall.Move\n    | ResponseComputerToolCall.Screenshot\n    | ResponseComputerToolCall.Scroll\n    | ResponseComputerToolCall.Type\n    | ResponseComputerToolCall.Wait;\n\n  /**\n   * An identifier used when responding to the tool call with output.\n   */\n  call_id: string;\n\n  /**\n   * The pending safety checks for the computer call.\n   */\n  pending_safety_checks: Array<ResponseComputerToolCall.PendingSafetyCheck>;\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the computer call. Always `computer_call`.\n   */\n  type: 'computer_call';\n}\n\nexport namespace ResponseComputerToolCall {\n  /**\n   * A click action.\n   */\n  export interface Click {\n    /**\n     * Indicates which mouse button was pressed during the click. One of `left`,\n     * `right`, `wheel`, `back`, or `forward`.\n     */\n    button: 'left' | 'right' | 'wheel' | 'back' | 'forward';\n\n    /**\n     * Specifies the event type. For a click action, this property is always `click`.\n     */\n    type: 'click';\n\n    /**\n     * The x-coordinate where the click occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the click occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * A double click action.\n   */\n  export interface DoubleClick {\n    /**\n     * Specifies the event type. For a double click action, this property is always set\n     * to `double_click`.\n     */\n    type: 'double_click';\n\n    /**\n     * The x-coordinate where the double click occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the double click occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * A drag action.\n   */\n  export interface Drag {\n    /**\n     * An array of coordinates representing the path of the drag action. Coordinates\n     * will appear as an array of objects, eg\n     *\n     * ```\n     * [\n     *   { x: 100, y: 200 },\n     *   { x: 200, y: 300 }\n     * ]\n     * ```\n     */\n    path: Array<Drag.Path>;\n\n    /**\n     * Specifies the event type. For a drag action, this property is always set to\n     * `drag`.\n     */\n    type: 'drag';\n  }\n\n  export namespace Drag {\n    /**\n     * An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.\n     */\n    export interface Path {\n      /**\n       * The x-coordinate.\n       */\n      x: number;\n\n      /**\n       * The y-coordinate.\n       */\n      y: number;\n    }\n  }\n\n  /**\n   * A collection of keypresses the model would like to perform.\n   */\n  export interface Keypress {\n    /**\n     * The combination of keys the model is requesting to be pressed. This is an array\n     * of strings, each representing a key.\n     */\n    keys: Array<string>;\n\n    /**\n     * Specifies the event type. For a keypress action, this property is always set to\n     * `keypress`.\n     */\n    type: 'keypress';\n  }\n\n  /**\n   * A mouse move action.\n   */\n  export interface Move {\n    /**\n     * Specifies the event type. For a move action, this property is always set to\n     * `move`.\n     */\n    type: 'move';\n\n    /**\n     * The x-coordinate to move to.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate to move to.\n     */\n    y: number;\n  }\n\n  /**\n   * A screenshot action.\n   */\n  export interface Screenshot {\n    /**\n     * Specifies the event type. For a screenshot action, this property is always set\n     * to `screenshot`.\n     */\n    type: 'screenshot';\n  }\n\n  /**\n   * A scroll action.\n   */\n  export interface Scroll {\n    /**\n     * The horizontal scroll distance.\n     */\n    scroll_x: number;\n\n    /**\n     * The vertical scroll distance.\n     */\n    scroll_y: number;\n\n    /**\n     * Specifies the event type. For a scroll action, this property is always set to\n     * `scroll`.\n     */\n    type: 'scroll';\n\n    /**\n     * The x-coordinate where the scroll occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the scroll occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * An action to type in text.\n   */\n  export interface Type {\n    /**\n     * The text to type.\n     */\n    text: string;\n\n    /**\n     * Specifies the event type. For a type action, this property is always set to\n     * `type`.\n     */\n    type: 'type';\n  }\n\n  /**\n   * A wait action.\n   */\n  export interface Wait {\n    /**\n     * Specifies the event type. For a wait action, this property is always set to\n     * `wait`.\n     */\n    type: 'wait';\n  }\n\n  /**\n   * A pending safety check for the computer call.\n   */\n  export interface PendingSafetyCheck {\n    /**\n     * The ID of the pending safety check.\n     */\n    id: string;\n\n    /**\n     * The type of the pending safety check.\n     */\n    code?: string | null;\n\n    /**\n     * Details about the pending safety check.\n     */\n    message?: string | null;\n  }\n}\n\nexport interface ResponseComputerToolCallOutputItem {\n  /**\n   * The unique ID of the computer call tool output.\n   */\n  id: string;\n\n  /**\n   * The ID of the computer tool call that produced the output.\n   */\n  call_id: string;\n\n  /**\n   * A computer screenshot image used with the computer use tool.\n   */\n  output: ResponseComputerToolCallOutputScreenshot;\n\n  /**\n   * The type of the computer tool call output. Always `computer_call_output`.\n   */\n  type: 'computer_call_output';\n\n  /**\n   * The safety checks reported by the API that have been acknowledged by the\n   * developer.\n   */\n  acknowledged_safety_checks?: Array<ResponseComputerToolCallOutputItem.AcknowledgedSafetyCheck>;\n\n  /**\n   * The status of the message input. One of `in_progress`, `completed`, or\n   * `incomplete`. Populated when input items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\nexport namespace ResponseComputerToolCallOutputItem {\n  /**\n   * A pending safety check for the computer call.\n   */\n  export interface AcknowledgedSafetyCheck {\n    /**\n     * The ID of the pending safety check.\n     */\n    id: string;\n\n    /**\n     * The type of the pending safety check.\n     */\n    code?: string | null;\n\n    /**\n     * Details about the pending safety check.\n     */\n    message?: string | null;\n  }\n}\n\n/**\n * A computer screenshot image used with the computer use tool.\n */\nexport interface ResponseComputerToolCallOutputScreenshot {\n  /**\n   * Specifies the event type. For a computer screenshot, this property is always set\n   * to `computer_screenshot`.\n   */\n  type: 'computer_screenshot';\n\n  /**\n   * The identifier of an uploaded file that contains the screenshot.\n   */\n  file_id?: string;\n\n  /**\n   * The URL of the screenshot image.\n   */\n  image_url?: string;\n}\n\n/**\n * Multi-modal input and output contents.\n */\nexport type ResponseContent =\n  | ResponseInputText\n  | ResponseInputImage\n  | ResponseInputFile\n  | ResponseOutputText\n  | ResponseOutputRefusal\n  | ResponseContent.ReasoningTextContent;\n\nexport namespace ResponseContent {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningTextContent {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * Emitted when a new content part is added.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part that was added.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the content part was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the content part was added to.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseOutputText | ResponseOutputRefusal | ResponseContentPartAddedEvent.ReasoningText;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\nexport namespace ResponseContentPartAddedEvent {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningText {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * Emitted when a content part is done.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part that is done.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the content part was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the content part was added to.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseOutputText | ResponseOutputRefusal | ResponseContentPartDoneEvent.ReasoningText;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\nexport namespace ResponseContentPartDoneEvent {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningText {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * The conversation that this response belongs to.\n */\nexport interface ResponseConversationParam {\n  /**\n   * The unique ID of the conversation.\n   */\n  id: string;\n}\n\n/**\n * An event that is emitted when a response is created.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The response that was created.\n   */\n  response: Response;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * A call to a custom tool created by the model.\n */\nexport interface ResponseCustomToolCall {\n  /**\n   * An identifier used to map this custom tool call to a tool call output.\n   */\n  call_id: string;\n\n  /**\n   * The input for the custom tool call generated by the model.\n   */\n  input: string;\n\n  /**\n   * The name of the custom tool being called.\n   */\n  name: string;\n\n  /**\n   * The type of the custom tool call. Always `custom_tool_call`.\n   */\n  type: 'custom_tool_call';\n\n  /**\n   * The unique ID of the custom tool call in the OpenAI platform.\n   */\n  id?: string;\n}\n\n/**\n * Event representing a delta (partial update) to the input of a custom tool call.\n */\nexport interface ResponseCustomToolCallInputDeltaEvent {\n  /**\n   * The incremental input data (delta) for the custom tool call.\n   */\n  delta: string;\n\n  /**\n   * Unique identifier for the API item associated with this event.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output this delta applies to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The event type identifier.\n   */\n  type: 'response.custom_tool_call_input.delta';\n}\n\n/**\n * Event indicating that input for a custom tool call is complete.\n */\nexport interface ResponseCustomToolCallInputDoneEvent {\n  /**\n   * The complete input data for the custom tool call.\n   */\n  input: string;\n\n  /**\n   * Unique identifier for the API item associated with this event.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output this event applies to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The event type identifier.\n   */\n  type: 'response.custom_tool_call_input.done';\n}\n\n/**\n * The output of a custom tool call from your code, being sent back to the model.\n */\nexport interface ResponseCustomToolCallOutput {\n  /**\n   * The call ID, used to map this custom tool call output to a custom tool call.\n   */\n  call_id: string;\n\n  /**\n   * The output from the custom tool call generated by your code. Can be a string or\n   * an list of output content.\n   */\n  output: string | Array<ResponseInputText | ResponseInputImage | ResponseInputFile>;\n\n  /**\n   * The type of the custom tool call output. Always `custom_tool_call_output`.\n   */\n  type: 'custom_tool_call_output';\n\n  /**\n   * The unique ID of the custom tool call output in the OpenAI platform.\n   */\n  id?: string;\n}\n\n/**\n * An error object returned when the model fails to generate a Response.\n */\nexport interface ResponseError {\n  /**\n   * The error code for the response.\n   */\n  code:\n    | 'server_error'\n    | 'rate_limit_exceeded'\n    | 'invalid_prompt'\n    | 'vector_store_timeout'\n    | 'invalid_image'\n    | 'invalid_image_format'\n    | 'invalid_base64_image'\n    | 'invalid_image_url'\n    | 'image_too_large'\n    | 'image_too_small'\n    | 'image_parse_error'\n    | 'image_content_policy_violation'\n    | 'invalid_image_mode'\n    | 'image_file_too_large'\n    | 'unsupported_image_media_type'\n    | 'empty_image_file'\n    | 'failed_to_download_image'\n    | 'image_file_not_found';\n\n  /**\n   * A human-readable description of the error.\n   */\n  message: string;\n}\n\n/**\n * Emitted when an error occurs.\n */\nexport interface ResponseErrorEvent {\n  /**\n   * The error code.\n   */\n  code: string | null;\n\n  /**\n   * The error message.\n   */\n  message: string;\n\n  /**\n   * The error parameter.\n   */\n  param: string | null;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `error`.\n   */\n  type: 'error';\n}\n\n/**\n * An event that is emitted when a response fails.\n */\nexport interface ResponseFailedEvent {\n  /**\n   * The response that failed.\n   */\n  response: Response;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.failed`.\n   */\n  type: 'response.failed';\n}\n\n/**\n * Emitted when a file search call is completed (results found).\n */\nexport interface ResponseFileSearchCallCompletedEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is initiated.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.completed`.\n   */\n  type: 'response.file_search_call.completed';\n}\n\n/**\n * Emitted when a file search call is initiated.\n */\nexport interface ResponseFileSearchCallInProgressEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is initiated.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.in_progress`.\n   */\n  type: 'response.file_search_call.in_progress';\n}\n\n/**\n * Emitted when a file search is currently searching.\n */\nexport interface ResponseFileSearchCallSearchingEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is searching.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.searching`.\n   */\n  type: 'response.file_search_call.searching';\n}\n\n/**\n * The results of a file search tool call. See the\n * [file search guide](https://platform.openai.com/docs/guides/tools-file-search)\n * for more information.\n */\nexport interface ResponseFileSearchToolCall {\n  /**\n   * The unique ID of the file search tool call.\n   */\n  id: string;\n\n  /**\n   * The queries used to search for files.\n   */\n  queries: Array<string>;\n\n  /**\n   * The status of the file search tool call. One of `in_progress`, `searching`,\n   * `incomplete` or `failed`,\n   */\n  status: 'in_progress' | 'searching' | 'completed' | 'incomplete' | 'failed';\n\n  /**\n   * The type of the file search tool call. Always `file_search_call`.\n   */\n  type: 'file_search_call';\n\n  /**\n   * The results of the file search tool call.\n   */\n  results?: Array<ResponseFileSearchToolCall.Result> | null;\n}\n\nexport namespace ResponseFileSearchToolCall {\n  export interface Result {\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard. Keys are strings with a maximum\n     * length of 64 characters. Values are strings with a maximum length of 512\n     * characters, booleans, or numbers.\n     */\n    attributes?: { [key: string]: string | number | boolean } | null;\n\n    /**\n     * The unique ID of the file.\n     */\n    file_id?: string;\n\n    /**\n     * The name of the file.\n     */\n    filename?: string;\n\n    /**\n     * The relevance score of the file - a value between 0 and 1.\n     */\n    score?: number;\n\n    /**\n     * The text that was retrieved from the file.\n     */\n    text?: string;\n  }\n}\n\n/**\n * An object specifying the format that the model must output.\n *\n * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n * ensures the model will match your supplied JSON schema. Learn more in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * The default format is `{ \"type\": \"text\" }` with no additional options.\n *\n * **Not recommended for gpt-4o and newer models:**\n *\n * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n * ensures the message the model generates is valid JSON. Using `json_schema` is\n * preferred for models that support it.\n */\nexport type ResponseFormatTextConfig =\n  | Shared.ResponseFormatText\n  | ResponseFormatTextJSONSchemaConfig\n  | Shared.ResponseFormatJSONObject;\n\n/**\n * JSON Schema response format. Used to generate structured JSON responses. Learn\n * more about\n * [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n */\nexport interface ResponseFormatTextJSONSchemaConfig {\n  /**\n   * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores\n   * and dashes, with a maximum length of 64.\n   */\n  name: string;\n\n  /**\n   * The schema for the response format, described as a JSON Schema object. Learn how\n   * to build JSON schemas [here](https://json-schema.org/).\n   */\n  schema: { [key: string]: unknown };\n\n  /**\n   * The type of response format being defined. Always `json_schema`.\n   */\n  type: 'json_schema';\n\n  /**\n   * A description of what the response format is for, used by the model to determine\n   * how to respond in the format.\n   */\n  description?: string;\n\n  /**\n   * Whether to enable strict schema adherence when generating the output. If set to\n   * true, the model will always follow the exact schema defined in the `schema`\n   * field. Only a subset of JSON Schema is supported when `strict` is `true`. To\n   * learn more, read the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   */\n  strict?: boolean | null;\n}\n\n/**\n * Emitted when there is a partial function-call arguments delta.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The function-call arguments delta that is added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the function-call arguments delta is added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the function-call arguments delta is added to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Emitted when function-call arguments are finalized.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The function-call arguments.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The name of the function that was called.\n   */\n  name: string;\n\n  /**\n   * The index of the output item.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * A piece of message content, such as text, an image, or a file.\n */\nexport type ResponseFunctionCallOutputItem =\n  | ResponseInputTextContent\n  | ResponseInputImageContent\n  | ResponseInputFileContent;\n\n/**\n * An array of content outputs (text, image, file) for the function tool call.\n */\nexport type ResponseFunctionCallOutputItemList = Array<ResponseFunctionCallOutputItem>;\n\n/**\n * Captured stdout and stderr for a portion of a shell tool call output.\n */\nexport interface ResponseFunctionShellCallOutputContent {\n  /**\n   * The exit or timeout outcome associated with this shell call.\n   */\n  outcome: ResponseFunctionShellCallOutputContent.Timeout | ResponseFunctionShellCallOutputContent.Exit;\n\n  /**\n   * Captured stderr output for the shell call.\n   */\n  stderr: string;\n\n  /**\n   * Captured stdout output for the shell call.\n   */\n  stdout: string;\n}\n\nexport namespace ResponseFunctionShellCallOutputContent {\n  /**\n   * Indicates that the shell call exceeded its configured time limit.\n   */\n  export interface Timeout {\n    /**\n     * The outcome type. Always `timeout`.\n     */\n    type: 'timeout';\n  }\n\n  /**\n   * Indicates that the shell commands finished and returned an exit code.\n   */\n  export interface Exit {\n    /**\n     * The exit code returned by the shell process.\n     */\n    exit_code: number;\n\n    /**\n     * The outcome type. Always `exit`.\n     */\n    type: 'exit';\n  }\n}\n\n/**\n * A tool call that executes one or more shell commands in a managed environment.\n */\nexport interface ResponseFunctionShellToolCall {\n  /**\n   * The unique ID of the shell tool call. Populated when this item is returned via\n   * API.\n   */\n  id: string;\n\n  /**\n   * The shell commands and limits that describe how to run the tool call.\n   */\n  action: ResponseFunctionShellToolCall.Action;\n\n  /**\n   * The unique ID of the shell tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The status of the shell call. One of `in_progress`, `completed`, or\n   * `incomplete`.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the item. Always `shell_call`.\n   */\n  type: 'shell_call';\n\n  /**\n   * The ID of the entity that created this tool call.\n   */\n  created_by?: string;\n}\n\nexport namespace ResponseFunctionShellToolCall {\n  /**\n   * The shell commands and limits that describe how to run the tool call.\n   */\n  export interface Action {\n    commands: Array<string>;\n\n    /**\n     * Optional maximum number of characters to return from each command.\n     */\n    max_output_length: number | null;\n\n    /**\n     * Optional timeout in milliseconds for the commands.\n     */\n    timeout_ms: number | null;\n  }\n}\n\n/**\n * The output of a shell tool call that was emitted.\n */\nexport interface ResponseFunctionShellToolCallOutput {\n  /**\n   * The unique ID of the shell call output. Populated when this item is returned via\n   * API.\n   */\n  id: string;\n\n  /**\n   * The unique ID of the shell tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The maximum length of the shell command output. This is generated by the model\n   * and should be passed back with the raw output.\n   */\n  max_output_length: number | null;\n\n  /**\n   * An array of shell call output contents\n   */\n  output: Array<ResponseFunctionShellToolCallOutput.Output>;\n\n  /**\n   * The status of the shell call output. One of `in_progress`, `completed`, or\n   * `incomplete`.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the shell call output. Always `shell_call_output`.\n   */\n  type: 'shell_call_output';\n\n  /**\n   * The identifier of the actor that created the item.\n   */\n  created_by?: string;\n}\n\nexport namespace ResponseFunctionShellToolCallOutput {\n  /**\n   * The content of a shell tool call output that was emitted.\n   */\n  export interface Output {\n    /**\n     * Represents either an exit outcome (with an exit code) or a timeout outcome for a\n     * shell call output chunk.\n     */\n    outcome: Output.Timeout | Output.Exit;\n\n    /**\n     * The standard error output that was captured.\n     */\n    stderr: string;\n\n    /**\n     * The standard output that was captured.\n     */\n    stdout: string;\n\n    /**\n     * The identifier of the actor that created the item.\n     */\n    created_by?: string;\n  }\n\n  export namespace Output {\n    /**\n     * Indicates that the shell call exceeded its configured time limit.\n     */\n    export interface Timeout {\n      /**\n       * The outcome type. Always `timeout`.\n       */\n      type: 'timeout';\n    }\n\n    /**\n     * Indicates that the shell commands finished and returned an exit code.\n     */\n    export interface Exit {\n      /**\n       * Exit code from the shell process.\n       */\n      exit_code: number;\n\n      /**\n       * The outcome type. Always `exit`.\n       */\n      type: 'exit';\n    }\n  }\n}\n\n/**\n * A tool call to run a function. See the\n * [function calling guide](https://platform.openai.com/docs/guides/function-calling)\n * for more information.\n */\nexport interface ResponseFunctionToolCall {\n  /**\n   * A JSON string of the arguments to pass to the function.\n   */\n  arguments: string;\n\n  /**\n   * The unique ID of the function tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The name of the function to run.\n   */\n  name: string;\n\n  /**\n   * The type of the function tool call. Always `function_call`.\n   */\n  type: 'function_call';\n\n  /**\n   * The unique ID of the function tool call.\n   */\n  id?: string;\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\n/**\n * A tool call to run a function. See the\n * [function calling guide](https://platform.openai.com/docs/guides/function-calling)\n * for more information.\n */\nexport interface ResponseFunctionToolCallItem extends ResponseFunctionToolCall {\n  /**\n   * The unique ID of the function tool call.\n   */\n  id: string;\n}\n\nexport interface ResponseFunctionToolCallOutputItem {\n  /**\n   * The unique ID of the function call tool output.\n   */\n  id: string;\n\n  /**\n   * The unique ID of the function tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The output from the function call generated by your code. Can be a string or an\n   * list of output content.\n   */\n  output: string | Array<ResponseInputText | ResponseInputImage | ResponseInputFile>;\n\n  /**\n   * The type of the function tool call output. Always `function_call_output`.\n   */\n  type: 'function_call_output';\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\n/**\n * The results of a web search tool call. See the\n * [web search guide](https://platform.openai.com/docs/guides/tools-web-search) for\n * more information.\n */\nexport interface ResponseFunctionWebSearch {\n  /**\n   * The unique ID of the web search tool call.\n   */\n  id: string;\n\n  /**\n   * The status of the web search tool call.\n   */\n  status: 'in_progress' | 'searching' | 'completed' | 'failed';\n\n  /**\n   * The type of the web search tool call. Always `web_search_call`.\n   */\n  type: 'web_search_call';\n}\n\nexport namespace ResponseFunctionWebSearch {\n  /**\n   * Action type \"search\" - Performs a web search query.\n   */\n  export interface Search {\n    /**\n     * [DEPRECATED] The search query.\n     */\n    query: string;\n\n    /**\n     * The action type.\n     */\n    type: 'search';\n\n    /**\n     * The search queries.\n     */\n    queries?: Array<string>;\n\n    /**\n     * The sources used in the search.\n     */\n    sources?: Array<Search.Source>;\n  }\n\n  export namespace Search {\n    /**\n     * A source used in the search.\n     */\n    export interface Source {\n      /**\n       * The type of source. Always `url`.\n       */\n      type: 'url';\n\n      /**\n       * The URL of the source.\n       */\n      url: string;\n    }\n  }\n\n  /**\n   * Action type \"open_page\" - Opens a specific URL from search results.\n   */\n  export interface OpenPage {\n    /**\n     * The action type.\n     */\n    type: 'open_page';\n\n    /**\n     * The URL opened by the model.\n     */\n    url: string;\n  }\n\n  /**\n   * Action type \"find\": Searches for a pattern within a loaded page.\n   */\n  export interface Find {\n    /**\n     * The pattern or text to search for within the page.\n     */\n    pattern: string;\n\n    /**\n     * The action type.\n     */\n    type: 'find';\n\n    /**\n     * The URL of the page searched for the pattern.\n     */\n    url: string;\n  }\n}\n\n/**\n * Emitted when an image generation tool call has completed and the final image is\n * available.\n */\nexport interface ResponseImageGenCallCompletedEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.completed'.\n   */\n  type: 'response.image_generation_call.completed';\n}\n\n/**\n * Emitted when an image generation tool call is actively generating an image\n * (intermediate state).\n */\nexport interface ResponseImageGenCallGeneratingEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the image generation item being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.generating'.\n   */\n  type: 'response.image_generation_call.generating';\n}\n\n/**\n * Emitted when an image generation tool call is in progress.\n */\nexport interface ResponseImageGenCallInProgressEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the image generation item being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.in_progress'.\n   */\n  type: 'response.image_generation_call.in_progress';\n}\n\n/**\n * Emitted when a partial image is available during image generation streaming.\n */\nexport interface ResponseImageGenCallPartialImageEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * Base64-encoded partial image data, suitable for rendering as an image.\n   */\n  partial_image_b64: string;\n\n  /**\n   * 0-based index for the partial image (backend is 1-based, but this is 0-based for\n   * the user).\n   */\n  partial_image_index: number;\n\n  /**\n   * The sequence number of the image generation item being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.partial_image'.\n   */\n  type: 'response.image_generation_call.partial_image';\n}\n\n/**\n * Emitted when the response is in progress.\n */\nexport interface ResponseInProgressEvent {\n  /**\n   * The response that is in progress.\n   */\n  response: Response;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.in_progress`.\n   */\n  type: 'response.in_progress';\n}\n\n/**\n * Specify additional output data to include in the model response. Currently\n * supported values are:\n *\n * - `web_search_call.action.sources`: Include the sources of the web search tool\n *   call.\n * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n *   in code interpreter tool call items.\n * - `computer_call_output.output.image_url`: Include image urls from the computer\n *   call output.\n * - `file_search_call.results`: Include the search results of the file search tool\n *   call.\n * - `message.input_image.image_url`: Include image urls from the input message.\n * - `computer_call_output.output.image_url`: Include image urls from the computer\n *   call output.\n * - `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n *   tokens in reasoning item outputs. This enables reasoning items to be used in\n *   multi-turn conversations when using the Responses API statelessly (like when\n *   the `store` parameter is set to `false`, or when an organization is enrolled\n *   in the zero data retention program).\n * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n *   in code interpreter tool call items.\n */\nexport type ResponseIncludable =\n  | 'file_search_call.results'\n  | 'web_search_call.results'\n  | 'web_search_call.action.sources'\n  | 'message.input_image.image_url'\n  | 'computer_call_output.output.image_url'\n  | 'code_interpreter_call.outputs'\n  | 'reasoning.encrypted_content'\n  | 'message.output_text.logprobs';\n\n/**\n * An event that is emitted when a response finishes as incomplete.\n */\nexport interface ResponseIncompleteEvent {\n  /**\n   * The response that was incomplete.\n   */\n  response: Response;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.incomplete`.\n   */\n  type: 'response.incomplete';\n}\n\n/**\n * A list of one or many input items to the model, containing different content\n * types.\n */\nexport type ResponseInput = Array<ResponseInputItem>;\n\n/**\n * An audio input to the model.\n */\nexport interface ResponseInputAudio {\n  input_audio: ResponseInputAudio.InputAudio;\n\n  /**\n   * The type of the input item. Always `input_audio`.\n   */\n  type: 'input_audio';\n}\n\nexport namespace ResponseInputAudio {\n  export interface InputAudio {\n    /**\n     * Base64-encoded audio data.\n     */\n    data: string;\n\n    /**\n     * The format of the audio data. Currently supported formats are `mp3` and `wav`.\n     */\n    format: 'mp3' | 'wav';\n  }\n}\n\n/**\n * A text input to the model.\n */\nexport type ResponseInputContent = ResponseInputText | ResponseInputImage | ResponseInputFile;\n\n/**\n * A file input to the model.\n */\nexport interface ResponseInputFile {\n  /**\n   * The type of the input item. Always `input_file`.\n   */\n  type: 'input_file';\n\n  /**\n   * The content of the file to be sent to the model.\n   */\n  file_data?: string;\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the file to be sent to the model.\n   */\n  file_url?: string;\n\n  /**\n   * The name of the file to be sent to the model.\n   */\n  filename?: string;\n}\n\n/**\n * A file input to the model.\n */\nexport interface ResponseInputFileContent {\n  /**\n   * The type of the input item. Always `input_file`.\n   */\n  type: 'input_file';\n\n  /**\n   * The base64-encoded data of the file to be sent to the model.\n   */\n  file_data?: string | null;\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the file to be sent to the model.\n   */\n  file_url?: string | null;\n\n  /**\n   * The name of the file to be sent to the model.\n   */\n  filename?: string | null;\n}\n\n/**\n * An image input to the model. Learn about\n * [image inputs](https://platform.openai.com/docs/guides/vision).\n */\nexport interface ResponseInputImage {\n  /**\n   * The detail level of the image to be sent to the model. One of `high`, `low`, or\n   * `auto`. Defaults to `auto`.\n   */\n  detail: 'low' | 'high' | 'auto';\n\n  /**\n   * The type of the input item. Always `input_image`.\n   */\n  type: 'input_image';\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the image to be sent to the model. A fully qualified URL or base64\n   * encoded image in a data URL.\n   */\n  image_url?: string | null;\n}\n\n/**\n * An image input to the model. Learn about\n * [image inputs](https://platform.openai.com/docs/guides/vision)\n */\nexport interface ResponseInputImageContent {\n  /**\n   * The type of the input item. Always `input_image`.\n   */\n  type: 'input_image';\n\n  /**\n   * The detail level of the image to be sent to the model. One of `high`, `low`, or\n   * `auto`. Defaults to `auto`.\n   */\n  detail?: 'low' | 'high' | 'auto' | null;\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the image to be sent to the model. A fully qualified URL or base64\n   * encoded image in a data URL.\n   */\n  image_url?: string | null;\n}\n\n/**\n * A message input to the model with a role indicating instruction following\n * hierarchy. Instructions given with the `developer` or `system` role take\n * precedence over instructions given with the `user` role. Messages with the\n * `assistant` role are presumed to have been generated by the model in previous\n * interactions.\n */\nexport type ResponseInputItem =\n  | EasyInputMessage\n  | ResponseInputItem.Message\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseComputerToolCall\n  | ResponseInputItem.ComputerCallOutput\n  | ResponseFunctionWebSearch\n  | ResponseFunctionToolCall\n  | ResponseInputItem.FunctionCallOutput\n  | ResponseReasoningItem\n  | ResponseCompactionItemParam\n  | ResponseInputItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseInputItem.LocalShellCall\n  | ResponseInputItem.LocalShellCallOutput\n  | ResponseInputItem.ShellCall\n  | ResponseInputItem.ShellCallOutput\n  | ResponseInputItem.ApplyPatchCall\n  | ResponseInputItem.ApplyPatchCallOutput\n  | ResponseInputItem.McpListTools\n  | ResponseInputItem.McpApprovalRequest\n  | ResponseInputItem.McpApprovalResponse\n  | ResponseInputItem.McpCall\n  | ResponseCustomToolCallOutput\n  | ResponseCustomToolCall\n  | ResponseInputItem.ItemReference;\n\nexport namespace ResponseInputItem {\n  /**\n   * A message input to the model with a role indicating instruction following\n   * hierarchy. Instructions given with the `developer` or `system` role take\n   * precedence over instructions given with the `user` role.\n   */\n  export interface Message {\n    /**\n     * A list of one or many input items to the model, containing different content\n     * types.\n     */\n    content: ResponsesAPI.ResponseInputMessageContentList;\n\n    /**\n     * The role of the message input. One of `user`, `system`, or `developer`.\n     */\n    role: 'user' | 'system' | 'developer';\n\n    /**\n     * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the message input. Always set to `message`.\n     */\n    type?: 'message';\n  }\n\n  /**\n   * The output of a computer tool call.\n   */\n  export interface ComputerCallOutput {\n    /**\n     * The ID of the computer tool call that produced the output.\n     */\n    call_id: string;\n\n    /**\n     * A computer screenshot image used with the computer use tool.\n     */\n    output: ResponsesAPI.ResponseComputerToolCallOutputScreenshot;\n\n    /**\n     * The type of the computer tool call output. Always `computer_call_output`.\n     */\n    type: 'computer_call_output';\n\n    /**\n     * The ID of the computer tool call output.\n     */\n    id?: string | null;\n\n    /**\n     * The safety checks reported by the API that have been acknowledged by the\n     * developer.\n     */\n    acknowledged_safety_checks?: Array<ComputerCallOutput.AcknowledgedSafetyCheck> | null;\n\n    /**\n     * The status of the message input. One of `in_progress`, `completed`, or\n     * `incomplete`. Populated when input items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  export namespace ComputerCallOutput {\n    /**\n     * A pending safety check for the computer call.\n     */\n    export interface AcknowledgedSafetyCheck {\n      /**\n       * The ID of the pending safety check.\n       */\n      id: string;\n\n      /**\n       * The type of the pending safety check.\n       */\n      code?: string | null;\n\n      /**\n       * Details about the pending safety check.\n       */\n      message?: string | null;\n    }\n  }\n\n  /**\n   * The output of a function tool call.\n   */\n  export interface FunctionCallOutput {\n    /**\n     * The unique ID of the function tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * Text, image, or file output of the function tool call.\n     */\n    output: string | ResponsesAPI.ResponseFunctionCallOutputItemList;\n\n    /**\n     * The type of the function tool call output. Always `function_call_output`.\n     */\n    type: 'function_call_output';\n\n    /**\n     * The unique ID of the function tool call output. Populated when this item is\n     * returned via API.\n     */\n    id?: string | null;\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * The output of a local shell tool call.\n   */\n  export interface LocalShellCallOutput {\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the output of the local shell tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the local shell tool call output. Always `local_shell_call_output`.\n     */\n    type: 'local_shell_call_output';\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * A tool representing a request to execute one or more shell commands.\n   */\n  export interface ShellCall {\n    /**\n     * The shell commands and limits that describe how to run the tool call.\n     */\n    action: ShellCall.Action;\n\n    /**\n     * The unique ID of the shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The type of the item. Always `shell_call`.\n     */\n    type: 'shell_call';\n\n    /**\n     * The unique ID of the shell tool call. Populated when this item is returned via\n     * API.\n     */\n    id?: string | null;\n\n    /**\n     * The status of the shell call. One of `in_progress`, `completed`, or\n     * `incomplete`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  export namespace ShellCall {\n    /**\n     * The shell commands and limits that describe how to run the tool call.\n     */\n    export interface Action {\n      /**\n       * Ordered shell commands for the execution environment to run.\n       */\n      commands: Array<string>;\n\n      /**\n       * Maximum number of UTF-8 characters to capture from combined stdout and stderr\n       * output.\n       */\n      max_output_length?: number | null;\n\n      /**\n       * Maximum wall-clock time in milliseconds to allow the shell commands to run.\n       */\n      timeout_ms?: number | null;\n    }\n  }\n\n  /**\n   * The streamed output items emitted by a shell tool call.\n   */\n  export interface ShellCallOutput {\n    /**\n     * The unique ID of the shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * Captured chunks of stdout and stderr output, along with their associated\n     * outcomes.\n     */\n    output: Array<ResponsesAPI.ResponseFunctionShellCallOutputContent>;\n\n    /**\n     * The type of the item. Always `shell_call_output`.\n     */\n    type: 'shell_call_output';\n\n    /**\n     * The unique ID of the shell tool call output. Populated when this item is\n     * returned via API.\n     */\n    id?: string | null;\n\n    /**\n     * The maximum number of UTF-8 characters captured for this shell call's combined\n     * output.\n     */\n    max_output_length?: number | null;\n\n    /**\n     * The status of the shell call output.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * A tool call representing a request to create, delete, or update files using diff\n   * patches.\n   */\n  export interface ApplyPatchCall {\n    /**\n     * The unique ID of the apply patch tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The specific create, delete, or update instruction for the apply_patch tool\n     * call.\n     */\n    operation: ApplyPatchCall.CreateFile | ApplyPatchCall.DeleteFile | ApplyPatchCall.UpdateFile;\n\n    /**\n     * The status of the apply patch tool call. One of `in_progress` or `completed`.\n     */\n    status: 'in_progress' | 'completed';\n\n    /**\n     * The type of the item. Always `apply_patch_call`.\n     */\n    type: 'apply_patch_call';\n\n    /**\n     * The unique ID of the apply patch tool call. Populated when this item is returned\n     * via API.\n     */\n    id?: string | null;\n  }\n\n  export namespace ApplyPatchCall {\n    /**\n     * Instruction for creating a new file via the apply_patch tool.\n     */\n    export interface CreateFile {\n      /**\n       * Unified diff content to apply when creating the file.\n       */\n      diff: string;\n\n      /**\n       * Path of the file to create relative to the workspace root.\n       */\n      path: string;\n\n      /**\n       * The operation type. Always `create_file`.\n       */\n      type: 'create_file';\n    }\n\n    /**\n     * Instruction for deleting an existing file via the apply_patch tool.\n     */\n    export interface DeleteFile {\n      /**\n       * Path of the file to delete relative to the workspace root.\n       */\n      path: string;\n\n      /**\n       * The operation type. Always `delete_file`.\n       */\n      type: 'delete_file';\n    }\n\n    /**\n     * Instruction for updating an existing file via the apply_patch tool.\n     */\n    export interface UpdateFile {\n      /**\n       * Unified diff content to apply to the existing file.\n       */\n      diff: string;\n\n      /**\n       * Path of the file to update relative to the workspace root.\n       */\n      path: string;\n\n      /**\n       * The operation type. Always `update_file`.\n       */\n      type: 'update_file';\n    }\n  }\n\n  /**\n   * The streamed output emitted by an apply patch tool call.\n   */\n  export interface ApplyPatchCallOutput {\n    /**\n     * The unique ID of the apply patch tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the apply patch tool call output. One of `completed` or `failed`.\n     */\n    status: 'completed' | 'failed';\n\n    /**\n     * The type of the item. Always `apply_patch_call_output`.\n     */\n    type: 'apply_patch_call_output';\n\n    /**\n     * The unique ID of the apply patch tool call output. Populated when this item is\n     * returned via API.\n     */\n    id?: string | null;\n\n    /**\n     * Optional human-readable log text from the apply patch tool (e.g., patch results\n     * or errors).\n     */\n    output?: string | null;\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n\n  /**\n   * A response to an MCP approval request.\n   */\n  export interface McpApprovalResponse {\n    /**\n     * The ID of the approval request being answered.\n     */\n    approval_request_id: string;\n\n    /**\n     * Whether the request was approved.\n     */\n    approve: boolean;\n\n    /**\n     * The type of the item. Always `mcp_approval_response`.\n     */\n    type: 'mcp_approval_response';\n\n    /**\n     * The unique ID of the approval response\n     */\n    id?: string | null;\n\n    /**\n     * Optional reason for the decision.\n     */\n    reason?: string | null;\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n\n  /**\n   * An internal identifier for an item to reference.\n   */\n  export interface ItemReference {\n    /**\n     * The ID of the item to reference.\n     */\n    id: string;\n\n    /**\n     * The type of item to reference. Always `item_reference`.\n     */\n    type?: 'item_reference' | null;\n  }\n}\n\n/**\n * A list of one or many input items to the model, containing different content\n * types.\n */\nexport type ResponseInputMessageContentList = Array<ResponseInputContent>;\n\nexport interface ResponseInputMessageItem {\n  /**\n   * The unique ID of the message input.\n   */\n  id: string;\n\n  /**\n   * A list of one or many input items to the model, containing different content\n   * types.\n   */\n  content: ResponseInputMessageContentList;\n\n  /**\n   * The role of the message input. One of `user`, `system`, or `developer`.\n   */\n  role: 'user' | 'system' | 'developer';\n\n  /**\n   * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the message input. Always set to `message`.\n   */\n  type?: 'message';\n}\n\n/**\n * A text input to the model.\n */\nexport interface ResponseInputText {\n  /**\n   * The text input to the model.\n   */\n  text: string;\n\n  /**\n   * The type of the input item. Always `input_text`.\n   */\n  type: 'input_text';\n}\n\n/**\n * A text input to the model.\n */\nexport interface ResponseInputTextContent {\n  /**\n   * The text input to the model.\n   */\n  text: string;\n\n  /**\n   * The type of the input item. Always `input_text`.\n   */\n  type: 'input_text';\n}\n\n/**\n * Content item used to generate a response.\n */\nexport type ResponseItem =\n  | ResponseInputMessageItem\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseComputerToolCall\n  | ResponseComputerToolCallOutputItem\n  | ResponseFunctionWebSearch\n  | ResponseFunctionToolCallItem\n  | ResponseFunctionToolCallOutputItem\n  | ResponseItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseItem.LocalShellCall\n  | ResponseItem.LocalShellCallOutput\n  | ResponseFunctionShellToolCall\n  | ResponseFunctionShellToolCallOutput\n  | ResponseApplyPatchToolCall\n  | ResponseApplyPatchToolCallOutput\n  | ResponseItem.McpListTools\n  | ResponseItem.McpApprovalRequest\n  | ResponseItem.McpApprovalResponse\n  | ResponseItem.McpCall;\n\nexport namespace ResponseItem {\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * The output of a local shell tool call.\n   */\n  export interface LocalShellCallOutput {\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the output of the local shell tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the local shell tool call output. Always `local_shell_call_output`.\n     */\n    type: 'local_shell_call_output';\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n\n  /**\n   * A response to an MCP approval request.\n   */\n  export interface McpApprovalResponse {\n    /**\n     * The unique ID of the approval response\n     */\n    id: string;\n\n    /**\n     * The ID of the approval request being answered.\n     */\n    approval_request_id: string;\n\n    /**\n     * Whether the request was approved.\n     */\n    approve: boolean;\n\n    /**\n     * The type of the item. Always `mcp_approval_response`.\n     */\n    type: 'mcp_approval_response';\n\n    /**\n     * Optional reason for the decision.\n     */\n    reason?: string | null;\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n}\n\n/**\n * Emitted when there is a delta (partial update) to the arguments of an MCP tool\n * call.\n */\nexport interface ResponseMcpCallArgumentsDeltaEvent {\n  /**\n   * A JSON string containing the partial update to the arguments for the MCP tool\n   * call.\n   */\n  delta: string;\n\n  /**\n   * The unique identifier of the MCP tool call item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call_arguments.delta'.\n   */\n  type: 'response.mcp_call_arguments.delta';\n}\n\n/**\n * Emitted when the arguments for an MCP tool call are finalized.\n */\nexport interface ResponseMcpCallArgumentsDoneEvent {\n  /**\n   * A JSON string containing the finalized arguments for the MCP tool call.\n   */\n  arguments: string;\n\n  /**\n   * The unique identifier of the MCP tool call item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call_arguments.done'.\n   */\n  type: 'response.mcp_call_arguments.done';\n}\n\n/**\n * Emitted when an MCP tool call has completed successfully.\n */\nexport interface ResponseMcpCallCompletedEvent {\n  /**\n   * The ID of the MCP tool call item that completed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that completed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call.completed'.\n   */\n  type: 'response.mcp_call.completed';\n}\n\n/**\n * Emitted when an MCP tool call has failed.\n */\nexport interface ResponseMcpCallFailedEvent {\n  /**\n   * The ID of the MCP tool call item that failed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that failed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call.failed'.\n   */\n  type: 'response.mcp_call.failed';\n}\n\n/**\n * Emitted when an MCP tool call is in progress.\n */\nexport interface ResponseMcpCallInProgressEvent {\n  /**\n   * The unique identifier of the MCP tool call item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call.in_progress'.\n   */\n  type: 'response.mcp_call.in_progress';\n}\n\n/**\n * Emitted when the list of available MCP tools has been successfully retrieved.\n */\nexport interface ResponseMcpListToolsCompletedEvent {\n  /**\n   * The ID of the MCP tool call item that produced this output.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that was processed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_list_tools.completed'.\n   */\n  type: 'response.mcp_list_tools.completed';\n}\n\n/**\n * Emitted when the attempt to list available MCP tools has failed.\n */\nexport interface ResponseMcpListToolsFailedEvent {\n  /**\n   * The ID of the MCP tool call item that failed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that failed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_list_tools.failed'.\n   */\n  type: 'response.mcp_list_tools.failed';\n}\n\n/**\n * Emitted when the system is in the process of retrieving the list of available\n * MCP tools.\n */\nexport interface ResponseMcpListToolsInProgressEvent {\n  /**\n   * The ID of the MCP tool call item that is being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that is being processed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_list_tools.in_progress'.\n   */\n  type: 'response.mcp_list_tools.in_progress';\n}\n\n/**\n * An audio output from the model.\n */\nexport interface ResponseOutputAudio {\n  /**\n   * Base64-encoded audio data from the model.\n   */\n  data: string;\n\n  /**\n   * The transcript of the audio data from the model.\n   */\n  transcript: string;\n\n  /**\n   * The type of the output audio. Always `output_audio`.\n   */\n  type: 'output_audio';\n}\n\n/**\n * An output message from the model.\n */\nexport type ResponseOutputItem =\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseFunctionToolCall\n  | ResponseFunctionWebSearch\n  | ResponseComputerToolCall\n  | ResponseReasoningItem\n  | ResponseCompactionItem\n  | ResponseOutputItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseOutputItem.LocalShellCall\n  | ResponseFunctionShellToolCall\n  | ResponseFunctionShellToolCallOutput\n  | ResponseApplyPatchToolCall\n  | ResponseApplyPatchToolCallOutput\n  | ResponseOutputItem.McpCall\n  | ResponseOutputItem.McpListTools\n  | ResponseOutputItem.McpApprovalRequest\n  | ResponseCustomToolCall;\n\nexport namespace ResponseOutputItem {\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n}\n\n/**\n * Emitted when a new output item is added.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The output item that was added.\n   */\n  item: ResponseOutputItem;\n\n  /**\n   * The index of the output item that was added.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Emitted when an output item is marked done.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The output item that was marked done.\n   */\n  item: ResponseOutputItem;\n\n  /**\n   * The index of the output item that was marked done.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * An output message from the model.\n */\nexport interface ResponseOutputMessage {\n  /**\n   * The unique ID of the output message.\n   */\n  id: string;\n\n  /**\n   * The content of the output message.\n   */\n  content: Array<ResponseOutputText | ResponseOutputRefusal>;\n\n  /**\n   * The role of the output message. Always `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * The status of the message input. One of `in_progress`, `completed`, or\n   * `incomplete`. Populated when input items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the output message. Always `message`.\n   */\n  type: 'message';\n}\n\n/**\n * A refusal from the model.\n */\nexport interface ResponseOutputRefusal {\n  /**\n   * The refusal explanation from the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the refusal. Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * A text output from the model.\n */\nexport interface ResponseOutputText {\n  /**\n   * The annotations of the text output.\n   */\n  annotations: Array<\n    | ResponseOutputText.FileCitation\n    | ResponseOutputText.URLCitation\n    | ResponseOutputText.ContainerFileCitation\n    | ResponseOutputText.FilePath\n  >;\n\n  /**\n   * The text output from the model.\n   */\n  text: string;\n\n  /**\n   * The type of the output text. Always `output_text`.\n   */\n  type: 'output_text';\n\n  logprobs?: Array<ResponseOutputText.Logprob>;\n}\n\nexport namespace ResponseOutputText {\n  /**\n   * A citation to a file.\n   */\n  export interface FileCitation {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The filename of the file cited.\n     */\n    filename: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file citation. Always `file_citation`.\n     */\n    type: 'file_citation';\n  }\n\n  /**\n   * A citation for a web resource used to generate a model response.\n   */\n  export interface URLCitation {\n    /**\n     * The index of the last character of the URL citation in the message.\n     */\n    end_index: number;\n\n    /**\n     * The index of the first character of the URL citation in the message.\n     */\n    start_index: number;\n\n    /**\n     * The title of the web resource.\n     */\n    title: string;\n\n    /**\n     * The type of the URL citation. Always `url_citation`.\n     */\n    type: 'url_citation';\n\n    /**\n     * The URL of the web resource.\n     */\n    url: string;\n  }\n\n  /**\n   * A citation for a container file used to generate a model response.\n   */\n  export interface ContainerFileCitation {\n    /**\n     * The ID of the container file.\n     */\n    container_id: string;\n\n    /**\n     * The index of the last character of the container file citation in the message.\n     */\n    end_index: number;\n\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The filename of the container file cited.\n     */\n    filename: string;\n\n    /**\n     * The index of the first character of the container file citation in the message.\n     */\n    start_index: number;\n\n    /**\n     * The type of the container file citation. Always `container_file_citation`.\n     */\n    type: 'container_file_citation';\n  }\n\n  /**\n   * A path to a file.\n   */\n  export interface FilePath {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file path. Always `file_path`.\n     */\n    type: 'file_path';\n  }\n\n  /**\n   * The log probability of a token.\n   */\n  export interface Logprob {\n    token: string;\n\n    bytes: Array<number>;\n\n    logprob: number;\n\n    top_logprobs: Array<Logprob.TopLogprob>;\n  }\n\n  export namespace Logprob {\n    /**\n     * The top log probability of a token.\n     */\n    export interface TopLogprob {\n      token: string;\n\n      bytes: Array<number>;\n\n      logprob: number;\n    }\n  }\n}\n\n/**\n * Emitted when an annotation is added to output text content.\n */\nexport interface ResponseOutputTextAnnotationAddedEvent {\n  /**\n   * The annotation object being added. (See annotation schema for details.)\n   */\n  annotation: unknown;\n\n  /**\n   * The index of the annotation within the content part.\n   */\n  annotation_index: number;\n\n  /**\n   * The index of the content part within the output item.\n   */\n  content_index: number;\n\n  /**\n   * The unique identifier of the item to which the annotation is being added.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.output_text.annotation.added'.\n   */\n  type: 'response.output_text.annotation.added';\n}\n\n/**\n * Reference to a prompt template and its variables.\n * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n */\nexport interface ResponsePrompt {\n  /**\n   * The unique identifier of the prompt template to use.\n   */\n  id: string;\n\n  /**\n   * Optional map of values to substitute in for variables in your prompt. The\n   * substitution values can either be strings, or other Response input types like\n   * images or files.\n   */\n  variables?: { [key: string]: string | ResponseInputText | ResponseInputImage | ResponseInputFile } | null;\n\n  /**\n   * Optional version of the prompt template.\n   */\n  version?: string | null;\n}\n\n/**\n * Emitted when a response is queued and waiting to be processed.\n */\nexport interface ResponseQueuedEvent {\n  /**\n   * The full response object that is queued.\n   */\n  response: Response;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.queued'.\n   */\n  type: 'response.queued';\n}\n\n/**\n * A description of the chain of thought used by a reasoning model while generating\n * a response. Be sure to include these items in your `input` to the Responses API\n * for subsequent turns of a conversation if you are manually\n * [managing context](https://platform.openai.com/docs/guides/conversation-state).\n */\nexport interface ResponseReasoningItem {\n  /**\n   * The unique identifier of the reasoning content.\n   */\n  id: string;\n\n  /**\n   * Reasoning summary content.\n   */\n  summary: Array<ResponseReasoningItem.Summary>;\n\n  /**\n   * The type of the object. Always `reasoning`.\n   */\n  type: 'reasoning';\n\n  /**\n   * Reasoning text content.\n   */\n  content?: Array<ResponseReasoningItem.Content>;\n\n  /**\n   * The encrypted content of the reasoning item - populated when a response is\n   * generated with `reasoning.encrypted_content` in the `include` parameter.\n   */\n  encrypted_content?: string | null;\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\nexport namespace ResponseReasoningItem {\n  /**\n   * A summary text from the model.\n   */\n  export interface Summary {\n    /**\n     * A summary of the reasoning output from the model so far.\n     */\n    text: string;\n\n    /**\n     * The type of the object. Always `summary_text`.\n     */\n    type: 'summary_text';\n  }\n\n  /**\n   * Reasoning text from the model.\n   */\n  export interface Content {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * Emitted when a new reasoning summary part is added.\n */\nexport interface ResponseReasoningSummaryPartAddedEvent {\n  /**\n   * The ID of the item this summary part is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary part is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The summary part that was added.\n   */\n  part: ResponseReasoningSummaryPartAddedEvent.Part;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_part.added`.\n   */\n  type: 'response.reasoning_summary_part.added';\n}\n\nexport namespace ResponseReasoningSummaryPartAddedEvent {\n  /**\n   * The summary part that was added.\n   */\n  export interface Part {\n    /**\n     * The text of the summary part.\n     */\n    text: string;\n\n    /**\n     * The type of the summary part. Always `summary_text`.\n     */\n    type: 'summary_text';\n  }\n}\n\n/**\n * Emitted when a reasoning summary part is completed.\n */\nexport interface ResponseReasoningSummaryPartDoneEvent {\n  /**\n   * The ID of the item this summary part is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary part is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The completed summary part.\n   */\n  part: ResponseReasoningSummaryPartDoneEvent.Part;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_part.done`.\n   */\n  type: 'response.reasoning_summary_part.done';\n}\n\nexport namespace ResponseReasoningSummaryPartDoneEvent {\n  /**\n   * The completed summary part.\n   */\n  export interface Part {\n    /**\n     * The text of the summary part.\n     */\n    text: string;\n\n    /**\n     * The type of the summary part. Always `summary_text`.\n     */\n    type: 'summary_text';\n  }\n}\n\n/**\n * Emitted when a delta is added to a reasoning summary text.\n */\nexport interface ResponseReasoningSummaryTextDeltaEvent {\n  /**\n   * The text delta that was added to the summary.\n   */\n  delta: string;\n\n  /**\n   * The ID of the item this summary text delta is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary text delta is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_text.delta`.\n   */\n  type: 'response.reasoning_summary_text.delta';\n}\n\n/**\n * Emitted when a reasoning summary text is completed.\n */\nexport interface ResponseReasoningSummaryTextDoneEvent {\n  /**\n   * The ID of the item this summary text is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary text is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The full text of the completed reasoning summary.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_text.done`.\n   */\n  type: 'response.reasoning_summary_text.done';\n}\n\n/**\n * Emitted when a delta is added to a reasoning text.\n */\nexport interface ResponseReasoningTextDeltaEvent {\n  /**\n   * The index of the reasoning content part this delta is associated with.\n   */\n  content_index: number;\n\n  /**\n   * The text delta that was added to the reasoning content.\n   */\n  delta: string;\n\n  /**\n   * The ID of the item this reasoning text delta is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this reasoning text delta is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_text.delta`.\n   */\n  type: 'response.reasoning_text.delta';\n}\n\n/**\n * Emitted when a reasoning text is completed.\n */\nexport interface ResponseReasoningTextDoneEvent {\n  /**\n   * The index of the reasoning content part.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the item this reasoning text is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this reasoning text is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The full text of the completed reasoning content.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `response.reasoning_text.done`.\n   */\n  type: 'response.reasoning_text.done';\n}\n\n/**\n * Emitted when there is a partial refusal text.\n */\nexport interface ResponseRefusalDeltaEvent {\n  /**\n   * The index of the content part that the refusal text is added to.\n   */\n  content_index: number;\n\n  /**\n   * The refusal text that is added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the refusal text is added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the refusal text is added to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.refusal.delta`.\n   */\n  type: 'response.refusal.delta';\n}\n\n/**\n * Emitted when refusal text is finalized.\n */\nexport interface ResponseRefusalDoneEvent {\n  /**\n   * The index of the content part that the refusal text is finalized.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the refusal text is finalized.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the refusal text is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The refusal text that is finalized.\n   */\n  refusal: string;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.refusal.done`.\n   */\n  type: 'response.refusal.done';\n}\n\n/**\n * The status of the response generation. One of `completed`, `failed`,\n * `in_progress`, `cancelled`, `queued`, or `incomplete`.\n */\nexport type ResponseStatus = 'completed' | 'failed' | 'in_progress' | 'cancelled' | 'queued' | 'incomplete';\n\n/**\n * Emitted when there is a partial audio response.\n */\nexport type ResponseStreamEvent =\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseCodeInterpreterCallCodeDeltaEvent\n  | ResponseCodeInterpreterCallCodeDoneEvent\n  | ResponseCodeInterpreterCallCompletedEvent\n  | ResponseCodeInterpreterCallInProgressEvent\n  | ResponseCodeInterpreterCallInterpretingEvent\n  | ResponseCompletedEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseCreatedEvent\n  | ResponseErrorEvent\n  | ResponseFileSearchCallCompletedEvent\n  | ResponseFileSearchCallInProgressEvent\n  | ResponseFileSearchCallSearchingEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | ResponseInProgressEvent\n  | ResponseFailedEvent\n  | ResponseIncompleteEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseReasoningSummaryPartAddedEvent\n  | ResponseReasoningSummaryPartDoneEvent\n  | ResponseReasoningSummaryTextDeltaEvent\n  | ResponseReasoningSummaryTextDoneEvent\n  | ResponseReasoningTextDeltaEvent\n  | ResponseReasoningTextDoneEvent\n  | ResponseRefusalDeltaEvent\n  | ResponseRefusalDoneEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | ResponseWebSearchCallCompletedEvent\n  | ResponseWebSearchCallInProgressEvent\n  | ResponseWebSearchCallSearchingEvent\n  | ResponseImageGenCallCompletedEvent\n  | ResponseImageGenCallGeneratingEvent\n  | ResponseImageGenCallInProgressEvent\n  | ResponseImageGenCallPartialImageEvent\n  | ResponseMcpCallArgumentsDeltaEvent\n  | ResponseMcpCallArgumentsDoneEvent\n  | ResponseMcpCallCompletedEvent\n  | ResponseMcpCallFailedEvent\n  | ResponseMcpCallInProgressEvent\n  | ResponseMcpListToolsCompletedEvent\n  | ResponseMcpListToolsFailedEvent\n  | ResponseMcpListToolsInProgressEvent\n  | ResponseOutputTextAnnotationAddedEvent\n  | ResponseQueuedEvent\n  | ResponseCustomToolCallInputDeltaEvent\n  | ResponseCustomToolCallInputDoneEvent;\n\n/**\n * Configuration options for a text response from the model. Can be plain text or\n * structured JSON data. Learn more:\n *\n * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n */\nexport interface ResponseTextConfig {\n  /**\n   * An object specifying the format that the model must output.\n   *\n   * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n   * ensures the model will match your supplied JSON schema. Learn more in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * The default format is `{ \"type\": \"text\" }` with no additional options.\n   *\n   * **Not recommended for gpt-4o and newer models:**\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n   * ensures the message the model generates is valid JSON. Using `json_schema` is\n   * preferred for models that support it.\n   */\n  format?: ResponseFormatTextConfig;\n\n  /**\n   * Constrains the verbosity of the model's response. Lower values will result in\n   * more concise responses, while higher values will result in more verbose\n   * responses. Currently supported values are `low`, `medium`, and `high`.\n   */\n  verbosity?: 'low' | 'medium' | 'high' | null;\n}\n\n/**\n * Emitted when there is an additional text delta.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part that the text delta was added to.\n   */\n  content_index: number;\n\n  /**\n   * The text delta that was added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the text delta was added to.\n   */\n  item_id: string;\n\n  /**\n   * The log probabilities of the tokens in the delta.\n   */\n  logprobs: Array<ResponseTextDeltaEvent.Logprob>;\n\n  /**\n   * The index of the output item that the text delta was added to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.output_text.delta`.\n   */\n  type: 'response.output_text.delta';\n}\n\nexport namespace ResponseTextDeltaEvent {\n  /**\n   * A logprob is the logarithmic probability that the model assigns to producing a\n   * particular token at a given position in the sequence. Less-negative (higher)\n   * logprob values indicate greater model confidence in that token choice.\n   */\n  export interface Logprob {\n    /**\n     * A possible text token.\n     */\n    token: string;\n\n    /**\n     * The log probability of this token.\n     */\n    logprob: number;\n\n    /**\n     * The log probability of the top 20 most likely tokens.\n     */\n    top_logprobs?: Array<Logprob.TopLogprob>;\n  }\n\n  export namespace Logprob {\n    export interface TopLogprob {\n      /**\n       * A possible text token.\n       */\n      token?: string;\n\n      /**\n       * The log probability of this token.\n       */\n      logprob?: number;\n    }\n  }\n}\n\n/**\n * Emitted when text content is finalized.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part that the text content is finalized.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the text content is finalized.\n   */\n  item_id: string;\n\n  /**\n   * The log probabilities of the tokens in the delta.\n   */\n  logprobs: Array<ResponseTextDoneEvent.Logprob>;\n\n  /**\n   * The index of the output item that the text content is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The text content that is finalized.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `response.output_text.done`.\n   */\n  type: 'response.output_text.done';\n}\n\nexport namespace ResponseTextDoneEvent {\n  /**\n   * A logprob is the logarithmic probability that the model assigns to producing a\n   * particular token at a given position in the sequence. Less-negative (higher)\n   * logprob values indicate greater model confidence in that token choice.\n   */\n  export interface Logprob {\n    /**\n     * A possible text token.\n     */\n    token: string;\n\n    /**\n     * The log probability of this token.\n     */\n    logprob: number;\n\n    /**\n     * The log probability of the top 20 most likely tokens.\n     */\n    top_logprobs?: Array<Logprob.TopLogprob>;\n  }\n\n  export namespace Logprob {\n    export interface TopLogprob {\n      /**\n       * A possible text token.\n       */\n      token?: string;\n\n      /**\n       * The log probability of this token.\n       */\n      logprob?: number;\n    }\n  }\n}\n\n/**\n * Represents token usage details including input tokens, output tokens, a\n * breakdown of output tokens, and the total tokens used.\n */\nexport interface ResponseUsage {\n  /**\n   * The number of input tokens.\n   */\n  input_tokens: number;\n\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  input_tokens_details: ResponseUsage.InputTokensDetails;\n\n  /**\n   * The number of output tokens.\n   */\n  output_tokens: number;\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  output_tokens_details: ResponseUsage.OutputTokensDetails;\n\n  /**\n   * The total number of tokens used.\n   */\n  total_tokens: number;\n}\n\nexport namespace ResponseUsage {\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  export interface InputTokensDetails {\n    /**\n     * The number of tokens that were retrieved from the cache.\n     * [More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n     */\n    cached_tokens: number;\n  }\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  export interface OutputTokensDetails {\n    /**\n     * The number of reasoning tokens.\n     */\n    reasoning_tokens: number;\n  }\n}\n\n/**\n * Emitted when a web search call is completed.\n */\nexport interface ResponseWebSearchCallCompletedEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the web search call being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.completed`.\n   */\n  type: 'response.web_search_call.completed';\n}\n\n/**\n * Emitted when a web search call is initiated.\n */\nexport interface ResponseWebSearchCallInProgressEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the web search call being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.in_progress`.\n   */\n  type: 'response.web_search_call.in_progress';\n}\n\n/**\n * Emitted when a web search call is executing.\n */\nexport interface ResponseWebSearchCallSearchingEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the web search call being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.searching`.\n   */\n  type: 'response.web_search_call.searching';\n}\n\n/**\n * A tool that can be used to generate a response.\n */\nexport type Tool =\n  | FunctionTool\n  | FileSearchTool\n  | ComputerTool\n  | WebSearchTool\n  | Tool.Mcp\n  | Tool.CodeInterpreter\n  | Tool.ImageGeneration\n  | Tool.LocalShell\n  | FunctionShellTool\n  | CustomTool\n  | WebSearchPreviewTool\n  | ApplyPatchTool;\n\nexport namespace Tool {\n  /**\n   * Give the model access to additional tools via remote Model Context Protocol\n   * (MCP) servers.\n   * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n   */\n  export interface Mcp {\n    /**\n     * A label for this MCP server, used to identify it in tool calls.\n     */\n    server_label: string;\n\n    /**\n     * The type of the MCP tool. Always `mcp`.\n     */\n    type: 'mcp';\n\n    /**\n     * List of allowed tool names or a filter object.\n     */\n    allowed_tools?: Array<string> | Mcp.McpToolFilter | null;\n\n    /**\n     * An OAuth access token that can be used with a remote MCP server, either with a\n     * custom MCP server URL or a service connector. Your application must handle the\n     * OAuth authorization flow and provide the token here.\n     */\n    authorization?: string;\n\n    /**\n     * Identifier for service connectors, like those available in ChatGPT. One of\n     * `server_url` or `connector_id` must be provided. Learn more about service\n     * connectors\n     * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n     *\n     * Currently supported `connector_id` values are:\n     *\n     * - Dropbox: `connector_dropbox`\n     * - Gmail: `connector_gmail`\n     * - Google Calendar: `connector_googlecalendar`\n     * - Google Drive: `connector_googledrive`\n     * - Microsoft Teams: `connector_microsoftteams`\n     * - Outlook Calendar: `connector_outlookcalendar`\n     * - Outlook Email: `connector_outlookemail`\n     * - SharePoint: `connector_sharepoint`\n     */\n    connector_id?:\n      | 'connector_dropbox'\n      | 'connector_gmail'\n      | 'connector_googlecalendar'\n      | 'connector_googledrive'\n      | 'connector_microsoftteams'\n      | 'connector_outlookcalendar'\n      | 'connector_outlookemail'\n      | 'connector_sharepoint';\n\n    /**\n     * Optional HTTP headers to send to the MCP server. Use for authentication or other\n     * purposes.\n     */\n    headers?: { [key: string]: string } | null;\n\n    /**\n     * Specify which of the MCP server's tools require approval.\n     */\n    require_approval?: Mcp.McpToolApprovalFilter | 'always' | 'never' | null;\n\n    /**\n     * Optional description of the MCP server, used to provide more context.\n     */\n    server_description?: string;\n\n    /**\n     * The URL for the MCP server. One of `server_url` or `connector_id` must be\n     * provided.\n     */\n    server_url?: string;\n  }\n\n  export namespace Mcp {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface McpToolFilter {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * Specify which of the MCP server's tools require approval. Can be `always`,\n     * `never`, or a filter object associated with tools that require approval.\n     */\n    export interface McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      always?: McpToolApprovalFilter.Always;\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      never?: McpToolApprovalFilter.Never;\n    }\n\n    export namespace McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Always {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Never {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n    }\n  }\n\n  /**\n   * A tool that runs Python code to help generate a response to a prompt.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The code interpreter container. Can be a container ID or an object that\n     * specifies uploaded file IDs to make available to your code, along with an\n     * optional `memory_limit` setting.\n     */\n    container: string | CodeInterpreter.CodeInterpreterToolAuto;\n\n    /**\n     * The type of the code interpreter tool. Always `code_interpreter`.\n     */\n    type: 'code_interpreter';\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Configuration for a code interpreter container. Optionally specify the IDs of\n     * the files to run the code on.\n     */\n    export interface CodeInterpreterToolAuto {\n      /**\n       * Always `auto`.\n       */\n      type: 'auto';\n\n      /**\n       * An optional list of uploaded files to make available to your code.\n       */\n      file_ids?: Array<string>;\n\n      /**\n       * The memory limit for the code interpreter container.\n       */\n      memory_limit?: '1g' | '4g' | '16g' | '64g' | null;\n    }\n  }\n\n  /**\n   * A tool that generates images using the GPT image models.\n   */\n  export interface ImageGeneration {\n    /**\n     * The type of the image generation tool. Always `image_generation`.\n     */\n    type: 'image_generation';\n\n    /**\n     * Background type for the generated image. One of `transparent`, `opaque`, or\n     * `auto`. Default: `auto`.\n     */\n    background?: 'transparent' | 'opaque' | 'auto';\n\n    /**\n     * Control how much effort the model will exert to match the style and features,\n     * especially facial features, of input images. This parameter is only supported\n     * for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and\n     * `low`. Defaults to `low`.\n     */\n    input_fidelity?: 'high' | 'low' | null;\n\n    /**\n     * Optional mask for inpainting. Contains `image_url` (string, optional) and\n     * `file_id` (string, optional).\n     */\n    input_image_mask?: ImageGeneration.InputImageMask;\n\n    /**\n     * The image generation model to use. Default: `gpt-image-1`.\n     */\n    model?: (string & {}) | 'gpt-image-1' | 'gpt-image-1-mini';\n\n    /**\n     * Moderation level for the generated image. Default: `auto`.\n     */\n    moderation?: 'auto' | 'low';\n\n    /**\n     * Compression level for the output image. Default: 100.\n     */\n    output_compression?: number;\n\n    /**\n     * The output format of the generated image. One of `png`, `webp`, or `jpeg`.\n     * Default: `png`.\n     */\n    output_format?: 'png' | 'webp' | 'jpeg';\n\n    /**\n     * Number of partial images to generate in streaming mode, from 0 (default value)\n     * to 3.\n     */\n    partial_images?: number;\n\n    /**\n     * The quality of the generated image. One of `low`, `medium`, `high`, or `auto`.\n     * Default: `auto`.\n     */\n    quality?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * The size of the generated image. One of `1024x1024`, `1024x1536`, `1536x1024`,\n     * or `auto`. Default: `auto`.\n     */\n    size?: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n  }\n\n  export namespace ImageGeneration {\n    /**\n     * Optional mask for inpainting. Contains `image_url` (string, optional) and\n     * `file_id` (string, optional).\n     */\n    export interface InputImageMask {\n      /**\n       * File ID for the mask image.\n       */\n      file_id?: string;\n\n      /**\n       * Base64-encoded mask image.\n       */\n      image_url?: string;\n    }\n  }\n\n  /**\n   * A tool that allows the model to execute shell commands in a local environment.\n   */\n  export interface LocalShell {\n    /**\n     * The type of the local shell tool. Always `local_shell`.\n     */\n    type: 'local_shell';\n  }\n}\n\n/**\n * Constrains the tools available to the model to a pre-defined set.\n */\nexport interface ToolChoiceAllowed {\n  /**\n   * Constrains the tools available to the model to a pre-defined set.\n   *\n   * `auto` allows the model to pick from among the allowed tools and generate a\n   * message.\n   *\n   * `required` requires the model to call one or more of the allowed tools.\n   */\n  mode: 'auto' | 'required';\n\n  /**\n   * A list of tool definitions that the model should be allowed to call.\n   *\n   * For the Responses API, the list of tool definitions might look like:\n   *\n   * ```json\n   * [\n   *   { \"type\": \"function\", \"name\": \"get_weather\" },\n   *   { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n   *   { \"type\": \"image_generation\" }\n   * ]\n   * ```\n   */\n  tools: Array<{ [key: string]: unknown }>;\n\n  /**\n   * Allowed tool configuration type. Always `allowed_tools`.\n   */\n  type: 'allowed_tools';\n}\n\n/**\n * Forces the model to call the apply_patch tool when executing a tool call.\n */\nexport interface ToolChoiceApplyPatch {\n  /**\n   * The tool to call. Always `apply_patch`.\n   */\n  type: 'apply_patch';\n}\n\n/**\n * Use this option to force the model to call a specific custom tool.\n */\nexport interface ToolChoiceCustom {\n  /**\n   * The name of the custom tool to call.\n   */\n  name: string;\n\n  /**\n   * For custom tool calling, the type is always `custom`.\n   */\n  type: 'custom';\n}\n\n/**\n * Use this option to force the model to call a specific function.\n */\nexport interface ToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * For function calling, the type is always `function`.\n   */\n  type: 'function';\n}\n\n/**\n * Use this option to force the model to call a specific tool on a remote MCP\n * server.\n */\nexport interface ToolChoiceMcp {\n  /**\n   * The label of the MCP server to use.\n   */\n  server_label: string;\n\n  /**\n   * For MCP tools, the type is always `mcp`.\n   */\n  type: 'mcp';\n\n  /**\n   * The name of the tool to call on the server.\n   */\n  name?: string | null;\n}\n\n/**\n * Controls which (if any) tool is called by the model.\n *\n * `none` means the model will not call any tool and instead generates a message.\n *\n * `auto` means the model can pick between generating a message or calling one or\n * more tools.\n *\n * `required` means the model must call one or more tools.\n */\nexport type ToolChoiceOptions = 'none' | 'auto' | 'required';\n\n/**\n * Forces the model to call the shell tool when a tool call is required.\n */\nexport interface ToolChoiceShell {\n  /**\n   * The tool to call. Always `shell`.\n   */\n  type: 'shell';\n}\n\n/**\n * Indicates that the model should use a built-in tool to generate a response.\n * [Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n */\nexport interface ToolChoiceTypes {\n  /**\n   * The type of hosted tool the model should to use. Learn more about\n   * [built-in tools](https://platform.openai.com/docs/guides/tools).\n   *\n   * Allowed values are:\n   *\n   * - `file_search`\n   * - `web_search_preview`\n   * - `computer_use_preview`\n   * - `code_interpreter`\n   * - `mcp`\n   * - `image_generation`\n   */\n  type:\n    | 'file_search'\n    | 'web_search_preview'\n    | 'computer_use_preview'\n    | 'web_search_preview_2025_03_11'\n    | 'image_generation'\n    | 'code_interpreter'\n    | 'mcp';\n}\n\n/**\n * This tool searches the web for relevant results to use in a response. Learn more\n * about the\n * [web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n */\nexport interface WebSearchPreviewTool {\n  /**\n   * The type of the web search tool. One of `web_search_preview` or\n   * `web_search_preview_2025_03_11`.\n   */\n  type: 'web_search_preview' | 'web_search_preview_2025_03_11';\n\n  /**\n   * High level guidance for the amount of context window space to use for the\n   * search. One of `low`, `medium`, or `high`. `medium` is the default.\n   */\n  search_context_size?: 'low' | 'medium' | 'high';\n\n  /**\n   * The user's location.\n   */\n  user_location?: WebSearchPreviewTool.UserLocation | null;\n}\n\nexport namespace WebSearchPreviewTool {\n  /**\n   * The user's location.\n   */\n  export interface UserLocation {\n    /**\n     * The type of location approximation. Always `approximate`.\n     */\n    type: 'approximate';\n\n    /**\n     * Free text input for the city of the user, e.g. `San Francisco`.\n     */\n    city?: string | null;\n\n    /**\n     * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n     * the user, e.g. `US`.\n     */\n    country?: string | null;\n\n    /**\n     * Free text input for the region of the user, e.g. `California`.\n     */\n    region?: string | null;\n\n    /**\n     * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n     * user, e.g. `America/Los_Angeles`.\n     */\n    timezone?: string | null;\n  }\n}\n\n/**\n * Search the Internet for sources related to the prompt. Learn more about the\n * [web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n */\nexport interface WebSearchTool {\n  /**\n   * The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.\n   */\n  type: 'web_search' | 'web_search_2025_08_26';\n\n  /**\n   * Filters for the search.\n   */\n  filters?: WebSearchTool.Filters | null;\n\n  /**\n   * High level guidance for the amount of context window space to use for the\n   * search. One of `low`, `medium`, or `high`. `medium` is the default.\n   */\n  search_context_size?: 'low' | 'medium' | 'high';\n\n  /**\n   * The approximate location of the user.\n   */\n  user_location?: WebSearchTool.UserLocation | null;\n}\n\nexport namespace WebSearchTool {\n  /**\n   * Filters for the search.\n   */\n  export interface Filters {\n    /**\n     * Allowed domains for the search. If not provided, all domains are allowed.\n     * Subdomains of the provided domains are allowed as well.\n     *\n     * Example: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n     */\n    allowed_domains?: Array<string> | null;\n  }\n\n  /**\n   * The approximate location of the user.\n   */\n  export interface UserLocation {\n    /**\n     * Free text input for the city of the user, e.g. `San Francisco`.\n     */\n    city?: string | null;\n\n    /**\n     * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n     * the user, e.g. `US`.\n     */\n    country?: string | null;\n\n    /**\n     * Free text input for the region of the user, e.g. `California`.\n     */\n    region?: string | null;\n\n    /**\n     * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n     * user, e.g. `America/Los_Angeles`.\n     */\n    timezone?: string | null;\n\n    /**\n     * The type of location approximation. Always `approximate`.\n     */\n    type?: 'approximate';\n  }\n}\n\nexport type ResponseCreateParams = ResponseCreateParamsNonStreaming | ResponseCreateParamsStreaming;\n\nexport interface ResponseCreateParamsBase {\n  /**\n   * Whether to run the model response in the background.\n   * [Learn more](https://platform.openai.com/docs/guides/background).\n   */\n  background?: boolean | null;\n\n  /**\n   * The conversation that this response belongs to. Items from this conversation are\n   * prepended to `input_items` for this response request. Input items and output\n   * items from this response are automatically added to this conversation after this\n   * response completes.\n   */\n  conversation?: string | ResponseConversationParam | null;\n\n  /**\n   * Specify additional output data to include in the model response. Currently\n   * supported values are:\n   *\n   * - `web_search_call.action.sources`: Include the sources of the web search tool\n   *   call.\n   * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n   *   in code interpreter tool call items.\n   * - `computer_call_output.output.image_url`: Include image urls from the computer\n   *   call output.\n   * - `file_search_call.results`: Include the search results of the file search tool\n   *   call.\n   * - `message.input_image.image_url`: Include image urls from the input message.\n   * - `computer_call_output.output.image_url`: Include image urls from the computer\n   *   call output.\n   * - `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n   *   tokens in reasoning item outputs. This enables reasoning items to be used in\n   *   multi-turn conversations when using the Responses API statelessly (like when\n   *   the `store` parameter is set to `false`, or when an organization is enrolled\n   *   in the zero data retention program).\n   * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n   *   in code interpreter tool call items.\n   */\n  include?: Array<ResponseIncludable> | null;\n\n  /**\n   * Text, image, or file inputs to the model, used to generate a response.\n   *\n   * Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Image inputs](https://platform.openai.com/docs/guides/images)\n   * - [File inputs](https://platform.openai.com/docs/guides/pdf-files)\n   * - [Conversation state](https://platform.openai.com/docs/guides/conversation-state)\n   * - [Function calling](https://platform.openai.com/docs/guides/function-calling)\n   */\n  input?: string | ResponseInput;\n\n  /**\n   * A system (or developer) message inserted into the model's context.\n   *\n   * When using along with `previous_response_id`, the instructions from a previous\n   * response will not be carried over to the next response. This makes it simple to\n   * swap out system (or developer) messages in new responses.\n   */\n  instructions?: string | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a response,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_output_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model?: Shared.ResponsesModel;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls?: boolean | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   * Cannot be used in conjunction with `conversation`.\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsePrompt | null;\n\n  /**\n   * Used by OpenAI to cache responses for similar requests to optimize your cache\n   * hit rates. Replaces the `user` field.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n   */\n  prompt_cache_key?: string;\n\n  /**\n   * The retention policy for the prompt cache. Set to `24h` to enable extended\n   * prompt caching, which keeps cached prefixes active for longer, up to a maximum\n   * of 24 hours.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).\n   */\n  prompt_cache_retention?: 'in-memory' | '24h' | null;\n\n  /**\n   * **gpt-5 and o-series models only**\n   *\n   * Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * A stable identifier used to help detect users of your application that may be\n   * violating OpenAI's usage policies. The IDs should be a string that uniquely\n   * identifies each user. We recommend hashing their username or email address, in\n   * order to avoid sending us any identifying information.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  safety_identifier?: string;\n\n  /**\n   * Specifies the latency tier to use for processing the request. This parameter is\n   * relevant for customers subscribed to the scale tier service:\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When this parameter is set, the response body will include the `service_tier`\n   * utilized.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * Whether to store the generated model response for later retrieval via API.\n   */\n  store?: boolean | null;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming responses. Only set this when you set `stream: true`.\n   */\n  stream_options?: ResponseCreateParams.StreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * How the model should select which tool (or tools) to use when generating a\n   * response. See the `tools` parameter to see how to specify which tools the model\n   * can call.\n   */\n  tool_choice?:\n    | ToolChoiceOptions\n    | ToolChoiceAllowed\n    | ToolChoiceTypes\n    | ToolChoiceFunction\n    | ToolChoiceMcp\n    | ToolChoiceCustom\n    | ToolChoiceApplyPatch\n    | ToolChoiceShell;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   *\n   * We support the following categories of tools:\n   *\n   * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n   *   capabilities, like\n   *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n   *   Learn more about\n   *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n   * - **MCP Tools**: Integrations with third-party systems via custom MCP servers or\n   *   predefined connectors such as Google Drive and SharePoint. Learn more about\n   *   [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n   * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n   *   the model to call your own code with strongly typed arguments and outputs.\n   *   Learn more about\n   *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n   *   You can also use custom tools to call your own code.\n   */\n  tools?: Array<Tool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * The truncation strategy to use for the model response.\n   *\n   * - `auto`: If the input to this Response exceeds the model's context window size,\n   *   the model will truncate the response to fit the context window by dropping\n   *   items from the beginning of the conversation.\n   * - `disabled` (default): If the input size will exceed the context window size\n   *   for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled' | null;\n\n  /**\n   * @deprecated This field is being replaced by `safety_identifier` and\n   * `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching\n   * optimizations. A stable identifier for your end-users. Used to boost cache hit\n   * rates by better bucketing similar requests and to help OpenAI detect and prevent\n   * abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  user?: string;\n}\n\nexport namespace ResponseCreateParams {\n  /**\n   * Options for streaming responses. Only set this when you set `stream: true`.\n   */\n  export interface StreamOptions {\n    /**\n     * When true, stream obfuscation will be enabled. Stream obfuscation adds random\n     * characters to an `obfuscation` field on streaming delta events to normalize\n     * payload sizes as a mitigation to certain side-channel attacks. These obfuscation\n     * fields are included by default, but add a small amount of overhead to the data\n     * stream. You can set `include_obfuscation` to false to optimize for bandwidth if\n     * you trust the network links between your application and the OpenAI API.\n     */\n    include_obfuscation?: boolean;\n  }\n\n  export type ResponseCreateParamsNonStreaming = ResponsesAPI.ResponseCreateParamsNonStreaming;\n  export type ResponseCreateParamsStreaming = ResponsesAPI.ResponseCreateParamsStreaming;\n}\n\nexport interface ResponseCreateParamsNonStreaming extends ResponseCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: false | null;\n}\n\nexport interface ResponseCreateParamsStreaming extends ResponseCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream: true;\n}\n\nexport type ResponseRetrieveParams = ResponseRetrieveParamsNonStreaming | ResponseRetrieveParamsStreaming;\n\nexport interface ResponseRetrieveParamsBase {\n  /**\n   * Additional fields to include in the response. See the `include` parameter for\n   * Response creation above for more information.\n   */\n  include?: Array<ResponseIncludable>;\n\n  /**\n   * When true, stream obfuscation will be enabled. Stream obfuscation adds random\n   * characters to an `obfuscation` field on streaming delta events to normalize\n   * payload sizes as a mitigation to certain side-channel attacks. These obfuscation\n   * fields are included by default, but add a small amount of overhead to the data\n   * stream. You can set `include_obfuscation` to false to optimize for bandwidth if\n   * you trust the network links between your application and the OpenAI API.\n   */\n  include_obfuscation?: boolean;\n\n  /**\n   * The sequence number of the event after which to start streaming.\n   */\n  starting_after?: number;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: boolean;\n}\n\nexport namespace ResponseRetrieveParams {\n  export type ResponseRetrieveParamsNonStreaming = ResponsesAPI.ResponseRetrieveParamsNonStreaming;\n  export type ResponseRetrieveParamsStreaming = ResponsesAPI.ResponseRetrieveParamsStreaming;\n}\n\nexport interface ResponseRetrieveParamsNonStreaming extends ResponseRetrieveParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: false;\n}\n\nexport interface ResponseRetrieveParamsStreaming extends ResponseRetrieveParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream: true;\n}\n\nexport interface ResponseCompactParams {\n  /**\n   * Model ID used to generate the response, like `gpt-5` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model:\n    | 'gpt-5.2'\n    | 'gpt-5.2-2025-12-11'\n    | 'gpt-5.2-chat-latest'\n    | 'gpt-5.2-pro'\n    | 'gpt-5.2-pro-2025-12-11'\n    | 'gpt-5.1'\n    | 'gpt-5.1-2025-11-13'\n    | 'gpt-5.1-codex'\n    | 'gpt-5.1-mini'\n    | 'gpt-5.1-chat-latest'\n    | 'gpt-5'\n    | 'gpt-5-mini'\n    | 'gpt-5-nano'\n    | 'gpt-5-2025-08-07'\n    | 'gpt-5-mini-2025-08-07'\n    | 'gpt-5-nano-2025-08-07'\n    | 'gpt-5-chat-latest'\n    | 'gpt-4.1'\n    | 'gpt-4.1-mini'\n    | 'gpt-4.1-nano'\n    | 'gpt-4.1-2025-04-14'\n    | 'gpt-4.1-mini-2025-04-14'\n    | 'gpt-4.1-nano-2025-04-14'\n    | 'o4-mini'\n    | 'o4-mini-2025-04-16'\n    | 'o3'\n    | 'o3-2025-04-16'\n    | 'o3-mini'\n    | 'o3-mini-2025-01-31'\n    | 'o1'\n    | 'o1-2024-12-17'\n    | 'o1-preview'\n    | 'o1-preview-2024-09-12'\n    | 'o1-mini'\n    | 'o1-mini-2024-09-12'\n    | 'gpt-4o'\n    | 'gpt-4o-2024-11-20'\n    | 'gpt-4o-2024-08-06'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4o-audio-preview'\n    | 'gpt-4o-audio-preview-2024-10-01'\n    | 'gpt-4o-audio-preview-2024-12-17'\n    | 'gpt-4o-audio-preview-2025-06-03'\n    | 'gpt-4o-mini-audio-preview'\n    | 'gpt-4o-mini-audio-preview-2024-12-17'\n    | 'gpt-4o-search-preview'\n    | 'gpt-4o-mini-search-preview'\n    | 'gpt-4o-search-preview-2025-03-11'\n    | 'gpt-4o-mini-search-preview-2025-03-11'\n    | 'chatgpt-4o-latest'\n    | 'codex-mini-latest'\n    | 'gpt-4o-mini'\n    | 'gpt-4o-mini-2024-07-18'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0301'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | 'o1-pro'\n    | 'o1-pro-2025-03-19'\n    | 'o3-pro'\n    | 'o3-pro-2025-06-10'\n    | 'o3-deep-research'\n    | 'o3-deep-research-2025-06-26'\n    | 'o4-mini-deep-research'\n    | 'o4-mini-deep-research-2025-06-26'\n    | 'computer-use-preview'\n    | 'computer-use-preview-2025-03-11'\n    | 'gpt-5-codex'\n    | 'gpt-5-pro'\n    | 'gpt-5-pro-2025-10-06'\n    | 'gpt-5.1-codex-max'\n    | (string & {})\n    | null;\n\n  /**\n   * Text, image, or file inputs to the model, used to generate a response\n   */\n  input?: string | Array<ResponseInputItem> | null;\n\n  /**\n   * A system (or developer) message inserted into the model's context. When used\n   * along with `previous_response_id`, the instructions from a previous response\n   * will not be carried over to the next response. This makes it simple to swap out\n   * system (or developer) messages in new responses.\n   */\n  instructions?: string | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   * Cannot be used in conjunction with `conversation`.\n   */\n  previous_response_id?: string | null;\n}\n\nResponses.InputItems = InputItems;\nResponses.InputTokens = InputTokens;\n\nexport declare namespace Responses {\n  export {\n    type ApplyPatchTool as ApplyPatchTool,\n    type CompactedResponse as CompactedResponse,\n    type ComputerTool as ComputerTool,\n    type CustomTool as CustomTool,\n    type EasyInputMessage as EasyInputMessage,\n    type FileSearchTool as FileSearchTool,\n    type FunctionShellTool as FunctionShellTool,\n    type FunctionTool as FunctionTool,\n    type Response as Response,\n    type ResponseApplyPatchToolCall as ResponseApplyPatchToolCall,\n    type ResponseApplyPatchToolCallOutput as ResponseApplyPatchToolCallOutput,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCodeInterpreterCallCodeDeltaEvent as ResponseCodeInterpreterCallCodeDeltaEvent,\n    type ResponseCodeInterpreterCallCodeDoneEvent as ResponseCodeInterpreterCallCodeDoneEvent,\n    type ResponseCodeInterpreterCallCompletedEvent as ResponseCodeInterpreterCallCompletedEvent,\n    type ResponseCodeInterpreterCallInProgressEvent as ResponseCodeInterpreterCallInProgressEvent,\n    type ResponseCodeInterpreterCallInterpretingEvent as ResponseCodeInterpreterCallInterpretingEvent,\n    type ResponseCodeInterpreterToolCall as ResponseCodeInterpreterToolCall,\n    type ResponseCompactionItem as ResponseCompactionItem,\n    type ResponseCompactionItemParam as ResponseCompactionItemParam,\n    type ResponseCompletedEvent as ResponseCompletedEvent,\n    type ResponseComputerToolCall as ResponseComputerToolCall,\n    type ResponseComputerToolCallOutputItem as ResponseComputerToolCallOutputItem,\n    type ResponseComputerToolCallOutputScreenshot as ResponseComputerToolCallOutputScreenshot,\n    type ResponseContent as ResponseContent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseConversationParam as ResponseConversationParam,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseCustomToolCall as ResponseCustomToolCall,\n    type ResponseCustomToolCallInputDeltaEvent as ResponseCustomToolCallInputDeltaEvent,\n    type ResponseCustomToolCallInputDoneEvent as ResponseCustomToolCallInputDoneEvent,\n    type ResponseCustomToolCallOutput as ResponseCustomToolCallOutput,\n    type ResponseError as ResponseError,\n    type ResponseErrorEvent as ResponseErrorEvent,\n    type ResponseFailedEvent as ResponseFailedEvent,\n    type ResponseFileSearchCallCompletedEvent as ResponseFileSearchCallCompletedEvent,\n    type ResponseFileSearchCallInProgressEvent as ResponseFileSearchCallInProgressEvent,\n    type ResponseFileSearchCallSearchingEvent as ResponseFileSearchCallSearchingEvent,\n    type ResponseFileSearchToolCall as ResponseFileSearchToolCall,\n    type ResponseFormatTextConfig as ResponseFormatTextConfig,\n    type ResponseFormatTextJSONSchemaConfig as ResponseFormatTextJSONSchemaConfig,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseFunctionCallOutputItem as ResponseFunctionCallOutputItem,\n    type ResponseFunctionCallOutputItemList as ResponseFunctionCallOutputItemList,\n    type ResponseFunctionShellCallOutputContent as ResponseFunctionShellCallOutputContent,\n    type ResponseFunctionShellToolCall as ResponseFunctionShellToolCall,\n    type ResponseFunctionShellToolCallOutput as ResponseFunctionShellToolCallOutput,\n    type ResponseFunctionToolCall as ResponseFunctionToolCall,\n    type ResponseFunctionToolCallItem as ResponseFunctionToolCallItem,\n    type ResponseFunctionToolCallOutputItem as ResponseFunctionToolCallOutputItem,\n    type ResponseFunctionWebSearch as ResponseFunctionWebSearch,\n    type ResponseImageGenCallCompletedEvent as ResponseImageGenCallCompletedEvent,\n    type ResponseImageGenCallGeneratingEvent as ResponseImageGenCallGeneratingEvent,\n    type ResponseImageGenCallInProgressEvent as ResponseImageGenCallInProgressEvent,\n    type ResponseImageGenCallPartialImageEvent as ResponseImageGenCallPartialImageEvent,\n    type ResponseInProgressEvent as ResponseInProgressEvent,\n    type ResponseIncludable as ResponseIncludable,\n    type ResponseIncompleteEvent as ResponseIncompleteEvent,\n    type ResponseInput as ResponseInput,\n    type ResponseInputAudio as ResponseInputAudio,\n    type ResponseInputContent as ResponseInputContent,\n    type ResponseInputFile as ResponseInputFile,\n    type ResponseInputFileContent as ResponseInputFileContent,\n    type ResponseInputImage as ResponseInputImage,\n    type ResponseInputImageContent as ResponseInputImageContent,\n    type ResponseInputItem as ResponseInputItem,\n    type ResponseInputMessageContentList as ResponseInputMessageContentList,\n    type ResponseInputMessageItem as ResponseInputMessageItem,\n    type ResponseInputText as ResponseInputText,\n    type ResponseInputTextContent as ResponseInputTextContent,\n    type ResponseItem as ResponseItem,\n    type ResponseMcpCallArgumentsDeltaEvent as ResponseMcpCallArgumentsDeltaEvent,\n    type ResponseMcpCallArgumentsDoneEvent as ResponseMcpCallArgumentsDoneEvent,\n    type ResponseMcpCallCompletedEvent as ResponseMcpCallCompletedEvent,\n    type ResponseMcpCallFailedEvent as ResponseMcpCallFailedEvent,\n    type ResponseMcpCallInProgressEvent as ResponseMcpCallInProgressEvent,\n    type ResponseMcpListToolsCompletedEvent as ResponseMcpListToolsCompletedEvent,\n    type ResponseMcpListToolsFailedEvent as ResponseMcpListToolsFailedEvent,\n    type ResponseMcpListToolsInProgressEvent as ResponseMcpListToolsInProgressEvent,\n    type ResponseOutputAudio as ResponseOutputAudio,\n    type ResponseOutputItem as ResponseOutputItem,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseOutputMessage as ResponseOutputMessage,\n    type ResponseOutputRefusal as ResponseOutputRefusal,\n    type ResponseOutputText as ResponseOutputText,\n    type ResponseOutputTextAnnotationAddedEvent as ResponseOutputTextAnnotationAddedEvent,\n    type ResponsePrompt as ResponsePrompt,\n    type ResponseQueuedEvent as ResponseQueuedEvent,\n    type ResponseReasoningItem as ResponseReasoningItem,\n    type ResponseReasoningSummaryPartAddedEvent as ResponseReasoningSummaryPartAddedEvent,\n    type ResponseReasoningSummaryPartDoneEvent as ResponseReasoningSummaryPartDoneEvent,\n    type ResponseReasoningSummaryTextDeltaEvent as ResponseReasoningSummaryTextDeltaEvent,\n    type ResponseReasoningSummaryTextDoneEvent as ResponseReasoningSummaryTextDoneEvent,\n    type ResponseReasoningTextDeltaEvent as ResponseReasoningTextDeltaEvent,\n    type ResponseReasoningTextDoneEvent as ResponseReasoningTextDoneEvent,\n    type ResponseRefusalDeltaEvent as ResponseRefusalDeltaEvent,\n    type ResponseRefusalDoneEvent as ResponseRefusalDoneEvent,\n    type ResponseStatus as ResponseStatus,\n    type ResponseStreamEvent as ResponseStreamEvent,\n    type ResponseTextConfig as ResponseTextConfig,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type ResponseUsage as ResponseUsage,\n    type ResponseWebSearchCallCompletedEvent as ResponseWebSearchCallCompletedEvent,\n    type ResponseWebSearchCallInProgressEvent as ResponseWebSearchCallInProgressEvent,\n    type ResponseWebSearchCallSearchingEvent as ResponseWebSearchCallSearchingEvent,\n    type Tool as Tool,\n    type ToolChoiceAllowed as ToolChoiceAllowed,\n    type ToolChoiceApplyPatch as ToolChoiceApplyPatch,\n    type ToolChoiceCustom as ToolChoiceCustom,\n    type ToolChoiceFunction as ToolChoiceFunction,\n    type ToolChoiceMcp as ToolChoiceMcp,\n    type ToolChoiceOptions as ToolChoiceOptions,\n    type ToolChoiceShell as ToolChoiceShell,\n    type ToolChoiceTypes as ToolChoiceTypes,\n    type WebSearchPreviewTool as WebSearchPreviewTool,\n    type WebSearchTool as WebSearchTool,\n    type ResponseCreateParams as ResponseCreateParams,\n    type ResponseCreateParamsNonStreaming as ResponseCreateParamsNonStreaming,\n    type ResponseCreateParamsStreaming as ResponseCreateParamsStreaming,\n    type ResponseRetrieveParams as ResponseRetrieveParams,\n    type ResponseRetrieveParamsNonStreaming as ResponseRetrieveParamsNonStreaming,\n    type ResponseRetrieveParamsStreaming as ResponseRetrieveParamsStreaming,\n    type ResponseCompactParams as ResponseCompactParams,\n  };\n\n  export {\n    InputItems as InputItems,\n    type ResponseItemList as ResponseItemList,\n    type InputItemListParams as InputItemListParams,\n  };\n\n  export {\n    InputTokens as InputTokens,\n    type InputTokenCountResponse as InputTokenCountResponse,\n    type InputTokenCountParams as InputTokenCountParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as RealtimeAPI from './realtime';\nimport * as Shared from '../../shared';\nimport * as SessionsAPI from './sessions';\nimport {\n  Session as SessionsAPISession,\n  SessionCreateParams,\n  SessionCreateResponse,\n  Sessions,\n} from './sessions';\nimport * as TranscriptionSessionsAPI from './transcription-sessions';\nimport {\n  TranscriptionSession,\n  TranscriptionSessionCreateParams,\n  TranscriptionSessions,\n} from './transcription-sessions';\n\n/**\n * @deprecated Realtime has now launched and is generally available. The old beta API is now deprecated.\n */\nexport class Realtime extends APIResource {\n  sessions: SessionsAPI.Sessions = new SessionsAPI.Sessions(this._client);\n  transcriptionSessions: TranscriptionSessionsAPI.TranscriptionSessions =\n    new TranscriptionSessionsAPI.TranscriptionSessions(this._client);\n}\n\n/**\n * Returned when a conversation is created. Emitted right after session creation.\n */\nexport interface ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  conversation: ConversationCreatedEvent.Conversation;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `conversation.created`.\n   */\n  type: 'conversation.created';\n}\n\nexport namespace ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  export interface Conversation {\n    /**\n     * The unique ID of the conversation.\n     */\n    id?: string;\n\n    /**\n     * The object type, must be `realtime.conversation`.\n     */\n    object?: 'realtime.conversation';\n  }\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItem {\n  /**\n   * The unique ID of the item, this can be generated by the client to help manage\n   * server-side context, but is not required because the server will generate one if\n   * not provided.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemContent>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`, `in_progress`). These have no\n   * effect on the conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output';\n}\n\nexport interface ConversationItemContent {\n  /**\n   * ID of a previous conversation item to reference (for `item_reference` content\n   * types in `response.create` events). These can reference both client and server\n   * created items.\n   */\n  id?: string;\n\n  /**\n   * Base64-encoded audio bytes, used for `input_audio` content type.\n   */\n  audio?: string;\n\n  /**\n   * The text content, used for `input_text` and `text` content types.\n   */\n  text?: string;\n\n  /**\n   * The transcript of the audio, used for `input_audio` and `audio` content types.\n   */\n  transcript?: string;\n\n  /**\n   * The content type (`input_text`, `input_audio`, `item_reference`, `text`,\n   * `audio`).\n   */\n  type?: 'input_text' | 'input_audio' | 'item_reference' | 'text' | 'audio';\n}\n\n/**\n * Add a new Item to the Conversation's context, including messages, function\n * calls, and function call responses. This event can be used both to populate a\n * \"history\" of the conversation and to add new items mid-stream, but has the\n * current limitation that it cannot populate assistant audio messages.\n *\n * If successful, the server will respond with a `conversation.item.created` event,\n * otherwise an `error` event will be sent.\n */\nexport interface ConversationItemCreateEvent {\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.create`.\n   */\n  type: 'conversation.item.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. If not\n   * set, the new item will be appended to the end of the conversation. If set to\n   * `root`, the new item will be added to the beginning of the conversation. If set\n   * to an existing ID, it allows an item to be inserted mid-conversation. If the ID\n   * cannot be found, an error will be returned and the item will not be added.\n   */\n  previous_item_id?: string;\n}\n\n/**\n * Returned when a conversation item is created. There are several scenarios that\n * produce this event:\n *\n * - The server is generating a Response, which if successful will produce either\n *   one or two Items, which will be of type `message` (role `assistant`) or type\n *   `function_call`.\n * - The input audio buffer has been committed, either by the client or the server\n *   (in `server_vad` mode). The server will take the content of the input audio\n *   buffer and add it to a new user message Item.\n * - The client has sent a `conversation.item.create` event to add a new Item to\n *   the Conversation.\n */\nexport interface ConversationItemCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.created`.\n   */\n  type: 'conversation.item.created';\n\n  /**\n   * The ID of the preceding item in the Conversation context, allows the client to\n   * understand the order of the conversation. Can be `null` if the item has no\n   * predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Send this event when you want to remove any item from the conversation history.\n * The server will respond with a `conversation.item.deleted` event, unless the\n * item does not exist in the conversation history, in which case the server will\n * respond with an error.\n */\nexport interface ConversationItemDeleteEvent {\n  /**\n   * The ID of the item to delete.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.delete`.\n   */\n  type: 'conversation.item.delete';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an item in the conversation is deleted by the client with a\n * `conversation.item.delete` event. This event is used to synchronize the server's\n * understanding of the conversation history with the client's view.\n */\nexport interface ConversationItemDeletedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item that was deleted.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.deleted`.\n   */\n  type: 'conversation.item.deleted';\n}\n\n/**\n * This event is the output of audio transcription for user audio written to the\n * user audio buffer. Transcription begins when the input audio buffer is committed\n * by the client or server (in `server_vad` mode). Transcription runs\n * asynchronously with Response creation, so this event may come before or after\n * the Response events.\n *\n * Realtime API models accept audio natively, and thus input transcription is a\n * separate process run on a separate ASR (Automatic Speech Recognition) model. The\n * transcript may diverge somewhat from the model's interpretation, and should be\n * treated as a rough guide.\n */\nexport interface ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item containing the audio.\n   */\n  item_id: string;\n\n  /**\n   * The transcribed text.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.completed`.\n   */\n  type: 'conversation.item.input_audio_transcription.completed';\n\n  /**\n   * Usage statistics for the transcription.\n   */\n  usage:\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageTokens\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageDuration;\n\n  /**\n   * The log probabilities of the transcription.\n   */\n  logprobs?: Array<ConversationItemInputAudioTranscriptionCompletedEvent.Logprob> | null;\n}\n\nexport namespace ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface TranscriptTextUsageTokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: TranscriptTextUsageTokens.InputTokenDetails;\n  }\n\n  export namespace TranscriptTextUsageTokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface TranscriptTextUsageDuration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n\n  /**\n   * A log probability object.\n   */\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob: number;\n  }\n}\n\n/**\n * Returned when the text value of an input audio transcription content part is\n * updated.\n */\nexport interface ConversationItemInputAudioTranscriptionDeltaEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.delta`.\n   */\n  type: 'conversation.item.input_audio_transcription.delta';\n\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index?: number;\n\n  /**\n   * The text delta.\n   */\n  delta?: string;\n\n  /**\n   * The log probabilities of the transcription.\n   */\n  logprobs?: Array<ConversationItemInputAudioTranscriptionDeltaEvent.Logprob> | null;\n}\n\nexport namespace ConversationItemInputAudioTranscriptionDeltaEvent {\n  /**\n   * A log probability object.\n   */\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob: number;\n  }\n}\n\n/**\n * Returned when input audio transcription is configured, and a transcription\n * request for a user message failed. These events are separate from other `error`\n * events so that the client can identify the related Item.\n */\nexport interface ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * Details of the transcription error.\n   */\n  error: ConversationItemInputAudioTranscriptionFailedEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.failed`.\n   */\n  type: 'conversation.item.input_audio_transcription.failed';\n}\n\nexport namespace ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * Details of the transcription error.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message?: string;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Send this event when you want to retrieve the server's representation of a\n * specific item in the conversation history. This is useful, for example, to\n * inspect user audio after noise cancellation and VAD. The server will respond\n * with a `conversation.item.retrieved` event, unless the item does not exist in\n * the conversation history, in which case the server will respond with an error.\n */\nexport interface ConversationItemRetrieveEvent {\n  /**\n   * The ID of the item to retrieve.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.retrieve`.\n   */\n  type: 'conversation.item.retrieve';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to truncate a previous assistant messages audio. The server\n * will produce audio faster than realtime, so this event is useful when the user\n * interrupts to truncate audio that has already been sent to the client but not\n * yet played. This will synchronize the server's understanding of the audio with\n * the client's playback.\n *\n * Truncating audio will delete the server-side text transcript to ensure there is\n * not text in the context that hasn't been heard by the user.\n *\n * If successful, the server will respond with a `conversation.item.truncated`\n * event.\n */\nexport interface ConversationItemTruncateEvent {\n  /**\n   * Inclusive duration up to which audio is truncated, in milliseconds. If the\n   * audio_end_ms is greater than the actual audio duration, the server will respond\n   * with an error.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part to truncate. Set this to 0.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the assistant message item to truncate. Only assistant message items\n   * can be truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncate`.\n   */\n  type: 'conversation.item.truncate';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an earlier assistant audio message item is truncated by the client\n * with a `conversation.item.truncate` event. This event is used to synchronize the\n * server's understanding of the audio with the client's playback.\n *\n * This action will truncate the audio and remove the server-side text transcript\n * to ensure there is no text in the context that hasn't been heard by the user.\n */\nexport interface ConversationItemTruncatedEvent {\n  /**\n   * The duration up to which the audio was truncated, in milliseconds.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part that was truncated.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the assistant message item that was truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncated`.\n   */\n  type: 'conversation.item.truncated';\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItemWithReference {\n  /**\n   * For an item of type (`message` | `function_call` | `function_call_output`) this\n   * field allows the client to assign the unique ID of the item. It is not required\n   * because the server will generate one if not provided.\n   *\n   * For an item of type `item_reference`, this field is required and is a reference\n   * to any item that has previously existed in the conversation.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemWithReference.Content>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`, `in_progress`). These have no\n   * effect on the conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`,\n   * `item_reference`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output' | 'item_reference';\n}\n\nexport namespace ConversationItemWithReference {\n  export interface Content {\n    /**\n     * ID of a previous conversation item to reference (for `item_reference` content\n     * types in `response.create` events). These can reference both client and server\n     * created items.\n     */\n    id?: string;\n\n    /**\n     * Base64-encoded audio bytes, used for `input_audio` content type.\n     */\n    audio?: string;\n\n    /**\n     * The text content, used for `input_text` and `text` content types.\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio, used for `input_audio` content type.\n     */\n    transcript?: string;\n\n    /**\n     * The content type (`input_text`, `input_audio`, `item_reference`, `text`).\n     */\n    type?: 'input_text' | 'input_audio' | 'item_reference' | 'text';\n  }\n}\n\n/**\n * Returned when an error occurs, which could be a client problem or a server\n * problem. Most errors are recoverable and the session will stay open, we\n * recommend to implementors to monitor and log error messages by default.\n */\nexport interface ErrorEvent {\n  /**\n   * Details of the error.\n   */\n  error: ErrorEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `error`.\n   */\n  type: 'error';\n}\n\nexport namespace ErrorEvent {\n  /**\n   * Details of the error.\n   */\n  export interface Error {\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The type of error (e.g., \"invalid_request_error\", \"server_error\").\n     */\n    type: string;\n\n    /**\n     * Error code, if any.\n     */\n    code?: string | null;\n\n    /**\n     * The event_id of the client event that caused the error, if applicable.\n     */\n    event_id?: string | null;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string | null;\n  }\n}\n\n/**\n * Send this event to append audio bytes to the input audio buffer. The audio\n * buffer is temporary storage you can write to and later commit. In Server VAD\n * mode, the audio buffer is used to detect speech and the server will decide when\n * to commit. When Server VAD is disabled, you must commit the audio buffer\n * manually.\n *\n * The client may choose how much audio to place in each event up to a maximum of\n * 15 MiB, for example streaming smaller chunks from the client may allow the VAD\n * to be more responsive. Unlike made other client events, the server will not send\n * a confirmation response to this event.\n */\nexport interface InputAudioBufferAppendEvent {\n  /**\n   * Base64-encoded audio bytes. This must be in the format specified by the\n   * `input_audio_format` field in the session configuration.\n   */\n  audio: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.append`.\n   */\n  type: 'input_audio_buffer.append';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to clear the audio bytes in the buffer. The server will respond\n * with an `input_audio_buffer.cleared` event.\n */\nexport interface InputAudioBufferClearEvent {\n  /**\n   * The event type, must be `input_audio_buffer.clear`.\n   */\n  type: 'input_audio_buffer.clear';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when the input audio buffer is cleared by the client with a\n * `input_audio_buffer.clear` event.\n */\nexport interface InputAudioBufferClearedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.cleared`.\n   */\n  type: 'input_audio_buffer.cleared';\n}\n\n/**\n * Send this event to commit the user input audio buffer, which will create a new\n * user message item in the conversation. This event will produce an error if the\n * input audio buffer is empty. When in Server VAD mode, the client does not need\n * to send this event, the server will commit the audio buffer automatically.\n *\n * Committing the input audio buffer will trigger input audio transcription (if\n * enabled in session configuration), but it will not create a response from the\n * model. The server will respond with an `input_audio_buffer.committed` event.\n */\nexport interface InputAudioBufferCommitEvent {\n  /**\n   * The event type, must be `input_audio_buffer.commit`.\n   */\n  type: 'input_audio_buffer.commit';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an input audio buffer is committed, either by the client or\n * automatically in server VAD mode. The `item_id` property is the ID of the user\n * message item that will be created, thus a `conversation.item.created` event will\n * also be sent to the client.\n */\nexport interface InputAudioBufferCommittedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.committed`.\n   */\n  type: 'input_audio_buffer.committed';\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. Can be\n   * `null` if the item has no predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Sent by the server when in `server_vad` mode to indicate that speech has been\n * detected in the audio buffer. This can happen any time audio is added to the\n * buffer (unless speech is already detected). The client may want to use this\n * event to interrupt audio playback or provide visual feedback to the user.\n *\n * The client should expect to receive a `input_audio_buffer.speech_stopped` event\n * when speech stops. The `item_id` property is the ID of the user message item\n * that will be created when speech stops and will also be included in the\n * `input_audio_buffer.speech_stopped` event (unless the client manually commits\n * the audio buffer during VAD activation).\n */\nexport interface InputAudioBufferSpeechStartedEvent {\n  /**\n   * Milliseconds from the start of all audio written to the buffer during the\n   * session when speech was first detected. This will correspond to the beginning of\n   * audio sent to the model, and thus includes the `prefix_padding_ms` configured in\n   * the Session.\n   */\n  audio_start_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created when speech stops.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_started`.\n   */\n  type: 'input_audio_buffer.speech_started';\n}\n\n/**\n * Returned in `server_vad` mode when the server detects the end of speech in the\n * audio buffer. The server will also send an `conversation.item.created` event\n * with the user message item that is created from the audio buffer.\n */\nexport interface InputAudioBufferSpeechStoppedEvent {\n  /**\n   * Milliseconds since the session started when speech stopped. This will correspond\n   * to the end of audio sent to the model, and thus includes the\n   * `min_silence_duration_ms` configured in the Session.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_stopped`.\n   */\n  type: 'input_audio_buffer.speech_stopped';\n}\n\n/**\n * Emitted at the beginning of a Response to indicate the updated rate limits. When\n * a Response is created some tokens will be \"reserved\" for the output tokens, the\n * rate limits shown here reflect that reservation, which is then adjusted\n * accordingly once the Response is completed.\n */\nexport interface RateLimitsUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * List of rate limit information.\n   */\n  rate_limits: Array<RateLimitsUpdatedEvent.RateLimit>;\n\n  /**\n   * The event type, must be `rate_limits.updated`.\n   */\n  type: 'rate_limits.updated';\n}\n\nexport namespace RateLimitsUpdatedEvent {\n  export interface RateLimit {\n    /**\n     * The maximum allowed value for the rate limit.\n     */\n    limit?: number;\n\n    /**\n     * The name of the rate limit (`requests`, `tokens`).\n     */\n    name?: 'requests' | 'tokens';\n\n    /**\n     * The remaining value before the limit is reached.\n     */\n    remaining?: number;\n\n    /**\n     * Seconds until the rate limit resets.\n     */\n    reset_seconds?: number;\n  }\n}\n\n/**\n * A realtime client event.\n */\nexport type RealtimeClientEvent =\n  | ConversationItemCreateEvent\n  | ConversationItemDeleteEvent\n  | ConversationItemRetrieveEvent\n  | ConversationItemTruncateEvent\n  | InputAudioBufferAppendEvent\n  | InputAudioBufferClearEvent\n  | RealtimeClientEvent.OutputAudioBufferClear\n  | InputAudioBufferCommitEvent\n  | ResponseCancelEvent\n  | ResponseCreateEvent\n  | SessionUpdateEvent\n  | TranscriptionSessionUpdate;\n\nexport namespace RealtimeClientEvent {\n  /**\n   * **WebRTC Only:** Emit to cut off the current audio response. This will trigger\n   * the server to stop generating audio and emit a `output_audio_buffer.cleared`\n   * event. This event should be preceded by a `response.cancel` client event to stop\n   * the generation of the current response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferClear {\n    /**\n     * The event type, must be `output_audio_buffer.clear`.\n     */\n    type: 'output_audio_buffer.clear';\n\n    /**\n     * The unique ID of the client event used for error handling.\n     */\n    event_id?: string;\n  }\n}\n\n/**\n * The response resource.\n */\nexport interface RealtimeResponse {\n  /**\n   * The unique ID of the response.\n   */\n  id?: string;\n\n  /**\n   * Which conversation the response is added to, determined by the `conversation`\n   * field in the `response.create` event. If `auto`, the response will be added to\n   * the default conversation and the value of `conversation_id` will be an id like\n   * `conv_1234`. If `none`, the response will not be added to any conversation and\n   * the value of `conversation_id` will be `null`. If responses are being triggered\n   * by server VAD, the response will be added to the default conversation, thus the\n   * `conversation_id` will be an id like `conv_1234`.\n   */\n  conversation_id?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls, that was used in this response.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The set of modalities the model used to respond. If there are multiple\n   * modalities, the model will pick one, for example if `modalities` is\n   * `[\"text\", \"audio\"]`, the model could be responding in either text or audio.\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The object type, must be `realtime.response`.\n   */\n  object?: 'realtime.response';\n\n  /**\n   * The list of output items generated by the response.\n   */\n  output?: Array<ConversationItem>;\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * The final status of the response (`completed`, `cancelled`, `failed`, or\n   * `incomplete`, `in_progress`).\n   */\n  status?: 'completed' | 'cancelled' | 'failed' | 'incomplete' | 'in_progress';\n\n  /**\n   * Additional details about the status.\n   */\n  status_details?: RealtimeResponseStatus;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * Usage statistics for the Response, this will correspond to billing. A Realtime\n   * API session will maintain a conversation context and append new Items to the\n   * Conversation, thus output from previous turns (text and audio tokens) will\n   * become the input for later turns.\n   */\n  usage?: RealtimeResponseUsage;\n\n  /**\n   * The voice the model used to respond. Current voice options are `alloy`, `ash`,\n   * `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\n/**\n * Additional details about the status.\n */\nexport interface RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  error?: RealtimeResponseStatus.Error;\n\n  /**\n   * The reason the Response did not complete. For a `cancelled` Response, one of\n   * `turn_detected` (the server VAD detected a new start of speech) or\n   * `client_cancelled` (the client sent a cancel event). For an `incomplete`\n   * Response, one of `max_output_tokens` or `content_filter` (the server-side safety\n   * filter activated and cut off the response).\n   */\n  reason?: 'turn_detected' | 'client_cancelled' | 'max_output_tokens' | 'content_filter';\n\n  /**\n   * The type of error that caused the response to fail, corresponding with the\n   * `status` field (`completed`, `cancelled`, `incomplete`, `failed`).\n   */\n  type?: 'completed' | 'cancelled' | 'incomplete' | 'failed';\n}\n\nexport namespace RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Usage statistics for the Response, this will correspond to billing. A Realtime\n * API session will maintain a conversation context and append new Items to the\n * Conversation, thus output from previous turns (text and audio tokens) will\n * become the input for later turns.\n */\nexport interface RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response.\n   */\n  input_token_details?: RealtimeResponseUsage.InputTokenDetails;\n\n  /**\n   * The number of input tokens used in the Response, including text and audio\n   * tokens.\n   */\n  input_tokens?: number;\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  output_token_details?: RealtimeResponseUsage.OutputTokenDetails;\n\n  /**\n   * The number of output tokens sent in the Response, including text and audio\n   * tokens.\n   */\n  output_tokens?: number;\n\n  /**\n   * The total number of tokens in the Response including input and output text and\n   * audio tokens.\n   */\n  total_tokens?: number;\n}\n\nexport namespace RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response.\n   */\n  export interface InputTokenDetails {\n    /**\n     * The number of audio tokens used in the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of cached tokens used in the Response.\n     */\n    cached_tokens?: number;\n\n    /**\n     * The number of text tokens used in the Response.\n     */\n    text_tokens?: number;\n  }\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  export interface OutputTokenDetails {\n    /**\n     * The number of audio tokens used in the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of text tokens used in the Response.\n     */\n    text_tokens?: number;\n  }\n}\n\n/**\n * A realtime server event.\n */\nexport type RealtimeServerEvent =\n  | ConversationCreatedEvent\n  | ConversationItemCreatedEvent\n  | ConversationItemDeletedEvent\n  | ConversationItemInputAudioTranscriptionCompletedEvent\n  | ConversationItemInputAudioTranscriptionDeltaEvent\n  | ConversationItemInputAudioTranscriptionFailedEvent\n  | RealtimeServerEvent.ConversationItemRetrieved\n  | ConversationItemTruncatedEvent\n  | ErrorEvent\n  | InputAudioBufferClearedEvent\n  | InputAudioBufferCommittedEvent\n  | InputAudioBufferSpeechStartedEvent\n  | InputAudioBufferSpeechStoppedEvent\n  | RateLimitsUpdatedEvent\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseCreatedEvent\n  | ResponseDoneEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | SessionCreatedEvent\n  | SessionUpdatedEvent\n  | TranscriptionSessionUpdatedEvent\n  | RealtimeServerEvent.OutputAudioBufferStarted\n  | RealtimeServerEvent.OutputAudioBufferStopped\n  | RealtimeServerEvent.OutputAudioBufferCleared;\n\nexport namespace RealtimeServerEvent {\n  /**\n   * Returned when a conversation item is retrieved with\n   * `conversation.item.retrieve`.\n   */\n  export interface ConversationItemRetrieved {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The item to add to the conversation.\n     */\n    item: RealtimeAPI.ConversationItem;\n\n    /**\n     * The event type, must be `conversation.item.retrieved`.\n     */\n    type: 'conversation.item.retrieved';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the server begins streaming audio to the client.\n   * This event is emitted after an audio content part has been added\n   * (`response.content_part.added`) to the response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStarted {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.started`.\n     */\n    type: 'output_audio_buffer.started';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the output audio buffer has been completely\n   * drained on the server, and no more audio is forthcoming. This event is emitted\n   * after the full response data has been sent to the client (`response.done`).\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStopped {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.stopped`.\n     */\n    type: 'output_audio_buffer.stopped';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the output audio buffer is cleared. This happens\n   * either in VAD mode when the user has interrupted\n   * (`input_audio_buffer.speech_started`), or when the client has emitted the\n   * `output_audio_buffer.clear` event to manually cut off the current audio\n   * response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferCleared {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.cleared`.\n     */\n    type: 'output_audio_buffer.cleared';\n  }\n}\n\n/**\n * Returned when the model-generated audio is updated.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * Base64-encoded audio data delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio.delta`.\n   */\n  type: 'response.audio.delta';\n}\n\n/**\n * Returned when the model-generated audio is done. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio.done`.\n   */\n  type: 'response.audio.done';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is updated.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The transcript delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio_transcript.delta`.\n   */\n  type: 'response.audio_transcript.delta';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is done\n * streaming. Also emitted when a Response is interrupted, incomplete, or\n * cancelled.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final transcript of the audio.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `response.audio_transcript.done`.\n   */\n  type: 'response.audio_transcript.done';\n}\n\n/**\n * Send this event to cancel an in-progress response. The server will respond with\n * a `response.done` event with a status of `response.status=cancelled`. If there\n * is no response to cancel, the server will respond with an error.\n */\nexport interface ResponseCancelEvent {\n  /**\n   * The event type, must be `response.cancel`.\n   */\n  type: 'response.cancel';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * A specific response ID to cancel - if not provided, will cancel an in-progress\n   * response in the default conversation.\n   */\n  response_id?: string;\n}\n\n/**\n * Returned when a new content part is added to an assistant message item during\n * response generation.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item to which the content part was added.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseContentPartAddedEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\nexport namespace ResponseContentPartAddedEvent {\n  /**\n   * The content part that was added.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * Returned when a content part is done streaming in an assistant message item.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseContentPartDoneEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\nexport namespace ResponseContentPartDoneEvent {\n  /**\n   * The content part that is done.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * This event instructs the server to create a Response, which means triggering\n * model inference. When in Server VAD mode, the server will create Responses\n * automatically.\n *\n * A Response will include at least one Item, and may have two, in which case the\n * second will be a function call. These Items will be appended to the conversation\n * history.\n *\n * The server will respond with a `response.created` event, events for Items and\n * content created, and finally a `response.done` event to indicate the Response is\n * complete.\n *\n * The `response.create` event includes inference configuration like\n * `instructions`, and `temperature`. These fields will override the Session's\n * configuration for this Response only.\n */\nexport interface ResponseCreateEvent {\n  /**\n   * The event type, must be `response.create`.\n   */\n  type: 'response.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  response?: ResponseCreateEvent.Response;\n}\n\nexport namespace ResponseCreateEvent {\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  export interface Response {\n    /**\n     * Controls which conversation the response is added to. Currently supports `auto`\n     * and `none`, with `auto` as the default value. The `auto` value means that the\n     * contents of the response will be added to the default conversation. Set this to\n     * `none` to create an out-of-band response which will not add items to default\n     * conversation.\n     */\n    conversation?: (string & {}) | 'auto' | 'none';\n\n    /**\n     * Input items to include in the prompt for the model. Using this field creates a\n     * new context for this Response instead of using the default conversation. An\n     * empty array `[]` will clear the context for this Response. Note that this can\n     * include references to items from the default conversation.\n     */\n    input?: Array<RealtimeAPI.ConversationItemWithReference>;\n\n    /**\n     * The default system instructions (i.e. system message) prepended to model calls.\n     * This field allows the client to guide the model on desired responses. The model\n     * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n     * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n     * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n     * instructions are not guaranteed to be followed by the model, but they provide\n     * guidance to the model on the desired behavior.\n     *\n     * Note that the server sets default instructions which will be used if this field\n     * is not set and are visible in the `session.created` event at the start of the\n     * session.\n     */\n    instructions?: string;\n\n    /**\n     * Maximum number of output tokens for a single assistant response, inclusive of\n     * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n     * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n     */\n    max_response_output_tokens?: number | 'inf';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     */\n    output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n     */\n    temperature?: number;\n\n    /**\n     * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n     * a function, like `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}`.\n     */\n    tool_choice?: string;\n\n    /**\n     * Tools (functions) available to the model.\n     */\n    tools?: Array<Response.Tool>;\n\n    /**\n     * The voice the model uses to respond. Voice cannot be changed during the session\n     * once the model has responded with audio at least once. Current voice options are\n     * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n     */\n    voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n  }\n\n  export namespace Response {\n    export interface Tool {\n      /**\n       * The description of the function, including guidance on when and how to call it,\n       * and guidance about what to tell the user when calling (if anything).\n       */\n      description?: string;\n\n      /**\n       * The name of the function.\n       */\n      name?: string;\n\n      /**\n       * Parameters of the function in JSON Schema.\n       */\n      parameters?: unknown;\n\n      /**\n       * The type of the tool, i.e. `function`.\n       */\n      type?: 'function';\n    }\n  }\n}\n\n/**\n * Returned when a new Response is created. The first event of response creation,\n * where the response is in an initial state of `in_progress`.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * Returned when a Response is done streaming. Always emitted, no matter the final\n * state. The Response object included in the `response.done` event will include\n * all output Items in the Response but will omit the raw audio data.\n */\nexport interface ResponseDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.done`.\n   */\n  type: 'response.done';\n}\n\n/**\n * Returned when the model-generated function call arguments are updated.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The arguments delta as a JSON string.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Returned when the model-generated function call arguments are done streaming.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The final arguments as a JSON string.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.done`.\n   */\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * Returned when a new Item is created during Response generation.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Returned when an Item is done streaming. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * Returned when the text value of a \"text\" content part is updated.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The text delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.text.delta`.\n   */\n  type: 'response.text.delta';\n}\n\n/**\n * Returned when the text value of a \"text\" content part is done streaming. Also\n * emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final text content.\n   */\n  text: string;\n\n  /**\n   * The event type, must be `response.text.done`.\n   */\n  type: 'response.text.done';\n}\n\n/**\n * Returned when a Session is created. Emitted automatically when a new connection\n * is established as the first server event. This event will contain the default\n * Session configuration.\n */\nexport interface SessionCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionsAPI.Session;\n\n  /**\n   * The event type, must be `session.created`.\n   */\n  type: 'session.created';\n}\n\n/**\n * Send this event to update the sessions default configuration. The client may\n * send this event at any time to update any field, except for `voice`. However,\n * note that once a session has been initialized with a particular `model`, it\n * cant be changed to another model using `session.update`.\n *\n * When the server receives a `session.update`, it will respond with a\n * `session.updated` event showing the full, effective configuration. Only the\n * fields that are present are updated. To clear a field like `instructions`, pass\n * an empty string.\n */\nexport interface SessionUpdateEvent {\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionUpdateEvent.Session;\n\n  /**\n   * The event type, must be `session.update`.\n   */\n  type: 'session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\nexport namespace SessionUpdateEvent {\n  /**\n   * Realtime session object configuration.\n   */\n  export interface Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    client_secret?: Session.ClientSecret;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n     * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n     * (mono), and little-endian byte order.\n     */\n    input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n    /**\n     * Configuration for input audio transcription, defaults to off and can be set to\n     * `null` to turn off once on. Input audio transcription is not native to the\n     * model, since the model consumes audio directly. Transcription runs\n     * asynchronously through\n     * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n     * and should be treated as guidance of input audio content rather than precisely\n     * what the model heard. The client can optionally set the language and prompt for\n     * transcription, these offer additional guidance to the transcription service.\n     */\n    input_audio_transcription?: Session.InputAudioTranscription;\n\n    /**\n     * The default system instructions (i.e. system message) prepended to model calls.\n     * This field allows the client to guide the model on desired responses. The model\n     * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n     * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n     * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n     * instructions are not guaranteed to be followed by the model, but they provide\n     * guidance to the model on the desired behavior.\n     *\n     * Note that the server sets default instructions which will be used if this field\n     * is not set and are visible in the `session.created` event at the start of the\n     * session.\n     */\n    instructions?: string;\n\n    /**\n     * Maximum number of output tokens for a single assistant response, inclusive of\n     * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n     * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n     */\n    max_response_output_tokens?: number | 'inf';\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * The Realtime model used for this session.\n     */\n    model?:\n      | 'gpt-4o-realtime-preview'\n      | 'gpt-4o-realtime-preview-2024-10-01'\n      | 'gpt-4o-realtime-preview-2024-12-17'\n      | 'gpt-4o-realtime-preview-2025-06-03'\n      | 'gpt-4o-mini-realtime-preview'\n      | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n    /**\n     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     * For `pcm16`, output audio is sampled at a rate of 24kHz.\n     */\n    output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n     * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n     * between model turns, not while a response is in progress.\n     */\n    speed?: number;\n\n    /**\n     * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n     * temperature of 0.8 is highly recommended for best performance.\n     */\n    temperature?: number;\n\n    /**\n     * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n     * a function.\n     */\n    tool_choice?: string;\n\n    /**\n     * Tools (functions) available to the model.\n     */\n    tools?: Array<Session.Tool>;\n\n    /**\n     * Configuration options for tracing. Set to null to disable tracing. Once tracing\n     * is enabled for a session, the configuration cannot be modified.\n     *\n     * `auto` will create a trace for the session with default values for the workflow\n     * name, group id, and metadata.\n     */\n    tracing?: 'auto' | Session.TracingConfiguration;\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    turn_detection?: Session.TurnDetection;\n\n    /**\n     * The voice the model uses to respond. Voice cannot be changed during the session\n     * once the model has responded with audio at least once. Current voice options are\n     * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n     */\n    voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n  }\n\n  export namespace Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    export interface ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      expires_after?: ClientSecret.ExpiresAfter;\n    }\n\n    export namespace ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      export interface ExpiresAfter {\n        /**\n         * The anchor point for the ephemeral token expiration. Only `created_at` is\n         * currently supported.\n         */\n        anchor: 'created_at';\n\n        /**\n         * The number of seconds from the anchor point to the expiration. Select a value\n         * between `10` and `7200`.\n         */\n        seconds?: number;\n      }\n    }\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    export interface InputAudioNoiseReduction {\n      /**\n       * Type of noise reduction. `near_field` is for close-talking microphones such as\n       * headphones, `far_field` is for far-field microphones such as laptop or\n       * conference room microphones.\n       */\n      type?: 'near_field' | 'far_field';\n    }\n\n    /**\n     * Configuration for input audio transcription, defaults to off and can be set to\n     * `null` to turn off once on. Input audio transcription is not native to the\n     * model, since the model consumes audio directly. Transcription runs\n     * asynchronously through\n     * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n     * and should be treated as guidance of input audio content rather than precisely\n     * what the model heard. The client can optionally set the language and prompt for\n     * transcription, these offer additional guidance to the transcription service.\n     */\n    export interface InputAudioTranscription {\n      /**\n       * The language of the input audio. Supplying the input language in\n       * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n       * format will improve accuracy and latency.\n       */\n      language?: string;\n\n      /**\n       * The model to use for transcription, current options are `gpt-4o-transcribe`,\n       * `gpt-4o-mini-transcribe`, and `whisper-1`.\n       */\n      model?: string;\n\n      /**\n       * An optional text to guide the model's style or continue a previous audio\n       * segment. For `whisper-1`, the\n       * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n       * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n       * \"expect words related to technology\".\n       */\n      prompt?: string;\n    }\n\n    export interface Tool {\n      /**\n       * The description of the function, including guidance on when and how to call it,\n       * and guidance about what to tell the user when calling (if anything).\n       */\n      description?: string;\n\n      /**\n       * The name of the function.\n       */\n      name?: string;\n\n      /**\n       * Parameters of the function in JSON Schema.\n       */\n      parameters?: unknown;\n\n      /**\n       * The type of the tool, i.e. `function`.\n       */\n      type?: 'function';\n    }\n\n    /**\n     * Granular configuration for tracing.\n     */\n    export interface TracingConfiguration {\n      /**\n       * The group id to attach to this trace to enable filtering and grouping in the\n       * traces dashboard.\n       */\n      group_id?: string;\n\n      /**\n       * The arbitrary metadata to attach to this trace to enable filtering in the traces\n       * dashboard.\n       */\n      metadata?: unknown;\n\n      /**\n       * The name of the workflow to attach to this trace. This is used to name the trace\n       * in the traces dashboard.\n       */\n      workflow_name?: string;\n    }\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    export interface TurnDetection {\n      /**\n       * Whether or not to automatically generate a response when a VAD stop event\n       * occurs.\n       */\n      create_response?: boolean;\n\n      /**\n       * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n       * will wait longer for the user to continue speaking, `high` will respond more\n       * quickly. `auto` is the default and is equivalent to `medium`.\n       */\n      eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n      /**\n       * Whether or not to automatically interrupt any ongoing response with output to\n       * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n       * occurs.\n       */\n      interrupt_response?: boolean;\n\n      /**\n       * Used only for `server_vad` mode. Amount of audio to include before the VAD\n       * detected speech (in milliseconds). Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n       * milliseconds). Defaults to 500ms. With shorter values the model will respond\n       * more quickly, but may jump in on short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n       * defaults to 0.5. A higher threshold will require louder audio to activate the\n       * model, and thus might perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection.\n       */\n      type?: 'server_vad' | 'semantic_vad';\n    }\n  }\n}\n\n/**\n * Returned when a session is updated with a `session.update` event, unless there\n * is an error.\n */\nexport interface SessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionsAPI.Session;\n\n  /**\n   * The event type, must be `session.updated`.\n   */\n  type: 'session.updated';\n}\n\n/**\n * Send this event to update a transcription session.\n */\nexport interface TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  session: TranscriptionSessionUpdate.Session;\n\n  /**\n   * The event type, must be `transcription_session.update`.\n   */\n  type: 'transcription_session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\nexport namespace TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  export interface Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    client_secret?: Session.ClientSecret;\n\n    /**\n     * The set of items to include in the transcription. Current available items are:\n     *\n     * - `item.input_audio_transcription.logprobs`\n     */\n    include?: Array<string>;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n     * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n     * (mono), and little-endian byte order.\n     */\n    input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n    /**\n     * Configuration for input audio transcription. The client can optionally set the\n     * language and prompt for transcription, these offer additional guidance to the\n     * transcription service.\n     */\n    input_audio_transcription?: Session.InputAudioTranscription;\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    turn_detection?: Session.TurnDetection;\n  }\n\n  export namespace Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    export interface ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      expires_at?: ClientSecret.ExpiresAt;\n    }\n\n    export namespace ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      export interface ExpiresAt {\n        /**\n         * The anchor point for the ephemeral token expiration. Only `created_at` is\n         * currently supported.\n         */\n        anchor?: 'created_at';\n\n        /**\n         * The number of seconds from the anchor point to the expiration. Select a value\n         * between `10` and `7200`.\n         */\n        seconds?: number;\n      }\n    }\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    export interface InputAudioNoiseReduction {\n      /**\n       * Type of noise reduction. `near_field` is for close-talking microphones such as\n       * headphones, `far_field` is for far-field microphones such as laptop or\n       * conference room microphones.\n       */\n      type?: 'near_field' | 'far_field';\n    }\n\n    /**\n     * Configuration for input audio transcription. The client can optionally set the\n     * language and prompt for transcription, these offer additional guidance to the\n     * transcription service.\n     */\n    export interface InputAudioTranscription {\n      /**\n       * The language of the input audio. Supplying the input language in\n       * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n       * format will improve accuracy and latency.\n       */\n      language?: string;\n\n      /**\n       * The model to use for transcription, current options are `gpt-4o-transcribe`,\n       * `gpt-4o-mini-transcribe`, and `whisper-1`.\n       */\n      model?: 'gpt-4o-transcribe' | 'gpt-4o-mini-transcribe' | 'whisper-1';\n\n      /**\n       * An optional text to guide the model's style or continue a previous audio\n       * segment. For `whisper-1`, the\n       * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n       * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n       * \"expect words related to technology\".\n       */\n      prompt?: string;\n    }\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    export interface TurnDetection {\n      /**\n       * Whether or not to automatically generate a response when a VAD stop event\n       * occurs. Not available for transcription sessions.\n       */\n      create_response?: boolean;\n\n      /**\n       * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n       * will wait longer for the user to continue speaking, `high` will respond more\n       * quickly. `auto` is the default and is equivalent to `medium`.\n       */\n      eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n      /**\n       * Whether or not to automatically interrupt any ongoing response with output to\n       * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n       * occurs. Not available for transcription sessions.\n       */\n      interrupt_response?: boolean;\n\n      /**\n       * Used only for `server_vad` mode. Amount of audio to include before the VAD\n       * detected speech (in milliseconds). Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n       * milliseconds). Defaults to 500ms. With shorter values the model will respond\n       * more quickly, but may jump in on short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n       * defaults to 0.5. A higher threshold will require louder audio to activate the\n       * model, and thus might perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection.\n       */\n      type?: 'server_vad' | 'semantic_vad';\n    }\n  }\n}\n\n/**\n * Returned when a transcription session is updated with a\n * `transcription_session.update` event, unless there is an error.\n */\nexport interface TranscriptionSessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A new Realtime transcription session configuration.\n   *\n   * When a session is created on the server via REST API, the session object also\n   * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n   * not present when a session is updated via the WebSocket API.\n   */\n  session: TranscriptionSessionsAPI.TranscriptionSession;\n\n  /**\n   * The event type, must be `transcription_session.updated`.\n   */\n  type: 'transcription_session.updated';\n}\n\nRealtime.Sessions = Sessions;\nRealtime.TranscriptionSessions = TranscriptionSessions;\n\nexport declare namespace Realtime {\n  export {\n    type ConversationCreatedEvent as ConversationCreatedEvent,\n    type ConversationItem as ConversationItem,\n    type ConversationItemContent as ConversationItemContent,\n    type ConversationItemCreateEvent as ConversationItemCreateEvent,\n    type ConversationItemCreatedEvent as ConversationItemCreatedEvent,\n    type ConversationItemDeleteEvent as ConversationItemDeleteEvent,\n    type ConversationItemDeletedEvent as ConversationItemDeletedEvent,\n    type ConversationItemInputAudioTranscriptionCompletedEvent as ConversationItemInputAudioTranscriptionCompletedEvent,\n    type ConversationItemInputAudioTranscriptionDeltaEvent as ConversationItemInputAudioTranscriptionDeltaEvent,\n    type ConversationItemInputAudioTranscriptionFailedEvent as ConversationItemInputAudioTranscriptionFailedEvent,\n    type ConversationItemRetrieveEvent as ConversationItemRetrieveEvent,\n    type ConversationItemTruncateEvent as ConversationItemTruncateEvent,\n    type ConversationItemTruncatedEvent as ConversationItemTruncatedEvent,\n    type ConversationItemWithReference as ConversationItemWithReference,\n    type ErrorEvent as ErrorEvent,\n    type InputAudioBufferAppendEvent as InputAudioBufferAppendEvent,\n    type InputAudioBufferClearEvent as InputAudioBufferClearEvent,\n    type InputAudioBufferClearedEvent as InputAudioBufferClearedEvent,\n    type InputAudioBufferCommitEvent as InputAudioBufferCommitEvent,\n    type InputAudioBufferCommittedEvent as InputAudioBufferCommittedEvent,\n    type InputAudioBufferSpeechStartedEvent as InputAudioBufferSpeechStartedEvent,\n    type InputAudioBufferSpeechStoppedEvent as InputAudioBufferSpeechStoppedEvent,\n    type RateLimitsUpdatedEvent as RateLimitsUpdatedEvent,\n    type RealtimeClientEvent as RealtimeClientEvent,\n    type RealtimeResponse as RealtimeResponse,\n    type RealtimeResponseStatus as RealtimeResponseStatus,\n    type RealtimeResponseUsage as RealtimeResponseUsage,\n    type RealtimeServerEvent as RealtimeServerEvent,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCancelEvent as ResponseCancelEvent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseCreateEvent as ResponseCreateEvent,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseDoneEvent as ResponseDoneEvent,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type SessionCreatedEvent as SessionCreatedEvent,\n    type SessionUpdateEvent as SessionUpdateEvent,\n    type SessionUpdatedEvent as SessionUpdatedEvent,\n    type TranscriptionSessionUpdate as TranscriptionSessionUpdate,\n    type TranscriptionSessionUpdatedEvent as TranscriptionSessionUpdatedEvent,\n  };\n\n  export {\n    Sessions as Sessions,\n    type SessionsAPISession as Session,\n    type SessionCreateResponse as SessionCreateResponse,\n    type SessionCreateParams as SessionCreateParams,\n  };\n\n  export {\n    TranscriptionSessions as TranscriptionSessions,\n    type TranscriptionSession as TranscriptionSession,\n    type TranscriptionSessionCreateParams as TranscriptionSessionCreateParams,\n  };\n}\n","import { concatBytes, decodeUTF8, encodeUTF8 } from '../utils/bytes';\n\nexport type Bytes = string | ArrayBuffer | Uint8Array | null | undefined;\n\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nexport class LineDecoder {\n  // prettier-ignore\n  static NEWLINE_CHARS = new Set(['\\n', '\\r']);\n  static NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n\n  #buffer: Uint8Array;\n  #carriageReturnIndex: number | null;\n\n  constructor() {\n    this.#buffer = new Uint8Array();\n    this.#carriageReturnIndex = null;\n  }\n\n  decode(chunk: Bytes): string[] {\n    if (chunk == null) {\n      return [];\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? encodeUTF8(chunk)\n      : chunk;\n\n    this.#buffer = concatBytes([this.#buffer, binaryChunk]);\n\n    const lines: string[] = [];\n    let patternIndex;\n    while ((patternIndex = findNewlineIndex(this.#buffer, this.#carriageReturnIndex)) != null) {\n      if (patternIndex.carriage && this.#carriageReturnIndex == null) {\n        // skip until we either get a corresponding `\\n`, a new `\\r` or nothing\n        this.#carriageReturnIndex = patternIndex.index;\n        continue;\n      }\n\n      // we got double \\r or \\rtext\\n\n      if (\n        this.#carriageReturnIndex != null &&\n        (patternIndex.index !== this.#carriageReturnIndex + 1 || patternIndex.carriage)\n      ) {\n        lines.push(decodeUTF8(this.#buffer.subarray(0, this.#carriageReturnIndex - 1)));\n        this.#buffer = this.#buffer.subarray(this.#carriageReturnIndex);\n        this.#carriageReturnIndex = null;\n        continue;\n      }\n\n      const endIndex =\n        this.#carriageReturnIndex !== null ? patternIndex.preceding - 1 : patternIndex.preceding;\n\n      const line = decodeUTF8(this.#buffer.subarray(0, endIndex));\n      lines.push(line);\n\n      this.#buffer = this.#buffer.subarray(patternIndex.index);\n      this.#carriageReturnIndex = null;\n    }\n\n    return lines;\n  }\n\n  flush(): string[] {\n    if (!this.#buffer.length) {\n      return [];\n    }\n    return this.decode('\\n');\n  }\n}\n\n/**\n * This function searches the buffer for the end patterns, (\\r or \\n)\n * and returns an object with the index preceding the matched newline and the\n * index after the newline char. `null` is returned if no new line is found.\n *\n * ```ts\n * findNewLineIndex('abc\\ndef') -> { preceding: 2, index: 3 }\n * ```\n */\nfunction findNewlineIndex(\n  buffer: Uint8Array,\n  startIndex: number | null,\n): { preceding: number; index: number; carriage: boolean } | null {\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = startIndex ?? 0; i < buffer.length; i++) {\n    if (buffer[i] === newline) {\n      return { preceding: i, index: i + 1, carriage: false };\n    }\n\n    if (buffer[i] === carriage) {\n      return { preceding: i, index: i + 1, carriage: true };\n    }\n  }\n\n  return null;\n}\n\nexport function findDoubleNewlineIndex(buffer: Uint8Array): number {\n  // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n  // and returns the index right after the first occurrence of any pattern,\n  // or -1 if none of the patterns are found.\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = 0; i < buffer.length - 1; i++) {\n    if (buffer[i] === newline && buffer[i + 1] === newline) {\n      // \\n\\n\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n      // \\r\\r\n      return i + 2;\n    }\n    if (\n      buffer[i] === carriage &&\n      buffer[i + 1] === newline &&\n      i + 3 < buffer.length &&\n      buffer[i + 2] === carriage &&\n      buffer[i + 3] === newline\n    ) {\n      // \\r\\n\\r\\n\n      return i + 4;\n    }\n  }\n\n  return -1;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as AssistantsAPI from './assistants';\nimport {\n  Assistant,\n  AssistantCreateParams,\n  AssistantDeleted,\n  AssistantListParams,\n  AssistantStreamEvent,\n  AssistantTool,\n  AssistantUpdateParams,\n  Assistants,\n  AssistantsPage,\n  CodeInterpreterTool,\n  FileSearchTool,\n  FunctionTool,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n  ThreadStreamEvent,\n} from './assistants';\nimport * as RealtimeAPI from './realtime/realtime';\nimport {\n  ConversationCreatedEvent,\n  ConversationItem,\n  ConversationItemContent,\n  ConversationItemCreateEvent,\n  ConversationItemCreatedEvent,\n  ConversationItemDeleteEvent,\n  ConversationItemDeletedEvent,\n  ConversationItemInputAudioTranscriptionCompletedEvent,\n  ConversationItemInputAudioTranscriptionDeltaEvent,\n  ConversationItemInputAudioTranscriptionFailedEvent,\n  ConversationItemRetrieveEvent,\n  ConversationItemTruncateEvent,\n  ConversationItemTruncatedEvent,\n  ConversationItemWithReference,\n  ErrorEvent,\n  InputAudioBufferAppendEvent,\n  InputAudioBufferClearEvent,\n  InputAudioBufferClearedEvent,\n  InputAudioBufferCommitEvent,\n  InputAudioBufferCommittedEvent,\n  InputAudioBufferSpeechStartedEvent,\n  InputAudioBufferSpeechStoppedEvent,\n  RateLimitsUpdatedEvent,\n  Realtime,\n  RealtimeClientEvent,\n  RealtimeResponse,\n  RealtimeResponseStatus,\n  RealtimeResponseUsage,\n  RealtimeServerEvent,\n  ResponseAudioDeltaEvent,\n  ResponseAudioDoneEvent,\n  ResponseAudioTranscriptDeltaEvent,\n  ResponseAudioTranscriptDoneEvent,\n  ResponseCancelEvent,\n  ResponseContentPartAddedEvent,\n  ResponseContentPartDoneEvent,\n  ResponseCreateEvent,\n  ResponseCreatedEvent,\n  ResponseDoneEvent,\n  ResponseFunctionCallArgumentsDeltaEvent,\n  ResponseFunctionCallArgumentsDoneEvent,\n  ResponseOutputItemAddedEvent,\n  ResponseOutputItemDoneEvent,\n  ResponseTextDeltaEvent,\n  ResponseTextDoneEvent,\n  SessionCreatedEvent,\n  SessionUpdateEvent,\n  SessionUpdatedEvent,\n  TranscriptionSessionUpdate,\n  TranscriptionSessionUpdatedEvent,\n} from './realtime/realtime';\nimport * as ChatKitAPI from './chatkit/chatkit';\nimport { ChatKit, ChatKitWorkflow } from './chatkit/chatkit';\nimport * as ThreadsAPI from './threads/threads';\nimport {\n  AssistantResponseFormatOption,\n  AssistantToolChoice,\n  AssistantToolChoiceFunction,\n  AssistantToolChoiceOption,\n  Thread,\n  ThreadCreateAndRunParams,\n  ThreadCreateAndRunParamsNonStreaming,\n  ThreadCreateAndRunParamsStreaming,\n  ThreadCreateAndRunPollParams,\n  ThreadCreateAndRunStreamParams,\n  ThreadCreateParams,\n  ThreadDeleted,\n  ThreadUpdateParams,\n  Threads,\n} from './threads/threads';\n\nexport class Beta extends APIResource {\n  realtime: RealtimeAPI.Realtime = new RealtimeAPI.Realtime(this._client);\n  chatkit: ChatKitAPI.ChatKit = new ChatKitAPI.ChatKit(this._client);\n  assistants: AssistantsAPI.Assistants = new AssistantsAPI.Assistants(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\nBeta.Realtime = Realtime;\nBeta.ChatKit = ChatKit;\nBeta.Assistants = Assistants;\nBeta.Threads = Threads;\n\nexport declare namespace Beta {\n  export {\n    Realtime as Realtime,\n    type ConversationCreatedEvent as ConversationCreatedEvent,\n    type ConversationItem as ConversationItem,\n    type ConversationItemContent as ConversationItemContent,\n    type ConversationItemCreateEvent as ConversationItemCreateEvent,\n    type ConversationItemCreatedEvent as ConversationItemCreatedEvent,\n    type ConversationItemDeleteEvent as ConversationItemDeleteEvent,\n    type ConversationItemDeletedEvent as ConversationItemDeletedEvent,\n    type ConversationItemInputAudioTranscriptionCompletedEvent as ConversationItemInputAudioTranscriptionCompletedEvent,\n    type ConversationItemInputAudioTranscriptionDeltaEvent as ConversationItemInputAudioTranscriptionDeltaEvent,\n    type ConversationItemInputAudioTranscriptionFailedEvent as ConversationItemInputAudioTranscriptionFailedEvent,\n    type ConversationItemRetrieveEvent as ConversationItemRetrieveEvent,\n    type ConversationItemTruncateEvent as ConversationItemTruncateEvent,\n    type ConversationItemTruncatedEvent as ConversationItemTruncatedEvent,\n    type ConversationItemWithReference as ConversationItemWithReference,\n    type ErrorEvent as ErrorEvent,\n    type InputAudioBufferAppendEvent as InputAudioBufferAppendEvent,\n    type InputAudioBufferClearEvent as InputAudioBufferClearEvent,\n    type InputAudioBufferClearedEvent as InputAudioBufferClearedEvent,\n    type InputAudioBufferCommitEvent as InputAudioBufferCommitEvent,\n    type InputAudioBufferCommittedEvent as InputAudioBufferCommittedEvent,\n    type InputAudioBufferSpeechStartedEvent as InputAudioBufferSpeechStartedEvent,\n    type InputAudioBufferSpeechStoppedEvent as InputAudioBufferSpeechStoppedEvent,\n    type RateLimitsUpdatedEvent as RateLimitsUpdatedEvent,\n    type RealtimeClientEvent as RealtimeClientEvent,\n    type RealtimeResponse as RealtimeResponse,\n    type RealtimeResponseStatus as RealtimeResponseStatus,\n    type RealtimeResponseUsage as RealtimeResponseUsage,\n    type RealtimeServerEvent as RealtimeServerEvent,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCancelEvent as ResponseCancelEvent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseCreateEvent as ResponseCreateEvent,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseDoneEvent as ResponseDoneEvent,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type SessionCreatedEvent as SessionCreatedEvent,\n    type SessionUpdateEvent as SessionUpdateEvent,\n    type SessionUpdatedEvent as SessionUpdatedEvent,\n    type TranscriptionSessionUpdate as TranscriptionSessionUpdate,\n    type TranscriptionSessionUpdatedEvent as TranscriptionSessionUpdatedEvent,\n    ChatKit as ChatKit,\n    type ChatKitWorkflow as ChatKitWorkflow,\n  };\n\n  export {\n    Assistants as Assistants,\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    type AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n\n  export {\n    Threads as Threads,\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as ItemsAPI from './items';\nimport {\n  ConversationItem,\n  ConversationItemList,\n  ConversationItemsPage,\n  ItemCreateParams,\n  ItemDeleteParams,\n  ItemListParams,\n  ItemRetrieveParams,\n  Items,\n} from './items';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Conversations extends APIResource {\n  items: ItemsAPI.Items = new ItemsAPI.Items(this._client);\n\n  /**\n   * Create a conversation.\n   */\n  create(\n    body: ConversationCreateParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<Conversation> {\n    return this._client.post('/conversations', { body, ...options });\n  }\n\n  /**\n   * Get a conversation\n   */\n  retrieve(conversationID: string, options?: RequestOptions): APIPromise<Conversation> {\n    return this._client.get(path`/conversations/${conversationID}`, options);\n  }\n\n  /**\n   * Update a conversation\n   */\n  update(\n    conversationID: string,\n    body: ConversationUpdateParams,\n    options?: RequestOptions,\n  ): APIPromise<Conversation> {\n    return this._client.post(path`/conversations/${conversationID}`, { body, ...options });\n  }\n\n  /**\n   * Delete a conversation. Items in the conversation will not be deleted.\n   */\n  delete(conversationID: string, options?: RequestOptions): APIPromise<ConversationDeletedResource> {\n    return this._client.delete(path`/conversations/${conversationID}`, options);\n  }\n}\n\n/**\n * A screenshot of a computer.\n */\nexport interface ComputerScreenshotContent {\n  /**\n   * The identifier of an uploaded file that contains the screenshot.\n   */\n  file_id: string | null;\n\n  /**\n   * The URL of the screenshot image.\n   */\n  image_url: string | null;\n\n  /**\n   * Specifies the event type. For a computer screenshot, this property is always set\n   * to `computer_screenshot`.\n   */\n  type: 'computer_screenshot';\n}\n\nexport interface Conversation {\n  /**\n   * The unique ID of the conversation.\n   */\n  id: string;\n\n  /**\n   * The time at which the conversation was created, measured in seconds since the\n   * Unix epoch.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters.\n   */\n  metadata: unknown;\n\n  /**\n   * The object type, which is always `conversation`.\n   */\n  object: 'conversation';\n}\n\nexport interface ConversationDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'conversation.deleted';\n}\n\nexport interface ConversationDeletedResource {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'conversation.deleted';\n}\n\n/**\n * A message to or from the model.\n */\nexport interface Message {\n  /**\n   * The unique ID of the message.\n   */\n  id: string;\n\n  /**\n   * The content of the message\n   */\n  content: Array<\n    | ResponsesAPI.ResponseInputText\n    | ResponsesAPI.ResponseOutputText\n    | TextContent\n    | SummaryTextContent\n    | Message.ReasoningText\n    | ResponsesAPI.ResponseOutputRefusal\n    | ResponsesAPI.ResponseInputImage\n    | ComputerScreenshotContent\n    | ResponsesAPI.ResponseInputFile\n  >;\n\n  /**\n   * The role of the message. One of `unknown`, `user`, `assistant`, `system`,\n   * `critic`, `discriminator`, `developer`, or `tool`.\n   */\n  role: 'unknown' | 'user' | 'assistant' | 'system' | 'critic' | 'discriminator' | 'developer' | 'tool';\n\n  /**\n   * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the message. Always set to `message`.\n   */\n  type: 'message';\n}\n\nexport namespace Message {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningText {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * A summary text from the model.\n */\nexport interface SummaryTextContent {\n  /**\n   * A summary of the reasoning output from the model so far.\n   */\n  text: string;\n\n  /**\n   * The type of the object. Always `summary_text`.\n   */\n  type: 'summary_text';\n}\n\n/**\n * A text content.\n */\nexport interface TextContent {\n  text: string;\n\n  type: 'text';\n}\n\nexport type InputTextContent = ResponsesAPI.ResponseInputText;\n\nexport type OutputTextContent = ResponsesAPI.ResponseOutputText;\n\nexport type RefusalContent = ResponsesAPI.ResponseOutputRefusal;\n\nexport type InputImageContent = ResponsesAPI.ResponseInputImage;\n\nexport type InputFileContent = ResponsesAPI.ResponseInputFile;\n\nexport interface ConversationCreateParams {\n  /**\n   * Initial items to include in the conversation context. You may add up to 20 items\n   * at a time.\n   */\n  items?: Array<ResponsesAPI.ResponseInputItem> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface ConversationUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n}\n\nConversations.Items = Items;\n\nexport declare namespace Conversations {\n  export {\n    type ComputerScreenshotContent as ComputerScreenshotContent,\n    type Conversation as Conversation,\n    type ConversationDeleted as ConversationDeleted,\n    type ConversationDeletedResource as ConversationDeletedResource,\n    type Message as Message,\n    type SummaryTextContent as SummaryTextContent,\n    type TextContent as TextContent,\n    type InputTextContent as InputTextContent,\n    type OutputTextContent as OutputTextContent,\n    type RefusalContent as RefusalContent,\n    type InputImageContent as InputImageContent,\n    type InputFileContent as InputFileContent,\n    type ConversationCreateParams as ConversationCreateParams,\n    type ConversationUpdateParams as ConversationUpdateParams,\n  };\n\n  export {\n    Items as Items,\n    type ConversationItem as ConversationItem,\n    type ConversationItemList as ConversationItemList,\n    type ConversationItemsPage as ConversationItemsPage,\n    type ItemCreateParams as ItemCreateParams,\n    type ItemRetrieveParams as ItemRetrieveParams,\n    type ItemListParams as ItemListParams,\n    type ItemDeleteParams as ItemDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../core/resource';\nimport * as StepsAPI from './steps';\nimport * as Shared from '../../../shared';\nimport { APIPromise } from '../../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../../core/pagination';\nimport { buildHeaders } from '../../../../internal/headers';\nimport { RequestOptions } from '../../../../internal/request-options';\nimport { path } from '../../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Steps extends APIResource {\n  /**\n   * Retrieves a run step.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(stepID: string, params: StepRetrieveParams, options?: RequestOptions): APIPromise<RunStep> {\n    const { thread_id, run_id, ...query } = params;\n    return this._client.get(path`/threads/${thread_id}/runs/${run_id}/steps/${stepID}`, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of run steps belonging to a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  list(runID: string, params: StepListParams, options?: RequestOptions): PagePromise<RunStepsPage, RunStep> {\n    const { thread_id, ...query } = params;\n    return this._client.getAPIList(path`/threads/${thread_id}/runs/${runID}/steps`, CursorPage<RunStep>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\nexport type RunStepsPage = CursorPage<RunStep>;\n\n/**\n * Text output from the Code Interpreter tool call as part of a run step.\n */\nexport interface CodeInterpreterLogs {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `logs`.\n   */\n  type: 'logs';\n\n  /**\n   * The text output from the Code Interpreter tool call.\n   */\n  logs?: string;\n}\n\nexport interface CodeInterpreterOutputImage {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `image`.\n   */\n  type: 'image';\n\n  image?: CodeInterpreterOutputImage.Image;\n}\n\nexport namespace CodeInterpreterOutputImage {\n  export interface Image {\n    /**\n     * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n     * image.\n     */\n    file_id?: string;\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter: CodeInterpreterToolCall.CodeInterpreter;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n}\n\nexport namespace CodeInterpreterToolCall {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs: Array<CodeInterpreter.Logs | CodeInterpreter.Image>;\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Text output from the Code Interpreter tool call as part of a run step.\n     */\n    export interface Logs {\n      /**\n       * The text output from the Code Interpreter tool call.\n       */\n      logs: string;\n\n      /**\n       * Always `logs`.\n       */\n      type: 'logs';\n    }\n\n    export interface Image {\n      image: Image.Image;\n\n      /**\n       * Always `image`.\n       */\n      type: 'image';\n    }\n\n    export namespace Image {\n      export interface Image {\n        /**\n         * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n         * image.\n         */\n        file_id: string;\n      }\n    }\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n\n  /**\n   * The ID of the tool call.\n   */\n  id?: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter?: CodeInterpreterToolCallDelta.CodeInterpreter;\n}\n\nexport namespace CodeInterpreterToolCallDelta {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input?: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs?: Array<StepsAPI.CodeInterpreterLogs | StepsAPI.CodeInterpreterOutputImage>;\n  }\n}\n\nexport interface FileSearchToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: FileSearchToolCall.FileSearch;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n}\n\nexport namespace FileSearchToolCall {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  export interface FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n\n    /**\n     * The results of the file search.\n     */\n    results?: Array<FileSearch.Result>;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    export interface RankingOptions {\n      /**\n       * The ranker to use for the file search. If not specified will use the `auto`\n       * ranker.\n       */\n      ranker: 'auto' | 'default_2024_08_21';\n\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n    }\n\n    /**\n     * A result instance of the file search.\n     */\n    export interface Result {\n      /**\n       * The ID of the file that result was found in.\n       */\n      file_id: string;\n\n      /**\n       * The name of the file that result was found in.\n       */\n      file_name: string;\n\n      /**\n       * The score of the result. All values must be a floating point number between 0\n       * and 1.\n       */\n      score: number;\n\n      /**\n       * The content of the result that was found. The content is only included if\n       * requested via the include query parameter.\n       */\n      content?: Array<Result.Content>;\n    }\n\n    export namespace Result {\n      export interface Content {\n        /**\n         * The text content of the file.\n         */\n        text?: string;\n\n        /**\n         * The type of the content.\n         */\n        type?: 'text';\n      }\n    }\n  }\n}\n\nexport interface FileSearchToolCallDelta {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: unknown;\n\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n}\n\nexport interface FunctionToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function: FunctionToolCall.Function;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n}\n\nexport namespace FunctionToolCall {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output: string | null;\n  }\n}\n\nexport interface FunctionToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function?: FunctionToolCallDelta.Function;\n}\n\nexport namespace FunctionToolCallDelta {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output?: string | null;\n  }\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface MessageCreationStepDetails {\n  message_creation: MessageCreationStepDetails.MessageCreation;\n\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n}\n\nexport namespace MessageCreationStepDetails {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id: string;\n  }\n}\n\n/**\n * Represents a step in execution of a run.\n */\nexport interface RunStep {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants)\n   * associated with the run step.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step expired. A step is\n   * considered expired if the parent run is expired.\n   */\n  expired_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  last_error: RunStep.LastError | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread.run.step`.\n   */\n  object: 'thread.run.step';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that\n   * this run step is a part of.\n   */\n  run_id: string;\n\n  /**\n   * The status of the run step, which can be either `in_progress`, `cancelled`,\n   * `failed`, `completed`, or `expired`.\n   */\n  status: 'in_progress' | 'cancelled' | 'failed' | 'completed' | 'expired';\n\n  /**\n   * The details of the run step.\n   */\n  step_details: MessageCreationStepDetails | ToolCallsStepDetails;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n\n  /**\n   * The type of run step, which can be either `message_creation` or `tool_calls`.\n   */\n  type: 'message_creation' | 'tool_calls';\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  usage: RunStep.Usage | null;\n}\n\nexport namespace RunStep {\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run step.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run step.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The delta containing the fields that have changed on the run step.\n */\nexport interface RunStepDelta {\n  /**\n   * The details of the run step.\n   */\n  step_details?: RunStepDeltaMessageDelta | ToolCallDeltaObject;\n}\n\n/**\n * Represents a run step delta i.e. any changed fields on a run step during\n * streaming.\n */\nexport interface RunStepDeltaEvent {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the run step.\n   */\n  delta: RunStepDelta;\n\n  /**\n   * The object type, which is always `thread.run.step.delta`.\n   */\n  object: 'thread.run.step.delta';\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface RunStepDeltaMessageDelta {\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n\n  message_creation?: RunStepDeltaMessageDelta.MessageCreation;\n}\n\nexport namespace RunStepDeltaMessageDelta {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id?: string;\n  }\n}\n\nexport type RunStepInclude = 'step_details.tool_calls[*].file_search.results[*].content';\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCall = CodeInterpreterToolCall | FileSearchToolCall | FunctionToolCall;\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCallDelta = CodeInterpreterToolCallDelta | FileSearchToolCallDelta | FunctionToolCallDelta;\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallDeltaObject {\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls?: Array<ToolCallDelta>;\n}\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallsStepDetails {\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls: Array<ToolCall>;\n\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n}\n\nexport interface StepRetrieveParams {\n  /**\n   * Path param: The ID of the thread to which the run and run step belongs.\n   */\n  thread_id: string;\n\n  /**\n   * Path param: The ID of the run to which the run step belongs.\n   */\n  run_id: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n}\n\nexport interface StepListParams extends CursorPageParams {\n  /**\n   * Path param: The ID of the thread the run and run steps belong to.\n   */\n  thread_id: string;\n\n  /**\n   * Query param: A cursor for use in pagination. `before` is an object ID that\n   * defines your place in the list. For instance, if you make a list request and\n   * receive 100 objects, starting with obj_foo, your subsequent call can include\n   * before=obj_foo in order to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n\n  /**\n   * Query param: Sort order by the `created_at` timestamp of the objects. `asc` for\n   * ascending order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Steps {\n  export {\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    type RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Messages extends APIResource {\n  /**\n   * Create a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  create(threadID: string, body: MessageCreateParams, options?: RequestOptions): APIPromise<Message> {\n    return this._client.post(path`/threads/${threadID}/messages`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieve a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(messageID: string, params: MessageRetrieveParams, options?: RequestOptions): APIPromise<Message> {\n    const { thread_id } = params;\n    return this._client.get(path`/threads/${thread_id}/messages/${messageID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  update(messageID: string, params: MessageUpdateParams, options?: RequestOptions): APIPromise<Message> {\n    const { thread_id, ...body } = params;\n    return this._client.post(path`/threads/${thread_id}/messages/${messageID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of messages for a given thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  list(\n    threadID: string,\n    query: MessageListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<MessagesPage, Message> {\n    return this._client.getAPIList(path`/threads/${threadID}/messages`, CursorPage<Message>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Deletes a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  delete(\n    messageID: string,\n    params: MessageDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<MessageDeleted> {\n    const { thread_id } = params;\n    return this._client.delete(path`/threads/${thread_id}/messages/${messageID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\nexport type MessagesPage = CursorPage<Message>;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type Annotation = FileCitationAnnotation | FilePathAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type AnnotationDelta = FileCitationDeltaAnnotation | FilePathDeltaAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationAnnotation {\n  end_index: number;\n\n  file_citation: FileCitationAnnotation.FileCitation;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n}\n\nexport namespace FileCitationAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n\n  end_index?: number;\n\n  file_citation?: FileCitationDeltaAnnotation.FileCitation;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FileCitationDeltaAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id?: string;\n\n    /**\n     * The specific quote in the file.\n     */\n    quote?: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathAnnotation {\n  end_index: number;\n\n  file_path: FilePathAnnotation.FilePath;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n}\n\nexport namespace FilePathAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n\n  end_index?: number;\n\n  file_path?: FilePathDeltaAnnotation.FilePath;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FilePathDeltaAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id?: string;\n  }\n}\n\nexport interface ImageFile {\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id: string;\n\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileContentBlock {\n  image_file: ImageFile;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n}\n\nexport interface ImageFileDelta {\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id?: string;\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n\n  image_file?: ImageFileDelta;\n}\n\nexport interface ImageURL {\n  /**\n   * The external URL of the image, must be a supported image types: jpeg, jpg, png,\n   * gif, webp.\n   */\n  url: string;\n\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`. Default value is `auto`\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLContentBlock {\n  image_url: ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport interface ImageURLDelta {\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The URL of the image, must be a supported image types: jpeg, jpg, png, gif,\n   * webp.\n   */\n  url?: string;\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n\n  image_url?: ImageURLDelta;\n}\n\n/**\n * Represents a message within a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Message {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * If applicable, the ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) that\n   * authored this message.\n   */\n  assistant_id: string | null;\n\n  /**\n   * A list of files attached to the message, and the tools they were added to.\n   */\n  attachments: Array<Message.Attachment> | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content: Array<MessageContent>;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was marked as incomplete.\n   */\n  incomplete_at: number | null;\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  incomplete_details: Message.IncompleteDetails | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread.message`.\n   */\n  object: 'thread.message';\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs)\n   * associated with the creation of this message. Value is `null` when messages are\n   * created manually using the create message or create thread endpoints.\n   */\n  run_id: string | null;\n\n  /**\n   * The status of the message, which can be either `in_progress`, `incomplete`, or\n   * `completed`.\n   */\n  status: 'in_progress' | 'incomplete' | 'completed';\n\n  /**\n   * The [thread](https://platform.openai.com/docs/api-reference/threads) ID that\n   * this message belongs to.\n   */\n  thread_id: string;\n}\n\nexport namespace Message {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.AssistantToolsFileSearchTypeOnly>;\n  }\n\n  export namespace Attachment {\n    export interface AssistantToolsFileSearchTypeOnly {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason the message is incomplete.\n     */\n    reason: 'content_filter' | 'max_tokens' | 'run_cancelled' | 'run_expired' | 'run_failed';\n  }\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContent =\n  | ImageFileContentBlock\n  | ImageURLContentBlock\n  | TextContentBlock\n  | RefusalContentBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentDelta =\n  | ImageFileDeltaBlock\n  | TextDeltaBlock\n  | RefusalDeltaBlock\n  | ImageURLDeltaBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentPartParam = ImageFileContentBlock | ImageURLContentBlock | TextContentBlockParam;\n\nexport interface MessageDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.message.deleted';\n}\n\n/**\n * The delta containing the fields that have changed on the Message.\n */\nexport interface MessageDelta {\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content?: Array<MessageContentDelta>;\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role?: 'user' | 'assistant';\n}\n\n/**\n * Represents a message delta i.e. any changed fields on a message during\n * streaming.\n */\nexport interface MessageDeltaEvent {\n  /**\n   * The identifier of the message, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the Message.\n   */\n  delta: MessageDelta;\n\n  /**\n   * The object type, which is always `thread.message.delta`.\n   */\n  object: 'thread.message.delta';\n}\n\n/**\n * The refusal content generated by the assistant.\n */\nexport interface RefusalContentBlock {\n  refusal: string;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * The refusal content that is part of a message.\n */\nexport interface RefusalDeltaBlock {\n  /**\n   * The index of the refusal part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n\n  refusal?: string;\n}\n\nexport interface Text {\n  annotations: Array<Annotation>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlock {\n  text: Text;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlockParam {\n  /**\n   * Text content to be sent to the model\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\nexport interface TextDelta {\n  annotations?: Array<AnnotationDelta>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value?: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n\n  text?: TextDelta;\n}\n\nexport interface MessageCreateParams {\n  /**\n   * The text contents of the message.\n   */\n  content: string | Array<MessageContentPartParam>;\n\n  /**\n   * The role of the entity that is creating the message. Allowed values include:\n   *\n   * - `user`: Indicates the message is sent by an actual user and should be used in\n   *   most cases to represent user-generated messages.\n   * - `assistant`: Indicates the message is generated by the assistant. Use this\n   *   value to insert messages from the assistant into the conversation.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * A list of files attached to the message, and the tools they should be added to.\n   */\n  attachments?: Array<MessageCreateParams.Attachment> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport namespace MessageCreateParams {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n  }\n\n  export namespace Attachment {\n    export interface FileSearch {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n}\n\nexport interface MessageRetrieveParams {\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * to which this message belongs.\n   */\n  thread_id: string;\n}\n\nexport interface MessageUpdateParams {\n  /**\n   * Path param: The ID of the thread to which this message belongs.\n   */\n  thread_id: string;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter messages by the run ID that generated them.\n   */\n  run_id?: string;\n}\n\nexport interface MessageDeleteParams {\n  /**\n   * The ID of the thread to which this message belongs.\n   */\n  thread_id: string;\n}\n\nexport declare namespace Messages {\n  export {\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type Message as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    type MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageRetrieveParams as MessageRetrieveParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n    type MessageDeleteParams as MessageDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as MessagesAPI from './threads/messages';\nimport * as ThreadsAPI from './threads/threads';\nimport * as RunsAPI from './threads/runs/runs';\nimport * as StepsAPI from './threads/runs/steps';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\nimport { AssistantStream } from '../../lib/AssistantStream';\n\nexport class Assistants extends APIResource {\n  /**\n   * Create an assistant with a model and instructions.\n   *\n   * @deprecated\n   */\n  create(body: AssistantCreateParams, options?: RequestOptions): APIPromise<Assistant> {\n    return this._client.post('/assistants', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves an assistant.\n   *\n   * @deprecated\n   */\n  retrieve(assistantID: string, options?: RequestOptions): APIPromise<Assistant> {\n    return this._client.get(path`/assistants/${assistantID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies an assistant.\n   *\n   * @deprecated\n   */\n  update(assistantID: string, body: AssistantUpdateParams, options?: RequestOptions): APIPromise<Assistant> {\n    return this._client.post(path`/assistants/${assistantID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of assistants.\n   *\n   * @deprecated\n   */\n  list(\n    query: AssistantListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<AssistantsPage, Assistant> {\n    return this._client.getAPIList('/assistants', CursorPage<Assistant>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete an assistant.\n   *\n   * @deprecated\n   */\n  delete(assistantID: string, options?: RequestOptions): APIPromise<AssistantDeleted> {\n    return this._client.delete(path`/assistants/${assistantID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\nexport type AssistantsPage = CursorPage<Assistant>;\n\n/**\n * @deprecated Represents an `assistant` that can call the model and use tools.\n */\nexport interface Assistant {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the assistant was created.\n   */\n  created_at: number;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name: string | null;\n\n  /**\n   * The object type, which is always `assistant`.\n   */\n  object: 'assistant';\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools: Array<AssistantTool>;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: Assistant.ToolResources | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Assistant {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter`` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'assistant.deleted';\n}\n\n/**\n * Represents an event emitted when streaming a Run.\n *\n * Each event in a server-sent events stream has an `event` and `data` property:\n *\n * ```\n * event: thread.created\n * data: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n * ```\n *\n * We emit events whenever a new object is created, transitions to a new state, or\n * is being streamed in parts (deltas). For example, we emit `thread.run.created`\n * when a new run is created, `thread.run.completed` when a run completes, and so\n * on. When an Assistant chooses to create a message during a run, we emit a\n * `thread.message.created event`, a `thread.message.in_progress` event, many\n * `thread.message.delta` events, and finally a `thread.message.completed` event.\n *\n * We may add additional events over time, so we recommend handling unknown events\n * gracefully in your code. See the\n * [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview)\n * to learn how to integrate the Assistants API with streaming.\n */\nexport type AssistantStreamEvent =\n  | AssistantStreamEvent.ThreadCreated\n  | AssistantStreamEvent.ThreadRunCreated\n  | AssistantStreamEvent.ThreadRunQueued\n  | AssistantStreamEvent.ThreadRunInProgress\n  | AssistantStreamEvent.ThreadRunRequiresAction\n  | AssistantStreamEvent.ThreadRunCompleted\n  | AssistantStreamEvent.ThreadRunIncomplete\n  | AssistantStreamEvent.ThreadRunFailed\n  | AssistantStreamEvent.ThreadRunCancelling\n  | AssistantStreamEvent.ThreadRunCancelled\n  | AssistantStreamEvent.ThreadRunExpired\n  | AssistantStreamEvent.ThreadRunStepCreated\n  | AssistantStreamEvent.ThreadRunStepInProgress\n  | AssistantStreamEvent.ThreadRunStepDelta\n  | AssistantStreamEvent.ThreadRunStepCompleted\n  | AssistantStreamEvent.ThreadRunStepFailed\n  | AssistantStreamEvent.ThreadRunStepCancelled\n  | AssistantStreamEvent.ThreadRunStepExpired\n  | AssistantStreamEvent.ThreadMessageCreated\n  | AssistantStreamEvent.ThreadMessageInProgress\n  | AssistantStreamEvent.ThreadMessageDelta\n  | AssistantStreamEvent.ThreadMessageCompleted\n  | AssistantStreamEvent.ThreadMessageIncomplete\n  | AssistantStreamEvent.ErrorEvent;\n\nexport namespace AssistantStreamEvent {\n  /**\n   * Occurs when a new\n   * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n   * created.\n   */\n  export interface ThreadCreated {\n    /**\n     * Represents a thread that contains\n     * [messages](https://platform.openai.com/docs/api-reference/messages).\n     */\n    data: ThreadsAPI.Thread;\n\n    event: 'thread.created';\n\n    /**\n     * Whether to enable input audio transcription.\n     */\n    enabled?: boolean;\n  }\n\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n\n  /**\n   * Occurs when an\n   * [error](https://platform.openai.com/docs/guides/error-codes#api-errors) occurs.\n   * This can happen due to an internal server error or a timeout.\n   */\n  export interface ErrorEvent {\n    data: Shared.ErrorObject;\n\n    event: 'error';\n  }\n}\n\nexport type AssistantTool = CodeInterpreterTool | FileSearchTool | FunctionTool;\n\nexport interface CodeInterpreterTool {\n  /**\n   * The type of tool being defined: `code_interpreter`\n   */\n  type: 'code_interpreter';\n}\n\nexport interface FileSearchTool {\n  /**\n   * The type of tool being defined: `file_search`\n   */\n  type: 'file_search';\n\n  /**\n   * Overrides for the file search tool.\n   */\n  file_search?: FileSearchTool.FileSearch;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Overrides for the file search tool.\n   */\n  export interface FileSearch {\n    /**\n     * The maximum number of results the file search tool should output. The default is\n     * 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between\n     * 1 and 50 inclusive.\n     *\n     * Note that the file search tool may output fewer than `max_num_results` results.\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    max_num_results?: number;\n\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    export interface RankingOptions {\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n\n      /**\n       * The ranker to use for the file search. If not specified will use the `auto`\n       * ranker.\n       */\n      ranker?: 'auto' | 'default_2024_08_21';\n    }\n  }\n}\n\nexport interface FunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of tool being defined: `function`\n   */\n  type: 'function';\n}\n\n/**\n * Occurs when a\n * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n * created.\n */\nexport type MessageStreamEvent =\n  | MessageStreamEvent.ThreadMessageCreated\n  | MessageStreamEvent.ThreadMessageInProgress\n  | MessageStreamEvent.ThreadMessageDelta\n  | MessageStreamEvent.ThreadMessageCompleted\n  | MessageStreamEvent.ThreadMessageIncomplete;\n\nexport namespace MessageStreamEvent {\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n}\n\n/**\n * Occurs when a\n * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n * is created.\n */\nexport type RunStepStreamEvent =\n  | RunStepStreamEvent.ThreadRunStepCreated\n  | RunStepStreamEvent.ThreadRunStepInProgress\n  | RunStepStreamEvent.ThreadRunStepDelta\n  | RunStepStreamEvent.ThreadRunStepCompleted\n  | RunStepStreamEvent.ThreadRunStepFailed\n  | RunStepStreamEvent.ThreadRunStepCancelled\n  | RunStepStreamEvent.ThreadRunStepExpired;\n\nexport namespace RunStepStreamEvent {\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n */\nexport type RunStreamEvent =\n  | RunStreamEvent.ThreadRunCreated\n  | RunStreamEvent.ThreadRunQueued\n  | RunStreamEvent.ThreadRunInProgress\n  | RunStreamEvent.ThreadRunRequiresAction\n  | RunStreamEvent.ThreadRunCompleted\n  | RunStreamEvent.ThreadRunIncomplete\n  | RunStreamEvent.ThreadRunFailed\n  | RunStreamEvent.ThreadRunCancelling\n  | RunStreamEvent.ThreadRunCancelled\n  | RunStreamEvent.ThreadRunExpired;\n\nexport namespace RunStreamEvent {\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n * created.\n */\nexport interface ThreadStreamEvent {\n  /**\n   * Represents a thread that contains\n   * [messages](https://platform.openai.com/docs/api-reference/messages).\n   */\n  data: ThreadsAPI.Thread;\n\n  event: 'thread.created';\n\n  /**\n   * Whether to enable input audio transcription.\n   */\n  enabled?: boolean;\n}\n\nexport interface AssistantCreateParams {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n   * Reducing reasoning effort can result in faster responses and fewer tokens used\n   * on reasoning in a response.\n   *\n   * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n   *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n   *   calls are supported for all reasoning values in gpt-5.1.\n   * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n   *   support `none`.\n   * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n   * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantCreateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantCreateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this assistant. There can be a maximum of 1\n       * vector store attached to the assistant.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to an object. This can be useful\n         * for storing additional information about the object in a structured format, and\n         * querying for objects via API or the dashboard.\n         *\n         * Keys are strings with a maximum length of 64 characters. Values are strings with\n         * a maximum length of 512 characters.\n         */\n        metadata?: Shared.Metadata | null;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface AssistantUpdateParams {\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-5'\n    | 'gpt-5-mini'\n    | 'gpt-5-nano'\n    | 'gpt-5-2025-08-07'\n    | 'gpt-5-mini-2025-08-07'\n    | 'gpt-5-nano-2025-08-07'\n    | 'gpt-4.1'\n    | 'gpt-4.1-mini'\n    | 'gpt-4.1-nano'\n    | 'gpt-4.1-2025-04-14'\n    | 'gpt-4.1-mini-2025-04-14'\n    | 'gpt-4.1-nano-2025-04-14'\n    | 'o3-mini'\n    | 'o3-mini-2025-01-31'\n    | 'o1'\n    | 'o1-2024-12-17'\n    | 'gpt-4o'\n    | 'gpt-4o-2024-11-20'\n    | 'gpt-4o-2024-08-06'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4o-mini'\n    | 'gpt-4o-mini-2024-07-18'\n    | 'gpt-4.5-preview'\n    | 'gpt-4.5-preview-2025-02-27'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613';\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n   * Reducing reasoning effort can result in faster responses and fewer tokens used\n   * on reasoning in a response.\n   *\n   * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n   *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n   *   calls are supported for all reasoning values in gpt-5.1.\n   * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n   *   support `none`.\n   * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n   * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantUpdateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantUpdateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * Overrides the list of\n       * [file](https://platform.openai.com/docs/api-reference/files) IDs made available\n       * to the `code_interpreter` tool. There can be a maximum of 20 files associated\n       * with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * Overrides the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Assistants {\n  export {\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    type AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n\n  export { AssistantStream };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as FilesAPI from './files/files';\nimport {\n  FileCreateParams,\n  FileCreateResponse,\n  FileDeleteParams,\n  FileListParams,\n  FileListResponse,\n  FileListResponsesPage,\n  FileRetrieveParams,\n  FileRetrieveResponse,\n  Files,\n} from './files/files';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Containers extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n\n  /**\n   * Create Container\n   */\n  create(body: ContainerCreateParams, options?: RequestOptions): APIPromise<ContainerCreateResponse> {\n    return this._client.post('/containers', { body, ...options });\n  }\n\n  /**\n   * Retrieve Container\n   */\n  retrieve(containerID: string, options?: RequestOptions): APIPromise<ContainerRetrieveResponse> {\n    return this._client.get(path`/containers/${containerID}`, options);\n  }\n\n  /**\n   * List Containers\n   */\n  list(\n    query: ContainerListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ContainerListResponsesPage, ContainerListResponse> {\n    return this._client.getAPIList('/containers', CursorPage<ContainerListResponse>, { query, ...options });\n  }\n\n  /**\n   * Delete Container\n   */\n  delete(containerID: string, options?: RequestOptions): APIPromise<void> {\n    return this._client.delete(path`/containers/${containerID}`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n}\n\nexport type ContainerListResponsesPage = CursorPage<ContainerListResponse>;\n\nexport interface ContainerCreateResponse {\n  /**\n   * Unique identifier for the container.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the container was created.\n   */\n  created_at: number;\n\n  /**\n   * Name of the container.\n   */\n  name: string;\n\n  /**\n   * The type of this object.\n   */\n  object: string;\n\n  /**\n   * Status of the container (e.g., active, deleted).\n   */\n  status: string;\n\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  expires_after?: ContainerCreateResponse.ExpiresAfter;\n\n  /**\n   * Unix timestamp (in seconds) when the container was last active.\n   */\n  last_active_at?: number;\n\n  /**\n   * The memory limit configured for the container.\n   */\n  memory_limit?: '1g' | '4g' | '16g' | '64g';\n}\n\nexport namespace ContainerCreateResponse {\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The reference point for the expiration.\n     */\n    anchor?: 'last_active_at';\n\n    /**\n     * The number of minutes after the anchor before the container expires.\n     */\n    minutes?: number;\n  }\n}\n\nexport interface ContainerRetrieveResponse {\n  /**\n   * Unique identifier for the container.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the container was created.\n   */\n  created_at: number;\n\n  /**\n   * Name of the container.\n   */\n  name: string;\n\n  /**\n   * The type of this object.\n   */\n  object: string;\n\n  /**\n   * Status of the container (e.g., active, deleted).\n   */\n  status: string;\n\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  expires_after?: ContainerRetrieveResponse.ExpiresAfter;\n\n  /**\n   * Unix timestamp (in seconds) when the container was last active.\n   */\n  last_active_at?: number;\n\n  /**\n   * The memory limit configured for the container.\n   */\n  memory_limit?: '1g' | '4g' | '16g' | '64g';\n}\n\nexport namespace ContainerRetrieveResponse {\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The reference point for the expiration.\n     */\n    anchor?: 'last_active_at';\n\n    /**\n     * The number of minutes after the anchor before the container expires.\n     */\n    minutes?: number;\n  }\n}\n\nexport interface ContainerListResponse {\n  /**\n   * Unique identifier for the container.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the container was created.\n   */\n  created_at: number;\n\n  /**\n   * Name of the container.\n   */\n  name: string;\n\n  /**\n   * The type of this object.\n   */\n  object: string;\n\n  /**\n   * Status of the container (e.g., active, deleted).\n   */\n  status: string;\n\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  expires_after?: ContainerListResponse.ExpiresAfter;\n\n  /**\n   * Unix timestamp (in seconds) when the container was last active.\n   */\n  last_active_at?: number;\n\n  /**\n   * The memory limit configured for the container.\n   */\n  memory_limit?: '1g' | '4g' | '16g' | '64g';\n}\n\nexport namespace ContainerListResponse {\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The reference point for the expiration.\n     */\n    anchor?: 'last_active_at';\n\n    /**\n     * The number of minutes after the anchor before the container expires.\n     */\n    minutes?: number;\n  }\n}\n\nexport interface ContainerCreateParams {\n  /**\n   * Name of the container to create.\n   */\n  name: string;\n\n  /**\n   * Container expiration time in seconds relative to the 'anchor' time.\n   */\n  expires_after?: ContainerCreateParams.ExpiresAfter;\n\n  /**\n   * IDs of files to copy to the container.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * Optional memory limit for the container. Defaults to \"1g\".\n   */\n  memory_limit?: '1g' | '4g' | '16g' | '64g';\n}\n\nexport namespace ContainerCreateParams {\n  /**\n   * Container expiration time in seconds relative to the 'anchor' time.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Time anchor for the expiration time. Currently only 'last_active_at' is\n     * supported.\n     */\n    anchor: 'last_active_at';\n\n    minutes: number;\n  }\n}\n\nexport interface ContainerListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nContainers.Files = Files;\n\nexport declare namespace Containers {\n  export {\n    type ContainerCreateResponse as ContainerCreateResponse,\n    type ContainerRetrieveResponse as ContainerRetrieveResponse,\n    type ContainerListResponse as ContainerListResponse,\n    type ContainerListResponsesPage as ContainerListResponsesPage,\n    type ContainerCreateParams as ContainerCreateParams,\n    type ContainerListParams as ContainerListParams,\n  };\n\n  export {\n    Files as Files,\n    type FileCreateResponse as FileCreateResponse,\n    type FileRetrieveResponse as FileRetrieveResponse,\n    type FileListResponse as FileListResponse,\n    type FileListResponsesPage as FileListResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { Page, PagePromise } from '../core/pagination';\nimport { RequestOptions } from '../internal/request-options';\nimport { path } from '../internal/utils/path';\n\nexport class Models extends APIResource {\n  /**\n   * Retrieves a model instance, providing basic information about the model such as\n   * the owner and permissioning.\n   */\n  retrieve(model: string, options?: RequestOptions): APIPromise<Model> {\n    return this._client.get(path`/models/${model}`, options);\n  }\n\n  /**\n   * Lists the currently available models, and provides basic information about each\n   * one such as the owner and availability.\n   */\n  list(options?: RequestOptions): PagePromise<ModelsPage, Model> {\n    return this._client.getAPIList('/models', Page<Model>, options);\n  }\n\n  /**\n   * Delete a fine-tuned model. You must have the Owner role in your organization to\n   * delete a model.\n   */\n  delete(model: string, options?: RequestOptions): APIPromise<ModelDeleted> {\n    return this._client.delete(path`/models/${model}`, options);\n  }\n}\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type ModelsPage = Page<Model>;\n\n/**\n * Describes an OpenAI model offering that can be used with the API.\n */\nexport interface Model {\n  /**\n   * The model identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) when the model was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always \"model\".\n   */\n  object: 'model';\n\n  /**\n   * The organization that owns the model.\n   */\n  owned_by: string;\n}\n\nexport interface ModelDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: string;\n}\n\nexport declare namespace Models {\n  export { type Model as Model, type ModelDeleted as ModelDeleted, type ModelsPage as ModelsPage };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ChatKitAPI from './chatkit';\nimport { APIPromise } from '../../../core/api-promise';\nimport {\n  ConversationCursorPage,\n  type ConversationCursorPageParams,\n  PagePromise,\n} from '../../../core/pagination';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Threads extends APIResource {\n  /**\n   * Retrieve a ChatKit thread\n   *\n   * @example\n   * ```ts\n   * const chatkitThread =\n   *   await client.beta.chatkit.threads.retrieve('cthr_123');\n   * ```\n   */\n  retrieve(threadID: string, options?: RequestOptions): APIPromise<ChatKitThread> {\n    return this._client.get(path`/chatkit/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * List ChatKit threads\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const chatkitThread of client.beta.chatkit.threads.list()) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    query: ThreadListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ChatKitThreadsPage, ChatKitThread> {\n    return this._client.getAPIList('/chatkit/threads', ConversationCursorPage<ChatKitThread>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a ChatKit thread\n   *\n   * @example\n   * ```ts\n   * const thread = await client.beta.chatkit.threads.delete(\n   *   'cthr_123',\n   * );\n   * ```\n   */\n  delete(threadID: string, options?: RequestOptions): APIPromise<ThreadDeleteResponse> {\n    return this._client.delete(path`/chatkit/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * List ChatKit thread items\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const thread of client.beta.chatkit.threads.listItems(\n   *   'cthr_123',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  listItems(\n    threadID: string,\n    query: ThreadListItemsParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<\n    ChatKitThreadItemListDataPage,\n    | ChatKitThreadUserMessageItem\n    | ChatKitThreadAssistantMessageItem\n    | ChatKitWidgetItem\n    | ChatKitThreadItemList.ChatKitClientToolCall\n    | ChatKitThreadItemList.ChatKitTask\n    | ChatKitThreadItemList.ChatKitTaskGroup\n  > {\n    return this._client.getAPIList(\n      path`/chatkit/threads/${threadID}/items`,\n      ConversationCursorPage<\n        | ChatKitThreadUserMessageItem\n        | ChatKitThreadAssistantMessageItem\n        | ChatKitWidgetItem\n        | ChatKitThreadItemList.ChatKitClientToolCall\n        | ChatKitThreadItemList.ChatKitTask\n        | ChatKitThreadItemList.ChatKitTaskGroup\n      >,\n      { query, ...options, headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]) },\n    );\n  }\n}\n\nexport type ChatKitThreadsPage = ConversationCursorPage<ChatKitThread>;\n\nexport type ChatKitThreadItemListDataPage = ConversationCursorPage<\n  | ChatKitThreadUserMessageItem\n  | ChatKitThreadAssistantMessageItem\n  | ChatKitWidgetItem\n  | ChatKitThreadItemList.ChatKitClientToolCall\n  | ChatKitThreadItemList.ChatKitTask\n  | ChatKitThreadItemList.ChatKitTaskGroup\n>;\n\n/**\n * Represents a ChatKit session and its resolved configuration.\n */\nexport interface ChatSession {\n  /**\n   * Identifier for the ChatKit session.\n   */\n  id: string;\n\n  /**\n   * Resolved ChatKit feature configuration for the session.\n   */\n  chatkit_configuration: ChatSessionChatKitConfiguration;\n\n  /**\n   * Ephemeral client secret that authenticates session requests.\n   */\n  client_secret: string;\n\n  /**\n   * Unix timestamp (in seconds) for when the session expires.\n   */\n  expires_at: number;\n\n  /**\n   * Convenience copy of the per-minute request limit.\n   */\n  max_requests_per_1_minute: number;\n\n  /**\n   * Type discriminator that is always `chatkit.session`.\n   */\n  object: 'chatkit.session';\n\n  /**\n   * Resolved rate limit values.\n   */\n  rate_limits: ChatSessionRateLimits;\n\n  /**\n   * Current lifecycle state of the session.\n   */\n  status: ChatSessionStatus;\n\n  /**\n   * User identifier associated with the session.\n   */\n  user: string;\n\n  /**\n   * Workflow metadata for the session.\n   */\n  workflow: ChatKitAPI.ChatKitWorkflow;\n}\n\n/**\n * Automatic thread title preferences for the session.\n */\nexport interface ChatSessionAutomaticThreadTitling {\n  /**\n   * Whether automatic thread titling is enabled.\n   */\n  enabled: boolean;\n}\n\n/**\n * ChatKit configuration for the session.\n */\nexport interface ChatSessionChatKitConfiguration {\n  /**\n   * Automatic thread titling preferences.\n   */\n  automatic_thread_titling: ChatSessionAutomaticThreadTitling;\n\n  /**\n   * Upload settings for the session.\n   */\n  file_upload: ChatSessionFileUpload;\n\n  /**\n   * History retention configuration.\n   */\n  history: ChatSessionHistory;\n}\n\n/**\n * Optional per-session configuration settings for ChatKit behavior.\n */\nexport interface ChatSessionChatKitConfigurationParam {\n  /**\n   * Configuration for automatic thread titling. When omitted, automatic thread\n   * titling is enabled by default.\n   */\n  automatic_thread_titling?: ChatSessionChatKitConfigurationParam.AutomaticThreadTitling;\n\n  /**\n   * Configuration for upload enablement and limits. When omitted, uploads are\n   * disabled by default (max_files 10, max_file_size 512 MB).\n   */\n  file_upload?: ChatSessionChatKitConfigurationParam.FileUpload;\n\n  /**\n   * Configuration for chat history retention. When omitted, history is enabled by\n   * default with no limit on recent_threads (null).\n   */\n  history?: ChatSessionChatKitConfigurationParam.History;\n}\n\nexport namespace ChatSessionChatKitConfigurationParam {\n  /**\n   * Configuration for automatic thread titling. When omitted, automatic thread\n   * titling is enabled by default.\n   */\n  export interface AutomaticThreadTitling {\n    /**\n     * Enable automatic thread title generation. Defaults to true.\n     */\n    enabled?: boolean;\n  }\n\n  /**\n   * Configuration for upload enablement and limits. When omitted, uploads are\n   * disabled by default (max_files 10, max_file_size 512 MB).\n   */\n  export interface FileUpload {\n    /**\n     * Enable uploads for this session. Defaults to false.\n     */\n    enabled?: boolean;\n\n    /**\n     * Maximum size in megabytes for each uploaded file. Defaults to 512 MB, which is\n     * the maximum allowable size.\n     */\n    max_file_size?: number;\n\n    /**\n     * Maximum number of files that can be uploaded to the session. Defaults to 10.\n     */\n    max_files?: number;\n  }\n\n  /**\n   * Configuration for chat history retention. When omitted, history is enabled by\n   * default with no limit on recent_threads (null).\n   */\n  export interface History {\n    /**\n     * Enables chat users to access previous ChatKit threads. Defaults to true.\n     */\n    enabled?: boolean;\n\n    /**\n     * Number of recent ChatKit threads users have access to. Defaults to unlimited\n     * when unset.\n     */\n    recent_threads?: number;\n  }\n}\n\n/**\n * Controls when the session expires relative to an anchor timestamp.\n */\nexport interface ChatSessionExpiresAfterParam {\n  /**\n   * Base timestamp used to calculate expiration. Currently fixed to `created_at`.\n   */\n  anchor: 'created_at';\n\n  /**\n   * Number of seconds after the anchor when the session expires.\n   */\n  seconds: number;\n}\n\n/**\n * Upload permissions and limits applied to the session.\n */\nexport interface ChatSessionFileUpload {\n  /**\n   * Indicates if uploads are enabled for the session.\n   */\n  enabled: boolean;\n\n  /**\n   * Maximum upload size in megabytes.\n   */\n  max_file_size: number | null;\n\n  /**\n   * Maximum number of uploads allowed during the session.\n   */\n  max_files: number | null;\n}\n\n/**\n * History retention preferences returned for the session.\n */\nexport interface ChatSessionHistory {\n  /**\n   * Indicates if chat history is persisted for the session.\n   */\n  enabled: boolean;\n\n  /**\n   * Number of prior threads surfaced in history views. Defaults to null when all\n   * history is retained.\n   */\n  recent_threads: number | null;\n}\n\n/**\n * Active per-minute request limit for the session.\n */\nexport interface ChatSessionRateLimits {\n  /**\n   * Maximum allowed requests per one-minute window.\n   */\n  max_requests_per_1_minute: number;\n}\n\n/**\n * Controls request rate limits for the session.\n */\nexport interface ChatSessionRateLimitsParam {\n  /**\n   * Maximum number of requests allowed per minute for the session. Defaults to 10.\n   */\n  max_requests_per_1_minute?: number;\n}\n\nexport type ChatSessionStatus = 'active' | 'expired' | 'cancelled';\n\n/**\n * Workflow reference and overrides applied to the chat session.\n */\nexport interface ChatSessionWorkflowParam {\n  /**\n   * Identifier for the workflow invoked by the session.\n   */\n  id: string;\n\n  /**\n   * State variables forwarded to the workflow. Keys may be up to 64 characters,\n   * values must be primitive types, and the map defaults to an empty object.\n   */\n  state_variables?: { [key: string]: string | boolean | number };\n\n  /**\n   * Optional tracing overrides for the workflow invocation. When omitted, tracing is\n   * enabled by default.\n   */\n  tracing?: ChatSessionWorkflowParam.Tracing;\n\n  /**\n   * Specific workflow version to run. Defaults to the latest deployed version.\n   */\n  version?: string;\n}\n\nexport namespace ChatSessionWorkflowParam {\n  /**\n   * Optional tracing overrides for the workflow invocation. When omitted, tracing is\n   * enabled by default.\n   */\n  export interface Tracing {\n    /**\n     * Whether tracing is enabled during the session. Defaults to true.\n     */\n    enabled?: boolean;\n  }\n}\n\n/**\n * Attachment metadata included on thread items.\n */\nexport interface ChatKitAttachment {\n  /**\n   * Identifier for the attachment.\n   */\n  id: string;\n\n  /**\n   * MIME type of the attachment.\n   */\n  mime_type: string;\n\n  /**\n   * Original display name for the attachment.\n   */\n  name: string;\n\n  /**\n   * Preview URL for rendering the attachment inline.\n   */\n  preview_url: string | null;\n\n  /**\n   * Attachment discriminator.\n   */\n  type: 'image' | 'file';\n}\n\n/**\n * Assistant response text accompanied by optional annotations.\n */\nexport interface ChatKitResponseOutputText {\n  /**\n   * Ordered list of annotations attached to the response text.\n   */\n  annotations: Array<ChatKitResponseOutputText.File | ChatKitResponseOutputText.URL>;\n\n  /**\n   * Assistant generated text.\n   */\n  text: string;\n\n  /**\n   * Type discriminator that is always `output_text`.\n   */\n  type: 'output_text';\n}\n\nexport namespace ChatKitResponseOutputText {\n  /**\n   * Annotation that references an uploaded file.\n   */\n  export interface File {\n    /**\n     * File attachment referenced by the annotation.\n     */\n    source: File.Source;\n\n    /**\n     * Type discriminator that is always `file` for this annotation.\n     */\n    type: 'file';\n  }\n\n  export namespace File {\n    /**\n     * File attachment referenced by the annotation.\n     */\n    export interface Source {\n      /**\n       * Filename referenced by the annotation.\n       */\n      filename: string;\n\n      /**\n       * Type discriminator that is always `file`.\n       */\n      type: 'file';\n    }\n  }\n\n  /**\n   * Annotation that references a URL.\n   */\n  export interface URL {\n    /**\n     * URL referenced by the annotation.\n     */\n    source: URL.Source;\n\n    /**\n     * Type discriminator that is always `url` for this annotation.\n     */\n    type: 'url';\n  }\n\n  export namespace URL {\n    /**\n     * URL referenced by the annotation.\n     */\n    export interface Source {\n      /**\n       * Type discriminator that is always `url`.\n       */\n      type: 'url';\n\n      /**\n       * URL referenced by the annotation.\n       */\n      url: string;\n    }\n  }\n}\n\n/**\n * Represents a ChatKit thread and its current status.\n */\nexport interface ChatKitThread {\n  /**\n   * Identifier of the thread.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Type discriminator that is always `chatkit.thread`.\n   */\n  object: 'chatkit.thread';\n\n  /**\n   * Current status for the thread. Defaults to `active` for newly created threads.\n   */\n  status: ChatKitThread.Active | ChatKitThread.Locked | ChatKitThread.Closed;\n\n  /**\n   * Optional human-readable title for the thread. Defaults to null when no title has\n   * been generated.\n   */\n  title: string | null;\n\n  /**\n   * Free-form string that identifies your end user who owns the thread.\n   */\n  user: string;\n}\n\nexport namespace ChatKitThread {\n  /**\n   * Indicates that a thread is active.\n   */\n  export interface Active {\n    /**\n     * Status discriminator that is always `active`.\n     */\n    type: 'active';\n  }\n\n  /**\n   * Indicates that a thread is locked and cannot accept new input.\n   */\n  export interface Locked {\n    /**\n     * Reason that the thread was locked. Defaults to null when no reason is recorded.\n     */\n    reason: string | null;\n\n    /**\n     * Status discriminator that is always `locked`.\n     */\n    type: 'locked';\n  }\n\n  /**\n   * Indicates that a thread has been closed.\n   */\n  export interface Closed {\n    /**\n     * Reason that the thread was closed. Defaults to null when no reason is recorded.\n     */\n    reason: string | null;\n\n    /**\n     * Status discriminator that is always `closed`.\n     */\n    type: 'closed';\n  }\n}\n\n/**\n * Assistant-authored message within a thread.\n */\nexport interface ChatKitThreadAssistantMessageItem {\n  /**\n   * Identifier of the thread item.\n   */\n  id: string;\n\n  /**\n   * Ordered assistant response segments.\n   */\n  content: Array<ChatKitResponseOutputText>;\n\n  /**\n   * Unix timestamp (in seconds) for when the item was created.\n   */\n  created_at: number;\n\n  /**\n   * Type discriminator that is always `chatkit.thread_item`.\n   */\n  object: 'chatkit.thread_item';\n\n  /**\n   * Identifier of the parent thread.\n   */\n  thread_id: string;\n\n  /**\n   * Type discriminator that is always `chatkit.assistant_message`.\n   */\n  type: 'chatkit.assistant_message';\n}\n\n/**\n * A paginated list of thread items rendered for the ChatKit API.\n */\nexport interface ChatKitThreadItemList {\n  /**\n   * A list of items\n   */\n  data: Array<\n    | ChatKitThreadUserMessageItem\n    | ChatKitThreadAssistantMessageItem\n    | ChatKitWidgetItem\n    | ChatKitThreadItemList.ChatKitClientToolCall\n    | ChatKitThreadItemList.ChatKitTask\n    | ChatKitThreadItemList.ChatKitTaskGroup\n  >;\n\n  /**\n   * The ID of the first item in the list.\n   */\n  first_id: string | null;\n\n  /**\n   * Whether there are more items available.\n   */\n  has_more: boolean;\n\n  /**\n   * The ID of the last item in the list.\n   */\n  last_id: string | null;\n\n  /**\n   * The type of object returned, must be `list`.\n   */\n  object: 'list';\n}\n\nexport namespace ChatKitThreadItemList {\n  /**\n   * Record of a client side tool invocation initiated by the assistant.\n   */\n  export interface ChatKitClientToolCall {\n    /**\n     * Identifier of the thread item.\n     */\n    id: string;\n\n    /**\n     * JSON-encoded arguments that were sent to the tool.\n     */\n    arguments: string;\n\n    /**\n     * Identifier for the client tool call.\n     */\n    call_id: string;\n\n    /**\n     * Unix timestamp (in seconds) for when the item was created.\n     */\n    created_at: number;\n\n    /**\n     * Tool name that was invoked.\n     */\n    name: string;\n\n    /**\n     * Type discriminator that is always `chatkit.thread_item`.\n     */\n    object: 'chatkit.thread_item';\n\n    /**\n     * JSON-encoded output captured from the tool. Defaults to null while execution is\n     * in progress.\n     */\n    output: string | null;\n\n    /**\n     * Execution status for the tool call.\n     */\n    status: 'in_progress' | 'completed';\n\n    /**\n     * Identifier of the parent thread.\n     */\n    thread_id: string;\n\n    /**\n     * Type discriminator that is always `chatkit.client_tool_call`.\n     */\n    type: 'chatkit.client_tool_call';\n  }\n\n  /**\n   * Task emitted by the workflow to show progress and status updates.\n   */\n  export interface ChatKitTask {\n    /**\n     * Identifier of the thread item.\n     */\n    id: string;\n\n    /**\n     * Unix timestamp (in seconds) for when the item was created.\n     */\n    created_at: number;\n\n    /**\n     * Optional heading for the task. Defaults to null when not provided.\n     */\n    heading: string | null;\n\n    /**\n     * Type discriminator that is always `chatkit.thread_item`.\n     */\n    object: 'chatkit.thread_item';\n\n    /**\n     * Optional summary that describes the task. Defaults to null when omitted.\n     */\n    summary: string | null;\n\n    /**\n     * Subtype for the task.\n     */\n    task_type: 'custom' | 'thought';\n\n    /**\n     * Identifier of the parent thread.\n     */\n    thread_id: string;\n\n    /**\n     * Type discriminator that is always `chatkit.task`.\n     */\n    type: 'chatkit.task';\n  }\n\n  /**\n   * Collection of workflow tasks grouped together in the thread.\n   */\n  export interface ChatKitTaskGroup {\n    /**\n     * Identifier of the thread item.\n     */\n    id: string;\n\n    /**\n     * Unix timestamp (in seconds) for when the item was created.\n     */\n    created_at: number;\n\n    /**\n     * Type discriminator that is always `chatkit.thread_item`.\n     */\n    object: 'chatkit.thread_item';\n\n    /**\n     * Tasks included in the group.\n     */\n    tasks: Array<ChatKitTaskGroup.Task>;\n\n    /**\n     * Identifier of the parent thread.\n     */\n    thread_id: string;\n\n    /**\n     * Type discriminator that is always `chatkit.task_group`.\n     */\n    type: 'chatkit.task_group';\n  }\n\n  export namespace ChatKitTaskGroup {\n    /**\n     * Task entry that appears within a TaskGroup.\n     */\n    export interface Task {\n      /**\n       * Optional heading for the grouped task. Defaults to null when not provided.\n       */\n      heading: string | null;\n\n      /**\n       * Optional summary that describes the grouped task. Defaults to null when omitted.\n       */\n      summary: string | null;\n\n      /**\n       * Subtype for the grouped task.\n       */\n      type: 'custom' | 'thought';\n    }\n  }\n}\n\n/**\n * User-authored messages within a thread.\n */\nexport interface ChatKitThreadUserMessageItem {\n  /**\n   * Identifier of the thread item.\n   */\n  id: string;\n\n  /**\n   * Attachments associated with the user message. Defaults to an empty list.\n   */\n  attachments: Array<ChatKitAttachment>;\n\n  /**\n   * Ordered content elements supplied by the user.\n   */\n  content: Array<ChatKitThreadUserMessageItem.InputText | ChatKitThreadUserMessageItem.QuotedText>;\n\n  /**\n   * Unix timestamp (in seconds) for when the item was created.\n   */\n  created_at: number;\n\n  /**\n   * Inference overrides applied to the message. Defaults to null when unset.\n   */\n  inference_options: ChatKitThreadUserMessageItem.InferenceOptions | null;\n\n  /**\n   * Type discriminator that is always `chatkit.thread_item`.\n   */\n  object: 'chatkit.thread_item';\n\n  /**\n   * Identifier of the parent thread.\n   */\n  thread_id: string;\n\n  type: 'chatkit.user_message';\n}\n\nexport namespace ChatKitThreadUserMessageItem {\n  /**\n   * Text block that a user contributed to the thread.\n   */\n  export interface InputText {\n    /**\n     * Plain-text content supplied by the user.\n     */\n    text: string;\n\n    /**\n     * Type discriminator that is always `input_text`.\n     */\n    type: 'input_text';\n  }\n\n  /**\n   * Quoted snippet that the user referenced in their message.\n   */\n  export interface QuotedText {\n    /**\n     * Quoted text content.\n     */\n    text: string;\n\n    /**\n     * Type discriminator that is always `quoted_text`.\n     */\n    type: 'quoted_text';\n  }\n\n  /**\n   * Inference overrides applied to the message. Defaults to null when unset.\n   */\n  export interface InferenceOptions {\n    /**\n     * Model name that generated the response. Defaults to null when using the session\n     * default.\n     */\n    model: string | null;\n\n    /**\n     * Preferred tool to invoke. Defaults to null when ChatKit should auto-select.\n     */\n    tool_choice: InferenceOptions.ToolChoice | null;\n  }\n\n  export namespace InferenceOptions {\n    /**\n     * Preferred tool to invoke. Defaults to null when ChatKit should auto-select.\n     */\n    export interface ToolChoice {\n      /**\n       * Identifier of the requested tool.\n       */\n      id: string;\n    }\n  }\n}\n\n/**\n * Thread item that renders a widget payload.\n */\nexport interface ChatKitWidgetItem {\n  /**\n   * Identifier of the thread item.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) for when the item was created.\n   */\n  created_at: number;\n\n  /**\n   * Type discriminator that is always `chatkit.thread_item`.\n   */\n  object: 'chatkit.thread_item';\n\n  /**\n   * Identifier of the parent thread.\n   */\n  thread_id: string;\n\n  /**\n   * Type discriminator that is always `chatkit.widget`.\n   */\n  type: 'chatkit.widget';\n\n  /**\n   * Serialized widget payload rendered in the UI.\n   */\n  widget: string;\n}\n\n/**\n * Confirmation payload returned after deleting a thread.\n */\nexport interface ThreadDeleteResponse {\n  /**\n   * Identifier of the deleted thread.\n   */\n  id: string;\n\n  /**\n   * Indicates that the thread has been deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * Type discriminator that is always `chatkit.thread.deleted`.\n   */\n  object: 'chatkit.thread.deleted';\n}\n\nexport interface ThreadListParams extends ConversationCursorPageParams {\n  /**\n   * List items created before this thread item ID. Defaults to null for the newest\n   * results.\n   */\n  before?: string;\n\n  /**\n   * Sort order for results by creation time. Defaults to `desc`.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter threads that belong to this user identifier. Defaults to null to return\n   * all users.\n   */\n  user?: string;\n}\n\nexport interface ThreadListItemsParams extends ConversationCursorPageParams {\n  /**\n   * List items created before this thread item ID. Defaults to null for the newest\n   * results.\n   */\n  before?: string;\n\n  /**\n   * Sort order for results by creation time. Defaults to `desc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Threads {\n  export {\n    type ChatSession as ChatSession,\n    type ChatSessionAutomaticThreadTitling as ChatSessionAutomaticThreadTitling,\n    type ChatSessionChatKitConfiguration as ChatSessionChatKitConfiguration,\n    type ChatSessionChatKitConfigurationParam as ChatSessionChatKitConfigurationParam,\n    type ChatSessionExpiresAfterParam as ChatSessionExpiresAfterParam,\n    type ChatSessionFileUpload as ChatSessionFileUpload,\n    type ChatSessionHistory as ChatSessionHistory,\n    type ChatSessionRateLimits as ChatSessionRateLimits,\n    type ChatSessionRateLimitsParam as ChatSessionRateLimitsParam,\n    type ChatSessionStatus as ChatSessionStatus,\n    type ChatSessionWorkflowParam as ChatSessionWorkflowParam,\n    type ChatKitAttachment as ChatKitAttachment,\n    type ChatKitResponseOutputText as ChatKitResponseOutputText,\n    type ChatKitThread as ChatKitThread,\n    type ChatKitThreadAssistantMessageItem as ChatKitThreadAssistantMessageItem,\n    type ChatKitThreadItemList as ChatKitThreadItemList,\n    type ChatKitThreadUserMessageItem as ChatKitThreadUserMessageItem,\n    type ChatKitWidgetItem as ChatKitWidgetItem,\n    type ThreadDeleteResponse as ThreadDeleteResponse,\n    type ChatKitThreadsPage as ChatKitThreadsPage,\n    type ChatKitThreadItemListDataPage as ChatKitThreadItemListDataPage,\n    type ThreadListParams as ThreadListParams,\n    type ThreadListItemsParams as ThreadListItemsParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { RequestOptions } from '../internal/request-options';\nimport { loggerFor, toFloat32Array } from '../internal/utils';\n\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   *\n   * @example\n   * ```ts\n   * const createEmbeddingResponse =\n   *   await client.embeddings.create({\n   *     input: 'The quick brown fox jumped over the lazy dog',\n   *     model: 'text-embedding-3-small',\n   *   });\n   * ```\n   */\n  create(body: EmbeddingCreateParams, options?: RequestOptions): APIPromise<CreateEmbeddingResponse> {\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\n    // No encoding_format specified, defaulting to base64 for performance reasons\n    // See https://github.com/openai/openai-node/pull/1312\n    let encoding_format: EmbeddingCreateParams['encoding_format'] =\n      hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\n\n    if (hasUserProvidedEncodingFormat) {\n      loggerFor(this._client).debug('embeddings/user defined encoding_format:', body.encoding_format);\n    }\n\n    const response: APIPromise<CreateEmbeddingResponse> = this._client.post('/embeddings', {\n      body: {\n        ...body,\n        encoding_format: encoding_format as EmbeddingCreateParams['encoding_format'],\n      },\n      ...options,\n    });\n\n    // if the user specified an encoding_format, return the response as-is\n    if (hasUserProvidedEncodingFormat) {\n      return response;\n    }\n\n    // in this stage, we are sure the user did not specify an encoding_format\n    // and we defaulted to base64 for performance reasons\n    // we are sure then that the response is base64 encoded, let's decode it\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\n    loggerFor(this._client).debug('embeddings/decoding base64 embeddings from base64');\n\n    return (response as APIPromise<CreateEmbeddingResponse>)._thenUnwrap((response) => {\n      if (response && response.data) {\n        response.data.forEach((embeddingBase64Obj) => {\n          const embeddingBase64Str = embeddingBase64Obj.embedding as unknown as string;\n          embeddingBase64Obj.embedding = toFloat32Array(embeddingBase64Str);\n        });\n      }\n\n      return response;\n    });\n  }\n}\n\nexport interface CreateEmbeddingResponse {\n  /**\n   * The list of embeddings generated by the model.\n   */\n  data: Array<Embedding>;\n\n  /**\n   * The name of the model used to generate the embedding.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"list\".\n   */\n  object: 'list';\n\n  /**\n   * The usage information for the request.\n   */\n  usage: CreateEmbeddingResponse.Usage;\n}\n\nexport namespace CreateEmbeddingResponse {\n  /**\n   * The usage information for the request.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens used by the prompt.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used by the request.\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * Represents an embedding vector returned by embedding endpoint.\n */\nexport interface Embedding {\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on\n   * the model as listed in the\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n   */\n  embedding: Array<number>;\n\n  /**\n   * The index of the embedding in the list of embeddings.\n   */\n  index: number;\n\n  /**\n   * The object type, which is always \"embedding\".\n   */\n  object: 'embedding';\n}\n\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\n\nexport interface EmbeddingCreateParams {\n  /**\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\n   * inputs in a single request, pass an array of strings or array of token arrays.\n   * The input must not exceed the max input tokens for the model (8192 tokens for\n   * all embedding models), cannot be an empty string, and any array must be 2048\n   * dimensions or less.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens. In addition to the per-input token limit, all embedding\n   * models enforce a maximum of 300,000 tokens summed across all inputs in a single\n   * request.\n   */\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | EmbeddingModel;\n\n  /**\n   * The number of dimensions the resulting output embeddings should have. Only\n   * supported in `text-embedding-3` and later models.\n   */\n  dimensions?: number;\n\n  /**\n   * The format to return the embeddings in. Can be either `float` or\n   * [`base64`](https://pypi.org/project/pybase64/).\n   */\n  encoding_format?: 'float' | 'base64';\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport declare namespace Embeddings {\n  export {\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as RealtimeAPI from './realtime';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Calls extends APIResource {\n  /**\n   * Accept an incoming SIP call and configure the realtime session that will handle\n   * it.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.accept('call_id', {\n   *   type: 'realtime',\n   * });\n   * ```\n   */\n  accept(callID: string, body: CallAcceptParams, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/accept`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * End an active Realtime API call, whether it was initiated over SIP or WebRTC.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.hangup('call_id');\n   * ```\n   */\n  hangup(callID: string, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/hangup`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Transfer an active SIP call to a new destination using the SIP REFER verb.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.refer('call_id', {\n   *   target_uri: 'tel:+14155550123',\n   * });\n   * ```\n   */\n  refer(callID: string, body: CallReferParams, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/refer`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Decline an incoming SIP call by returning a SIP status code to the caller.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.reject('call_id');\n   * ```\n   */\n  reject(\n    callID: string,\n    body: CallRejectParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/reject`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n}\n\nexport interface CallAcceptParams {\n  /**\n   * The type of session to create. Always `realtime` for the Realtime API.\n   */\n  type: 'realtime';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeAPI.RealtimeAudioConfig;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-realtime-mini-2025-12-15'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06'\n    | 'gpt-audio-mini-2025-12-15';\n\n  /**\n   * The set of modalities the model can respond with. It defaults to `[\"audio\"]`,\n   * indicating that the model will respond with audio plus a transcript. `[\"text\"]`\n   * can be used to make the model respond with text only. It is not possible to\n   * request both `text` and `audio` at the same time.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: RealtimeAPI.RealtimeToolChoiceConfig;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: RealtimeAPI.RealtimeToolsConfig;\n\n  /**\n   * Realtime API can write session traces to the\n   * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n   * tracing is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: RealtimeAPI.RealtimeTracingConfig | null;\n\n  /**\n   * When the number of tokens in a conversation exceeds the model's input token\n   * limit, the conversation be truncated, meaning messages (starting from the\n   * oldest) will not be included in the model's context. A 32k context model with\n   * 4,096 max output tokens can only include 28,224 tokens in the context before\n   * truncation occurs.\n   *\n   * Clients can configure truncation behavior to truncate with a lower max token\n   * limit, which is an effective way to control token usage and cost.\n   *\n   * Truncation will reduce the number of cached tokens on the next turn (busting the\n   * cache), since messages are dropped from the beginning of the context. However,\n   * clients can also configure truncation to retain messages up to a fraction of the\n   * maximum context size, which will reduce the need for future truncations and thus\n   * improve the cache rate.\n   *\n   * Truncation can be disabled entirely, which means the server will never truncate\n   * but would instead return an error if the conversation exceeds the model's input\n   * token limit.\n   */\n  truncation?: RealtimeAPI.RealtimeTruncation;\n}\n\nexport interface CallReferParams {\n  /**\n   * URI that should appear in the SIP Refer-To header. Supports values like\n   * `tel:+14155550123` or `sip:agent@example.com`.\n   */\n  target_uri: string;\n}\n\nexport interface CallRejectParams {\n  /**\n   * SIP response code to send back to the caller. Defaults to `603` (Decline) when\n   * omitted.\n   */\n  status_code?: number;\n}\n\nexport declare namespace Calls {\n  export {\n    type CallAcceptParams as CallAcceptParams,\n    type CallReferParams as CallReferParams,\n    type CallRejectParams as CallRejectParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ThreadsAPI from './threads';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Sessions extends APIResource {\n  /**\n   * Create a ChatKit session\n   *\n   * @example\n   * ```ts\n   * const chatSession =\n   *   await client.beta.chatkit.sessions.create({\n   *     user: 'x',\n   *     workflow: { id: 'id' },\n   *   });\n   * ```\n   */\n  create(body: SessionCreateParams, options?: RequestOptions): APIPromise<ThreadsAPI.ChatSession> {\n    return this._client.post('/chatkit/sessions', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Cancel a ChatKit session\n   *\n   * @example\n   * ```ts\n   * const chatSession =\n   *   await client.beta.chatkit.sessions.cancel('cksess_123');\n   * ```\n   */\n  cancel(sessionID: string, options?: RequestOptions): APIPromise<ThreadsAPI.ChatSession> {\n    return this._client.post(path`/chatkit/sessions/${sessionID}/cancel`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n}\n\nexport interface SessionCreateParams {\n  /**\n   * A free-form string that identifies your end user; ensures this Session can\n   * access other objects that have the same `user` scope.\n   */\n  user: string;\n\n  /**\n   * Workflow that powers the session.\n   */\n  workflow: ThreadsAPI.ChatSessionWorkflowParam;\n\n  /**\n   * Optional overrides for ChatKit runtime configuration features\n   */\n  chatkit_configuration?: ThreadsAPI.ChatSessionChatKitConfigurationParam;\n\n  /**\n   * Optional override for session expiration timing in seconds from creation.\n   * Defaults to 10 minutes.\n   */\n  expires_after?: ThreadsAPI.ChatSessionExpiresAfterParam;\n\n  /**\n   * Optional override for per-minute request limits. When omitted, defaults to 10.\n   */\n  rate_limits?: ThreadsAPI.ChatSessionRateLimitsParam;\n}\n\nexport declare namespace Sessions {\n  export { type SessionCreateParams as SessionCreateParams };\n}\n","import {\n  ResponseTextConfig,\n  type ParsedResponse,\n  type Response,\n  type ResponseCreateParamsBase,\n  type ResponseCreateParamsStreaming,\n  type ResponseStreamEvent,\n} from '../../resources/responses/responses';\nimport { RequestOptions } from '../../internal/request-options';\nimport { APIUserAbortError, OpenAIError } from '../../error';\nimport OpenAI from '../../index';\nimport { type BaseEvents, EventStream } from '../EventStream';\nimport { type ResponseFunctionCallArgumentsDeltaEvent, type ResponseTextDeltaEvent } from './EventTypes';\nimport { maybeParseResponse, ParseableToolsParams } from '../ResponsesParser';\nimport { Stream } from '../../streaming';\n\nexport type ResponseStreamParams = ResponseCreateAndStreamParams | ResponseStreamByIdParams;\n\nexport type ResponseCreateAndStreamParams = Omit<ResponseCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type ResponseStreamByIdParams = {\n  /**\n   * The ID of the response to stream.\n   */\n  response_id: string;\n  /**\n   * If provided, the stream will start after the event with the given sequence number.\n   */\n  starting_after?: number;\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * An array of tools the model may call while generating a response. When continuing a stream, provide\n   * the same tools as the original request.\n   */\n  tools?: ParseableToolsParams;\n};\n\ntype ResponseEvents = BaseEvents &\n  Omit<\n    {\n      [K in ResponseStreamEvent['type']]: (event: Extract<ResponseStreamEvent, { type: K }>) => void;\n    },\n    'response.output_text.delta' | 'response.function_call_arguments.delta'\n  > & {\n    event: (event: ResponseStreamEvent) => void;\n    'response.output_text.delta': (event: ResponseTextDeltaEvent) => void;\n    'response.function_call_arguments.delta': (event: ResponseFunctionCallArgumentsDeltaEvent) => void;\n  };\n\nexport type ResponseStreamingParams = Omit<ResponseCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class ResponseStream<ParsedT = null>\n  extends EventStream<ResponseEvents>\n  implements AsyncIterable<ResponseStreamEvent>\n{\n  #params: ResponseStreamingParams | null;\n  #currentResponseSnapshot: Response | undefined;\n  #finalResponse: ParsedResponse<ParsedT> | undefined;\n\n  constructor(params: ResponseStreamingParams | null) {\n    super();\n    this.#params = params;\n  }\n\n  static createResponse<ParsedT>(\n    client: OpenAI,\n    params: ResponseStreamParams,\n    options?: RequestOptions,\n  ): ResponseStream<ParsedT> {\n    const runner = new ResponseStream<ParsedT>(params as ResponseCreateParamsStreaming);\n    runner._run(() =>\n      runner._createOrRetrieveResponse(client, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentResponseSnapshot = undefined;\n  }\n\n  #addEvent(this: ResponseStream<ParsedT>, event: ResponseStreamEvent, starting_after: number | null) {\n    if (this.ended) return;\n\n    const maybeEmit = (name: string, event: ResponseStreamEvent & { snapshot?: string }) => {\n      if (starting_after == null || event.sequence_number > starting_after) {\n        this._emit(name as any, event);\n      }\n    };\n\n    const response = this.#accumulateResponse(event);\n    maybeEmit('event', event);\n\n    switch (event.type) {\n      case 'response.output_text.delta': {\n        const output = response.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'message') {\n          const content = output.content[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'output_text') {\n            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);\n          }\n\n          maybeEmit('response.output_text.delta', {\n            ...event,\n            snapshot: content.text,\n          });\n        }\n        break;\n      }\n      case 'response.function_call_arguments.delta': {\n        const output = response.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'function_call') {\n          maybeEmit('response.function_call_arguments.delta', {\n            ...event,\n            snapshot: output.arguments,\n          });\n        }\n        break;\n      }\n      default:\n        maybeEmit(event.type, event);\n        break;\n    }\n  }\n\n  #endRequest(): ParsedResponse<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentResponseSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any events`);\n    }\n    this.#currentResponseSnapshot = undefined;\n    const parsedResponse = finalizeResponse<ParsedT>(snapshot, this.#params);\n    this.#finalResponse = parsedResponse;\n\n    return parsedResponse;\n  }\n\n  protected async _createOrRetrieveResponse(\n    client: OpenAI,\n    params: ResponseStreamParams,\n    options?: RequestOptions,\n  ): Promise<ParsedResponse<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    let stream: Stream<ResponseStreamEvent> | undefined;\n    let starting_after: number | null = null;\n    if ('response_id' in params) {\n      stream = await client.responses.retrieve(\n        params.response_id,\n        { stream: true },\n        { ...options, signal: this.controller.signal, stream: true },\n      );\n      starting_after = params.starting_after ?? null;\n    } else {\n      stream = await client.responses.create(\n        { ...params, stream: true },\n        { ...options, signal: this.controller.signal },\n      );\n    }\n\n    this._connected();\n    for await (const event of stream) {\n      this.#addEvent(event, starting_after);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this.#endRequest();\n  }\n\n  #accumulateResponse(event: ResponseStreamEvent): Response {\n    let snapshot = this.#currentResponseSnapshot;\n    if (!snapshot) {\n      if (event.type !== 'response.created') {\n        throw new OpenAIError(\n          `When snapshot hasn't been set yet, expected 'response.created' event, got ${event.type}`,\n        );\n      }\n      snapshot = this.#currentResponseSnapshot = event.response;\n      return snapshot;\n    }\n\n    switch (event.type) {\n      case 'response.output_item.added': {\n        snapshot.output.push(event.item);\n        break;\n      }\n      case 'response.content_part.added': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        const type = output.type;\n        const part = event.part;\n        if (type === 'message' && part.type !== 'reasoning_text') {\n          output.content.push(part);\n        } else if (type === 'reasoning' && part.type === 'reasoning_text') {\n          if (!output.content) {\n            output.content = [];\n          }\n          output.content.push(part);\n        }\n        break;\n      }\n      case 'response.output_text.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'message') {\n          const content = output.content[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'output_text') {\n            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);\n          }\n          content.text += event.delta;\n        }\n        break;\n      }\n      case 'response.function_call_arguments.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'function_call') {\n          output.arguments += event.delta;\n        }\n        break;\n      }\n      case 'response.reasoning_text.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'reasoning') {\n          const content = output.content?.[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'reasoning_text') {\n            throw new OpenAIError(`expected content to be 'reasoning_text', got ${content.type}`);\n          }\n          content.text += event.delta;\n        }\n        break;\n      }\n      case 'response.completed': {\n        this.#currentResponseSnapshot = event.response;\n        break;\n      }\n    }\n\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ResponseStream<ParsedT>): AsyncIterator<ResponseStreamEvent> {\n    const pushQueue: ResponseStreamEvent[] = [];\n    const readQueue: {\n      resolve: (event: ResponseStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ResponseStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ResponseStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((event) => (event ? { value: event, done: false } : { value: undefined, done: true }));\n        }\n        const event = pushQueue.shift()!;\n        return { value: event, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  /**\n   * @returns a promise that resolves with the final Response, or rejects\n   * if an error occurred or the stream ended prematurely without producing a REsponse.\n   */\n  async finalResponse(): Promise<ParsedResponse<ParsedT>> {\n    await this.done();\n    const response = this.#finalResponse;\n    if (!response) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return response;\n  }\n}\n\nfunction finalizeResponse<ParsedT>(\n  snapshot: Response,\n  params: ResponseStreamingParams | null,\n): ParsedResponse<ParsedT> {\n  return maybeParseResponse(snapshot, params);\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as CompletionsAPI from './completions';\nimport { ChatCompletionStoreMessagesPage } from './completions';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Messages extends APIResource {\n  /**\n   * Get the messages in a stored chat completion. Only Chat Completions that have\n   * been created with the `store` parameter set to `true` will be returned.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const chatCompletionStoreMessage of client.chat.completions.messages.list(\n   *   'completion_id',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    completionID: string,\n    query: MessageListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ChatCompletionStoreMessagesPage, CompletionsAPI.ChatCompletionStoreMessage> {\n    return this._client.getAPIList(\n      path`/chat/completions/${completionID}/messages`,\n      CursorPage<CompletionsAPI.ChatCompletionStoreMessage>,\n      { query, ...options },\n    );\n  }\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * Sort order for messages by timestamp. Use `asc` for ascending order or `desc`\n   * for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Messages {\n  export { type MessageListParams as MessageListParams };\n}\n\nexport { type ChatCompletionStoreMessagesPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport { APIPromise } from '../../core/api-promise';\nimport { type Uploadable } from '../../core/uploads';\nimport { RequestOptions } from '../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../internal/uploads';\nimport { path } from '../../internal/utils/path';\n\nexport class Parts extends APIResource {\n  /**\n   * Adds a\n   * [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object.\n   * A Part represents a chunk of bytes from the file you are trying to upload.\n   *\n   * Each Part can be at most 64 MB, and you can add Parts until you hit the Upload\n   * maximum of 8 GB.\n   *\n   * It is possible to add multiple Parts in parallel. You can decide the intended\n   * order of the Parts when you\n   * [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).\n   */\n  create(uploadID: string, body: PartCreateParams, options?: RequestOptions): APIPromise<UploadPart> {\n    return this._client.post(\n      path`/uploads/${uploadID}/parts`,\n      multipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n}\n\n/**\n * The upload Part represents a chunk of bytes we can add to an Upload object.\n */\nexport interface UploadPart {\n  /**\n   * The upload Part unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Part was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type, which is always `upload.part`.\n   */\n  object: 'upload.part';\n\n  /**\n   * The ID of the Upload object that this Part was added to.\n   */\n  upload_id: string;\n}\n\nexport interface PartCreateParams {\n  /**\n   * The chunk of bytes for this Part.\n   */\n  data: Uploadable;\n}\n\nexport declare namespace Parts {\n  export { type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as ResponsesAPI from './responses';\nimport { ResponseItemsPage } from './responses';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class InputItems extends APIResource {\n  /**\n   * Returns a list of input items for a given response.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const responseItem of client.responses.inputItems.list(\n   *   'response_id',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    responseID: string,\n    query: InputItemListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ResponseItemsPage, ResponsesAPI.ResponseItem> {\n    return this._client.getAPIList(\n      path`/responses/${responseID}/input_items`,\n      CursorPage<ResponsesAPI.ResponseItem>,\n      { query, ...options },\n    );\n  }\n}\n\n/**\n * A list of Response items.\n */\nexport interface ResponseItemList {\n  /**\n   * A list of items used to generate this response.\n   */\n  data: Array<ResponsesAPI.ResponseItem>;\n\n  /**\n   * The ID of the first item in the list.\n   */\n  first_id: string;\n\n  /**\n   * Whether there are more items available.\n   */\n  has_more: boolean;\n\n  /**\n   * The ID of the last item in the list.\n   */\n  last_id: string;\n\n  /**\n   * The type of object returned, must be `list`.\n   */\n  object: 'list';\n}\n\nexport interface InputItemListParams extends CursorPageParams {\n  /**\n   * Additional fields to include in the response. See the `include` parameter for\n   * Response creation above for more information.\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n\n  /**\n   * The order to return the input items in. Default is `desc`.\n   *\n   * - `asc`: Return the input items in ascending order.\n   * - `desc`: Return the input items in descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace InputItems {\n  export { type ResponseItemList as ResponseItemList, type InputItemListParams as InputItemListParams };\n}\n\nexport { type ResponseItemsPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Checkpoints extends APIResource {\n  /**\n   * List checkpoints for a fine-tuning job.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const fineTuningJobCheckpoint of client.fineTuning.jobs.checkpoints.list(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    fineTuningJobID: string,\n    query: CheckpointListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint> {\n    return this._client.getAPIList(\n      path`/fine_tuning/jobs/${fineTuningJobID}/checkpoints`,\n      CursorPage<FineTuningJobCheckpoint>,\n      { query, ...options },\n    );\n  }\n}\n\nexport type FineTuningJobCheckpointsPage = CursorPage<FineTuningJobCheckpoint>;\n\n/**\n * The `fine_tuning.job.checkpoint` object represents a model checkpoint for a\n * fine-tuning job that is ready to use.\n */\nexport interface FineTuningJobCheckpoint {\n  /**\n   * The checkpoint identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the checkpoint was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the fine-tuned checkpoint model that is created.\n   */\n  fine_tuned_model_checkpoint: string;\n\n  /**\n   * The name of the fine-tuning job that this checkpoint was created from.\n   */\n  fine_tuning_job_id: string;\n\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  metrics: FineTuningJobCheckpoint.Metrics;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.checkpoint\".\n   */\n  object: 'fine_tuning.job.checkpoint';\n\n  /**\n   * The step number that the checkpoint was created at.\n   */\n  step_number: number;\n}\n\nexport namespace FineTuningJobCheckpoint {\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  export interface Metrics {\n    full_valid_loss?: number;\n\n    full_valid_mean_token_accuracy?: number;\n\n    step?: number;\n\n    train_loss?: number;\n\n    train_mean_token_accuracy?: number;\n\n    valid_loss?: number;\n\n    valid_mean_token_accuracy?: number;\n  }\n}\n\nexport interface CheckpointListParams extends CursorPageParams {}\n\nexport declare namespace Checkpoints {\n  export {\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    type FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\n\nexport class TranscriptionSessions extends APIResource {\n  /**\n   * Create an ephemeral API token for use in client-side applications with the\n   * Realtime API specifically for realtime transcriptions. Can be configured with\n   * the same session parameters as the `transcription_session.update` client event.\n   *\n   * It responds with a session object, plus a `client_secret` key which contains a\n   * usable ephemeral API token that can be used to authenticate browser clients for\n   * the Realtime API.\n   *\n   * @example\n   * ```ts\n   * const transcriptionSession =\n   *   await client.beta.realtime.transcriptionSessions.create();\n   * ```\n   */\n  create(body: TranscriptionSessionCreateParams, options?: RequestOptions): APIPromise<TranscriptionSession> {\n    return this._client.post('/realtime/transcription_sessions', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\n/**\n * A new Realtime transcription session configuration.\n *\n * When a session is created on the server via REST API, the session object also\n * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n * not present when a session is updated via the WebSocket API.\n */\nexport interface TranscriptionSession {\n  /**\n   * Ephemeral key returned by the API. Only present when the session is created on\n   * the server via REST API.\n   */\n  client_secret: TranscriptionSession.ClientSecret;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  input_audio_format?: string;\n\n  /**\n   * Configuration of the transcription model.\n   */\n  input_audio_transcription?: TranscriptionSession.InputAudioTranscription;\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  turn_detection?: TranscriptionSession.TurnDetection;\n}\n\nexport namespace TranscriptionSession {\n  /**\n   * Ephemeral key returned by the API. Only present when the session is created on\n   * the server via REST API.\n   */\n  export interface ClientSecret {\n    /**\n     * Timestamp for when the token expires. Currently, all tokens expire after one\n     * minute.\n     */\n    expires_at: number;\n\n    /**\n     * Ephemeral key usable in client environments to authenticate connections to the\n     * Realtime API. Use this in client-side environments rather than a standard API\n     * token, which should only be used server-side.\n     */\n    value: string;\n  }\n\n  /**\n   * Configuration of the transcription model.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription. Can be `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, or `whisper-1`.\n     */\n    model?: 'gpt-4o-transcribe' | 'gpt-4o-mini-transcribe' | 'whisper-1';\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. The\n     * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n     * should match the audio language.\n     */\n    prompt?: string;\n  }\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  export interface TurnDetection {\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     * Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n     * With shorter values the model will respond more quickly, but may jump in on\n     * short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection, only `server_vad` is currently supported.\n     */\n    type?: string;\n  }\n}\n\nexport interface TranscriptionSessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  client_secret?: TranscriptionSessionCreateParams.ClientSecret;\n\n  /**\n   * The set of items to include in the transcription. Current available items are:\n   *\n   * - `item.input_audio_transcription.logprobs`\n   */\n  include?: Array<string>;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: TranscriptionSessionCreateParams.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription. The client can optionally set the\n   * language and prompt for transcription, these offer additional guidance to the\n   * transcription service.\n   */\n  input_audio_transcription?: TranscriptionSessionCreateParams.InputAudioTranscription;\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  turn_detection?: TranscriptionSessionCreateParams.TurnDetection;\n}\n\nexport namespace TranscriptionSessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  export interface ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    expires_at?: ClientSecret.ExpiresAt;\n  }\n\n  export namespace ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    export interface ExpiresAt {\n      /**\n       * The anchor point for the ephemeral token expiration. Only `created_at` is\n       * currently supported.\n       */\n      anchor?: 'created_at';\n\n      /**\n       * The number of seconds from the anchor point to the expiration. Select a value\n       * between `10` and `7200`.\n       */\n      seconds?: number;\n    }\n  }\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: 'near_field' | 'far_field';\n  }\n\n  /**\n   * Configuration for input audio transcription. The client can optionally set the\n   * language and prompt for transcription, these offer additional guidance to the\n   * transcription service.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription, current options are `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, and `whisper-1`.\n     */\n    model?: 'gpt-4o-transcribe' | 'gpt-4o-mini-transcribe' | 'whisper-1';\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. For `whisper-1`, the\n     * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n     * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n     * \"expect words related to technology\".\n     */\n    prompt?: string;\n  }\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs. Not available for transcription sessions.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs. Not available for transcription sessions.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection.\n     */\n    type?: 'server_vad' | 'semantic_vad';\n  }\n}\n\nexport declare namespace TranscriptionSessions {\n  export {\n    type TranscriptionSession as TranscriptionSession,\n    type TranscriptionSessionCreateParams as TranscriptionSessionCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { VERSION } from '../version';\n\nexport const isRunningInBrowser = () => {\n  return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n    // @ts-ignore\n    typeof window.document !== 'undefined' &&\n    // @ts-ignore\n    typeof navigator !== 'undefined'\n  );\n};\n\ntype DetectedPlatform = 'deno' | 'node' | 'edge' | 'unknown';\n\n/**\n * Note this does not detect 'browser'; for that, use getBrowserInfo().\n */\nfunction getDetectedPlatform(): DetectedPlatform {\n  if (typeof Deno !== 'undefined' && Deno.build != null) {\n    return 'deno';\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return 'edge';\n  }\n  if (\n    Object.prototype.toString.call(\n      typeof (globalThis as any).process !== 'undefined' ? (globalThis as any).process : 0,\n    ) === '[object process]'\n  ) {\n    return 'node';\n  }\n  return 'unknown';\n}\n\ndeclare const Deno: any;\ndeclare const EdgeRuntime: any;\ntype Arch = 'x32' | 'x64' | 'arm' | 'arm64' | `other:${string}` | 'unknown';\ntype PlatformName =\n  | 'MacOS'\n  | 'Linux'\n  | 'Windows'\n  | 'FreeBSD'\n  | 'OpenBSD'\n  | 'iOS'\n  | 'Android'\n  | `Other:${string}`\n  | 'Unknown';\ntype Browser = 'ie' | 'edge' | 'chrome' | 'firefox' | 'safari';\ntype PlatformProperties = {\n  'X-Stainless-Lang': 'js';\n  'X-Stainless-Package-Version': string;\n  'X-Stainless-OS': PlatformName;\n  'X-Stainless-Arch': Arch;\n  'X-Stainless-Runtime': 'node' | 'deno' | 'edge' | `browser:${Browser}` | 'unknown';\n  'X-Stainless-Runtime-Version': string;\n};\nconst getPlatformProperties = (): PlatformProperties => {\n  const detectedPlatform = getDetectedPlatform();\n  if (detectedPlatform === 'deno') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(Deno.build.os),\n      'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n      'X-Stainless-Runtime': 'deno',\n      'X-Stainless-Runtime-Version':\n        typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n    };\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': `other:${EdgeRuntime}`,\n      'X-Stainless-Runtime': 'edge',\n      'X-Stainless-Runtime-Version': (globalThis as any).process.version,\n    };\n  }\n  // Check if Node.js\n  if (detectedPlatform === 'node') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform((globalThis as any).process.platform ?? 'unknown'),\n      'X-Stainless-Arch': normalizeArch((globalThis as any).process.arch ?? 'unknown'),\n      'X-Stainless-Runtime': 'node',\n      'X-Stainless-Runtime-Version': (globalThis as any).process.version ?? 'unknown',\n    };\n  }\n\n  const browserInfo = getBrowserInfo();\n  if (browserInfo) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': 'unknown',\n      'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n      'X-Stainless-Runtime-Version': browserInfo.version,\n    };\n  }\n\n  // TODO add support for Cloudflare workers, etc.\n  return {\n    'X-Stainless-Lang': 'js',\n    'X-Stainless-Package-Version': VERSION,\n    'X-Stainless-OS': 'Unknown',\n    'X-Stainless-Arch': 'unknown',\n    'X-Stainless-Runtime': 'unknown',\n    'X-Stainless-Runtime-Version': 'unknown',\n  };\n};\n\ntype BrowserInfo = {\n  browser: Browser;\n  version: string;\n};\n\ndeclare const navigator: { userAgent: string } | undefined;\n\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo(): BrowserInfo | null {\n  if (typeof navigator === 'undefined' || !navigator) {\n    return null;\n  }\n\n  // NOTE: The order matters here!\n  const browserPatterns = [\n    { key: 'edge' as const, pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'chrome' as const, pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'firefox' as const, pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'safari' as const, pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n  ];\n\n  // Find the FIRST matching browser\n  for (const { key, pattern } of browserPatterns) {\n    const match = pattern.exec(navigator.userAgent);\n    if (match) {\n      const major = match[1] || 0;\n      const minor = match[2] || 0;\n      const patch = match[3] || 0;\n\n      return { browser: key, version: `${major}.${minor}.${patch}` };\n    }\n  }\n\n  return null;\n}\n\nconst normalizeArch = (arch: string): Arch => {\n  // Node docs:\n  // - https://nodejs.org/api/process.html#processarch\n  // Deno docs:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  if (arch === 'x32') return 'x32';\n  if (arch === 'x86_64' || arch === 'x64') return 'x64';\n  if (arch === 'arm') return 'arm';\n  if (arch === 'aarch64' || arch === 'arm64') return 'arm64';\n  if (arch) return `other:${arch}`;\n  return 'unknown';\n};\n\nconst normalizePlatform = (platform: string): PlatformName => {\n  // Node platforms:\n  // - https://nodejs.org/api/process.html#processplatform\n  // Deno platforms:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  // - https://github.com/denoland/deno/issues/14799\n\n  platform = platform.toLowerCase();\n\n  // NOTE: this iOS check is untested and may not work\n  // Node does not work natively on IOS, there is a fork at\n  // https://github.com/nodejs-mobile/nodejs-mobile\n  // however it is unknown at the time of writing how to detect if it is running\n  if (platform.includes('ios')) return 'iOS';\n  if (platform === 'android') return 'Android';\n  if (platform === 'darwin') return 'MacOS';\n  if (platform === 'win32') return 'Windows';\n  if (platform === 'freebsd') return 'FreeBSD';\n  if (platform === 'openbsd') return 'OpenBSD';\n  if (platform === 'linux') return 'Linux';\n  if (platform) return `Other:${platform}`;\n  return 'Unknown';\n};\n\nlet _platformHeaders: PlatformProperties;\nexport const getPlatformHeaders = () => {\n  return (_platformHeaders ??= getPlatformProperties());\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as GraderModelsAPI from '../../graders/grader-models';\nimport { APIPromise } from '../../../core/api-promise';\nimport { RequestOptions } from '../../../internal/request-options';\n\nexport class Graders extends APIResource {\n  /**\n   * Run a grader.\n   *\n   * @example\n   * ```ts\n   * const response = await client.fineTuning.alpha.graders.run({\n   *   grader: {\n   *     input: 'input',\n   *     name: 'name',\n   *     operation: 'eq',\n   *     reference: 'reference',\n   *     type: 'string_check',\n   *   },\n   *   model_sample: 'model_sample',\n   * });\n   * ```\n   */\n  run(body: GraderRunParams, options?: RequestOptions): APIPromise<GraderRunResponse> {\n    return this._client.post('/fine_tuning/alpha/graders/run', { body, ...options });\n  }\n\n  /**\n   * Validate a grader.\n   *\n   * @example\n   * ```ts\n   * const response =\n   *   await client.fineTuning.alpha.graders.validate({\n   *     grader: {\n   *       input: 'input',\n   *       name: 'name',\n   *       operation: 'eq',\n   *       reference: 'reference',\n   *       type: 'string_check',\n   *     },\n   *   });\n   * ```\n   */\n  validate(body: GraderValidateParams, options?: RequestOptions): APIPromise<GraderValidateResponse> {\n    return this._client.post('/fine_tuning/alpha/graders/validate', { body, ...options });\n  }\n}\n\nexport interface GraderRunResponse {\n  metadata: GraderRunResponse.Metadata;\n\n  model_grader_token_usage_per_model: { [key: string]: unknown };\n\n  reward: number;\n\n  sub_rewards: { [key: string]: unknown };\n}\n\nexport namespace GraderRunResponse {\n  export interface Metadata {\n    errors: Metadata.Errors;\n\n    execution_time: number;\n\n    name: string;\n\n    sampled_model_name: string | null;\n\n    scores: { [key: string]: unknown };\n\n    token_usage: number | null;\n\n    type: string;\n  }\n\n  export namespace Metadata {\n    export interface Errors {\n      formula_parse_error: boolean;\n\n      invalid_variable_error: boolean;\n\n      model_grader_parse_error: boolean;\n\n      model_grader_refusal_error: boolean;\n\n      model_grader_server_error: boolean;\n\n      model_grader_server_error_details: string | null;\n\n      other_error: boolean;\n\n      python_grader_runtime_error: boolean;\n\n      python_grader_runtime_error_details: string | null;\n\n      python_grader_server_error: boolean;\n\n      python_grader_server_error_type: string | null;\n\n      sample_parse_error: boolean;\n\n      truncated_observation_error: boolean;\n\n      unresponsive_reward_error: boolean;\n    }\n  }\n}\n\nexport interface GraderValidateResponse {\n  /**\n   * The grader used for the fine-tuning job.\n   */\n  grader?:\n    | GraderModelsAPI.StringCheckGrader\n    | GraderModelsAPI.TextSimilarityGrader\n    | GraderModelsAPI.PythonGrader\n    | GraderModelsAPI.ScoreModelGrader\n    | GraderModelsAPI.MultiGrader;\n}\n\nexport interface GraderRunParams {\n  /**\n   * The grader used for the fine-tuning job.\n   */\n  grader:\n    | GraderModelsAPI.StringCheckGrader\n    | GraderModelsAPI.TextSimilarityGrader\n    | GraderModelsAPI.PythonGrader\n    | GraderModelsAPI.ScoreModelGrader\n    | GraderModelsAPI.MultiGrader;\n\n  /**\n   * The model sample to be evaluated. This value will be used to populate the\n   * `sample` namespace. See\n   * [the guide](https://platform.openai.com/docs/guides/graders) for more details.\n   * The `output_json` variable will be populated if the model sample is a valid JSON\n   * string.\n   */\n  model_sample: string;\n\n  /**\n   * The dataset item provided to the grader. This will be used to populate the\n   * `item` namespace. See\n   * [the guide](https://platform.openai.com/docs/guides/graders) for more details.\n   */\n  item?: unknown;\n}\n\nexport interface GraderValidateParams {\n  /**\n   * The grader used for the fine-tuning job.\n   */\n  grader:\n    | GraderModelsAPI.StringCheckGrader\n    | GraderModelsAPI.TextSimilarityGrader\n    | GraderModelsAPI.PythonGrader\n    | GraderModelsAPI.ScoreModelGrader\n    | GraderModelsAPI.MultiGrader;\n}\n\nexport declare namespace Graders {\n  export {\n    type GraderRunResponse as GraderRunResponse,\n    type GraderValidateResponse as GraderValidateResponse,\n    type GraderRunParams as GraderRunParams,\n    type GraderValidateParams as GraderValidateParams,\n  };\n}\n","import type { RequestInit } from './internal/builtin-types';\nimport type { NullableHeaders } from './internal/headers';\nimport { buildHeaders } from './internal/headers';\nimport * as Errors from './error';\nimport { FinalRequestOptions } from './internal/request-options';\nimport { isObj, readEnv } from './internal/utils';\nimport { ClientOptions, OpenAI } from './client';\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport interface AzureClientOptions extends ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_VERSION'].\n   */\n  apiVersion?: string | undefined;\n\n  /**\n   * Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   */\n  endpoint?: string | undefined;\n\n  /**\n   * A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * Note: this means you won't be able to use non-deployment endpoints. Not supported with Assistants APIs.\n   */\n  deployment?: string | undefined;\n\n  /**\n   * Defaults to process.env['AZURE_OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * A function that returns an access token for Microsoft Entra (formerly known as Azure Active Directory),\n   * which will be invoked on every request.\n   */\n  azureADTokenProvider?: (() => Promise<string>) | undefined;\n}\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport class AzureOpenAI extends OpenAI {\n  deploymentName: string | undefined;\n  apiVersion: string = '';\n\n  /**\n   * API Client for interfacing with the Azure OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]\n   * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]\n   * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API, e.g. `https://example-resource.azure.openai.com/openai/`.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = readEnv('OPENAI_BASE_URL'),\n    apiKey = readEnv('AZURE_OPENAI_API_KEY'),\n    apiVersion = readEnv('OPENAI_API_VERSION'),\n    endpoint,\n    deployment,\n    azureADTokenProvider,\n    dangerouslyAllowBrowser,\n    ...opts\n  }: AzureClientOptions = {}) {\n    if (!apiVersion) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).\",\n      );\n    }\n\n    if (typeof azureADTokenProvider === 'function') {\n      dangerouslyAllowBrowser = true;\n    }\n\n    if (!azureADTokenProvider && !apiKey) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    if (azureADTokenProvider && apiKey) {\n      throw new Errors.OpenAIError(\n        'The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.',\n      );\n    }\n\n    opts.defaultQuery = { ...opts.defaultQuery, 'api-version': apiVersion };\n\n    if (!baseURL) {\n      if (!endpoint) {\n        endpoint = process.env['AZURE_OPENAI_ENDPOINT'];\n      }\n\n      if (!endpoint) {\n        throw new Errors.OpenAIError(\n          'Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable',\n        );\n      }\n\n      baseURL = `${endpoint}/openai`;\n    } else {\n      if (endpoint) {\n        throw new Errors.OpenAIError('baseURL and endpoint are mutually exclusive');\n      }\n    }\n\n    super({\n      apiKey: azureADTokenProvider ?? apiKey,\n      baseURL,\n      ...opts,\n      ...(dangerouslyAllowBrowser !== undefined ? { dangerouslyAllowBrowser } : {}),\n    });\n\n    this.apiVersion = apiVersion;\n    this.deploymentName = deployment;\n  }\n\n  override async buildRequest(\n    options: FinalRequestOptions,\n    props: { retryCount?: number } = {},\n  ): Promise<{ req: RequestInit & { headers: Headers }; url: string; timeout: number }> {\n    if (_deployments_endpoints.has(options.path) && options.method === 'post' && options.body !== undefined) {\n      if (!isObj(options.body)) {\n        throw new Error('Expected request body to be an object');\n      }\n      const model = this.deploymentName || options.body['model'] || options.__metadata?.['model'];\n      if (model !== undefined && !this.baseURL.includes('/deployments')) {\n        options.path = `/deployments/${model}${options.path}`;\n      }\n    }\n    return super.buildRequest(options, props);\n  }\n\n  protected override async authHeaders(opts: FinalRequestOptions): Promise<NullableHeaders | undefined> {\n    if (typeof this._options.apiKey === 'string') {\n      return buildHeaders([{ 'api-key': this.apiKey }]);\n    }\n    return super.authHeaders(opts);\n  }\n}\n\nconst _deployments_endpoints = new Set([\n  '/completions',\n  '/chat/completions',\n  '/embeddings',\n  '/audio/transcriptions',\n  '/audio/translations',\n  '/audio/speech',\n  '/images/generations',\n  '/batches',\n  '/images/edits',\n]);\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../core/resource';\nimport * as RunsAPI from './runs';\nimport * as Shared from '../../../shared';\nimport * as AssistantsAPI from '../../assistants';\nimport * as MessagesAPI from '../messages';\nimport * as ThreadsAPI from '../threads';\nimport * as StepsAPI from './steps';\nimport {\n  CodeInterpreterLogs,\n  CodeInterpreterOutputImage,\n  CodeInterpreterToolCall,\n  CodeInterpreterToolCallDelta,\n  FileSearchToolCall,\n  FileSearchToolCallDelta,\n  FunctionToolCall,\n  FunctionToolCallDelta,\n  MessageCreationStepDetails,\n  RunStep,\n  RunStepDelta,\n  RunStepDeltaEvent,\n  RunStepDeltaMessageDelta,\n  RunStepInclude,\n  RunStepsPage,\n  StepListParams,\n  StepRetrieveParams,\n  Steps,\n  ToolCall,\n  ToolCallDelta,\n  ToolCallDeltaObject,\n  ToolCallsStepDetails,\n} from './steps';\nimport { APIPromise } from '../../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../../core/pagination';\nimport { Stream } from '../../../../core/streaming';\nimport { buildHeaders } from '../../../../internal/headers';\nimport { RequestOptions } from '../../../../internal/request-options';\nimport { AssistantStream, RunCreateParamsBaseStream } from '../../../../lib/AssistantStream';\nimport { sleep } from '../../../../internal/utils/sleep';\nimport { RunSubmitToolOutputsParamsStream } from '../../../../lib/AssistantStream';\nimport { path } from '../../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Runs extends APIResource {\n  steps: StepsAPI.Steps = new StepsAPI.Steps(this._client);\n\n  /**\n   * Create a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  create(threadID: string, params: RunCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Run>;\n  create(\n    threadID: string,\n    params: RunCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  create(\n    threadID: string,\n    params: RunCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  create(\n    threadID: string,\n    params: RunCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    const { include, ...body } = params;\n    return this._client.post(path`/threads/${threadID}/runs`, {\n      query: { include },\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      stream: params.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(runID: string, params: RunRetrieveParams, options?: RequestOptions): APIPromise<Run> {\n    const { thread_id } = params;\n    return this._client.get(path`/threads/${thread_id}/runs/${runID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  update(runID: string, params: RunUpdateParams, options?: RequestOptions): APIPromise<Run> {\n    const { thread_id, ...body } = params;\n    return this._client.post(path`/threads/${thread_id}/runs/${runID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of runs belonging to a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  list(\n    threadID: string,\n    query: RunListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<RunsPage, Run> {\n    return this._client.getAPIList(path`/threads/${threadID}/runs`, CursorPage<Run>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Cancels a run that is `in_progress`.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  cancel(runID: string, params: RunCancelParams, options?: RequestOptions): APIPromise<Run> {\n    const { thread_id } = params;\n    return this._client.post(path`/threads/${thread_id}/runs/${runID}/cancel`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * A helper to create a run an poll for a terminal state. More information on Run\n   * lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndPoll(\n    threadId: string,\n    body: RunCreateParamsNonStreaming,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.create(threadId, body, options);\n    return await this.poll(run.id, { thread_id: threadId }, options);\n  }\n\n  /**\n   * Create a Run stream\n   *\n   * @deprecated use `stream` instead\n   */\n  createAndStream(\n    threadId: string,\n    body: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * A helper to poll a run status until it reaches a terminal state. More\n   * information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async poll(\n    runId: string,\n    params: RunRetrieveParams,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const headers = buildHeaders([\n      options?.headers,\n      {\n        'X-Stainless-Poll-Helper': 'true',\n        'X-Stainless-Custom-Poll-Interval': options?.pollIntervalMs?.toString() ?? undefined,\n      },\n    ]);\n\n    while (true) {\n      const { data: run, response } = await this.retrieve(runId, params, {\n        ...options,\n        headers: { ...options?.headers, ...headers },\n      }).withResponse();\n\n      switch (run.status) {\n        //If we are in any sort of intermediate state we poll\n        case 'queued':\n        case 'in_progress':\n        case 'cancelling':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        //We return the run in any terminal state.\n        case 'requires_action':\n        case 'incomplete':\n        case 'cancelled':\n        case 'completed':\n        case 'failed':\n        case 'expired':\n          return run;\n      }\n    }\n  }\n\n  /**\n   * Create a Run stream\n   */\n  stream(threadId: string, body: RunCreateParamsBaseStream, options?: RequestOptions): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * When a run has the `status: \"requires_action\"` and `required_action.type` is\n   * `submit_tool_outputs`, this endpoint can be used to submit the outputs from the\n   * tool calls once they're all completed. All outputs must be submitted in a single\n   * request.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParamsNonStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Run>;\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParams,\n    options?: RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    const { thread_id, ...body } = params;\n    return this._client.post(path`/threads/${thread_id}/runs/${runID}/submit_tool_outputs`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      stream: params.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to submit a tool output to a run and poll for a terminal run state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async submitToolOutputsAndPoll(\n    runId: string,\n    params: RunSubmitToolOutputsParamsNonStreaming,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.submitToolOutputs(runId, params, options);\n    return await this.poll(run.id, params, options);\n  }\n\n  /**\n   * Submit the tool outputs from a previous run and stream the run to a terminal\n   * state. More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  submitToolOutputsStream(\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createToolAssistantStream(runId, this._client.beta.threads.runs, params, options);\n  }\n}\n\nexport type RunsPage = CursorPage<Run>;\n\n/**\n * Tool call objects\n */\nexport interface RequiredActionFunctionToolCall {\n  /**\n   * The ID of the tool call. This ID must be referenced when you submit the tool\n   * outputs in using the\n   * [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n   * endpoint.\n   */\n  id: string;\n\n  /**\n   * The function definition.\n   */\n  function: RequiredActionFunctionToolCall.Function;\n\n  /**\n   * The type of tool call the output is required for. For now, this is always\n   * `function`.\n   */\n  type: 'function';\n}\n\nexport namespace RequiredActionFunctionToolCall {\n  /**\n   * The function definition.\n   */\n  export interface Function {\n    /**\n     * The arguments that the model expects you to pass to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents an execution run on a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Run {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * execution of this run.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run will expire.\n   */\n  expires_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  incomplete_details: Run.IncompleteDetails | null;\n\n  /**\n   * The instructions that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  instructions: string;\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  last_error: Run.LastError | null;\n\n  /**\n   * The maximum number of completion tokens specified to have been used over the\n   * course of the run.\n   */\n  max_completion_tokens: number | null;\n\n  /**\n   * The maximum number of prompt tokens specified to have been used over the course\n   * of the run.\n   */\n  max_prompt_tokens: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `thread.run`.\n   */\n  object: 'thread.run';\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  required_action: Run.RequiredAction | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was started.\n   */\n  started_at: number | null;\n\n  /**\n   * The status of the run, which can be either `queued`, `in_progress`,\n   * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n   * `incomplete`, or `expired`.\n   */\n  status: RunStatus;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was executed on as a part of this run.\n   */\n  thread_id: string;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * The list of tools that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  tools: Array<AssistantsAPI.AssistantTool>;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  truncation_strategy: Run.TruncationStrategy | null;\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  usage: Run.Usage | null;\n\n  /**\n   * The sampling temperature used for this run. If not set, defaults to 1.\n   */\n  temperature?: number | null;\n\n  /**\n   * The nucleus sampling value used for this run. If not set, defaults to 1.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Run {\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the run is incomplete. This will point to which specific token\n     * limit was reached over the course of the run.\n     */\n    reason?: 'max_completion_tokens' | 'max_prompt_tokens';\n  }\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded' | 'invalid_prompt';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  export interface RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    submit_tool_outputs: RequiredAction.SubmitToolOutputs;\n\n    /**\n     * For now, this is always `submit_tool_outputs`.\n     */\n    type: 'submit_tool_outputs';\n  }\n\n  export namespace RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    export interface SubmitToolOutputs {\n      /**\n       * A list of the relevant tool calls.\n       */\n      tool_calls: Array<RunsAPI.RequiredActionFunctionToolCall>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The status of the run, which can be either `queued`, `in_progress`,\n * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n * `incomplete`, or `expired`.\n */\nexport type RunStatus =\n  | 'queued'\n  | 'in_progress'\n  | 'requires_action'\n  | 'cancelling'\n  | 'cancelled'\n  | 'failed'\n  | 'completed'\n  | 'incomplete'\n  | 'expired';\n\nexport type RunCreateParams = RunCreateParamsNonStreaming | RunCreateParamsStreaming;\n\nexport interface RunCreateParamsBase {\n  /**\n   * Body param: The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<StepsAPI.RunStepInclude>;\n\n  /**\n   * Body param: Appends additional instructions at the end of the instructions for\n   * the run. This is useful for modifying the behavior on a per-run basis without\n   * overriding other instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Body param: Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateParams.AdditionalMessage> | null;\n\n  /**\n   * Body param: Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * Body param: The maximum number of completion tokens that may be used over the\n   * course of the run. The run will make a best effort to use only the number of\n   * completion tokens specified, across multiple turns of the run. If the run\n   * exceeds the number of completion tokens specified, the run will end with status\n   * `incomplete`. See `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * Body param: The maximum number of prompt tokens that may be used over the course\n   * of the run. The run will make a best effort to use only the number of prompt\n   * tokens specified, across multiple turns of the run. If the run exceeds the\n   * number of prompt tokens specified, the run will end with status `incomplete`.\n   * See `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Body param: The ID of the\n   * [Model](https://platform.openai.com/docs/api-reference/models) to be used to\n   * execute this run. If a value is provided here, it will override the model\n   * associated with the assistant. If not, the model associated with the assistant\n   * will be used.\n   */\n  model?: (string & {}) | Shared.ChatModel | null;\n\n  /**\n   * Body param: Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Body param: Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.\n   * Reducing reasoning effort can result in faster responses and fewer tokens used\n   * on reasoning in a response.\n   *\n   * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported\n   *   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool\n   *   calls are supported for all reasoning values in gpt-5.1.\n   * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not\n   *   support `none`.\n   * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n   * - `xhigh` is supported for all models after `gpt-5.1-codex-max`.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Body param: Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Body param: What sampling temperature to use, between 0 and 2. Higher values\n   * like 0.8 will make the output more random, while lower values like 0.2 will make\n   * it more focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Body param: Controls which (if any) tool is called by the model. `none` means\n   * the model will not call any tools and instead generates a message. `auto` is the\n   * default value and means the model can pick between generating a message or\n   * calling one or more tools. `required` means the model must call one or more\n   * tools before responding to the user. Specifying a particular tool like\n   * `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Body param: Override the tools the assistant can use for this run. This is\n   * useful for modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * Body param: An alternative to sampling with temperature, called nucleus\n   * sampling, where the model considers the results of the tokens with top_p\n   * probability mass. So 0.1 means only the tokens comprising the top 10%\n   * probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Body param: Controls for how a thread will be truncated prior to the run. Use\n   * this to control the initial context window of the run.\n   */\n  truncation_strategy?: RunCreateParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export type RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n}\n\nexport interface RunCreateParamsNonStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunCreateParamsStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream: true;\n}\n\nexport interface RunRetrieveParams {\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n}\n\nexport interface RunUpdateParams {\n  /**\n   * Path param: The ID of the\n   * [thread](https://platform.openai.com/docs/api-reference/threads) that was run.\n   */\n  thread_id: string;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface RunCancelParams {\n  /**\n   * The ID of the thread to which this run belongs.\n   */\n  thread_id: string;\n}\n\nexport type RunCreateAndPollParams = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n\nexport type RunCreateAndStreamParams = RunCreateParamsBaseStream;\n\nexport type RunStreamParams = RunCreateParamsBaseStream;\n\nexport type RunSubmitToolOutputsParams =\n  | RunSubmitToolOutputsParamsNonStreaming\n  | RunSubmitToolOutputsParamsStreaming;\n\nexport interface RunSubmitToolOutputsParamsBase {\n  /**\n   * Path param: The ID of the\n   * [thread](https://platform.openai.com/docs/api-reference/threads) to which this\n   * run belongs.\n   */\n  thread_id: string;\n\n  /**\n   * Body param: A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsParams.ToolOutput>;\n\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: boolean | null;\n}\n\nexport namespace RunSubmitToolOutputsParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n\n  export type RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export type RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n}\n\nexport interface RunSubmitToolOutputsParamsNonStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunSubmitToolOutputsParamsStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream: true;\n}\n\nexport type RunSubmitToolOutputsAndPollParams = RunSubmitToolOutputsParamsNonStreaming;\nexport type RunSubmitToolOutputsStreamParams = RunSubmitToolOutputsParamsStream;\n\nRuns.Steps = Steps;\n\nexport declare namespace Runs {\n  export {\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    type RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Steps as Steps,\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    type RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { Page, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Permissions extends APIResource {\n  /**\n   * **NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).\n   *\n   * This enables organization owners to share fine-tuned models with other projects\n   * in their organization.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const permissionCreateResponse of client.fineTuning.checkpoints.permissions.create(\n   *   'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',\n   *   { project_ids: ['string'] },\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  create(\n    fineTunedModelCheckpoint: string,\n    body: PermissionCreateParams,\n    options?: RequestOptions,\n  ): PagePromise<PermissionCreateResponsesPage, PermissionCreateResponse> {\n    return this._client.getAPIList(\n      path`/fine_tuning/checkpoints/${fineTunedModelCheckpoint}/permissions`,\n      Page<PermissionCreateResponse>,\n      { body, method: 'post', ...options },\n    );\n  }\n\n  /**\n   * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).\n   *\n   * Organization owners can use this endpoint to view all permissions for a\n   * fine-tuned model checkpoint.\n   *\n   * @example\n   * ```ts\n   * const permission =\n   *   await client.fineTuning.checkpoints.permissions.retrieve(\n   *     'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   *   );\n   * ```\n   */\n  retrieve(\n    fineTunedModelCheckpoint: string,\n    query: PermissionRetrieveParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<PermissionRetrieveResponse> {\n    return this._client.get(path`/fine_tuning/checkpoints/${fineTunedModelCheckpoint}/permissions`, {\n      query,\n      ...options,\n    });\n  }\n\n  /**\n   * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).\n   *\n   * Organization owners can use this endpoint to delete a permission for a\n   * fine-tuned model checkpoint.\n   *\n   * @example\n   * ```ts\n   * const permission =\n   *   await client.fineTuning.checkpoints.permissions.delete(\n   *     'cp_zc4Q7MP6XxulcVzj4MZdwsAB',\n   *     {\n   *       fine_tuned_model_checkpoint:\n   *         'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',\n   *     },\n   *   );\n   * ```\n   */\n  delete(\n    permissionID: string,\n    params: PermissionDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<PermissionDeleteResponse> {\n    const { fine_tuned_model_checkpoint } = params;\n    return this._client.delete(\n      path`/fine_tuning/checkpoints/${fine_tuned_model_checkpoint}/permissions/${permissionID}`,\n      options,\n    );\n  }\n}\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type PermissionCreateResponsesPage = Page<PermissionCreateResponse>;\n\n/**\n * The `checkpoint.permission` object represents a permission for a fine-tuned\n * model checkpoint.\n */\nexport interface PermissionCreateResponse {\n  /**\n   * The permission identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the permission was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type, which is always \"checkpoint.permission\".\n   */\n  object: 'checkpoint.permission';\n\n  /**\n   * The project identifier that the permission is for.\n   */\n  project_id: string;\n}\n\nexport interface PermissionRetrieveResponse {\n  data: Array<PermissionRetrieveResponse.Data>;\n\n  has_more: boolean;\n\n  object: 'list';\n\n  first_id?: string | null;\n\n  last_id?: string | null;\n}\n\nexport namespace PermissionRetrieveResponse {\n  /**\n   * The `checkpoint.permission` object represents a permission for a fine-tuned\n   * model checkpoint.\n   */\n  export interface Data {\n    /**\n     * The permission identifier, which can be referenced in the API endpoints.\n     */\n    id: string;\n\n    /**\n     * The Unix timestamp (in seconds) for when the permission was created.\n     */\n    created_at: number;\n\n    /**\n     * The object type, which is always \"checkpoint.permission\".\n     */\n    object: 'checkpoint.permission';\n\n    /**\n     * The project identifier that the permission is for.\n     */\n    project_id: string;\n  }\n}\n\nexport interface PermissionDeleteResponse {\n  /**\n   * The ID of the fine-tuned model checkpoint permission that was deleted.\n   */\n  id: string;\n\n  /**\n   * Whether the fine-tuned model checkpoint permission was successfully deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * The object type, which is always \"checkpoint.permission\".\n   */\n  object: 'checkpoint.permission';\n}\n\nexport interface PermissionCreateParams {\n  /**\n   * The project identifiers to grant access to.\n   */\n  project_ids: Array<string>;\n}\n\nexport interface PermissionRetrieveParams {\n  /**\n   * Identifier for the last permission ID from the previous pagination request.\n   */\n  after?: string;\n\n  /**\n   * Number of permissions to retrieve.\n   */\n  limit?: number;\n\n  /**\n   * The order in which to retrieve permissions.\n   */\n  order?: 'ascending' | 'descending';\n\n  /**\n   * The ID of the project to get permissions for.\n   */\n  project_id?: string;\n}\n\nexport interface PermissionDeleteParams {\n  /**\n   * The ID of the fine-tuned model checkpoint to delete a permission for.\n   */\n  fine_tuned_model_checkpoint: string;\n}\n\nexport declare namespace Permissions {\n  export {\n    type PermissionCreateResponse as PermissionCreateResponse,\n    type PermissionRetrieveResponse as PermissionRetrieveResponse,\n    type PermissionDeleteResponse as PermissionDeleteResponse,\n    type PermissionCreateResponsesPage as PermissionCreateResponsesPage,\n    type PermissionCreateParams as PermissionCreateParams,\n    type PermissionRetrieveParams as PermissionRetrieveParams,\n    type PermissionDeleteParams as PermissionDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as GraderModelsAPI from '../graders/grader-models';\nimport * as ResponsesAPI from '../responses/responses';\nimport * as RunsAPI from './runs/runs';\nimport {\n  CreateEvalCompletionsRunDataSource,\n  CreateEvalJSONLRunDataSource,\n  EvalAPIError,\n  RunCancelParams,\n  RunCancelResponse,\n  RunCreateParams,\n  RunCreateResponse,\n  RunDeleteParams,\n  RunDeleteResponse,\n  RunListParams,\n  RunListResponse,\n  RunListResponsesPage,\n  RunRetrieveParams,\n  RunRetrieveResponse,\n  Runs,\n} from './runs/runs';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Evals extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n\n  /**\n   * Create the structure of an evaluation that can be used to test a model's\n   * performance. An evaluation is a set of testing criteria and the config for a\n   * data source, which dictates the schema of the data used in the evaluation. After\n   * creating an evaluation, you can run it on different models and model parameters.\n   * We support several types of graders and datasources. For more information, see\n   * the [Evals guide](https://platform.openai.com/docs/guides/evals).\n   */\n  create(body: EvalCreateParams, options?: RequestOptions): APIPromise<EvalCreateResponse> {\n    return this._client.post('/evals', { body, ...options });\n  }\n\n  /**\n   * Get an evaluation by ID.\n   */\n  retrieve(evalID: string, options?: RequestOptions): APIPromise<EvalRetrieveResponse> {\n    return this._client.get(path`/evals/${evalID}`, options);\n  }\n\n  /**\n   * Update certain properties of an evaluation.\n   */\n  update(evalID: string, body: EvalUpdateParams, options?: RequestOptions): APIPromise<EvalUpdateResponse> {\n    return this._client.post(path`/evals/${evalID}`, { body, ...options });\n  }\n\n  /**\n   * List evaluations for a project.\n   */\n  list(\n    query: EvalListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<EvalListResponsesPage, EvalListResponse> {\n    return this._client.getAPIList('/evals', CursorPage<EvalListResponse>, { query, ...options });\n  }\n\n  /**\n   * Delete an evaluation.\n   */\n  delete(evalID: string, options?: RequestOptions): APIPromise<EvalDeleteResponse> {\n    return this._client.delete(path`/evals/${evalID}`, options);\n  }\n}\n\nexport type EvalListResponsesPage = CursorPage<EvalListResponse>;\n\n/**\n * A CustomDataSourceConfig which specifies the schema of your `item` and\n * optionally `sample` namespaces. The response schema defines the shape of the\n * data that will be:\n *\n * - Used to define your testing criteria and\n * - What data is required when creating a run\n */\nexport interface EvalCustomDataSourceConfig {\n  /**\n   * The json schema for the run data source items. Learn how to build JSON schemas\n   * [here](https://json-schema.org/).\n   */\n  schema: { [key: string]: unknown };\n\n  /**\n   * The type of data source. Always `custom`.\n   */\n  type: 'custom';\n}\n\n/**\n * @deprecated Deprecated in favor of LogsDataSourceConfig.\n */\nexport interface EvalStoredCompletionsDataSourceConfig {\n  /**\n   * The json schema for the run data source items. Learn how to build JSON schemas\n   * [here](https://json-schema.org/).\n   */\n  schema: { [key: string]: unknown };\n\n  /**\n   * The type of data source. Always `stored_completions`.\n   */\n  type: 'stored_completions';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalCreateResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalCreateResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalCreateResponse.EvalGraderTextSimilarity\n    | EvalCreateResponse.EvalGraderPython\n    | EvalCreateResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalCreateResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalRetrieveResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalRetrieveResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalRetrieveResponse.EvalGraderTextSimilarity\n    | EvalRetrieveResponse.EvalGraderPython\n    | EvalRetrieveResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalRetrieveResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalUpdateResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalUpdateResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalUpdateResponse.EvalGraderTextSimilarity\n    | EvalUpdateResponse.EvalGraderPython\n    | EvalUpdateResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalUpdateResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalListResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalListResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalListResponse.EvalGraderTextSimilarity\n    | EvalListResponse.EvalGraderPython\n    | EvalListResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalListResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\nexport interface EvalDeleteResponse {\n  deleted: boolean;\n\n  eval_id: string;\n\n  object: string;\n}\n\nexport interface EvalCreateParams {\n  /**\n   * The configuration for the data source used for the evaluation runs. Dictates the\n   * schema of the data used in the evaluation.\n   */\n  data_source_config: EvalCreateParams.Custom | EvalCreateParams.Logs | EvalCreateParams.StoredCompletions;\n\n  /**\n   * A list of graders for all eval runs in this group. Graders can reference\n   * variables in the data source using double curly braces notation, like\n   * `{{item.variable_name}}`. To reference the model's output, use the `sample`\n   * namespace (ie, `{{sample.output_text}}`).\n   */\n  testing_criteria: Array<\n    | EvalCreateParams.LabelModel\n    | GraderModelsAPI.StringCheckGrader\n    | EvalCreateParams.TextSimilarity\n    | EvalCreateParams.Python\n    | EvalCreateParams.ScoreModel\n  >;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name?: string;\n}\n\nexport namespace EvalCreateParams {\n  /**\n   * A CustomDataSourceConfig object that defines the schema for the data source used\n   * for the evaluation runs. This schema is used to define the shape of the data\n   * that will be:\n   *\n   * - Used to define your testing criteria and\n   * - What data is required when creating a run\n   */\n  export interface Custom {\n    /**\n     * The json schema for each row in the data source.\n     */\n    item_schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `custom`.\n     */\n    type: 'custom';\n\n    /**\n     * Whether the eval should expect you to populate the sample namespace (ie, by\n     * generating responses off of your data source)\n     */\n    include_sample_schema?: boolean;\n  }\n\n  /**\n   * A data source config which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\n   */\n  export interface Logs {\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Metadata filters for the logs data source.\n     */\n    metadata?: { [key: string]: unknown };\n  }\n\n  /**\n   * @deprecated Deprecated in favor of LogsDataSourceConfig.\n   */\n  export interface StoredCompletions {\n    /**\n     * The type of data source. Always `stored_completions`.\n     */\n    type: 'stored_completions';\n\n    /**\n     * Metadata filters for the stored completions data source.\n     */\n    metadata?: { [key: string]: unknown };\n  }\n\n  /**\n   * A LabelModelGrader object which uses a model to assign labels to each item in\n   * the evaluation.\n   */\n  export interface LabelModel {\n    /**\n     * A list of chat messages forming the prompt or context. May include variable\n     * references to the `item` namespace, ie {{item.name}}.\n     */\n    input: Array<LabelModel.SimpleInputMessage | LabelModel.EvalItem>;\n\n    /**\n     * The labels to classify to each item in the evaluation.\n     */\n    labels: Array<string>;\n\n    /**\n     * The model to use for the evaluation. Must support structured outputs.\n     */\n    model: string;\n\n    /**\n     * The name of the grader.\n     */\n    name: string;\n\n    /**\n     * The labels that indicate a passing result. Must be a subset of labels.\n     */\n    passing_labels: Array<string>;\n\n    /**\n     * The object type, which is always `label_model`.\n     */\n    type: 'label_model';\n  }\n\n  export namespace LabelModel {\n    export interface SimpleInputMessage {\n      /**\n       * The content of the message.\n       */\n      content: string;\n\n      /**\n       * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n       */\n      role: string;\n    }\n\n    /**\n     * A message input to the model with a role indicating instruction following\n     * hierarchy. Instructions given with the `developer` or `system` role take\n     * precedence over instructions given with the `user` role. Messages with the\n     * `assistant` role are presumed to have been generated by the model in previous\n     * interactions.\n     */\n    export interface EvalItem {\n      /**\n       * Inputs to the model - can contain template strings. Supports text, output text,\n       * input images, and input audio, either as a single item or an array of items.\n       */\n      content:\n        | string\n        | ResponsesAPI.ResponseInputText\n        | EvalItem.OutputText\n        | EvalItem.InputImage\n        | ResponsesAPI.ResponseInputAudio\n        | GraderModelsAPI.GraderInputs;\n\n      /**\n       * The role of the message input. One of `user`, `assistant`, `system`, or\n       * `developer`.\n       */\n      role: 'user' | 'assistant' | 'system' | 'developer';\n\n      /**\n       * The type of the message input. Always `message`.\n       */\n      type?: 'message';\n    }\n\n    export namespace EvalItem {\n      /**\n       * A text output from the model.\n       */\n      export interface OutputText {\n        /**\n         * The text output from the model.\n         */\n        text: string;\n\n        /**\n         * The type of the output text. Always `output_text`.\n         */\n        type: 'output_text';\n      }\n\n      /**\n       * An image input block used within EvalItem content arrays.\n       */\n      export interface InputImage {\n        /**\n         * The URL of the image input.\n         */\n        image_url: string;\n\n        /**\n         * The type of the image input. Always `input_image`.\n         */\n        type: 'input_image';\n\n        /**\n         * The detail level of the image to be sent to the model. One of `high`, `low`, or\n         * `auto`. Defaults to `auto`.\n         */\n        detail?: string;\n      }\n    }\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface TextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface Python extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface ScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\nexport interface EvalUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Rename the evaluation.\n   */\n  name?: string;\n}\n\nexport interface EvalListParams extends CursorPageParams {\n  /**\n   * Sort order for evals by timestamp. Use `asc` for ascending order or `desc` for\n   * descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Evals can be ordered by creation time or last updated time. Use `created_at` for\n   * creation time or `updated_at` for last updated time.\n   */\n  order_by?: 'created_at' | 'updated_at';\n}\n\nEvals.Runs = Runs;\n\nexport declare namespace Evals {\n  export {\n    type EvalCustomDataSourceConfig as EvalCustomDataSourceConfig,\n    type EvalStoredCompletionsDataSourceConfig as EvalStoredCompletionsDataSourceConfig,\n    type EvalCreateResponse as EvalCreateResponse,\n    type EvalRetrieveResponse as EvalRetrieveResponse,\n    type EvalUpdateResponse as EvalUpdateResponse,\n    type EvalListResponse as EvalListResponse,\n    type EvalDeleteResponse as EvalDeleteResponse,\n    type EvalListResponsesPage as EvalListResponsesPage,\n    type EvalCreateParams as EvalCreateParams,\n    type EvalUpdateParams as EvalUpdateParams,\n    type EvalListParams as EvalListParams,\n  };\n\n  export {\n    Runs as Runs,\n    type CreateEvalCompletionsRunDataSource as CreateEvalCompletionsRunDataSource,\n    type CreateEvalJSONLRunDataSource as CreateEvalJSONLRunDataSource,\n    type EvalAPIError as EvalAPIError,\n    type RunCreateResponse as RunCreateResponse,\n    type RunRetrieveResponse as RunRetrieveResponse,\n    type RunListResponse as RunListResponse,\n    type RunDeleteResponse as RunDeleteResponse,\n    type RunCancelResponse as RunCancelResponse,\n    type RunListResponsesPage as RunListResponsesPage,\n    type RunCreateParams as RunCreateParams,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunListParams as RunListParams,\n    type RunDeleteParams as RunDeleteParams,\n    type RunCancelParams as RunCancelParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ThreadsAPI from './threads';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport * as MessagesAPI from './messages';\nimport {\n  Annotation,\n  AnnotationDelta,\n  FileCitationAnnotation,\n  FileCitationDeltaAnnotation,\n  FilePathAnnotation,\n  FilePathDeltaAnnotation,\n  ImageFile,\n  ImageFileContentBlock,\n  ImageFileDelta,\n  ImageFileDeltaBlock,\n  ImageURL,\n  ImageURLContentBlock,\n  ImageURLDelta,\n  ImageURLDeltaBlock,\n  Message as MessagesAPIMessage,\n  MessageContent,\n  MessageContentDelta,\n  MessageContentPartParam,\n  MessageCreateParams,\n  MessageDeleteParams,\n  MessageDeleted,\n  MessageDelta,\n  MessageDeltaEvent,\n  MessageListParams,\n  MessageRetrieveParams,\n  MessageUpdateParams,\n  Messages,\n  MessagesPage,\n  RefusalContentBlock,\n  RefusalDeltaBlock,\n  Text,\n  TextContentBlock,\n  TextContentBlockParam,\n  TextDelta,\n  TextDeltaBlock,\n} from './messages';\nimport * as RunsAPI from './runs/runs';\nimport {\n  RequiredActionFunctionToolCall,\n  Run,\n  RunCreateAndPollParams,\n  RunCreateAndStreamParams,\n  RunCancelParams,\n  RunCreateParams,\n  RunCreateParamsNonStreaming,\n  RunCreateParamsStreaming,\n  RunListParams,\n  RunRetrieveParams,\n  RunStatus,\n  RunStreamParams,\n  RunSubmitToolOutputsAndPollParams,\n  RunSubmitToolOutputsParams,\n  RunSubmitToolOutputsParamsNonStreaming,\n  RunSubmitToolOutputsParamsStreaming,\n  RunSubmitToolOutputsStreamParams,\n  RunUpdateParams,\n  Runs,\n  RunsPage,\n} from './runs/runs';\nimport { APIPromise } from '../../../core/api-promise';\nimport { Stream } from '../../../core/streaming';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { AssistantStream, ThreadCreateAndRunParamsBaseStream } from '../../../lib/AssistantStream';\nimport { path } from '../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Threads extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * Create a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  create(body: ThreadCreateParams | null | undefined = {}, options?: RequestOptions): APIPromise<Thread> {\n    return this._client.post('/threads', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(threadID: string, options?: RequestOptions): APIPromise<Thread> {\n    return this._client.get(path`/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  update(threadID: string, body: ThreadUpdateParams, options?: RequestOptions): APIPromise<Thread> {\n    return this._client.post(path`/threads/${threadID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  delete(threadID: string, options?: RequestOptions): APIPromise<ThreadDeleted> {\n    return this._client.delete(path`/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Create a thread and run it in one request.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  createAndRun(body: ThreadCreateAndRunParamsNonStreaming, options?: RequestOptions): APIPromise<RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParams,\n    options?: RequestOptions,\n  ): APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post('/threads/runs', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      stream: body.stream ?? false,\n    }) as APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to create a thread, start a run and then poll for a terminal state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndRunPoll(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Threads.Run> {\n    const run = await this.createAndRun(body, options);\n    return await this.runs.poll(run.id, { thread_id: run.thread_id }, options);\n  }\n\n  /**\n   * Create a thread and stream the run back\n   */\n  createAndRunStream(body: ThreadCreateAndRunParamsBaseStream, options?: RequestOptions): AssistantStream {\n    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n  }\n}\n\n/**\n * Specifies the format that the model must output. Compatible with\n * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n *\n * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n * Outputs which ensures the model will match your supplied JSON schema. Learn more\n * in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n * message the model generates is valid JSON.\n *\n * **Important:** when using JSON mode, you **must** also instruct the model to\n * produce JSON yourself via a system or user message. Without this, the model may\n * generate an unending stream of whitespace until the generation reaches the token\n * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n * the message content may be partially cut off if `finish_reason=\"length\"`, which\n * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n * max context length.\n */\nexport type AssistantResponseFormatOption =\n  | 'auto'\n  | Shared.ResponseFormatText\n  | Shared.ResponseFormatJSONObject\n  | Shared.ResponseFormatJSONSchema;\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * tool.\n */\nexport interface AssistantToolChoice {\n  /**\n   * The type of the tool. If type is `function`, the function name must be set\n   */\n  type: 'function' | 'code_interpreter' | 'file_search';\n\n  function?: AssistantToolChoiceFunction;\n}\n\nexport interface AssistantToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tools and instead generates a message. `auto` is the default value\n * and means the model can pick between generating a message or calling one or more\n * tools. `required` means the model must call one or more tools before responding\n * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n */\nexport type AssistantToolChoiceOption = 'none' | 'auto' | 'required' | AssistantToolChoice;\n\n/**\n * Represents a thread that contains\n * [messages](https://platform.openai.com/docs/api-reference/messages).\n */\nexport interface Thread {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread`.\n   */\n  object: 'thread';\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources: Thread.ToolResources | null;\n}\n\nexport namespace Thread {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface ThreadDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.deleted';\n}\n\nexport interface ThreadCreateParams {\n  /**\n   * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n   * start the thread with.\n   */\n  messages?: Array<ThreadCreateParams.Message>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadCreateParams.ToolResources | null;\n}\n\nexport namespace ThreadCreateParams {\n  export interface Message {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<Message.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  export namespace Message {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n       * store attached to the thread.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to an object. This can be useful\n         * for storing additional information about the object in a structured format, and\n         * querying for objects via API or the dashboard.\n         *\n         * Keys are strings with a maximum length of 64 characters. Values are strings with\n         * a maximum length of 512 characters.\n         */\n        metadata?: Shared.Metadata | null;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface ThreadUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadUpdateParams.ToolResources | null;\n}\n\nexport namespace ThreadUpdateParams {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport type ThreadCreateAndRunParams =\n  | ThreadCreateAndRunParamsNonStreaming\n  | ThreadCreateAndRunParamsStreaming;\n\nexport interface ThreadCreateAndRunParamsBase {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?: (string & {}) | Shared.ChatModel | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Options to create a new thread. If no thread is provided when running a request,\n   * an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunParams {\n  /**\n   * Options to create a new thread. If no thread is provided when running a request,\n   * an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format, and\n       * querying for objects via API or the dashboard.\n       *\n       * Keys are strings with a maximum length of 64 characters. Values are strings with\n       * a maximum length of 512 characters.\n       */\n      metadata?: Shared.Metadata | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n      }\n\n      export namespace Attachment {\n        export interface FileSearch {\n          /**\n           * The type of tool being defined: `file_search`\n           */\n          type: 'file_search';\n        }\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n           * strategy.\n           */\n          chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to an object. This can be useful\n           * for storing additional information about the object in a structured format, and\n           * querying for objects via API or the dashboard.\n           *\n           * Keys are strings with a maximum length of 64 characters. Values are strings with\n           * a maximum length of 512 characters.\n           */\n          metadata?: Shared.Metadata | null;\n        }\n\n        export namespace VectorStore {\n          /**\n           * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n           * `800` and `chunk_overlap_tokens` of `400`.\n           */\n          export interface Auto {\n            /**\n             * Always `auto`.\n             */\n            type: 'auto';\n          }\n\n          export interface Static {\n            static: Static.Static;\n\n            /**\n             * Always `static`.\n             */\n            type: 'static';\n          }\n\n          export namespace Static {\n            export interface Static {\n              /**\n               * The number of tokens that overlap between chunks. The default value is `400`.\n               *\n               * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n               */\n              chunk_overlap_tokens: number;\n\n              /**\n               * The maximum number of tokens in each chunk. The default value is `800`. The\n               * minimum value is `100` and the maximum value is `4096`.\n               */\n              max_chunk_size_tokens: number;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export type ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n}\n\nexport interface ThreadCreateAndRunParamsNonStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface ThreadCreateAndRunParamsStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface ThreadCreateAndRunPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunPollParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunPollParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunPollParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunPollParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport type ThreadCreateAndRunStreamParams = ThreadCreateAndRunParamsBaseStream;\n\nThreads.Runs = Runs;\nThreads.Messages = Messages;\n\nexport declare namespace Threads {\n  export {\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n\n  export {\n    Runs as Runs,\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    type RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCancelParams as RunCancelParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Messages as Messages,\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type MessagesAPIMessage as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    type MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageRetrieveParams as MessageRetrieveParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n    type MessageDeleteParams as MessageDeleteParams,\n  };\n\n  export { AssistantStream };\n}\n","import type { BaseNextRequest, BaseNextResponse } from './base-http'\nimport { isNodeNextResponse } from './base-http/helpers'\n\nimport { pipeToNodeResponse } from './pipe-readable'\nimport { splitCookiesString } from './web/utils'\n\n/**\n * Sends the response on the underlying next response object.\n *\n * @param req the underlying request object\n * @param res the underlying response object\n * @param response the response to send\n */\nexport async function sendResponse(\n  req: BaseNextRequest,\n  res: BaseNextResponse,\n  response: Response,\n  waitUntil?: Promise<unknown>\n): Promise<void> {\n  if (\n    // The type check here ensures that `req` is correctly typed, and the\n    // environment variable check provides dead code elimination.\n    process.env.NEXT_RUNTIME !== 'edge' &&\n    isNodeNextResponse(res)\n  ) {\n    // Copy over the response status.\n    res.statusCode = response.status\n    res.statusMessage = response.statusText\n\n    // TODO: this is not spec-compliant behavior and we should not restrict\n    // headers that are allowed to appear many times.\n    //\n    // See:\n    // https://github.com/vercel/next.js/pull/70127\n    const headersWithMultipleValuesAllowed = [\n      // can add more headers to this list if needed\n      'set-cookie',\n      'www-authenticate',\n      'proxy-authenticate',\n      'vary',\n    ]\n\n    // Copy over the response headers.\n    response.headers?.forEach((value, name) => {\n      // `x-middleware-set-cookie` is an internal header not needed for the response\n      if (name.toLowerCase() === 'x-middleware-set-cookie') {\n        return\n      }\n\n      // The append handling is special cased for `set-cookie`.\n      if (name.toLowerCase() === 'set-cookie') {\n        // TODO: (wyattjoh) replace with native response iteration when we can upgrade undici\n        for (const cookie of splitCookiesString(value)) {\n          res.appendHeader(name, cookie)\n        }\n      } else {\n        // only append the header if it is either not present in the outbound response\n        // or if the header supports multiple values\n        const isHeaderPresent = typeof res.getHeader(name) !== 'undefined'\n        if (\n          headersWithMultipleValuesAllowed.includes(name.toLowerCase()) ||\n          !isHeaderPresent\n        ) {\n          res.appendHeader(name, value)\n        }\n      }\n    })\n\n    /**\n     * The response can't be directly piped to the underlying response. The\n     * following is duplicated from the edge runtime handler.\n     *\n     * See packages/next/server/next-server.ts\n     */\n\n    const { originalResponse } = res\n\n    // A response body must not be sent for HEAD requests. See https://httpwg.org/specs/rfc9110.html#HEAD\n    if (response.body && req.method !== 'HEAD') {\n      await pipeToNodeResponse(response.body, originalResponse, waitUntil)\n    } else {\n      originalResponse.end()\n    }\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as FilesAPI from '../files';\nimport * as PartsAPI from './parts';\nimport { PartCreateParams, Parts, UploadPart } from './parts';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Uploads extends APIResource {\n  parts: PartsAPI.Parts = new PartsAPI.Parts(this._client);\n\n  /**\n   * Creates an intermediate\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object\n   * that you can add\n   * [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.\n   * Currently, an Upload can accept at most 8 GB in total and expires after an hour\n   * after you create it.\n   *\n   * Once you complete the Upload, we will create a\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * contains all the parts you uploaded. This File is usable in the rest of our\n   * platform as a regular File object.\n   *\n   * For certain `purpose` values, the correct `mime_type` must be specified. Please\n   * refer to documentation for the\n   * [supported MIME types for your use case](https://platform.openai.com/docs/assistants/tools/file-search#supported-files).\n   *\n   * For guidance on the proper filename extensions for each purpose, please follow\n   * the documentation on\n   * [creating a File](https://platform.openai.com/docs/api-reference/files/create).\n   */\n  create(body: UploadCreateParams, options?: RequestOptions): APIPromise<Upload> {\n    return this._client.post('/uploads', { body, ...options });\n  }\n\n  /**\n   * Cancels the Upload. No Parts may be added after an Upload is cancelled.\n   */\n  cancel(uploadID: string, options?: RequestOptions): APIPromise<Upload> {\n    return this._client.post(path`/uploads/${uploadID}/cancel`, options);\n  }\n\n  /**\n   * Completes the\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object).\n   *\n   * Within the returned Upload object, there is a nested\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * is ready to use in the rest of the platform.\n   *\n   * You can specify the order of the Parts by passing in an ordered list of the Part\n   * IDs.\n   *\n   * The number of bytes uploaded upon completion must match the number of bytes\n   * initially specified when creating the Upload object. No Parts may be added after\n   * an Upload is completed.\n   */\n  complete(uploadID: string, body: UploadCompleteParams, options?: RequestOptions): APIPromise<Upload> {\n    return this._client.post(path`/uploads/${uploadID}/complete`, { body, ...options });\n  }\n}\n\n/**\n * The Upload object can accept byte chunks in the form of Parts.\n */\nexport interface Upload {\n  /**\n   * The Upload unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The intended number of bytes to be uploaded.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload will expire.\n   */\n  expires_at: number;\n\n  /**\n   * The name of the file to be uploaded.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always \"upload\".\n   */\n  object: 'upload';\n\n  /**\n   * The intended purpose of the file.\n   * [Please refer here](https://platform.openai.com/docs/api-reference/files/object#files/object-purpose)\n   * for acceptable values.\n   */\n  purpose: string;\n\n  /**\n   * The status of the Upload.\n   */\n  status: 'pending' | 'completed' | 'cancelled' | 'expired';\n\n  /**\n   * The `File` object represents a document that has been uploaded to OpenAI.\n   */\n  file?: FilesAPI.FileObject | null;\n}\n\nexport interface UploadCreateParams {\n  /**\n   * The number of bytes in the file you are uploading.\n   */\n  bytes: number;\n\n  /**\n   * The name of the file to upload.\n   */\n  filename: string;\n\n  /**\n   * The MIME type of the file.\n   *\n   * This must fall within the supported MIME types for your file purpose. See the\n   * supported MIME types for assistants and vision.\n   */\n  mime_type: string;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * See the\n   * [documentation on File purposes](https://platform.openai.com/docs/api-reference/files/create#files-create-purpose).\n   */\n  purpose: FilesAPI.FilePurpose;\n\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  expires_after?: UploadCreateParams.ExpiresAfter;\n}\n\nexport namespace UploadCreateParams {\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `created_at`.\n     */\n    anchor: 'created_at';\n\n    /**\n     * The number of seconds after the anchor time that the file will expire. Must be\n     * between 3600 (1 hour) and 2592000 (30 days).\n     */\n    seconds: number;\n  }\n}\n\nexport interface UploadCompleteParams {\n  /**\n   * The ordered list of Part IDs.\n   */\n  part_ids: Array<string>;\n\n  /**\n   * The optional md5 checksum for the file contents to verify if the bytes uploaded\n   * matches what you expect.\n   */\n  md5?: string;\n}\n\nUploads.Parts = Parts;\n\nexport declare namespace Uploads {\n  export {\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export { Parts as Parts, type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../core/pagination';\nimport { type Uploadable } from '../core/uploads';\nimport { buildHeaders } from '../internal/headers';\nimport { RequestOptions } from '../internal/request-options';\nimport { sleep } from '../internal/utils/sleep';\nimport { APIConnectionTimeoutError } from '../error';\nimport { multipartFormRequestOptions } from '../internal/uploads';\nimport { path } from '../internal/utils/path';\n\nexport class Files extends APIResource {\n  /**\n   * Upload a file that can be used across various endpoints. Individual files can be\n   * up to 512 MB, and each project can store up to 2.5 TB of files in total. There\n   * is no organization-wide storage limit.\n   *\n   * - The Assistants API supports files up to 2 million tokens and of specific file\n   *   types. See the\n   *   [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools)\n   *   for details.\n   * - The Fine-tuning API only supports `.jsonl` files. The input also has certain\n   *   required formats for fine-tuning\n   *   [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input)\n   *   or\n   *   [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   *   models.\n   * - The Batch API only supports `.jsonl` files up to 200 MB in size. The input\n   *   also has a specific required\n   *   [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n   *\n   * Please [contact us](https://help.openai.com/) if you need to increase these\n   * storage limits.\n   */\n  create(body: FileCreateParams, options?: RequestOptions): APIPromise<FileObject> {\n    return this._client.post('/files', multipartFormRequestOptions({ body, ...options }, this._client));\n  }\n\n  /**\n   * Returns information about a specific file.\n   */\n  retrieve(fileID: string, options?: RequestOptions): APIPromise<FileObject> {\n    return this._client.get(path`/files/${fileID}`, options);\n  }\n\n  /**\n   * Returns a list of files.\n   */\n  list(\n    query: FileListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FileObjectsPage, FileObject> {\n    return this._client.getAPIList('/files', CursorPage<FileObject>, { query, ...options });\n  }\n\n  /**\n   * Delete a file and remove it from all vector stores.\n   */\n  delete(fileID: string, options?: RequestOptions): APIPromise<FileDeleted> {\n    return this._client.delete(path`/files/${fileID}`, options);\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   */\n  content(fileID: string, options?: RequestOptions): APIPromise<Response> {\n    return this._client.get(path`/files/${fileID}/content`, {\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/binary' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n\n  /**\n   * Waits for the given file to be processed, default timeout is 30 mins.\n   */\n  async waitForProcessing(\n    id: string,\n    { pollInterval = 5000, maxWait = 30 * 60 * 1000 }: { pollInterval?: number; maxWait?: number } = {},\n  ): Promise<FileObject> {\n    const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\n\n    const start = Date.now();\n    let file = await this.retrieve(id);\n\n    while (!file.status || !TERMINAL_STATES.has(file.status)) {\n      await sleep(pollInterval);\n\n      file = await this.retrieve(id);\n      if (Date.now() - start > maxWait) {\n        throw new APIConnectionTimeoutError({\n          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\n        });\n      }\n    }\n\n    return file;\n  }\n}\n\nexport type FileObjectsPage = CursorPage<FileObject>;\n\nexport type FileContent = string;\n\nexport interface FileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'file';\n}\n\n/**\n * The `File` object represents a document that has been uploaded to OpenAI.\n */\nexport interface FileObject {\n  /**\n   * The file identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The size of the file, in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the file.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always `file`.\n   */\n  object: 'file';\n\n  /**\n   * The intended purpose of the file. Supported values are `assistants`,\n   * `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`,\n   * `vision`, and `user_data`.\n   */\n  purpose:\n    | 'assistants'\n    | 'assistants_output'\n    | 'batch'\n    | 'batch_output'\n    | 'fine-tune'\n    | 'fine-tune-results'\n    | 'vision'\n    | 'user_data';\n\n  /**\n   * @deprecated Deprecated. The current status of the file, which can be either\n   * `uploaded`, `processed`, or `error`.\n   */\n  status: 'uploaded' | 'processed' | 'error';\n\n  /**\n   * The Unix timestamp (in seconds) for when the file will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * @deprecated Deprecated. For details on why a fine-tuning training file failed\n   * validation, see the `error` field on `fine_tuning.job`.\n   */\n  status_details?: string;\n}\n\n/**\n * The intended purpose of the uploaded file. One of:\n *\n * - `assistants`: Used in the Assistants API\n * - `batch`: Used in the Batch API\n * - `fine-tune`: Used for fine-tuning\n * - `vision`: Images used for vision fine-tuning\n * - `user_data`: Flexible file type for any purpose\n * - `evals`: Used for eval data sets\n */\nexport type FilePurpose = 'assistants' | 'batch' | 'fine-tune' | 'vision' | 'user_data' | 'evals';\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file: Uploadable;\n\n  /**\n   * The intended purpose of the uploaded file. One of:\n   *\n   * - `assistants`: Used in the Assistants API\n   * - `batch`: Used in the Batch API\n   * - `fine-tune`: Used for fine-tuning\n   * - `vision`: Images used for vision fine-tuning\n   * - `user_data`: Flexible file type for any purpose\n   * - `evals`: Used for eval data sets\n   */\n  purpose: FilePurpose;\n\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  expires_after?: FileCreateParams.ExpiresAfter;\n}\n\nexport namespace FileCreateParams {\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `created_at`.\n     */\n    anchor: 'created_at';\n\n    /**\n     * The number of seconds after the anchor time that the file will expire. Must be\n     * between 3600 (1 hour) and 2592000 (30 days).\n     */\n    seconds: number;\n  }\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Only return files with the given purpose.\n   */\n  purpose?: string;\n}\n\nexport declare namespace Files {\n  export {\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    type FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n}\n"],"names":["sharedAsyncLocalStorageNotAvailableError","Error","FakeAsyncLocalStorage","disable","getStore","undefined","run","exit","enterWith","bind","fn","maybeGlobalAsyncLocalStorage","globalThis","AsyncLocalStorage","createAsyncLocalStorage","bindSnapshot","createSnapshot","snapshot","args","getEdgePreviewProps","previewModeId","process","env","__NEXT_PREVIEW_MODE_ID","previewModeSigningKey","__NEXT_PREVIEW_MODE_SIGNING_KEY","previewModeEncryptionKey","__NEXT_PREVIEW_MODE_ENCRYPTION_KEY","getTestReqInfo","withRequest","testStorage","extractTestInfoFromRequest","req","reader","proxyPortHeader","header","url","proxyPort","Number","testData","testReqInfo","handleFetch","interceptFetch","name","headers","get","getTestStack","stack","split","i","length","slice","filter","f","includes","map","s","replace","trim","join","buildProxyRequest","request","method","body","cache","credentials","integrity","mode","redirect","referrer","referrerPolicy","api","Array","from","Buffer","arrayBuffer","toString","buildResponse","proxyResponse","status","response","Response","Headers","originalFetch","testInfo","proxyRequest","resp","JSON","stringify","next","internal","ok","json","global","fetch","testFetch","input","init","Request","interceptTestApis","wrapRequestHandler","handler","withRequestContext","path","NEXT_RUNTIME","require","module","exports","MODERN_BROWSERSLIST_TARGET","AppRouterContext","GlobalLayoutRouterContext","LayoutRouterContext","MissingSlotContext","TemplateContext","React","createContext","NODE_ENV","displayName","Set","__NEXT_EXPERIMENTAL_REACT","TURBOPACK","RSC_HEADER","forEach","value","toLowerCase","__NEXT_CACHE_COMPONENTS","URL","params","__NEXT_NO_MIDDLEWARE_URL_NORMALIZE"],"mappings":"4HAEA,IAAMA,EAA2C,OAAA,cAEhD,CAFoDC,AAAJ,MAC/C,8EAD+C,oBAAA,OAAA,mBAAA,gBAAA,CAEjD,EAEA,OAAMC,EAGJC,SAAgB,CACd,MAAMH,CACR,CAEAI,UAA8B,CAG9B,CAEAE,KAAY,CACV,MAAMN,CACR,CAEAO,MAAa,CACX,MAAMP,CACR,CAEAQ,WAAkB,CAChB,MAAMR,CACR,CAEA,OAAOS,KAAQC,CAAK,CAAK,CACvB,OAAOA,CACT,CACF,CAEA,IAAMC,EACkB,IAAtB,OAAOC,YAA+BA,WAAmBC,iBAAiB,CAErE,SAASC,WAGd,AAAIH,EACK,IAAIA,EAEN,IAAIT,CACb,iBAJoC,qDCxCpC,IAAI,EAAY,OAAO,cAAc,CACjC,EAAmB,OAAO,wBAAwB,CAClD,EAAoB,OAAO,mBAAmB,CAC9C,EAAe,OAAO,SAAS,CAAC,cAAc,CAgB9C,EAAc,CAAC,EAfK,EAgBF,CACpB,eAAgB,IAAM,EACtB,gBAAiB,IAAM,EACvB,YAAa,IAAM,EACnB,eAAgB,IAAM,EACtB,gBAAiB,IAAM,CACzB,EArBE,IAAK,IAAI,KAAQ,EACf,EAcK,EAda,EAAM,CAAE,GAAhB,CAAqB,CAAG,CAAC,EAAK,CAAE,YAAY,CAAK,GAwB/D,SAAS,EAAgB,CAAC,EACxB,IAAI,EACJ,IAAM,EAAQ,CACZ,SAAU,GAAK,EAAE,IAAI,EAAI,CAAC,KAAK,EAAE,EAAE,IAAI,CAAA,CAAE,CACzC,YAAa,IAAM,CAAD,CAAG,OAAO,MAAI,EAAE,OAAO,AAAK,CAAC,EAAK,CAAC,QAAQ,EAAE,CAAsB,UAArB,OAAO,EAAE,OAAO,CAAgB,IAAI,KAAK,EAAE,OAAO,EAAI,EAAE,OAAO,AAAP,EAAS,WAAW,GAAA,CAAI,CAChJ,WAAY,GAAyB,UAApB,OAAO,EAAE,MAAM,EAAiB,CAAC,QAAQ,EAAE,EAAE,MAAM,CAAA,CAAE,CACtE,WAAY,GAAK,EAAE,MAAM,EAAI,CAAC,OAAO,EAAE,EAAE,MAAM,CAAA,CAAE,CACjD,WAAY,GAAK,EAAE,MAAM,EAAI,SAC7B,aAAc,GAAK,EAAE,QAAQ,EAAI,WACjC,aAAc,GAAK,EAAE,QAAQ,EAAI,CAAC,SAAS,EAAE,EAAE,QAAQ,CAAA,CAAE,CACzD,gBAAiB,GAAK,EAAE,WAAW,EAAI,cACvC,aAAc,GAAK,EAAE,QAAQ,EAAI,CAAC,SAAS,EAAE,EAAE,QAAQ,CAAA,CAAE,CAC1D,CAAC,MAAM,CAAC,SACH,EAAc,CAAA,EAAG,EAAE,IAAI,CAAC,CAAC,EAAE,mBAAqC,AAAlB,OAAC,EAAK,EAAE,KAAK,AAAL,EAAiB,EAAK,IAAA,CAAK,CACvF,OAAwB,IAAjB,EAAM,MAAM,CAAS,EAAc,CAAA,EAAG,EAAY,EAAE,EAAE,EAAM,IAAI,CAAC,MAAA,CAC1E,AADiF,CAEjF,SAAS,EAAY,CAAM,EACzB,IAAM,EAAsB,IAAhB,AAAoB,IAChC,IAAK,IAAM,CADc,IACN,EAAO,KAAK,CAAC,OAAQ,CACtC,GAAI,CAAC,EACH,SACF,IAAM,EAAU,EAAK,OAAO,CAAC,KAC7B,GAAgB,CAAC,IAAb,EAAgB,CAClB,EAAI,GAAG,CAAC,EAAM,QACd,QACF,CACA,GAAM,CAAC,EAAK,EAAM,CAAG,CAAC,EAAK,KAAK,CAAC,EAAG,GAAU,EAAK,KAAK,CAAC,EAAU,GAAG,CACtE,GAAI,CACF,EAAI,GAAG,CAAC,EAAK,mBAAmB,AAAS,QAAO,EAAQ,QAC1D,CAAE,KAAM,CACR,CACF,CACA,OAAO,CACT,CACA,SAAS,EAAe,CAAS,EAC/B,GAAI,CAAC,EACH,OAAO,AAET,EAHgB,CAGV,CAAC,CAFO,AAEN,EAAM,EAAM,CAAE,GAAG,EAAW,CAAG,EAAY,GAC7C,QACJ,CAAM,SACN,CAAO,UACP,CAAQ,QACR,CAAM,MACN,CAAI,UACJ,CAAQ,QACR,CAAM,aACN,CAAW,UACX,CAAQ,CACT,CAAG,OAAO,WAAW,CACpB,EAAW,GAAG,CAAC,CAAC,CAAC,EAAK,EAAO,GAAK,CAChC,EAAI,WAAW,GAAG,OAAO,CAAC,KAAM,IAChC,EACD,EAeI,MAYc,EAZN,EAEA,CAAC,CAfD,AAyBY,CAxBzB,OACA,MAAO,mBAAmB,UAC1B,EACA,GAAG,GAAW,CAAE,QAAS,IAAI,KAAK,EAAS,CAAC,CAC5C,GAAG,GAAY,CAAE,SAAU,EAAK,CAAC,CACjC,GAAqB,UAAlB,OAAO,GAAuB,CAAE,OAAQ,OAAO,EAAQ,CAAC,CAC3D,OACA,GAAG,GAAY,CAAE,QAAA,CAmBZ,CAnBsB,CAmBZ,QAAQ,CADzB,AAC0B,EADjB,GAlBkC,GAkB3B,WAAW,IACS,EAAS,KAAK,CAnBG,CAAC,CACpD,GAAG,GAAU,CAAE,QAAQ,CAAK,CAAC,CAC7B,GAAG,GAAY,CAAE,QAAA,CAsBZ,CAtBsB,CAsBb,QAAQ,CADxB,AACyB,EADhB,CADY,EApBsB,GAqB3B,CADW,UACA,IACQ,EAAS,KAAK,CAtBI,CAAC,CACpD,GAAG,GAAe,CAAE,aAAa,CAAK,CACxC,AADyC,EAKzC,IAAM,EAAO,CAAC,EACd,IAAK,IAAM,KAAO,EAAG,AACf,CAAC,CAAC,EAAI,EAAE,CACV,CAAI,CAAC,EAAI,CAAG,CAAC,CAAC,EAAI,AAAJ,EAGlB,OAAO,CATQ,CACjB,CAxEA,EAAO,OAAO,CAXc,CARV,CAmBD,AAnBE,EAAI,EAAM,EAAQ,KACnC,GAAI,GAAwB,UAAhB,OAAO,GAAqC,YAAhB,AAA4B,OAArB,EAC7C,IAAK,IAAI,KAAO,EAAkB,GAC3B,AAAD,EAAc,CAAlB,GAAsB,CAAC,EAAI,IAAQ,IAAQ,GACzC,EAAU,EAAI,EAAK,CAAE,IAAK,IAAM,CAAI,CAAC,EAAI,CAAE,WAAY,CAAC,CAAC,EAAO,EAAiB,EAAM,EAAA,CAAI,EAAK,EAAK,UAAU,AAAC,GAEtH,OAAO,EACT,EACwC,EAAU,CAAC,EAAG,aAAc,CAAE,OAAO,CAAK,GAWpD,CAXwD,EA6FtF,IAAI,EAAY,CAAC,SAAU,MAAO,OAAO,CAKrC,EAAW,CAAC,MAAO,SAAU,OAAO,CA0DpC,EAAiB,MACnB,YAAY,CAAc,CAAE,CAE1B,IAAI,CAAC,OAAO,CAAmB,EAAhB,EAAoB,IACnC,IAAI,CAAC,EADuB,MACf,CAAG,EAChB,MAAM,EAAS,EAAe,GAAG,CAAC,UAClC,GAAI,EAEF,IAAK,EAFK,GAEC,CAAC,EAAM,EAAM,GADT,CACa,CADD,GAEzB,GADkC,CAC9B,CAAC,OAAO,CAAC,GAAG,CAAC,EAAM,MAAE,QAAM,CAAM,EAG3C,CACA,CAAC,OAAO,QAAQ,CAAC,EAAG,CAClB,OAAO,IAAI,CAAC,OAAO,CAAC,OAAO,QAAQ,CAAC,EACtC,CAIA,IAAI,MAAO,CACT,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,AAC1B,CACA,IAAI,GAAG,CAAI,CAAE,CACX,IAAM,EAA0B,UAAnB,OAAO,CAAI,CAAC,EAAE,CAAgB,CAAI,CAAC,EAAE,CAAG,CAAI,CAAC,EAAE,CAAC,IAAI,CACjE,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,EAC1B,CACA,OAAO,GAAG,CAAI,CAAE,CACd,IAAI,EACJ,IAAM,EAAM,MAAM,IAAI,CAAC,IAAI,CAAC,OAAO,EACnC,GAAI,CAAC,EAAK,MAAM,CACd,CADgB,MACT,EAAI,GAAG,CAAC,CAAC,CAAC,EAAG,EAAM,GAAK,GAEjC,IAAM,EAA0B,UAAnB,OAAO,CAAI,CAAC,EAAE,CAAgB,CAAI,CAAC,EAAE,CAAG,AAAkB,OAAjB,EAAK,CAAI,CAAC,EAAA,AAAE,EAAY,KAAK,EAAI,EAAG,IAAI,CAC9F,OAAO,EAAI,MAAM,CAAC,CAAC,CAAC,EAAE,GAAK,IAAM,GAAM,GAAG,CAAC,CAAC,CAAC,EAAG,EAAM,GAAK,EAC7D,CACA,IAAI,CAAI,CAAE,CACR,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,EAC1B,CACA,IAAI,GAAG,CAAI,CAAE,CACX,GAAM,CAAC,EAAM,EAAM,CAAmB,IAAhB,EAAK,MAAM,CAAS,CAAC,CAAI,CAAC,EAAE,CAAC,IAAI,CAAE,CAAI,CAAC,EAAE,CAAC,KAAK,CAAC,CAAG,EACpE,EAAM,IAAI,CAAC,OAAO,CAMxB,OALA,EAAI,GAAG,CAAC,EAAM,MAAE,QAAM,CAAM,GAC5B,IAAI,CAAC,QAAQ,CAAC,GAAG,CACf,SACA,MAAM,IAAI,CAAC,GAAK,GAAG,CAAC,CAAC,CAAC,EAAG,EAAO,GAAK,EAAgB,IAAS,IAAI,CAAC,OAE9D,IAAI,AACb,CAIA,OAAO,CAAK,CAAE,CACZ,IAAM,EAAM,IAAI,CAAC,OAAO,CAClB,EAAS,AAAC,MAAM,OAAO,CAAC,GAA6B,EAAM,GAAG,CAAC,AAAC,GAAS,EAAI,MAAM,CAAC,IAAnD,EAAI,MAAM,CAAC,GAKlD,OAJA,IAAI,CAAC,QAAQ,CAAC,GAAG,CACf,SACA,MAAM,IAAI,CAAC,GAAK,GAAG,CAAC,CAAC,CAAC,EAAG,EAAM,GAAK,EAAgB,IAAQ,IAAI,CAAC,OAE5D,CACT,CAIA,OAAQ,CAEN,OADA,IAAI,CAAC,MAAM,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,KACjC,IAAI,AACb,CAIA,CAAC,OAAO,GAAG,CAAC,+BAA+B,EAAG,CAC5C,MAAO,CAAC,eAAe,EAAE,KAAK,SAAS,CAAC,OAAO,WAAW,CAAC,IAAI,CAAC,OAAO,GAAA,CAAI,AAC7E,CACA,UAAW,CACT,MAAO,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,GAAG,CAAC,AAAC,GAAM,CAAA,EAAG,EAAE,IAAI,CAAC,CAAC,EAAE,mBAAmB,EAAE,KAAK,EAAA,CAAG,EAAE,IAAI,CAAC,KAChG,CACF,EAGI,EAAkB,MACpB,YAAY,CAAe,CAAE,KAGvB,EAAI,EAAI,EADZ,IAAI,CAAC,OAAO,CAAmB,EAAhB,EAAoB,IAEnC,IAAI,CAAC,EAFuB,MAEf,CAAG,EAChB,MAAM,EAA8J,AAAlJ,OAAC,EAAK,AAA0F,OAAzF,EAAK,AAAuC,OAAtC,EAAK,EAAgB,YAAA,AAAY,EAAY,KAAK,EAAI,EAAG,IAAI,CAAC,EAAA,CAAgB,CAAY,EAAK,EAAgB,GAAG,CAAC,aAAA,CAAa,CAAY,EAAK,EAAE,CAElL,IAAK,MAAM,KADW,MAAM,KACD,EADQ,CAAC,GAAa,EAAY,AA3IjE,SAAS,AAAmB,CAAa,EACvC,GAAI,CAAC,EACH,MAAO,EAAE,CACX,IAEI,EACA,EACA,EACA,EACA,EANA,EAAiB,EAAE,CACnB,EAAM,EAMV,SAAS,IACP,KAAO,EAAM,EAAc,MAAM,EAAI,KAAK,IAAI,CAAC,EAAc,MAAM,CAAC,KAClE,CADyE,EAClE,EAET,OAAO,EAAM,EAAc,MAAM,AACnC,CAKA,KAAO,EAAM,EAAc,MAAM,EAAE,CAGjC,IAFA,EAAQ,EACR,GAAwB,EACjB,KAEL,GAAW,AAAP,OADJ,EADuB,AAClB,EAAc,MAAM,CAAC,EAAA,EACV,CAKd,IAJA,EAAY,EACZ,GAAO,EACP,IACA,EAAY,EACL,EAAM,EAAc,MAAM,EAZ9B,AAAO,EAY2B,KAbzC,EAAK,EAAc,MAAM,CAAC,CAaiC,CAbjC,GACE,MAAP,GAAqB,MAAP,GAa7B,GAAO,EAEL,EAAM,EAAc,MAAM,EAAI,AAA8B,KAAK,GAArB,MAAM,CAAC,IACrD,GAAwB,EACxB,EAAM,EACN,EAAe,IAAI,CAAC,EAAc,SAAS,CAAC,EAAO,IACnD,EAAQ,GAER,EAAM,EAAY,CAEtB,MACE,CADK,EACE,GAGP,CAAC,GAAyB,GAAO,EAAc,MAAA,AAAM,EAAE,CACzD,EAAe,IAAI,CAAC,EAAc,SAAS,CAAC,EAAO,EAAc,MAAM,EAE3E,CACA,OAAO,CACT,EAyFoF,GACtC,CACxC,MAAM,EAAS,EAAe,GAC1B,GACF,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,EAAO,IAAI,CAAE,EAClC,CACF,CAIA,IAAI,GAAG,CAAI,CAAE,CACX,IAAM,EAAM,AAAmB,iBAAZ,CAAI,CAAC,EAAE,CAAgB,CAAI,CAAC,EAAE,CAAG,CAAI,CAAC,EAAE,CAAC,IAAI,CAChE,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,EAC1B,CAIA,OAAO,GAAG,CAAI,CAAE,CACd,IAAI,EACJ,IAAM,EAAM,MAAM,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,MAAM,IAC1C,GAAI,CAAC,EAAK,MAAM,CACd,CADgB,MACT,EAET,IAAM,EAAM,AAAmB,iBAAZ,CAAI,CAAC,EAAE,CAAgB,CAAI,CAAC,EAAE,CAAG,AAAkB,OAAjB,EAAK,CAAI,CAAC,EAAA,AAAE,EAAY,KAAK,EAAI,EAAG,IAAI,CAC7F,OAAO,EAAI,MAAM,CAAC,AAAC,GAAM,EAAE,IAAI,GAAK,EACtC,CACA,IAAI,CAAI,CAAE,CACR,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,EAC1B,CAIA,IAAI,GAAG,CAAI,CAAE,CACX,GAAM,CAAC,EAAM,EAAO,EAAO,CAAmB,IAAhB,EAAK,MAAM,CAAS,CAAC,CAAI,CAAC,EAAE,CAAC,IAAI,CAAE,CAAI,CAAC,EAAE,CAAC,KAAK,CAAE,CAAI,CAAC,EAAE,CAAC,CAAG,EACrF,EAAM,IAAI,CAAC,OAAO,CAGxB,OAFA,EAAI,GAAG,CAAC,EAAM,AAyBlB,SAAS,AAAgB,EAAS,CAAE,KAAM,GAAI,MAAO,EAAG,CAAC,EAUvD,MAT8B,UAA1B,AAAoC,OAA7B,EAAO,OAAO,GACvB,EAAO,OAAO,CAAG,IAAI,KAAK,EAAO,QAAO,EAEtC,EAAO,MAAM,EAAE,CACjB,EAAO,OAAO,CAAG,IAAI,KAAK,KAAK,GAAG,GAAK,AAAgB,MAAT,MAAM,CAAG,GAErC,OAAhB,EAAO,IAAI,EAA6B,SAAhB,EAAO,IAAc,AAAV,GAAa,CAClD,EAAO,IAAI,CAAG,GAAA,EAET,CACT,EApCkC,MAAE,QAAM,EAAO,GAAG,CAAO,AAAD,IAkB1D,AAjBI,SAiBK,AAAQ,CAAG,CAAE,CAAO,EAE3B,IAAK,GAAM,EAAG,EAAM,GADpB,EAAQ,MAAM,CAAC,cACS,GAAK,CAC3B,IAAM,EAAa,EAAgB,GACnC,EAAQ,MAAM,CAAC,aAAc,EAC/B,CACF,EAvBY,EAAK,IAAI,CAAC,QAAQ,EACnB,IACT,AADa,CAKb,OAAO,GAAG,CAAI,CAAE,CACd,GAAM,CAAC,EAAM,EAAQ,CAAsB,UAAnB,OAAO,CAAI,CAAC,EAAE,CAAgB,CAAC,CAAI,CAAC,EAAE,CAAC,CAAG,CAAC,CAAI,CAAC,EAAE,CAAC,IAAI,CAAE,CAAI,CAAC,EAAE,CAAC,CACzF,OAAO,IAAI,CAAC,GAAG,CAAC,CAAE,GAAG,CAAO,MAAE,EAAM,MAAO,GAAI,QAAyB,CAAhB,GAAoB,KAAK,EAAG,EACtF,CADuE,AAEvE,CAAC,OAAO,GAAG,CAAC,+BAA+B,EAAG,CAC5C,MAAO,CAAC,gBAAgB,EAAE,KAAK,SAAS,CAAC,OAAO,WAAW,CAAC,IAAI,CAAC,OAAO,GAAA,CAAI,AAC9E,CACA,UAAW,CACT,MAAO,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,GAAG,CAAC,GAAiB,IAAI,CAAC,KAC9D,CACF,0D0B7RoB,GA0Db,YvBrEK,EFUA,EgCyCA,CRxCE,AlBaA,W0B2BU,AhC3BvB,AAdW,EyB2DC,EAAA,UzB3Da,kByBcL,6BAE8B,GRDT,AQC0B,IAAI,GAAG,EAAE,SAE5D,CAAA,SAAA,CAAA,EAAoB,OAAA,CfIM,CeJD,eAAe,CAAC,CI8DY,EJ9DT,CAAC,EAAzB,CAA4B,AAAC,CAAA,ATaT,ASbU,UAElD,CAAA,SAAA,CAAA,CAAA,CAAA,EACX,IAAA,EAAgB,IAAI,EAAY,EAAA,eAAoB,CAAC,AO0CE,CP1CD,SAC9C,eAAA,CAAA,GAAA,CAAA,EAAA,QAIL,CI4DK,UJ5DM,CAAA,SAAI,CAAW,CclCM,OdmCnB,IAAA,EAAA,EAAqB,CPLC,CAAC,CAAC,YOKY,SACpD,EAAQ,eAAe,CAAC,MAAM,CAAC,shBYjC7B,CGE6B,CAAA,8CHGjC,CAAuB,CACvB,CAAK,CACL,CAAA,mBACA,C3BsDoB,CAAA,UAAA,MAAA,C2BtDpB,iCAEU,IAAI,CAAA,KAAA,CAAA,EAAA,EAAA,CAAC,8BAGb,CAAA,SAAA,CAA2B,CAAE,CAAS,8BAIpC,CAAN,kBACS,IAAA,wCAIA,IAAA,GAEX,CAzBA,AAyBC,GHhBY,EACW,AADX,UAAA,OAAA,WACW,WAAA,AAEX,UAFW,OAEX,KACP,KAGA,EAFA,AAEA,CAAA,CZlBO,EAAA,kCYiBP,Q1ByGO,EAAe,UAtGR,M0BFd,O1BwG6C,GApGR,iBAGlB,EAAA,KAAgB,CAAC,2BAGzB,MAAA,+BAKS,CAAA,EAAA,SACA,CAAA,EAAA,aACI,CAAC,CAAC,CAAA,KAIK,MAAM,6BACV,CAAA,aACF,CYWG,WZPvB,EAAA,CAAA,cACa,CAAC,aAShB,SAAA,CAA2C,CEqBvB,A6BrCY,CfkBK,QhBDlB,CAAC,SAChB,OADgC,KAIhB,KEiB4B,CAAC,UFbhD,EAAA,EAAmC,KAAK,CAAC,EAAE,KAC5C,SAGI,EAAA,GAGT,IAAM,EAAsB,CUPH,CAAC,KVQjB,CAAA,CAAA,CAAA,EAAA,OACA,CAAC,CAAkB,CAAC,EAAE,CFaG,AEZhC,MAAO,CAAC,CAAkB,CAAA,EAAG,EgCvCT,CAAA,ShCwCR,CAAkB,CAAC,CAAC,CAAC,KAIG,MAAM,YAAV,EAKlC,EAAqB,KAAA,GAAU,EAAoB,KAAK,CAJtD,CAIwD,MAJjD,CUTK,CAAC,AVSE,MAQc,CAAC,EAAE,GAAb,KAAK,E+BfkB,M/BiBxC,EAAiB,KAAK,EgCpDT,ChCoDc,AgCpDb,EhCoDiC,EiCrDtD,EjCqDuB,CAAoC,EAAA,EACnC,KAAK,EAAI,CADoB,CACA,G+Bbb,E/BakB,EACnD,MACO,OAGF,E8BFa,A9BEL,I+BfJ,Q/BkBQ,KAAA,EAAS,EAAoB,KAAA,EAAO,MACxC,AAjDI,OAoDrB,EAAA,GAEJ,CAAC,AiCrDA,CjCsEmD,OAAO,CAAC,CAAC,GQjHjB,GAAA,CAAA,0BAClB,AAFJ,KAAA,CAAA,IAAA,CAAA,EAAA,EAOhB,SAAU,EAAA,CAAA,CAEd,CAA6B,CAC7B,CAAA,CACA,CAAqB,iCAE6B,CAAG,MAAA,CAAA,EAAA,CAAO,CAC1D,EACD,AADC,EACD,EAAI,EAAJ,QAAA,KAIG,CAAA,CAJH,EAIG,CAAA,CAAA,CAJH,CAIG,CAAA,OAEU,AAAI,CkBbD,ELkDM,GAAA,gEbpC6C,IAAM,CACvE,CAAC,8BACiC,sBAIR,CGTD,MHWV,MAAA,gDACkC,EAAI,OAAO,CAAA,QAAQ,EAAI,EAAA,4CAA8C,OAAS,CAC/H,CAAC,QACQ,CAAA,EAAA,KAAU,EAAA,EAAQ,OAAA,gBAIrB,CAAA,yDAEwC,EoBhDe,ApBgDX,CoBhDY,CpBgDZ,GAAK,EAAO,GAAG,CACnE,CADgE,AAC/D,CAEK,CShBD,kCTsBgB,CAAA,CAAA,EAAA,AAAqC,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,IAAS,CAAC,EAAV,CACtD,Ea2CE,Cb3CgB,CADoC,CACvB,UAG7B,MAH6C,AAG7C,CAAA,EAAA,CAAA,CAAA,EAAA,AAAqC,EAAA,KAAA,EAAA,CAAA,CAAG,EAAK,CAAC,SAGvC,EAAA,CAA0C,CAAA,CAAA,IACnD,KAAK,CAAA,kDAAA,EAC8C,KAAK,CqBpD1B,CrBoDiC,GAAG,CACtE,CAAC,AADkE,MApDtD,AAsDF,CAAA,CAAA,EAAqC,CAAC,WAGtC,CAAA,EAAM,0gByBvDD,CAAA,EAAA,SAAA,EAAsB,+CAGvC,8CAA2B,CAAd,IAAc,CAAA,0BACT,QAAS,IAAA,CAAK,UAAU,CAAA,EAC1C,CAAC,AH4BA,AhCiBA,AEZA,CgBAG,iCiB/BS,IAAA,EAAA,EAAA,CAAA,EAAA,EAAA,EAAA,UAAA,MAAA,CAAA,+BACK,CjCsCD,OiCtCU,IAAA,CAAA,UAAe,CAAA,qBAG1C,eAAY,SAAA,EAAA,EAAA,EAAA,UAAA,MAAc,CAAd,+BACM,CvBoCC,MAAA,IuBpCW,CAAC,UAAU,CAAA,EACzC,EAEO,EAAA,SAAA,CAAA,IAAA,CAAA,eAAK,SAAA,EAAA,EAAA,EAAA,UAAA,MAAA,CAAA,IAAc,AAAd,CH+CmC,AG/CnC,CAAA,EAAA,CAAA,SAAA,CAAA,EAAA,QACH,EAAS,OAAQ,CnC4DC,GmC5DG,CAAC,KnC4DK,KmC5DK,CAAE,wBAG3C,mBjC+CG,EAAA,EAAA,wBiC/CY,IAAc,ALuBjB,2BKtBM,UAAW,IAAI,CAAC,UAAA,CAAA,SAIpC,SAAS,EACP,CAAA,CACA,CAAiB,CACjB,CAAS,MAEH,EAAS,EAAA,WAEV,EAKL,CjCqDC,AUZF,CVYG,IiC1DW,CvB2CD,EuBvCP,OAAO,CAAC,GACN,CAAM,CAAC,EAAS,CAAA,GLsBL,EKtBK,CAAhB,EAAM,CFyCgB,AAAM,CAAC,AAAC,CAAA,CAAA,CAAA,EAAA,IEzC2B,OTFtD,CSEwD,ETFxD,CAAA,EAAY,CAAA,CAAA,qnBO7BxB,EAAA,oCAiBiD,wBAC1B,CrBUL,ARwBqB,QQxBrB,EAAA,EAAA,EqBVK,UAAA,MAAO,CAAP,IAAO,AAAP,CAAA,CAAA,EAAA,CAAA,SAAA,CAAA,EAAA,KCfT,EDgBS,EAAU,QAEzB,GAAK,CAAD,CACJ,OAAA,CAAA,CAAA,EAAuB,CAAA,KAAA,CAAA,EAAA,EAAA,EAAA,CAAA,EAAI,IAAI,QAAE,OA+CrC,C/BYC,E+BZI,CAAD,QAAU,GAAG,OArCf,C7BmCyB,C6BlCzB,CAAmD,EDchB,A7BUgB,C6BVf,A7BUgB,e8BxBpD,EAAA,CAAsB,QAAQ,CAAE,EAAa,IAAI,CAAA,CAAE,IAAP,CAE7B,EAAM,CAInB,CrBKiB,AqBTA,A/BgBI,S+BZrB,EAAY,AAAI,MAAA,sIAIhB,SADK,KAAA,CAAA,MAAA,CAAA,EAAM,EAAI,KAAA,AAAK,EAAA,EAAI,EAAI,CAAD,MAAQ,CAAC,CAAC,CAC9B,ErBQC,UqBLN,AAAuC,ErBKjC,KAAA,MqBJY,CAClB,SAAU,IAId,IAAM,EAAY,EAAU,QACtB,EAAY,OAAH,EpBvEnB,CAAA,CACA,CCEgB,ADFE,CFDsC,AhBFH,CAAC,SkBc7C,EAAA,CAAA,CAEP,CAAsB,MAEhB,EAAA,CAAA,CAAA,EAAA,OAEK,YAAP,OAAO,GAAA,GAAsC,QAC5B,CAAA,GAEd,WAAa,mBAlBY,CHCG,AYLA,ACKA,CbAC,CaAC,KVC5B,EAAA,EAAA,GAA2B,EAAE,CACtC,EAAW,EAAA,GAAA,AAAgB,UAkBtB,OACE,EAAA,QAAqB,CDPgB,CAAC,ACOJ,CDPK,AVDX,AEOF,ISCa,CAAC,ETDI,ISE7C,EAAA,OAAA,EAAA,IAAA,SACY,OAAA,EAAA,IAAA,QACX,EAAY,QAAA,EAAA,KAA2B,CJLG,AIKF,CJLG,CLOH,AKPI,CLOH,AsBqCtC,QbtCW,UAAA,EAAwB,CVGG,MUHI,IoB2ChD,OAAA,EAAA,EAAkB,QAAA,AAAQ,EAAA,EAAI,EAAJ,AAAiB,CAA1B,GAA8B,CAC/C,GAD0B,AAI5B,EAJ4C,CACpC,AAGR,CAFC,CAAC,CAEF,CAAkB,AAJU,EAIQ,GAJR,U/BiBmB,U+BbY,CAAE,KACrD,EAAQ,OAAA,EAAA,AAAI,KAAK,C/BcK,EAAA,K+BdG,A/BcH,CUTY,CAAC,EqBLN,iCAAiC,CAAC,AACrE,CEzCS,CFyCC,IAAI,CAAC,CCtCK,CAAC,yCDsCqC,GAC1D,EAAA,AADiE,CAAC,CAAC,EACrD,CACZ,EEtCuB,CAAC,0DFsCqC,GAIjE,EAJwE,CACrE,CAAC,GAGG,EAAA,OAAA,EAAkC,GAAM,aAKrC,C/BYE,CAAA,U+BXZ,SAA2B,CEzClB,CF0CX,CAAC,CAAC,AAEF,EAAK,EAHc,AAGf,mBAAsB,CAAG,SAAC,CAAA,EAC5B,OAAO,IAAI,EAAoB,EACjC,CAAC,CAAC,EAEG,CAHmC,CAAC,CAAC,IAG9B,CAAG,CHpBC,CGoBS,WACzB,EAAK,EAAD,GAAM,CAAG,EAAU,OAAO,AAAR,CAAS,CAAC,AAChC,EAAK,IAAI,CAAG,CHpBf,CGoByB,MAAM,CAAC,AAAR,CAAS,AAC9B,EAAI,EAAA,EAAK,CAAG,EAAU,MAAM,CAAP,AAAQ,CAAC,AAC9B,EAAK,EAAD,GAAM,CAAG,EAAU,SAsB3B,SArGgB,QAAQ,CAAtB,WDiFD,AC5EG,OAJI,AAAC,EDgFR,EChFY,CAAC,SAAS,EAAE,CACnB,IAAI,CAAC,SAAS,CAAG,IAAI,CAAO,CAAE,CAGzB,AAH0B,IAGtB,AAHmB,CAGlB,SAAS,CAAC,CAgG1B,CAAA,CAzGA,AAyGC,iiBHxG0B,CAAA,WAKvB,CIRiE,CAAC,CAAC,SJIzD,SAAS,iBACH,CAAG,IAAI,CIL+B,EJQ/C,IAAA,CAAA,SAAc,+CAQQ,CAA8B,SACpD,EAAA,EAAA,EAAyC,EAAQ,QAAA,wBAM1D,yCACgC,GAAA,MAAS,EACzC,AAD2C,A1B6CA,C0B7CC,AE0B3C,A7BUA,A2BnCA,CASE,EAAA,SAAA,CAAA,IACQ,C5B0Bc,CAAA,QAAA,C4BzBP,C5ByB0B,A4BxB1C,CAAK,CACL,CAA8B,MAC9B,WAAA,EAAA,EAAA,EAAA,UAAA,MAAA,CAAA,KAAU,4BAEH,IAAA,CAAA,kBAAA,EAAA,EAAA,IAA8B,CAAA,GKxBW,CAAC,CAAA,CAAA,EAAA,EAAA,CLwBX,EAAS,EAAE,AAAE,EAAO,CAAb,AAAa,EAAK,EAAL,EAAS,QAAE,cASvE,SAAe,ClBqBsB,CAAA,CAAA,ckBpBvB,KlBqBK,CVUD,AUVE,YkBrBY,GAAA,IAAO,CAAC,EAAS,MAAM,CAAC,CAAC,0BAG/B,CAA1B,kBACS,EAAU,IAAa,sBAIlB,CAAd,OGmBkC,SHlB3B,EEoBR,gBFpB0B,EAAE,CAAC,OAAO,EAAE,CAAC,EACnB,EAAU,EGoBO,GAAV,EHpBU,AGoBA,GHpBS,EAAE,CAAC,AAChD,CADiD,AAChD,EACH,CAAC,AAnED,yBTN4B,QAAQ,8dWoFpC,yCAnE2B,CAAE,CAAwB,yCAOnD,SAAgB,CtByBiC,AsBzBpB,CjCDe,CiCCW,uCAOvD,SAAA,CAA2B,CAAE,CAAA,2CAOV,CAAnB,SAAA,CAAA,CAAmC,CAAwB,8CAOtC,CAArB,C5B2B2C,Q4B1BzC,CAAa,C5B0B2C,A4BzBxD,CAAwB,gDAQH,CAAvB,SACE,CAAa,CACb,CAAA,aAQF,EAAA,SAAA,CAAA,6BAA6B,CAA7B,SACE,CAAa,CACb,CAAwB,EAExB,OAAO,EACT,CAAC,uCAKyB,CAA1B,SACE,CAAkC,CAClC,CAA0B,EACnB,CAAC,CAKV,ChCgBD,CAAA,SAAA,CAAA,6BgChB8B,CAA7B,SAA8B,CAAkC,EAAS,CAAC,CAC5E,CAAA,CAAC,AAzED,GGRA,eHqFA,EAAA,SAAA,CAAA,6DAEA,CFxBG,AEwBF,cADC,EAAA,SAAA,CAAA,GAAG,CAAH,SAAI,CAAc,CAAE,CAA6B,EAAS,CAAC,EAC7D,CAAC,AAFD,CAAuC,GAIvC,EAAA,SAAA,CAAA,EAAA,CFnBC,QAAA,0DEoBS,EAAA,EAAA,kBAGL,CAAH,SAAI,CAAc,CCjFkC,ADiFhC,CAA6B,EAAS,CAAC,EAC7D,CAAC,AALD,CACU,GAMV,EAAA,SAAA,CAAA,EAAA,CC7EG,C/B4FG,OAAA,kD8BbN,CAAA,ACgBC,ADhBA,OAFoC,EAAA,EAAA,GACnC,EAAA,SAAA,CAAA,MAAM,CAAN,SAAO,CAAc,CAAE,CAA6B,EAAS,CAAC,CAChE,CAAA,CAFA,AAEC,CAFoC,GAIrC,EAAA,KAJ+C,EAE9C,CAAA,CAED,CAAA,EAAA,SAAA,kDAEA,CAAA,AAAC,OAFwC,EAAA,EAAA,GACvC,EAAA,GADiD,MACjD,CAAA,MAAM,CAAN,SAAO,CAAc,CAAE,CAA6B,EAAS,CAAC,CAChE,CAAA,CAAC,AAFD,CAAyC,GAIzC,EAAA,KAJmD,GAElD,GAED,AAFC,SAED,IAIA,CAAC,AAAD,OAHE,EAAA,SAAA,CAAA,WAAW,CAAX,SAAY,CAA6B,EAAG,CAAC,CAE7C,EAAA,SAAA,CAAA,cAAc,CAAd,SAAe,CAA6B,EAAG,CAAC,CAClD,CAAA,CAAC,AAJD,GAMA,CAFC,CAED,SAAA,CAAA,EAAA,CAFC,QAED,kDAEgC,CAAC,AAAD,OADtB,EAAA,EAAA,GACsB,CAAA,CAAC,AAFjC,CACU,EAAoB,CAG9B,EAAA,SAAA,CAAA,EAAA,GAH8B,GACG,CAAA,EAEjC,kDAE8B,CAAA,AAAC,OADrB,EAAA,EAAA,GACoB,CAAA,CAAC,AAF/B,CACU,EAAoB,CAG9B,EAAA,SAAA,CAAA,EAAA,GAH8B,EACC,CAAA,GAE/B,kDAEsC,CAAA,AAAC,OAD7B,EAAA,EAAA,GAC4B,CAAA,CAAC,AAFvC,CACU,EAAoB,CAGjB,EAAa,IAAI,EAGjB,EAAsB,AAHZ,IAGgB,CAHA,CAI1B,CAJ4B,AAHX,CAGY,CAIT,CANM,GAMF,EACxB,EAFmB,AALO,CAOF,GAFmB,CAEf,CADX,AAD4B,CAAC,AAG9C,GAA8B,CAFS,EAAE,CAEP,AAFQ,EAK1C,GAAiC,AAJZ,IAIgB,CAJU,CAK/C,CALiD,CAAC,CAKnB,IAAI,EACnC,AAL2B,GAMtC,AANoE,EAAE,CAAC,CAMnE,EAKA,GARqC,IAAkC,EAQ7D,AAR+D,CACtC,AADuC,IAS9E,AARuE,EAAE,CAAC,IAQnE,CACT,CAAC,CAF8B,KANoB,EAOhC,AANoB,CAMnB,CANqB,CAAC,qDxBzIxC,SAAS,CAAa,CAAE,CAAiB,CAAE,CSGwB,ATHD,CoBCJ,AXEM,gFHUpE,4GAYA,SAAA,CAAqD,cACnB,EAAU,EAAQ,QAAQ,EAAE,+BAMvC,CAAvB,6DASE,CAAA,CACA,CAAA,iCAE+B,QAAA,CAAS,EAAM,EAAS,EACzD,GADuD,EAAS,CAAC,eAInD,CAAd,CkBhB4B,elBiBC,EAAQ,QAAA,+EalDrC,QJemD,CIf5C,C3BgBiD,A2BhBhC,CAAE,C3BgBgC,A2BhBf,C3BgBgB,C2BhBP,CAAC,CAErD,CtBSD,CJPK,AoBHA,SAAA,CAAA,OMCG,CAAP,KjBYiD,IAAA,CiBZzB,CAAE,CAAiB,KCCiC,IDAnE,ejBYqB,wBiBTrB,EAAE,U7BkFsC,Cc/FhB,CECC,AZFA,ACGlC,AHCA,CYHmC,AGEA,AbHA,ADAA,cHiGnB,CS1FgB,APDF,AmBHA,AfDA,AgBCA,wCtBqGlB,CEhFgB,CiBbD,OnB8FV,CSvFK,OTwFX,EAAE,YAEO,CAAA,QAI6B,kBAC/B,CAAA,aAKT,CAAA,EAAA,CAAA,CAAA,kDWtGgB,CAAA,qDAUlB,GAAA,EAAsB,WAAA,GAAc,MAAM,IAS7C,SAAA,GAAA,CAAA,CAAuC,CAAA,SACpC,EAAA,QAAA,CAAiB,GAAa,EACvC,CAAC,AAOK,SAAA,GAAA,CAAA,SACG,EAAA,WAAmB,CAAC,GAC7B,CAAC,inByBxCgB,CAAG,EAAU,IAAI,IAAA,GAAe,IAAA,IAuCjD,4BApCE,CtB2BkC,AbJV,QmCvBf,CAAW,YACA,CAAC,QAAA,CAAA,GAAA,CAAa,aACpB,EAIL,OAAA,MAAA,CAAc,CAAA,EAAI,6BAGd,CAAA,6BACO,IAAA,CAAA,QAAA,CAAA,OAAqB,EAAE,EAAE,EpBuCE,CoBvCC,CAAC,SAAC,CAAM,iBAAL,CAAC,KAAA,CAAA,CAAA,EAAA,CJKd,AILiB,CAAA,AAAD,CAAC,EAAA,yBAG/C,CAAR,SAAS,CAAA,CAAa,CCF4B,CAAF,CAAC,CAAC,GDG1C,EAAA,IAAiB,ChB+BG,CAAA,IgB/Ba,CAAC,QAAQ,CAAC,CAAC,iBAC/B,CAAA,GAAI,CAAA,EAAM,CDgBD,ECfrB,0BAGE,CAAX,SAAY,CAAA,QACS,IAAA,EAAgB,EtB2BA,AoBEA,CAAC,CAAA,CAAA,QAAA,mBE5BjB,CAAC,GCNG,GDMG,CAAC,GACpB,CACT,CAAC,ChBkCG,yBgBhCS,CtB0BuB,AAAC,CAAA,csB1BvB,aAAA,EAAA,EAAA,EAAA,UAAA,MAAA,CAAA,IAAA,CAAiB,AAAjB,CAAA,EAAA,CAAA,SAAA,CAAA,EAAA,KACZ,EAAmB,IAAI,EtB+BJ,IsB/BoB,CAAC,QAAQ,CAAC,CAAC,cAChC,GAAA,GAAA,EAAA,EAAA,IAAA,GAAI,CAAA,EAAA,IAAA,CAAA,EAAA,EAAA,IAAA,GAAE,cAAV,GACD,QAAQ,CAAA,MAAA,CAAQ,GAAG,CAAC,iGAEjC,OAAO,GAGT,EAAA,SAAA,CAAA,KAAA,CAAA,WACE,OAAO,IAAI,GAEf,CAAA,CAAC,AA3CD,CD+EiB,KT9EyB,OAAA,iDvBS1B,GACd,CMMkC,4BNJ3B,IAAA,GAAA,IAAoB,CIED,EJFI,AH6FF,CAAA,OG7FU,OAAA,CAAA,kBAU3B,QAEQ,UAAU,cACtB,KAAA,CAAA,qDACkD,OAAO,GAAK,CAClE,CAAC,AACI,C4BRU,CAAA,6C5BiBpB,CAAC,qBDhBK,GAA2B,IAAA,MAKjC,CAAA,uFAsE4B,kBAET,CAAA,yBAOnB,oBAxE2B,CAAA,kBAClB,IAAA,CAAA,SAAc,QACZ,EmBPE,OAAA,CAAA,IAAA,CAAA,OnBUG,SAAA,iCAQY,CAA1B,SAA2B,CAAA,cACO,EAAY,EAAQ,QAAQ,uBAUjD,CAAb,SACE,CAAA,CAAA,CACgB,CYdwC,CZeH,CYfW,CAAC,CAAC,CAAC,KZenE,KAAA,GAAA,CAAA,AEXwB,cFab,CAAA,oBAAA,GAAA,MAA8B,CAAA,EAAU,EAAS,KAAF,CAAQ,CAAC,CAAC,eAUxD,CAAA,SACZ,CAAgB,CEXmC,AFYnD,CAAgB,CAChB,CAAqD,iBAArD,WAEO,IAAA,CAAA,oBAAA,GAAA,OAAA,CAAA,EAAA,EAAA,EACT,CAAC,mBAKY,CAAA,kBACJ,IAAA,CAAA,oBAAyB,GAAG,MAAM,EAAE,AAC7C,CAD8C,AAC7C,qBAGD,aACmB,GiC5BD,AjC4BW,CiC5BV,CEhCK,AnC4Da,QAAQ,EmC5DE,AnC4DA,CmC5DC,AnC4DA,CmC5DC,AnC4DA,iCAarB,CAA5B,kBACS,EAAU,KAAa,EAChC,CAD2B,AiCtCJ,AjCuCtB,CAD2B,AAE9B,EAAA,CAAC,AA/ED,iBA6E0D,CAAC,MH3G/C,EAAA,CAAA,CAAA,gHSMqC,kESW5B,CAAgD,sCAApC,CAAZ,CdJQ,6Fcaf,CAAZ,SAAa,CAAY,CAAA,CAAiB,wCAK7B,CAAA,SAAC,CfKyC,CAAA,4CeA9C,ChBXgC,AgBWnB,CAAE,CAA4B,4CAI5C,CAAW,oCAInB,SAAS,ChBZgC,AgBYlB,QLcmC,CKbjD,IAAI,CQyDN,ARzDO,CXoBC,qBWhBN,CAAT,SAAA,CAA6B,+CAKlB,CAAa,aACX,iBAIV,CAAH,SAAI,CAAoB,EAAS,yBAGtB,CAAA,iDAKX,GoB3C2B,MpB2CX,CXawC,AWbnB,CXaoB,AWblB,CXamB,AWbF,EAAS,CAAC,EACpE,CArDA,AAqDC,MGzDgB,EAAA,8CAOO,CAAA,8BACyB,uBAOxC,GAAA,EAAA,WAAA,GAAA,MAAA,4BAUA,EAAA,QAAgB,CAAC,GAAU,eAQT,CAAgB,SAClC,EAAA,WAAA,CAAoB,CRoBG,GQV1B,SAAA,GACJ,CAAA,CAAA,CACwB,qBAEqB,GAC/C,CAAC,AAOK,SAAU,GAAe,CAAA,8BACN,CAAA,KAAA,EAAA,EAAA,WAAa,EAAE,AACxC,CADyC,AACxC,yDD7De,GAAA,CAA8B,qBACA,IAAA,YAG9B,GAAA,CAA4B,iBACX,IAAA,IAAsB,eAOpB,CAAwB,cAE5B,OAAO,CAAC,AMiDoB,CAAC,CNjDjB,GAAc,EAAY,MAAM,cAU3C,CAAA,0BbrBb,EAAA,WAAA,qEAQf,CAAY,CAAA,CACS,CAAA,CACQ,YAGnB,WAHW,CGI2B,CgByCqB,InB7C1C,EAAA,CAAE,OAER,EIRkC,KAAA,EJQlC,EAAS,IAAI,CAAN,AAAO,CAAC,GAAf,KD6DuB,AuBtBrC,CvBsBsC,AuBtBtC,CtBvCqB,AIRwB,EAAE,CAAC,IJuElD,mBAEE,UADT,OADO,AAEE,MAC0B,AAD1B,UAAA,OAAA,EACY,MAAS,C+B7DJ,C/B8DjB,UAAP,OAAO,EAAA,OAAA,EAAA,AACyB,UADzB,OAAA,EACY,SAAD,CAAc,yBA1D9B,CSF0C,AMHP,2Bf2BxB,CAAA,SAAA,CACD,CAAA,CAAA,CAAA,CAAA,CAGZ,CAAQ,uBAMY,CAAA,CAAA,GAEY,CAAC,EAAE,UAAd,C8BtDH,AX4FT,KAAA,0BnBnCP,EAAA,cAIM,EACN,EAAK,WAZH,EAeE,AAfG,QAea,EAAA,CcnBkC,CAAC,AdmB5B,CAAJ,EAAe,MAAM,CAAP,CAAS,CAAC,AAA3B,C6BrCa,K7BsClB,CAAC,C8BrDD,CAAC,OAAA,C9BqDU,EAAM,EAAM,CFrBD,CEqBD,GACX,GAAQ,EAAe,UAE3C,GAAA,IAAe,CAAC,EAAA,OAAwB,EAAW,IAAI,CAAC,CAAC,AAEpE,CAAC,AApED,EckDG,QX1DqB,CHLD,2BGeX,CDTY,CCUJ,CAAY,CACZ,CAAgB,CoBZM,ApBYN,CACO,EAH/B,CgBMH,GLbyD,AKazD,CLb0D,AKa1D,ShBNY,CAAT,EACQ,CgBSlB,GAAA,CAAA,IAAA,ChBTkB,cACO,CAAP,6CAIT,CAAA,SAAA,CAAa,CAAE,CAAqB,CAAE,CgBwCiB,CV1CL,AU0CI,CAAC,sBhBvCxC,GAAG,SAAA,CAAU,EAAA,EAAA,gCAGrC,SACE,CAAa,CACb,CAAyB,CACzB,CUToD,AVS9B,CACtB,CAAA,EUVgE,UVY7C,CAAC,UAAU,uBACV,CAAA,EAAA,eAAuB,CAAA,EAAA,+DAQzB,EAAE,yBAId,EAAA,IAAA,CAAA,SAAuB,CAAC,iBAAA,CAC5B,IAAI,CAAC,IAAA,CAAA,IAAA,CACA,OAAO,CACZ,IAAI,CAAC,OAAO,CACb,CAAC,yCAOmB,CAAC,CAJb,KAMb,CA/CA,AGkDC,AHHA,+DF/CU,CAAT,SACE,CAAc,CACd,CAAiB,CACjB,CAAwB,aAEb,AkBuCyB,CAAC,kEZlCvC,SAAA,CAAA,CAAwB,CAAgB,CAAE,CAAuB,+CAEtC,CQCa,ANIA,AXNY,ADCR,CAAA,EUAF,EAAA,CAAQ,CQCa,AI6D1D,CJ7D2D,CAAC,AI6D5D,IZ7DG,GAAY,IAAI,CAAE,EAAM,CAAb,CAAW,AAAW,KAAF,EAAS,CAAC,CAC9C,CAAC,mDAIK,CCHS,GAAA,CAAA,SAAA,EAAA,EAAA,2BDSP,CQC2B,AI6DM,AZ9D5C,CQCuC,EI6DU,CUtFjC,CVsFmC,CAAC,CUrFrD,EtBuBa,CAAwB,EsBvB/B,mBAA0B,CAAC,2BtB2Bf,CAAA,SACf,CAAY,CACZ,CAAgB,CAChB,CAAuB,iDAEA,SAAS,CAAC,EAAM,EAAS,AAAX,KAAS,EAAS,CAAC,CAAC,cWzCxC,mKnBqFI,uBAEC,sCAIH,CAAA,wBA3DrB,wCAES,SAAS,C2BtCO,IAAA,CAAA,O3ByCX,SAAS,sCAQvB,SAAA,CAAuD,iBAG/C,CAAA,oBAAA,CACJ,EAAQ,KAAD,GAAS,EAAE,CACnB,CAAC,OACE,4CAGG,GAMF,C4BzCN,CAAA,SAAA,CAAA,iBAAA,CAAA,oB5B0CkB,KAAa,IAAA,CAAK,oBAAoB,CAAC,uBAM1D,G8B5B4B,AHPI,M3BmCf,CAAA,CAAc,C8B5BZ,A9B4B4B,K2BnCU,I3BoChD,IAAA,CAAK,CCWf,E+B3DkB,cAAA,GhCgDiB,CSfD,CAAC,OTeS,CAAA,EAAA,uBAI7B,CAAA,gBACe,EAAA,QAAA,SACtB,oBAAA,CAAA,IAAA,UmB1EY,WAAA,UCgGN,GdhEC,APAF,iGHjCmD,CIFtD,ADDO,AFEP,ACFO,CMCC,AHDA,AR4BlB,AS5BkB,AGEA,ACFA,AHCA,CHCjB,ASDkB,AFEA,ACDA,AXClB,CHCD,AgBJiD,ALE7B,ACFA,ALAA,AGCA,ADAA,ADDA,wCNMjB,EAAA,wCAEA,EAAA,UAAc,CcAG,AdAF,AwBQL,CAAA,4BxBsBL,IAAI,CAAC,AmBME,CnBNC,EAAG,CAAC,CAAA,GAAA,MAAoB,CAAE,CAAC,EAAE,CAAE,cAClB,SArBJ,CAAwB,wBAC3B,CQeL,QAAA,EAAA,EAAA,EAAA,UAAA,MRfY,CAAA,sBACtB,GAAA,QAAA,iBAGiC,CAQ/B,A2B0CE,A/B/CoC,AwBKF,ApBRJ,eACG,wBAGZ,CkCnBV,AlCmBW,AoBSQ,CpBLT,YAAY,AAA/B,OAAA,gBACkB,CAAC,QAAA,GAG3B,GAIwB,EAAuB,CAAC,CAAC,CAAC,CAAC,CAAC,U0BO9C,EAAA,CAAA,CAAA,6J7B/CA,GAAA,CAAA,EAAA,CAAA,CAAA,gIFcV,GAJU,GAAA,CAAA,EAAA,CAAA,CAAA,EAIV,CAAA,EAAA,KAAA,CAAA,EAAA,CAAA,GAAA,IAAS,CAAA,AAKT,CAAA,CAAA,EAAA,EAAA,CAAA,EAAA,CAAA,IAAM,CAAA,CAAN,wBClBI,EGgGA,AFjGA,ACAA,CAAA,qCFEoB,CcAC,ASGA,APDA,AMHA,6CtBE6C,YAC9B,MACX,KAF6D,OACrC,CAD6C,CAAC,gEiBgB7E,CAAwB,IAAI,YAGxB,MAAA,CAAA,0BAG1B,CVA0C,QUAtC,CCMoC,CDNvB,CAAa,mBAGE,EEQA,AFRE,wBACH,CAAC,GAAA,CAAI,MACrB,AAD2B,cACb,CAAC,EmB7BQ,InB6BF,CAAC,EWiEQ,kBX/DjB,GAAG,CAAC,EAAA,wBAIhC,SAAM,CHCsC,AAAC,CAAA,KGArC,EAAA,IAAiB,CAAC,MAAM,GAE9B,CR4BC,EmBqCI,oBXlEoB,CAAC,EoBHE,IpBGI,CAAC,CsB3BG,CAAC,CtB2BD,AAC7B,CAD8B,CAAC,gBAIrC,CAAH,SAAI,CAAA,cACU,cAAc,CAAC,GAAA,CAAI,CsB3BC,AhB6BE,CNDpC,AMCqC,CNFD,AVEnC,AUDA,AsB3BA,CzB4BG,qBGCK,CAAA,sBACP,CRyBC,MQzBM,IAAI,CAAC,KAAK,GAAA,MAAA,CACP,CsB5BmD,ApByChE,QFbc,CAAa,CAAE,CAAG,EAEzB,SADI,IAAI,CAAA,MAAO,AAAiC,EAAK,GAAG,CAAC,IACzD,CACF,CAAC,CAAE,EAAA,EACF,IAAI,CAAC,EGWI,CAAC,CmBvCG,EtB+BV,CmB3BP,CAAA,SAAA,CAAA,MnB2Ba,CAAd,SAAe,CAAqB,GAClC,CAAA,EAAkB,CqBbH,EFdlB,GnB2B2B,CAnDA,EAmDG,CAAA,IAC3B,IAAI,CAAC,cAAc,CVKC,AULE,EAAA,KACd,CApDmB,AAoDlB,KACN,OAAO,EAAE,CAAC,AACV,EsB5Bc,CAAC,GtB4Bf,CAAO,SAAC,CAAA,CAA0B,CAAA,QACd,EAAA,IAAS,GACtB,EAAA,EAAA,OAAsB,CAvDG,QAwDrB,CAAC,IAAP,EAAU,CACZ,IAAA,EAAA,EAAuB,EAH4C,CAFe,EAKtD,CAAC,CAAC,CAAE,CAAC,EACjC,EAAc,EuBpCE,AvBoCS,KAAK,CAAC,EAAI,CAAC,CAAE,CR0BC,A+B9DA,CAAC,A/B+D/C,AQ3BkD,CuBpCF,A/B+D/C,CQ3BgD,IAAO,CAAC,AAC9C,CjBjDL,AiBgDoD,CqBR7C,EtCxCS,IAAA,CiBiDC,OjBxCC,CiBwCO,ECjCA,CAAA,KAAA,CAAA,GAAA,CDiCa,GCjCb,CDiCc,AjBvCN,IiBwC9B,CADyC,CAAC,AsB9BlC,AtB+BJ,CAAD,CADyC,CACrC,CAAC,EAAA,GAKZ,CqBND,MrBMQ,CACT,CAAC,CADW,AACT,CADU,GACN,KAGL,IAAI,CAAA,cAAe,CAAC,IAAA,CAxEtB,EAwE6B,sBACV,CADiC,AACjC,IAAO,IAAA,MAClB,IAAI,CAAC,IAAI,CAAA,cAAe,CAAC,OAAO,EAAE,CAAC,CACtC,OAAO,EAAE,AVQA,CUPT,KAAK,CAAC,EA5EX,CA4Ec,GAAA,EAGlB,CAAC,kBAEY,CAAb,WACE,OAAO,EAPgE,IAO1D,IAAA,CAAA,IAAS,CAAA,cAAA,CAAA,IAAoB,IAAI,OAAO,EAAE,CAAC,mBAG5C,CAAd,EVSgC,CAAC,CAAC,OURhC,CVSC,GAAA,EUTkB,IAAI,0BACK,IAAI,IAAI,IAAI,CAAA,cAAA,EACjC,IAEX,CA5EA,AA4EC,gBQ1FsD,CdAN,QcCxC,IAAI,CNIG,ADFF,AQJE,EAAA,yqBelBf,AAAD,MAAM,aAA6C,IAA7B,OAAO,qBAAkC,qBAAoB,EAAE,CAAC,gFAAU,EAAI,IAMzD,QAN6D,EAAE,CAAC,CAMxG,GAAE,KAAK,CAAyI,EAAxI,OANqF,AAM4D,AAAM,CAAC,CAAC,CAAC,EAAE,GAAG,AAAW,UAAS,OAAb,EAAc,MAAU,AAAJ,UAAc,iCAAyF,IAAI,IAAxD,EAAE,CAAC,EAAkB,EAAE,EAAE,KAAK,CAAC,GAAO,EAA3B,AAA6B,IAA1B,EAAC,EAA2B,MAAM,EAAE,EAAU,EAAE,EAAE,EAAE,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAK,EAAE,EAAE,OAAO,CAAC,KAAK,KAAG,GAAE,GAAE,AAAU,IAAI,EAAE,EAAE,MAAM,CAAC,EAAE,GAAG,IAAI,GAAO,EAAE,EAAE,MAAM,CAAC,EAAE,EAAE,EAAE,MAAM,EAAE,IAAI,GAAM,KAAK,CAAC,CAAC,EAAE,EAAC,CAAC,EAAE,EAAE,KAAK,CAAC,EAAE,CAAC,EAAA,EAAM,QAAW,CAAC,CAAC,EAAE,EAAC,CAAC,CAAC,CAAC,EAAE,CAAC,AAA2pC,SAAS,AAAU,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,OAAO,EAAE,EAAE,CAAC,MAAM,EAAE,CAAC,OAAO,CAAC,CAAC,EAA3sC,EAAE,EAAA,EAAG,CAAC,OAAO,CAAC,EAN9Y,AAMxG,EAAE,SAAS,CAA4e,EAA3e,OAAof,AAAU,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,GAAG,CAAC,EAAM,EAAE,EAAE,MAAM,EAAE,EAAE,GAAc,YAAX,AAAsB,OAAf,EAAgB,MAAU,AAAJ,UAAc,4BAA4B,GAAG,CAAC,EAAE,IAAI,CAAC,GAAI,CAAD,KAAO,AAAI,UAAU,4BAA4B,IAAI,EAAE,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,IAAI,CAAC,GAAI,CAAD,KAAO,AAAI,UAAU,2BAA2B,IAAI,EAAE,EAAE,IAAI,EAAE,GAAG,MAAM,EAAE,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,MAAM,CAAC,EAAE,GAAG,MAAM,IAAI,CAAC,SAAS,GAAI,CAAD,KAAO,AAAI,UAAU,4BAA4B,GAAG,aAAa,KAAK,KAAK,CAAC,EAAE,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC,GAAG,CAAC,EAAE,IAAI,CAAC,EAAE,MAAM,EAAG,CAAD,KAAO,AAAI,UAAU,4BAA4B,GAAG,YAAY,EAAE,MAAM,CAAC,GAAG,EAAE,IAAI,CAAC,CAAC,GAAG,CAAC,EAAE,IAAI,CAAC,EAAE,IAAI,EAAG,CAAD,KAAO,AAAI,UAAU,0BAA0B,GAAG,UAAU,EAAE,IAAI,CAAC,GAAG,EAAE,OAAO,CAAC,CAAC,GAAG,AAA+B,YAAW,OAAnC,EAAE,OAAO,CAAC,WAAW,CAAe,MAAM,AAAI,UAAU,6BAA6B,GAAG,aAAa,EAAE,OAAO,CAAC,WAAW,EAAE,CAA2D,GAAvD,EAAE,QAAQ,EAAC,CAAC,GAAG,YAAA,EAAgB,EAAE,MAAM,EAAC,CAAC,GAAG,UAAA,EAAc,EAAE,QAAQ,CAAyE,CAAxE,MAA2B,AAAoD,UAAxE,OAAO,EAAE,QAAQ,CAAY,EAAE,QAAQ,CAAC,WAAW,GAAG,EAAE,QAAQ,EAAW,KAAK,EAAsE,IAAI,SAArE,GAAG,oBAAoB,KAAM,KAAI,MAAM,GAAG,iBAAiB,KAAgD,KAAI,OAAO,GAAG,kBAAkB,KAAM,SAAQ,MAAM,AAAI,UAAU,6BAA6B,CAAE,OAAO,CAAC,IAA5lD,mBAAuB,EAAE,mBAAuB,EAAE,MAAU,EAAE,wCAA+lD,EAAO,OAAO,CAAC,EAAC,CAAC,oBCN3tD,CAAC,KAAK,iBAA6sK,EAAiC,EAAiC,EAAiC,EAAmB,EAAtzK,IAAI,EAAE,CAAC,IAAI,IAAI,IAAI,EAAE,OAAO,SAAS,CAAC,cAAc,CAAC,EAAE,IAAI,SAAS,IAAS,CAA2F,SAAS,EAAG,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,GAAG,EAAK,CAAC,SAAS,EAAY,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAc,YAAX,AAAsB,OAAf,EAAgB,MAAM,AAAI,UAAU,mCAAmC,IAAI,EAAE,IAAI,EAAG,EAAE,GAAG,EAAE,GAAG,EAAE,EAAE,EAAE,EAAE,EAAoI,OAA9H,EAAE,OAAO,CAAC,EAAE,CAA0C,EAAE,OAAO,CAAC,EAAE,CAAC,EAAE,CAA2B,EAAE,OAAO,CAAC,EAAE,CAAC,CAAC,EAAE,OAAO,CAAC,EAAE,CAAC,EAAE,CAAvD,EAAE,OAAO,CAAC,EAAE,CAAC,IAAI,CAAC,IAA3E,EAAE,OAAO,CAAC,EAAE,CAAC,EAAE,EAAE,YAAY,EAAA,EAA2F,CAAC,CAAC,SAAS,EAAW,CAAC,CAAC,CAAC,EAAwB,GAAnB,EAAE,EAAE,YAAY,CAAK,EAAE,OAAO,CAAC,IAAI,EAAY,OAAO,EAAE,OAAO,CAAC,EAAE,CAAC,SAAS,IAAe,IAAI,CAAC,OAAO,CAAC,IAAI,EAAO,IAAI,CAAC,YAAY,CAAC,CAAC,CAArlB,OAAO,MAAM,EAAC,CAAC,EAAO,SAAS,CAAC,OAAO,MAAM,CAAC,MAAS,AAAC,CAAC,IAAI,CAAA,CAAM,CAAE,SAAS,GAAC,GAAE,CAAA,GAAqgB,EAAa,SAAS,CAAC,UAAU,CAAC,SAAS,EAAa,IAAS,EAAE,EAAP,EAAE,EAAE,CAAK,GAAuB,IAApB,IAAI,CAAC,YAAY,CAAK,OAAO,EAAE,IAAI,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,AAAI,EAAE,IAAI,CAAC,EAAE,IAAG,EAAE,IAAI,CAAC,EAAE,EAAE,KAAK,CAAC,GAAG,UAAG,AAAG,OAAO,qBAAqB,CAAS,CAAR,CAAU,MAAM,CAAC,OAAO,qBAAqB,CAAC,IAAW,CAAC,EAAE,EAAa,SAAS,CAAC,SAAS,CAAC,SAAS,AAAU,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,MAAM,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,MAAM,CAAC,EAAE,EAAE,CAAC,CAAC,IAAI,IAAI,EAAE,EAAE,EAAE,EAAE,MAAM,CAAC,EAAE,AAAI,MAAM,GAAG,EAAE,EAAE,IAAI,AAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,OAAO,CAAC,EAAE,EAAa,SAAS,CAAC,aAAa,CAAC,SAAS,AAAc,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE,QAAC,AAAI,EAAc,CAAZ,CAAH,AAAiB,EAAE,CAAQ,CAAP,CAAgB,EAAE,MAAM,CAAlC,CAAkC,EAAE,EAAa,SAAS,CAAC,IAAI,CAAC,SAAS,AAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,EAAE,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,OAAO,EAAM,IAAyC,EAAE,EAAvC,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,EAAE,UAAU,MAAM,CAAK,GAAG,EAAE,EAAE,CAAC,CAAsD,OAAlD,EAAE,IAAI,EAAC,IAAI,CAAC,cAAc,CAAC,EAAE,EAAE,EAAE,MAAC,GAAU,GAAa,GAAG,KAAK,EAAE,OAAO,EAAE,EAAE,CAAC,IAAI,CAAC,EAAE,OAAO,GAAE,CAAK,MAAK,EAAE,OAAO,EAAE,EAAE,CAAC,IAAI,CAAC,EAAE,OAAO,CAAC,IAAG,CAAK,MAAK,EAAE,OAAO,EAAE,EAAE,CAAC,IAAI,CAAC,EAAE,OAAO,CAAC,EAAE,IAAG,CAAK,MAAK,EAAE,OAAO,EAAE,EAAE,CAAC,IAAI,CAAC,EAAE,OAAO,CAAC,EAAE,EAAE,GAAG,EAAK,MAAK,EAAE,OAAO,EAAE,EAAE,CAAC,IAAI,CAAC,EAAE,OAAO,CAAC,EAAE,EAAE,EAAE,IAAG,CAAK,MAAK,EAAE,OAAO,EAAE,EAAE,CAAC,IAAI,CAAC,EAAE,OAAO,CAAC,EAAE,EAAE,EAAE,EAAE,IAAG,CAAI,CAAC,IAAI,EAAE,EAAE,EAAE,AAAI,MAAM,EAAE,GAAG,EAAE,EAAE,IAAK,AAAD,CAAE,CAAC,EAAE,EAAE,CAAC,SAAS,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,EAAE,OAAO,CAAC,EAAE,KAAK,CAAC,IAAe,EAAX,EAAE,EAAE,MAAM,CAAG,IAAI,EAAE,EAAE,EAAE,EAAE,IAAgE,AAA5D,OAAI,CAAC,CAAC,EAAE,CAAC,IAAI,EAAC,IAAI,CAAC,cAAc,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,MAAC,GAAU,GAAa,GAAG,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,OAAO,EAAE,KAAM,MAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,OAAO,CAAC,GAAG,KAAM,MAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,OAAO,CAAC,EAAE,GAAG,KAAM,MAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,OAAO,CAAC,EAAE,EAAE,GAAG,KAAM,SAAQ,GAAG,CAAC,EAAE,IAAI,EAAE,EAAE,EAAM,AAAJ,MAAU,EAAE,GAAG,EAAE,EAAE,IAAI,AAAC,CAAC,CAAC,EAAE,EAAE,CAAC,SAAS,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,OAAO,CAAC,EAAE,CAAE,CAAC,OAAO,CAAI,EAAE,EAAa,SAAS,CAAC,EAAE,CAAC,SAAS,AAAG,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,EAAY,IAAI,CAAC,EAAE,EAAE,GAAE,EAAM,EAAE,EAAa,SAAS,CAAC,IAAI,CAAC,SAAS,AAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,EAAY,IAAI,CAAC,EAAE,EAAE,GAAE,EAAK,EAAE,EAAa,SAAS,CAAC,cAAc,CAAC,SAAS,AAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,EAAE,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,OAAO,IAAI,CAAC,GAAG,CAAC,EAAsB,CAApB,MAAC,EAAW,IAAI,CAAC,GAAU,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAK,CAAJ,CAAM,EAAE,GAAG,GAAI,AAAC,EAAF,EAAK,EAAE,IAAI,EAAI,AAAC,GAAG,AAAL,EAAO,OAAO,GAAG,CAAC,EAAG,CAAD,CAAY,IAAI,CAAC,OAAQ,CAAC,IAAI,IAAI,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,EAAE,MAAM,CAAC,EAAE,EAAE,IAAI,CAAI,CAAC,CAAC,EAAE,CAAC,EAAE,GAAG,GAAG,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,OAAO,IAAG,GAAE,AAAC,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,EAAM,EAAE,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,EAAE,CAAY,IAAX,EAAE,MAAM,CAAK,CAAC,CAAC,EAAE,CAAC,EAAO,EAAW,IAAI,CAAC,EAAE,CAAC,OAAO,IAAI,EAAE,EAAa,SAAS,CAAC,kBAAkB,CAAC,SAAS,AAAmB,CAAC,EAAE,IAAI,EAAyG,OAApG,GAAE,AAAC,EAAE,EAAE,EAAE,EAAE,EAAK,IAAI,CAAC,OAAO,CAAC,EAAE,EAAC,EAAW,IAAI,CAAC,KAAQ,IAAI,CAAC,OAAO,CAAC,IAAI,EAAO,IAAI,CAAC,YAAY,CAAC,GAAS,IAAI,EAAE,EAAa,SAAS,CAAC,GAAG,CAAC,EAAa,SAAS,CAAC,cAAc,CAAC,EAAa,SAAS,CAAC,WAAW,CAAC,EAAa,SAAS,CAAC,EAAE,CAAC,EAAa,QAAQ,CAAC,EAAE,EAAa,YAAY,CAAC,EAAsB,EAAE,OAAO,CAAC,CAAa,EAAE,IAAI,IAAI,EAAE,OAAO,CAAC,CAAC,EAAE,KAAK,EAAE,GAAI,EAAD,KAAM,CAAC,CAAS,EAAE,IAAI,CAAE,GAAG,IAAI,QAAS,IAAI,EAAE,IAAI,GAAI,IAAI,CAAE,IAAI,GAAM,GAAG,IAAI,QAAS,IAAI,EAAE,IAAI,GAAI,IAAI,CAAE,KAAK,MAAM,CAAC,IAAM,EAAE,IAAI,CAAC,EAAE,KAAK,OAAO,cAAc,CAAC,EAAE,aAAa,CAAC,OAAM,CAAI,GAAyI,CAAC,CAAC,OAAU,CAAlJ,EAAmJ,OAA1I,AAAW,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,EAAM,EAAE,EAAE,MAAM,CAAC,KAAM,EAAE,GAAE,CAAC,IAAM,EAAE,EAAE,EAAE,EAAM,EAAE,EAAE,CAAK,CAAW,GAAE,EAAX,CAAC,CAAC,EAAE,CAAC,IAAO,EAAE,EAAE,EAAE,GAAG,EAAE,GAAO,EAAE,CAAE,CAAC,OAAO,CAAC,CAAwB,EAAE,IAAI,CAAC,EAAE,EAAE,KAAK,OAAO,cAAc,CAAC,EAAE,aAAa,CAAC,OAAM,CAAI,GAAG,IAAM,EAAE,EAAE,KAAggB,CAAC,CAAC,OAAU,CAAvgB,EAAwgB,IAAlgB,AAAc,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAiC,IAAM,EAAE,CAAC,SAAS,CAAlD,EAAE,OAAO,MAAM,CAAC,CAAC,SAAS,CAAC,EAAE,EAAA,EAAuB,QAAQ,CAAC,IAAI,CAAC,EAAE,GAAG,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,QAAQ,EAAE,EAAE,QAAQ,CAAC,YAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,GAAU,IAAM,EAAE,EAAE,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,EAAG,CAAC,EAAE,IAAI,EAAE,QAAQ,CAAC,EAAE,QAAQ,EAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,EAAE,EAAE,CAAC,SAAS,CAAC,IAAM,EAAE,IAAI,CAAC,MAAM,CAAC,KAAK,GAAG,aAAO,EAAqB,IAAjB,CAAsB,EAAE,EAAE,GAApB,AAAuB,CAAC,KAApB,EAA2B,CAAC,CAAC,CAAxB,AAAyB,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,CAAE,GAAG,EAAE,QAAQ,GAAG,EAAE,QAAQ,EAAG,GAAG,CAAE,GAAG,EAAE,GAAG,CAAE,CAAC,IAAI,MAAM,CAAC,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAA2B,EAAE,IAAI,CAAC,EAAE,EAAE,KAAK,IAAM,EAAE,EAAE,IAAK,OAAM,UAAqB,MAAM,YAAY,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,IAAM,EAAS,CAAC,EAAE,EAAE,IAAI,IAAI,QAAS,CAAC,EAAE,KAAK,GAAc,UAAX,OAAO,GAAc,EAAE,EAAG,CAAD,KAAO,AAAI,UAAU,mDAAmD,GAAG,IAAI,IAAS,YAAC,EAAE,GAAU,IAAM,EAAE,WAAY,KAAK,GAAG,AAAW,mBAAJ,EAAe,CAAC,GAAG,CAAC,EAAE,IAAI,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC,MAAM,CAAC,IAAM,EAAa,UAAX,OAAO,EAAa,EAAE,CAAC,wBAAwB,EAAE,EAAE,aAAa,CAAC,CAAO,EAAE,aAAa,MAAM,EAAE,IAAI,EAAa,GAAwB,YAAW,AAA7B,OAAO,EAAE,MAAM,EAAe,EAAE,MAAM,GAAG,EAAE,EAAE,EAAG,GAAG,EAAE,EAAE,IAAI,CAAC,EAAE,GAAI,KAAK,aAAa,EAAE,EAAG,GAAI,EAAE,OAAO,CAAC,EAAS,EAAE,OAAO,CAAC,OAAU,CAAC,EAAS,EAAE,OAAO,CAAC,YAAY,CAAC,CAAY,CAAC,EAAM,EAAE,CAAC,EAAE,SAAS,EAAoB,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,QAAO,IAAJ,EAAe,KAAD,EAAQ,EAAE,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,QAAQ,CAAC,CAAC,EAAM,GAAE,EAAK,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,OAAO,CAAC,GAAqB,GAAE,CAAK,QAAQ,CAAI,GAAE,OAAO,CAAC,CAAC,EAAE,CAAC,OAAO,EAAE,OAAO,CAA6C,EAAoB,EAAE,CAAC,kFAAc,IAAI,EAAE,CAAC,EAAgB,OAAO,cAAc,CAAC,EAAE,EAAnD,WAAgE,CAAC,MAAM,EAAI,KAAW,EAAoB,OAAa,EAAoB,OAAa,EAAoB,OAAiB,KAAK,IAAU,IAAI,EAAE,YAAY,CAArM,AAA2/I,CAAC,CAAC,OAAU,CAAj0I,EAAk0I,IAA5zI,QAAe,EAAE,YAAY,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,EAAE,EAAwQ,GAAtQ,KAAK,GAAG,IAAI,CAAC,cAAc,CAAC,EAAE,IAAI,CAAC,YAAY,CAAC,EAAE,IAAI,CAAC,aAAa,CAAC,EAAE,IAAI,CAAC,aAAa,CAAC,EAAM,IAAI,CAAC,YAAY,CAAC,EAAuJ,CAAC,CAAC,AAAuB,gBAAhB,CAA1J,EAAE,OAAO,MAAM,CAAC,CAAC,2BAA0B,EAAM,YAAY,IAAS,SAAS,EAAE,YAAY,IAAS,WAAU,EAAK,WAAW,EAAE,OAAO,EAAE,EAAA,EAAiB,WAAW,EAAa,EAAE,WAAW,GAAE,CAAC,CAAG,EAAD,IAAW,AAAJ,UAAc,CAAC,6DAA6D,EAAE,OAAC,EAAE,MAAC,GAAE,EAAE,WAAA,AAAW,EAAqB,IAAjB,CAAsB,EAAE,EAAE,GAApB,KAA4B,CAAxB,CAAwB,CAAE,CAAqB,EAA1C,AAA4C,GAAnB,AAAsB,IAAI,EAAE,EAAtB,KAA6B,CAAzB,CAA2B,IAAtB,OAAiC,CAAC,CAAC,CAAC,EAAE,QAAgB,IAAb,EAAE,QAAQ,EAAc,CAAC,CAAC,OAAO,QAAQ,CAAC,EAAE,QAAQ,GAAG,EAAE,QAAQ,GAAE,CAAC,CAAG,EAAD,IAAW,AAAJ,UAAc,CAAC,wDAAwD,EAAE,OAAC,EAAE,OAAC,EAAE,EAAE,QAAA,AAAQ,EAAqB,IAAjB,CAAsB,EAAE,EAAE,GAApB,KAA4B,CAAxB,CAAwB,CAAE,CAAqB,EAA1C,AAA4C,GAAnB,AAAsB,IAAI,EAAE,EAAtB,KAA6B,CAAzB,CAA2B,IAAtB,IAA8B,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,0BAA0B,CAAC,EAAE,yBAAyB,CAAC,IAAI,CAAC,kBAAkB,CAAC,EAAE,WAAW,GAAG,KAAuB,IAAb,EAAE,QAAQ,CAAK,IAAI,CAAC,YAAY,CAAC,EAAE,WAAW,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE,QAAQ,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,UAAU,CAAC,IAAI,CAAC,WAAW,CAAC,EAAE,UAAU,CAAC,IAAI,CAAC,WAAW,CAAC,EAAE,WAAW,CAAC,IAAI,CAAC,QAAQ,CAAC,EAAE,OAAO,CAAC,IAAI,CAAC,eAAe,EAAoB,IAAnB,EAAE,cAAc,CAAQ,IAAI,CAAC,SAAS,CAAC,AAAc,OAAZ,SAAS,AAAQ,CAAC,IAAI,2BAA2B,CAAC,OAAO,IAAI,CAAC,kBAAkB,EAAE,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,YAAY,CAAC,IAAI,6BAA6B,CAAC,OAAO,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,kBAAkB,CAAC,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,aAAa,CAAC,EAA8B,GAAE,CAAvB,IAAI,CAAC,aAAa,GAAM,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC,EAAM,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,mBAAmB,CAAC,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,2BAA2B,GAAG,IAAI,CAAC,UAAU,MAAC,CAAS,CAAC,mBAAmB,CAAC,IAAM,EAAE,KAAK,GAAG,GAAG,QAAsB,IAAnB,IAAI,CAAC,WAAW,CAAa,CAAC,IAAM,EAAE,IAAI,CAAC,YAAY,CAAC,EAAE,KAAG,GAAE,EAAgL,CAA9K,MAAkF,KAAkB,QAAd,CAAC,EAAuB,QAAb,GAAc,IAAI,CAAC,UAAU,CAAC,WAAY,KAAK,IAAI,CAAC,iBAAiB,EAAE,EAAG,EAAA,GAAU,EAApL,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,0BAA0B,CAAC,IAAI,CAAC,aAAa,CAAC,CAAkH,CAAC,OAAO,CAAK,CAAC,oBAAoB,CAAC,GAAsB,GAAE,CAArB,IAAI,CAAC,MAAM,CAAC,IAAI,CAA8G,OAArG,IAAI,CAAC,WAAW,EAAC,AAAC,cAAc,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,WAAW,MAAC,EAAU,IAAI,CAAC,gBAAgB,IAAU,EAAM,GAAG,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,IAAM,EAAE,CAAC,IAAI,CAAC,iBAAiB,GAAG,GAAG,IAAI,CAAC,yBAAyB,EAAE,IAAI,CAAC,2BAA2B,CAAC,CAAC,IAAM,EAAE,IAAI,CAAC,MAAM,CAAC,OAAO,SAAG,CAAG,CAAC,GAAE,CAAc,IAAI,CAAC,IAAI,CAAC,UAAU,IAAO,GAAG,AAAD,IAAK,CAAC,2BAA2B,IAAU,EAAI,CAAC,CAAC,OAAO,CAAK,CAAC,6BAA6B,CAAI,IAAI,CAAC,kBAAkB,EAAE,KAAmB,QAAf,CAAC,EAAwB,SAAb,GAAqB,IAAI,CAAC,WAAW,CAAC,YAAa,KAAK,IAAI,CAAC,WAAW,EAAE,EAAG,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,YAAY,CAAC,KAAK,GAAG,GAAG,IAAI,CAAC,SAAS,CAAA,CAAC,aAAa,CAA0B,IAAtB,IAAI,CAAC,cAAc,EAA2B,IAArB,IAAI,CAAC,aAAa,EAAM,IAAI,CAAC,WAAW,EAAC,CAAC,cAAc,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,WAAW,CAAC,QAAU,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,0BAA0B,CAAC,IAAI,CAAC,aAAa,CAAC,EAAE,IAAI,CAAC,aAAa,EAAE,CAAC,eAAe,CAAC,KAAM,IAAI,CAAC,kBAAkB,GAAG,CAAC,CAAC,CAAC,IAAI,aAAa,CAAC,OAAO,IAAI,CAAC,YAAY,CAAC,IAAI,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC,CAAY,UAAX,OAAO,GAAc,IAAG,CAAC,CAAG,EAAD,IAAO,AAAI,UAAU,CAAC,6DAA6D,EAAE,EAAE,IAAI,EAAE,OAAO,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC,YAAY,CAAC,EAAE,IAAI,CAAC,aAAa,EAAE,CAAC,MAAM,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,OAAO,IAAI,QAAS,CAAC,EAAE,KAAK,IAAM,EAAI,UAAU,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,cAAc,GAAG,GAAG,CAAC,IAAM,EAAE,KAAgB,QAAZ,CAAC,QAAQ,EAAc,AAAY,WAAV,OAAO,CAAa,IAAI,EAAE,OAAO,CAAC,QAAQ,OAAO,CAAC,UAAiB,IAAZ,EAAE,OAAO,CAAa,IAAI,CAAC,QAAQ,CAAC,EAAE,OAAO,CAAE,WAA2B,IAAnB,EAAE,cAAc,CAAa,IAAI,CAAC,eAAe,CAAC,EAAE,cAAA,AAAc,EAAC,CAAC,EAAE,EAAmB,GAAI,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC,IAAI,CAAC,KAAK,EAAE,EAAE,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,EAAI,GAAG,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,EAAG,CAAC,MAAM,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,GAAG,CAAC,EAAE,GAAG,CAAE,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,EAAE,IAAK,CAAC,OAAO,QAAK,IAAI,CAAC,SAAS,EAAC,CAAa,IAAI,CAAC,SAAS,CAAC,GAAM,IAAI,CAAC,aAAa,IAA5C,IAAI,AAAsD,CAAC,OAAO,CAAC,IAAI,CAAC,SAAS,EAAC,CAAI,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,WAAW,CAAC,MAAM,SAAS,CAAC,GAAsB,GAAE,CAArB,IAAI,CAAC,MAAM,CAAC,IAAI,CAAa,OAAO,IAAI,QAAS,IAAI,IAAM,EAAE,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,aAAa,CAAC,KAAK,IAAI,GAAG,CAAC,EAAG,CAAC,MAAM,QAAQ,CAAC,GAAwB,IAArB,IAAI,CAAC,aAAa,EAAM,AAAmB,GAAE,KAAjB,CAAC,MAAM,CAAC,IAAI,CAAa,OAAO,IAAI,QAAS,IAAI,IAAM,EAAE,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,YAAY,CAAC,KAAK,IAAI,GAAG,CAAC,EAAG,CAAC,IAAI,MAAM,CAAC,OAAO,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,GAAG,MAAM,CAAC,IAAI,SAAS,CAAC,OAAO,IAAI,CAAC,aAAa,CAAC,IAAI,UAAU,CAAC,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,SAAS,CAAC,OAAO,IAAI,CAAC,QAAQ,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAyB,EAAO,OAAO,CAAC,EAAC,CAAC,oGCKrrT,SAASiB,IACd,MAAO,CACLC,cAAeC,QAAQC,GAAG,CAACC,sBAAsB,EAAI,GACrDC,sBAAuBH,QAAQC,GAAG,CAACG,+BAA+B,EAAI,GACtEC,yBACEL,QAAQC,GAAG,CAACK,kCAAkC,EAAI,EACtD,CACF,6MC6BgBC,cAAc,CAAA,kBAAdA,GAZAC,WAAW,CAAA,kBAAXA,uEAhBhB,IAAMC,EAAc,GAAIjB,GAbU,CAAA,CAAA,IAAA,EAAA,EAaVA,iBAAiB,CAEzC,SAASkB,EACPC,CAAM,CACNC,CAA4B,EAE5B,IAAMC,EAAkBD,EAAOE,MAAM,CAACH,EAAK,wBAC3C,GAAI,CAACE,EACH,OAAO7B,AAET,IAAM+B,EAAMH,EAAOG,AAHG,GAGA,CAACJ,GAGvB,MAAO,KAAEI,EAAKC,UAFIC,OAAOJ,GAEAK,SADRN,EAAOE,MAAM,CAACH,EAAK,mBAAqB,EACvB,CACpC,CAEO,SAASH,EACdG,CAAM,CACNC,CAA4B,CAC5BvB,CAAW,EAEX,IAAM8B,EAAcT,EAA2BC,EAAKC,UACpD,AAAKO,EAGEV,EAHH,AAGexB,GAAG,CAACkC,EAAa9B,GAHlB,AACTA,GAGX,CAEO,SAASkB,EACdI,CAAO,CACPC,CAA6B,EAE7B,IAAMO,EAAcV,EAAY1B,QAAQ,UACxC,AAAIoC,IAGAR,GAAOC,EACFF,EAA2BC,EAJnB,AAIwBC,EADtB,QAIrB,gCCUUyC,IAAAA,EAAAA,EAAAA,CAAAA,CAAAA,+DAqBYjC,WAAW,CAAA,kBAAXA,GA0CNC,cAAc,CAAA,kBAAdA,GAnHHT,MAAM,CAAA,kBAANA,+EAN0C,CAAA,CAAA,IAAA,GAM1CA,EAAqC,KAChDG,AAAIJ,GAAG,AACEA,EAAII,GAAG,QAEhBD,CAAOH,EAAKW,CAAF,GACDX,AADO,EACHY,OAAO,CAACC,GAAG,CAACF,EAE3B,EAoBA,eAAeiB,EACbrB,CAAgB,CAChBsB,CAAgB,EAEhB,GAAM,KACJzB,CAAG,QACH0B,CAAM,SACNlB,CAAO,MACPmB,CAAI,CACJC,OAAK,CACLC,aAAW,WACXC,CAAS,MACTC,CAAI,UACJC,CAAQ,UACRC,CAAQ,gBACRC,CAAc,CACf,CAAGT,EACJ,MAAO,UACLtB,EACAgC,IAAK,QACLV,QAAS,KACPzB,SACA0B,EACAlB,QAAS,IAAI4B,MAAMC,IAAI,CAAC7B,GAAU,CAAC,kBAAmBE,AAzC5D,SAASA,EACP,IAAIC,EAAS,CAAA,AAAI9C,QAAQ8C,KAAK,EAAI,EAAA,CAAC,CAAGC,KAAK,CAAC,MAE5C,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAMG,MAAM,CAAED,IAAK,AACrC,GAAIF,CAAK,CAACE,EAAE,CAACC,MAAM,CAAG,EAAG,CACvBH,EAAQA,EAAMI,KAAK,CAACF,GACpB,KACF,CAQF,MAAOF,CADPA,EAAQA,CAFRA,EAAQA,CAFRA,EAAQA,EAAMK,MAAM,CAAEC,AAAD,GAAO,CAACA,EAAEC,QAAQ,CAAC,eAAA,EAE1BH,KAAK,CAAC,EAAG,EAAA,EAETI,GAAG,CAAC,AAACC,GAAMA,EAAEC,OAAO,CAAC,6BAA8B,IAAIC,IAAI,GAAA,EAC5DC,IAAI,CAAC,OACpB,IAyB2E,CAAC,CACtEI,KAAMA,EAAAA,EAAAA,MACFW,CAAOD,IAAI,CAAC,MAAMZ,EAAQc,WAAW,IAAIC,QAAQ,CAAC,UAClD,WACJZ,cACAC,YACAC,OACAC,EACAC,oBACAC,iBACAC,CACF,CACF,CACF,CAUO,eAAe7B,EACpB0C,CAAoB,CACpBtB,CAAgB,EAEhB,IAAMuB,EAAWxD,CAAAA,EAAAA,EAAAA,cAAAA,AAAc,EAACiC,EAAS5B,GACzC,GAAI,CAACmD,EAEH,OAAOD,CAFM,CAEQtB,GAGvB,GAAM,UAAEtB,CAAQ,WAAEF,CAAS,CAAE,CAAG+C,EAC1BC,EAAe,MAAMzB,EAAkBrB,EAAUsB,GAEjDyB,EAAO,MAAMH,EAAc,CAAC,iBAAiB,EAAE9C,EAAAA,CAAW,CAAE,CAChEyB,OAAQ,OACRC,KAAMwB,KAAKC,SAAS,CAACH,GACrBI,KAAM,CAEJC,UAAU,CACZ,CACF,GACA,GAAI,CAACJ,EAAKK,EAAE,CACV,CADY,KACN,OAAA,cAAiD,CAAjD,AAAI1F,MAAM,CAAC,sBAAsB,EAAEqF,EAAKP,MAAM,CAAA,CAAE,EAAhD,oBAAA,OAAA,kBAAA,iBAAA,CAAgD,GAGxD,IAAMD,EAAiB,MAAMQ,EAAKM,IAAI,GAChC,KAAErB,CAAG,CAAE,CAAGO,EAChB,OAAQP,GACN,IAAK,WACH,OAAOY,EAActB,EACvB,KAAK,QACL,IAAK,YACH,MAAM,OAAA,cAEL,CAFK,AAAI5D,MACR,CAAC,uBAAuB,EAAE4D,EAAQC,MAAM,CAAC,CAAC,EAAED,EAAQzB,GAAG,CAAC,CAAC,CAAC,EADtD,oBAAA,OAAA,mBAAA,gBAAA,CAEN,EACF,KAAK,QACH,OAAOyC,AA5Cb,SAASA,AAAcC,CAAiC,EACtD,GAAM,QAAEC,CAAM,SAAEnC,CAAO,MAAEmB,CAAI,CAAE,CAAGe,EAAcE,QAAQ,CACxD,OAAO,IAAIC,SAASlB,EAAOW,EAAAA,MAAAA,CAAOD,IAAI,CAACV,EAAM,UAAY,KAAM,QAC7DgB,EACAnC,QAAS,IAAIsC,QAAQtC,EACvB,EACF,EAsC2BkC,EACvB,SACE,OAAOP,CACX,CACF,CAEO,SAAS7B,EAAeyC,CAAoB,EAYjD,OAXAU,EAAAA,CAAAA,CAAOC,KAAK,CAAG,SAASC,AACtBC,CAAoB,CACpBC,CAAmB,MAIfA,QAAJ,CAAIA,MAAAA,CAAAA,EAAU,AAAVA,GAAAA,IAAAA,EAAAA,EAAMR,IAAAA,AAAI,EAAA,KAAA,EAAVQ,EAAYP,QAAQ,EAAE,AACjBP,EAAca,EAAOC,GAEvBxD,EAAY0C,EAAe,IAAIe,QAAQF,EAAOC,GACvD,EACO,KACLJ,EAAAA,CAAAA,CAAOC,KAAK,CAAGX,CACjB,CACF,wFC1IgBgB,iBAAiB,CAAA,kBAAjBA,GAIAC,kBAAkB,CAAA,kBAAlBA,+EAPkC,CAAA,CAAA,IAAA,OACX,CAAA,CAAA,IAAA,GAEhC,SAASD,IACd,MAAOzD,CAAAA,EAAAA,EAAAA,cAAAA,AAAc,EAACmD,EAAAA,CAAAA,CAAOC,KAAK,CACpC,CAEO,SAASM,EACdC,CAA0C,EAE1C,MAAO,CAACrE,EAAKtB,IAAO4F,CAAAA,EAAAA,EAAAA,WAAAA,AAAkB,EAACtE,EAAKC,EAAAA,MAAM,CAAE,IAAMoE,EAAQrE,EAAKtB,GACzE,oBCXA,AAAC,WAAW,aAAa,IAAI,EAAE,CAAC,IAAI,SAAS,CAAC,EAAE,SAAS,EAAW,CAAC,EAAE,GAAc,UAAX,AAAoB,OAAb,EAAc,MAAM,AAAI,UAAU,mCAAmC,KAAK,SAAS,CAAC,GAAI,CAAC,SAAS,EAAqB,CAAC,CAAC,CAAC,EAA0C,IAAI,IAAN,EAAlC,EAAE,GAAO,EAAE,EAAM,EAAE,CAAC,EAAM,EAAE,EAAgB,EAAE,EAAE,GAAG,EAAE,MAAM,CAAC,EAAE,EAAE,CAAC,GAAG,EAAE,EAAE,MAAM,CAAC,EAAE,EAAE,UAAU,CAAC,QAAQ,GAAO,KAAJ,EAAO,WAAW,EAAE,GAAG,GAAO,KAAJ,EAAO,CAAC,GAAG,IAAI,EAAE,GAAO,GAAE,CAAN,AAAO,QAAM,GAAG,IAAI,EAAE,GAAO,IAAJ,EAAM,CAAC,GAAG,EAAE,MAAM,CAAC,GAAO,IAAJ,GAAkC,KAA3B,EAAE,UAAU,CAAC,EAAE,MAAM,CAAC,IAAoC,IAAG,CAA9B,EAAE,UAAU,CAAC,EAAE,MAAM,CAAC,IAAS,GAAG,EAAE,MAAM,CAAC,EAAE,CAAC,IAAI,EAAE,EAAE,WAAW,CAAC,KAAK,GAAG,IAAI,EAAE,MAAM,CAAC,EAAE,CAAQ,CAAC,GAAE,CAAP,GAAQ,EAAE,GAAG,EAAE,GAAsB,EAAE,CAAjB,EAAE,EAAE,KAAK,CAAC,EAAE,EAAA,EAAO,MAAM,CAAC,EAAE,EAAE,WAAW,CAAC,KAAK,EAAE,EAAE,EAAE,EAAE,QAAQ,CAAC,MAAM,GAAc,IAAX,EAAE,MAAM,EAAiB,IAAX,EAAE,MAAM,CAAK,CAAC,EAAE,GAAG,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,SAAQ,CAAK,GAAE,CAAI,EAAE,MAAM,CAAC,EAAE,GAAG,MAAW,EAAE,KAAK,EAAE,EAAE,MAAS,CAAJ,CAAM,MAAM,CAAC,EAAE,GAAG,IAAI,EAAE,KAAK,CAAC,EAAE,EAAE,GAAQ,EAAE,EAAE,KAAK,CAAC,EAAE,EAAE,GAAG,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,MAAa,CAAP,IAAG,GAAY,CAAC,GAAE,CAAP,EAAQ,EAAE,EAAO,EAAE,CAAC,CAAE,CAAC,OAAO,CAAC,CAAyI,IAAI,EAAE,CAAC,QAAQ,SAAS,EAAqC,IAAI,IAAN,EAAkD,EAAvE,EAAE,GAAO,GAAE,EAAoB,EAAE,UAAU,MAAM,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,EAAE,IAAc,AAAV,GAAa,EAAE,EAAE,SAAS,CAAC,EAAE,EAAS,AAAI,YAAU,GAAE,EAAA,EAAG,EAAE,GAAE,EAAW,GAAiB,GAAE,CAAb,EAAE,MAAM,GAAe,EAAE,EAAE,IAAI,EAAE,EAAE,AAAkB,OAAhB,UAAU,CAAC,IAAqC,GAA7B,EAAE,EAAqB,EAAE,CAAC,GAAM,EAAG,CAAD,EAAI,EAAE,MAAM,CAAC,EAAE,MAAM,IAAI,OAAO,MAAM,WAAS,AAAG,EAAE,MAAM,CAAC,EAAU,CAAR,CAAqB,GAAI,EAAE,UAAU,SAAS,AAAU,CAAC,EAAgB,GAAd,EAAW,GAAiB,IAAX,EAAE,MAAM,CAAK,MAAM,IAAI,IAAI,EAAoB,KAAlB,EAAE,UAAU,CAAC,GAAY,EAA6B,AAA3B,OAAE,UAAU,CAAC,EAAE,MAAM,CAAC,SAAuF,CAApC,IAAX,CAAhC,AAA8C,EAA5C,EAAqB,EAAE,CAAC,EAAA,EAAQ,MAAM,EAAO,IAAE,EAAE,GAAA,EAAO,EAAE,MAAM,CAAC,GAAG,IAAE,GAAG,GAAA,EAAO,GAAE,AAAM,IAAI,EAAS,CAAC,EAAE,WAAW,SAAoB,AAAX,CAAY,EAAgB,OAAd,EAAW,GAAU,EAAE,MAAM,CAAC,GAAqB,KAAlB,EAAE,UAAU,CAAC,EAAO,EAAE,KAAK,SAAS,EAAO,GAAsB,GAAnB,UAAU,MAAM,CAAK,MAAM,IAAU,IAAI,IAAN,EAAU,EAAE,EAAE,EAAE,UAAU,MAAM,CAAC,EAAE,EAAE,CAAC,IAAI,EAAE,SAAS,CAAC,EAAE,CAAC,EAAW,GAAM,EAAE,MAAM,CAAC,GAAE,MAAQ,IAAJ,EAAc,EAAE,EAAO,GAAG,IAAI,EAAE,QAAC,KAAO,IAAJ,EAAoB,IAAW,CAAjB,CAAmB,SAAS,CAAC,EAAE,EAAE,SAAS,SAAS,AAAS,CAAC,CAAC,CAAC,EAA8B,GAA5B,EAAW,GAAG,EAAW,GAAM,IAAI,IAAW,EAAE,EAAE,OAAO,CAAC,EAAA,KAAG,EAAE,EAAE,OAAO,CAAC,EAAA,EAApC,MAAM,GAA2D,IAAR,IAAI,EAAE,EAAO,EAAE,EAAE,MAAM,EAA2B,IAAG,CAArB,EAAE,UAAU,CAAC,GAArB,EAAE,EAAE,CAAgE,IAAjC,IAAI,EAAE,EAAE,MAAM,CAAK,EAAE,EAAE,EAAM,EAAE,EAAO,EAAE,EAAE,MAAM,EAA2B,IAAG,CAArB,EAAE,UAAU,CAAC,GAArB,EAAE,EAAE,CAAuF,IAAzC,IAAI,EAAb,AAAe,EAAb,MAAM,CAAS,EAAM,EAAE,EAAE,EAAE,EAAE,EAAM,EAAE,CAAC,EAAM,EAAE,EAAO,GAAG,EAAE,EAAE,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,EAAE,GAAE,AAAC,GAAuB,IAAG,CAAvB,EAAE,UAAU,CAAC,EAAE,GAAS,OAAO,EAAE,KAAK,CAAC,EAAE,EAAE,QAAQ,GAAG,AAAI,GAAE,GAAC,OAAO,EAAE,KAAK,CAAC,EAAE,EAAE,MAAU,EAAE,GAAE,CAAwB,IAAG,CAAvB,EAAE,UAAU,CAAC,EAAE,GAAS,EAAE,EAAc,GAAE,CAAN,IAAO,GAAE,GAAG,KAAK,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,EAAE,GAA2B,GAAG,IAArB,EAAE,AAAuB,UAAb,CAAC,EAAE,GAAY,MAAkB,KAAJ,IAAO,GAAE,CAAC,CAAC,IAAI,EAAE,GAAG,IAAI,EAAE,EAAE,EAAE,EAAE,GAAG,EAAE,EAAE,EAAE,CAAI,IAAI,GAAqB,KAAlB,EAAE,UAAU,CAAC,EAAK,GAAG,CAAe,IAAX,EAAE,MAAM,CAAK,GAAG,KAAU,GAAG,cAAO,AAAG,EAAE,MAAM,CAAC,EAAS,CAAP,CAAS,EAAE,KAAK,CAAC,EAAE,IAAQ,GAAG,EAAuB,KAAlB,EAAE,UAAU,CAAC,IAAQ,EAAE,EAAS,EAAE,KAAK,CAAC,GAAG,EAAE,UAAU,SAAS,AAAU,CAAC,EAAE,OAAO,CAAC,EAAE,QAAQ,SAAS,AAAQ,CAAC,EAAgB,GAAd,EAAW,GAAiB,IAAX,EAAE,MAAM,CAAK,MAAM,IAA2D,IAAI,IAAvD,EAAE,EAAE,UAAU,CAAC,GAAO,EAAM,KAAJ,EAAW,EAAE,CAAC,EAAM,GAAE,EAAa,EAAE,EAAE,MAAM,CAAC,EAAE,GAAG,EAAE,EAAE,EAAE,AAAmB,GAAG,AAAI,IAAG,EAA5B,EAAE,EAAE,UAAU,CAAC,EAAA,GAAc,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,MAAK,MAAO,EAAE,UAAO,AAAO,CAAC,GAAE,CAAP,EAAc,EAAE,IAAI,IAAO,GAAO,GAAE,CAAN,EAAY,KAAY,EAAE,KAAK,CAAC,EAAE,EAAE,EAAE,SAAS,SAAkB,AAAT,CAAU,CAAC,CAAC,EAAE,GAAG,KAAI,OAAsB,UAAX,OAAO,EAAa,MAAM,AAAI,UAAU,mCAAmC,EAAW,GAAG,IAAgC,EAA5B,EAAE,EAAM,EAAE,CAAC,EAAM,GAAE,EAAW,GAAG,AAAI,YAAW,EAAE,MAAM,CAAC,GAAG,EAAE,MAAM,EAAE,EAAE,MAAM,CAAC,CAAC,GAAG,EAAE,MAAM,GAAG,EAAE,MAAM,EAAE,IAAI,EAAE,MAAM,GAAG,IAAI,EAAE,EAAE,MAAM,CAAC,EAAM,EAAE,CAAC,EAAE,IAAI,EAAE,EAAE,MAAM,CAAC,EAAE,GAAG,EAAE,EAAE,EAAE,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,GAAG,GAAO,IAAG,CAAP,GAAQ,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,MAAK,MAAc,CAAC,GAAE,CAAP,IAAQ,GAAE,EAAM,EAAE,EAAE,GAAK,GAAG,GAAE,CAAI,IAAI,EAAE,UAAU,CAAC,GAAa,CAAV,AAAW,GAAP,AAAS,EAAP,IAAQ,GAAE,GAAQ,EAAE,CAAC,EAAE,EAAE,GAAI,CAAwC,OAApC,IAAI,EAAE,EAAE,EAAc,CAAC,IAAL,IAAO,EAAE,EAAE,MAAM,AAAN,EAAc,EAAE,KAAK,CAAC,EAAE,EAAE,CAAM,IAAI,EAAL,AAAO,EAAE,MAAM,CAAC,EAAE,GAAG,EAAE,EAAE,EAAE,AAAC,GAAqB,IAAG,CAArB,EAAE,UAAU,CAAC,IAAS,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,MAAK,MAAc,CAAC,GAAE,CAAP,IAAQ,GAAE,EAAM,EAAE,EAAE,UAAG,AAAO,CAAC,GAAE,CAAP,EAAa,GAAU,EAAE,KAAK,CAAC,EAAE,EAAG,EAAE,QAAQ,SAAS,AAAQ,CAAC,EAAE,EAAW,GAAgD,IAAI,IAA7C,EAAE,CAAC,EAAM,EAAE,EAAM,EAAE,CAAC,EAAM,GAAE,EAAS,EAAE,EAAU,EAAE,EAAE,MAAM,CAAC,EAAE,GAAG,EAAE,EAAE,EAAE,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,GAAG,GAAO,KAAJ,EAAO,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,KAAK,CAAC,QAAQ,CAAQ,CAAC,GAAE,CAAP,IAAQ,GAAE,EAAM,EAAE,EAAE,GAAS,IAAG,CAAP,EAAW,AAAI,CAAC,MAAE,EAAE,EAAc,IAAJ,IAAM,GAAE,EAAc,CAAC,GAAE,CAAP,IAAQ,EAAE,EAAC,CAAE,QAAC,AAAO,CAAC,IAAL,GAAY,CAAC,IAAL,GAAY,IAAJ,GAAW,IAAJ,GAAO,IAAI,EAAE,GAAG,IAAI,EAAE,EAAS,CAAP,EAAiB,EAAE,KAAK,CAAC,EAAE,EAAE,EAAE,OAAO,SAAgB,AAAP,CAAQ,MAA9nG,EAAoB,EAA4mG,GAAG,AAAI,UAAiB,UAAX,AAAoB,OAAb,EAAc,MAAM,AAAI,UAAU,mEAAmE,OAAO,GAAG,OAAO,EAAxwG,EAAE,GAAG,EAAE,EAAE,IAAI,GAAO,EAAE,IAAI,EAAE,CAAC,EAAE,IAAI,EAAE,EAAA,CAAE,EAAG,EAAD,AAAG,GAAG,EAAE,EAAA,CAAE,CAAM,AAAJ,EAAmB,CAAb,CAAH,EAAoB,AAAwsG,EAAtsG,IAAI,CAAS,CAAR,CAAU,EAAS,EAA0qG,EAAxqG,EAAE,EAAvC,CAAmtG,EAAE,MAAM,SAAS,AAAM,CAAC,EAAE,EAAW,GAAG,IAA8G,EAA1G,EAAE,CAAC,KAAK,GAAG,IAAI,GAAG,KAAK,GAAG,IAAI,GAAG,KAAK,EAAE,EAAE,GAAG,AAAW,MAAT,MAAM,CAAK,OAAO,EAAE,IAAI,EAAE,EAAE,UAAU,CAAC,GAAO,EAAM,KAAJ,EAAgB,GAAE,AAAC,EAAE,IAAI,CAAC,IAAI,EAAE,GAAO,EAAE,EAAgE,IAA9D,IAAI,EAAE,CAAC,EAAM,EAAE,EAAM,EAAE,CAAC,EAAM,GAAE,EAAS,EAAE,EAAE,MAAM,CAAC,EAAM,EAAE,EAAO,GAAG,EAAE,EAAE,EAAE,CAAmB,GAAG,AAAI,MAAzB,EAAE,EAAE,UAAU,CAAC,EAAA,EAAa,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,KAAK,CAAC,QAAQ,CAAQ,CAAC,GAAE,CAAP,IAAQ,GAAE,EAAM,EAAE,EAAE,GAAS,IAAG,CAAP,EAAe,CAAC,IAAL,EAAO,EAAE,EAAc,IAAJ,IAAM,GAAE,EAAU,AAAI,CAAC,GAAE,IAAC,GAAE,EAAC,CAAE,CAAiT,OAAzS,CAAC,IAAL,GAAY,CAAC,IAAL,GAAY,AAAJ,OAAW,AAAJ,OAAO,IAAI,EAAE,GAAG,IAAI,EAAE,EAAU,CAAR,AAAS,GAAE,CAAP,IAAW,AAAI,OAAG,EAAE,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,KAAK,CAAC,EAAE,GAAQ,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,KAAK,CAAC,EAAE,KAAgB,IAAJ,GAAO,GAAE,AAAC,EAAE,IAAI,CAAC,EAAE,KAAK,CAAC,EAAE,GAAG,EAAE,IAAI,CAAC,EAAE,KAAK,CAAC,EAAE,KAAQ,EAAE,IAAI,CAAC,EAAE,KAAK,CAAC,EAAE,GAAG,EAAE,IAAI,CAAC,EAAE,KAAK,CAAC,EAAE,IAAG,EAAE,GAAG,CAAC,EAAE,KAAK,CAAC,EAAE,IAAM,EAAE,EAAE,EAAE,GAAG,CAAC,EAAE,KAAK,CAAC,EAAE,EAAE,GAAW,IAAE,EAAE,GAAG,CAAC,GAAA,EAAW,CAAC,EAAE,IAAI,IAAI,UAAU,IAAI,MAAM,KAAK,MAAM,IAAI,EAAE,EAAE,KAAK,CAAC,EAAE,EAAE,OAAO,CAAC,CAAC,CAAC,EAAM,EAAE,CAAC,EAAE,SAAS,EAAoB,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,QAAO,IAAJ,EAAe,KAAD,EAAQ,EAAE,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,QAAQ,CAAC,CAAC,EAAM,EAAE,GAAK,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,OAAO,CAAC,GAAqB,GAAE,CAAK,QAAQ,CAAI,GAAE,OAAO,CAAC,CAAC,EAAE,CAAC,OAAO,EAAE,OAAO,CAA6C,EAAoB,EAAE,CAAC,0FAA6C,EAAO,OAAO,CAAvC,EAAoB,AAAoB,IAAC,CAAC,kBAApD,ECavsKgG,EAAOC,OAAO,CALLF,EAAQ,AAKAF,CALA,CAAA,IAAA,oBCRjB,CAAC,KAAK,YAAgB,CAA6B,WAAtB,sBAAkC,oBAAoB,EAAE,CAAC,wFAAU,EAAI,IAAI,EAAE,CAAC,EAAE,CAAC,KAAm3C,SAAS,EAAM,CAAC,CAAC,CAAC,EAAS,GAA55C,EAAi6C,GAAE,CAAX,IAAY,EAAE,EAAC,EAAq7B,IAAn7B,IAAI,EAAxvC,AAA0vC,SAAjvC,AAAM,CAAC,EAAmB,IAAjB,IAAI,EAAE,EAAE,CAAK,EAAE,EAAQ,EAAE,EAAE,MAAM,EAAC,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,GAAO,MAAJ,GAAa,MAAJ,GAAa,MAAJ,EAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,KAAK,WAAW,MAAM,EAAE,MAAM,CAAC,CAAC,IAAI,GAAG,QAAQ,CAAC,GAAO,OAAJ,EAAS,CAAC,EAAE,IAAI,CAAC,CAAC,KAAK,eAAe,MAAM,IAAI,MAAM,CAAC,CAAC,IAAI,GAAG,QAAQ,CAAC,GAAO,MAAJ,EAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,KAAK,OAAO,MAAM,EAAE,MAAM,CAAC,CAAC,IAAI,GAAG,QAAQ,CAAC,GAAO,MAAJ,EAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,KAAK,QAAQ,MAAM,EAAE,MAAM,CAAC,CAAC,IAAI,GAAG,QAAQ,CAAC,GAAO,MAAJ,EAAQ,CAAoB,IAAnB,IAAI,EAAE,GAAO,EAAE,EAAE,EAAQ,EAAE,EAAE,MAAM,EAAC,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,GAAG,GAAG,GAAG,IAAI,GAAG,IAAI,GAAG,IAAI,GAAG,IAAI,GAAG,IAAI,GAAG,KAAS,KAAJ,EAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,GAAG,CAAC,EAAE,MAAU,AAAJ,UAAc,6BAA6B,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,KAAK,OAAO,MAAM,EAAE,MAAM,CAAC,GAAG,EAAE,EAAE,QAAQ,CAAC,GAAO,MAAJ,EAAQ,CAAC,IAAI,EAAE,EAAM,EAAE,GAAO,EAAE,EAAE,EAAE,GAAU,KAAI,CAAX,CAAC,CAAC,EAAE,CAAQ,MAAM,AAAI,UAAU,oCAAoC,MAAM,CAAC,IAAI,KAAM,EAAE,EAAE,MAAM,EAAC,CAAC,GAAU,AAAP,QAAC,CAAC,EAAE,CAAQ,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAU,KAAI,CAAX,CAAC,CAAC,EAAE,EAAY,GAAO,KAAJ,EAAM,CAAC,IAAI,KAAK,OAAO,GAAU,KAAI,CAAX,CAAC,CAAC,EAAE,GAAQ,IAAgB,KAAI,CAAb,CAAC,CAAC,EAAE,EAAE,EAAQ,MAAU,AAAJ,UAAc,uCAAuC,MAAM,CAAC,IAAK,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,EAAE,MAAM,AAAI,UAAU,yBAAyB,MAAM,CAAC,IAAI,GAAG,CAAC,EAAE,MAAM,AAAI,UAAU,sBAAsB,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,KAAK,UAAU,MAAM,EAAE,MAAM,CAAC,GAAG,EAAE,EAAE,QAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,KAAK,OAAO,MAAM,EAAE,MAAM,CAAC,CAAC,IAAI,EAAE,CAAuC,OAAtC,EAAE,IAAI,CAAC,CAAC,KAAK,MAAM,MAAM,EAAE,MAAM,EAAE,GAAU,CAAC,EAAqD,GAAO,EAAE,EAAE,QAAQ,CAAC,EAAM,KAAK,IAAT,EAAW,KAAK,EAAE,EAAE,EAAE,SAAS,CAAC,EAAM,KAAK,IAAT,EAAW,MAAM,EAAM,EAAE,EAAE,CAAK,EAAE,EAAM,EAAE,EAAM,EAAE,GAAO,EAAW,SAAS,CAAC,EAAE,GAAG,EAAE,EAAE,MAAM,EAAE,CAAC,CAAC,EAAE,CAAC,IAAI,GAAG,EAAE,OAAO,CAAC,CAAC,IAAI,CAAC,KAAK,EAAM,EAAY,SAAS,CAAC,EAAE,IAAI,EAAE,EAAW,GAAG,QAAO,IAAJ,EAAc,OAAO,EAAE,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,IAAI,CAAC,EAAE,EAAE,KAAK,AAAC,OAAM,AAAI,UAAU,cAAc,MAAM,CAAC,EAAE,QAAQ,MAAM,CAAC,EAAE,eAAe,MAAM,CAAC,GAAG,EAAM,EAAY,WAA0B,IAAf,IAAa,EAAT,EAAE,GAAe,EAAE,EAAW,SAAS,EAAW,gBAAgB,CAAC,GAAG,EAAE,OAAO,CAAC,EAAM,EAAO,SAAS,CAAC,EAAE,IAAI,IAAI,EAAE,EAAM,CAAJ,CAAE,AAAI,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,GAAG,EAAE,OAAO,CAAC,GAAG,CAAC,EAAE,OAAO,CAAI,CAAC,OAAO,CAAK,EAAM,EAAY,SAAS,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC,EAAE,MAAM,CAAC,EAAE,CAAK,EAAE,IAAI,CAAD,EAAe,UAAX,OAAO,EAAa,EAAE,EAAA,CAAE,CAAE,GAAG,GAAG,CAAC,EAAG,CAAD,KAAO,AAAI,UAAU,8DAA8D,MAAM,CAAC,EAAE,IAAI,CAAC,YAAM,AAAG,CAAC,GAAG,EAAO,GAAS,CAAN,IAAW,MAAM,CAAC,EAAa,GAAG,OAAa,SAAS,MAAM,CAAC,EAAa,GAAG,OAAO,MAAM,CAAC,EAAa,GAAG,OAAO,EAAQ,EAAE,EAAE,MAAM,EAAC,CAAC,IAAI,EAAE,EAAW,QAAY,EAAE,EAAW,QAAY,EAAE,EAAW,WAAW,GAAG,GAAG,EAAE,CAAC,IAAI,EAAE,GAAG,GAAqB,CAAC,GAAE,CAAlB,EAAE,OAAO,CAAC,KAAS,GAAG,EAAE,EAAE,IAAM,GAAE,CAAC,EAAE,IAAI,CAAC,GAAG,EAAE,IAAG,EAAE,IAAI,CAAC,CAAC,KAAK,GAAG,IAAI,OAAO,EAAE,OAAO,GAAG,QAAQ,GAAG,EAAY,GAAG,SAAS,EAAW,aAAa,EAAE,GAAG,QAAQ,CAAC,IAAI,EAAE,GAAG,EAAW,gBAAgB,GAAG,EAAE,CAAC,GAAG,EAAE,QAAQ,CAA+C,GAA3C,CAA8C,EAA5C,CAAC,EAAE,IAAI,CAAC,GAAG,EAAE,IAAS,EAAW,QAAa,CAAC,IAAI,EAAE,IAAkB,EAAE,EAAW,SAAS,GAAO,EAAE,EAAW,YAAY,GAAO,EAAE,IAAc,EAAY,SAAS,EAAE,IAAI,CAAC,CAAC,KAAK,GAAI,EAAD,CAAG,IAAI,EAAA,CAAE,CAAE,QAAQ,GAAG,CAAC,EAAE,EAAY,GAAG,EAAE,OAAO,EAAE,OAAO,EAAE,SAAS,EAAW,aAAa,EAAE,GAAG,QAAQ,CAAC,EAAY,MAAM,CAAC,OAAO,CAAC,CAA6F,SAAS,EAAiB,CAAC,CAAC,CAAC,EAAS,KAAK,GAAE,CAAX,IAAY,EAAE,EAAC,EAAE,IAAI,EAAE,EAAM,GAAO,EAAE,EAAE,MAAM,CAAC,EAAM,KAAK,IAAT,EAAW,SAAS,CAAC,EAAE,OAAO,CAAC,EAAE,EAAE,EAAE,EAAE,QAAQ,CAAC,EAAM,KAAK,IAAE,AAAX,GAAgB,EAAM,EAAE,EAAE,GAAG,CAAE,SAAS,CAAC,EAAE,GAAc,UAAX,AAAoB,OAAb,EAAc,OAAO,IAAI,OAAO,OAAO,MAAM,CAAC,EAAE,OAAO,CAAC,MAAM,EAAG,GAAI,OAAO,SAAS,CAAC,EAAW,IAAI,IAAT,EAAE,GAAW,EAAE,EAAE,EAAE,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,GAAc,UAAX,OAAO,EAAa,CAAC,GAAG,EAAE,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC,MAAC,EAAc,EAAE,AAAa,QAAX,QAAQ,EAAqB,MAAb,EAAE,QAAQ,CAAW,EAAe,MAAb,EAAE,QAAQ,EAAqB,MAAb,EAAE,QAAQ,CAAO,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,GAAG,CAAC,EAAG,CAAD,KAAO,AAAI,UAAU,aAAa,MAAM,CAAC,EAAE,IAAI,CAAC,sCAAsC,GAAc,IAAX,EAAE,MAAM,CAAK,CAAC,GAAG,EAAE,QAAS,OAAM,AAAI,UAAU,aAAa,MAAM,CAAC,EAAE,IAAI,CAAC,qBAAqB,CAAC,IAAI,IAAI,EAAE,EAAE,EAAE,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,GAAG,GAAG,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,GAAI,CAAD,KAAO,AAAI,UAAU,iBAAiB,MAAM,CAAC,EAAE,IAAI,CAAC,gBAAgB,MAAM,CAAC,EAAE,OAAO,CAAC,gBAAgB,MAAM,CAAC,EAAE,MAAM,GAAG,EAAE,MAAM,CAAC,EAAE,EAAE,MAAM,CAAC,QAAQ,CAAC,GAAc,UAAX,OAAO,GAAyB,UAAX,OAAO,EAAa,CAAC,IAAI,EAAE,EAAE,OAAO,GAAG,GAAG,GAAG,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,GAAI,CAAD,KAAO,AAAI,UAAU,aAAa,MAAM,CAAC,EAAE,IAAI,CAAC,gBAAgB,MAAM,CAAC,EAAE,OAAO,CAAC,gBAAgB,MAAM,CAAC,EAAE,MAAM,GAAG,EAAE,MAAM,CAAC,EAAE,EAAE,MAAM,CAAC,QAAQ,CAAC,IAAG,GAAW,AAAT,IAAa,EAAE,EAAE,WAAW,UAAW,OAAM,AAAI,UAAU,aAAa,MAAM,CAAC,EAAE,IAAI,CAAC,YAAY,MAAM,CAAC,IAAG,CAAC,OAAO,CAAC,CAAC,CAAyI,SAAS,EAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,EAAS,KAAK,GAAE,CAAX,IAAY,EAAE,EAAC,EAAE,IAAI,EAAE,EAAE,MAAM,CAAC,EAAM,KAAK,IAAT,EAAW,SAAS,CAAC,EAAE,OAAO,CAAC,EAAE,EAAE,OAAO,SAAS,CAAC,EAAE,IAAI,EAAE,EAAE,IAAI,CAAC,GAAG,GAAG,CAAC,EAAE,OAAO,EAA2Q,IAAI,IAArQ,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,KAAK,CAAK,EAAE,OAAO,MAAM,CAAC,MAAoO,EAAE,EAAE,EAAE,EAAE,MAAM,CAAC,IAAI,CAArO,AAAsO,SAA7N,CAAC,EAAE,GAAG,KAAO,KAAN,CAAC,EAAE,EAA8B,CAAjB,GAAqB,EAAE,CAAC,CAAC,AAAnB,EAAqB,EAAE,CAAiB,MAAb,EAAE,QAAQ,EAAqB,KAAI,CAAjB,EAAE,QAAQ,CAAQ,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,EAAE,MAAM,CAAC,EAAE,MAAM,EAAE,GAAG,CAAE,SAAS,CAAC,EAAE,OAAO,EAAE,EAAE,EAAE,GAAS,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,GAAG,EAAsC,GAAG,MAAM,CAAC,KAAK,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC,CAAC,CAAqC,SAAS,EAAa,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,4BAA4B,OAAO,CAAC,SAAS,EAAM,CAAC,EAAE,OAAO,GAAG,EAAE,SAAS,CAAC,GAAG,GAAG,CAAgb,SAAS,EAAe,CAAC,CAAC,CAAC,CAAC,CAAC,EAAS,KAAK,GAAE,CAAX,IAAY,EAAE,EAAC,EAA+S,IAAI,IAA7S,EAAE,EAAE,MAAM,CAAC,EAAM,KAAK,IAAE,AAAX,GAAiB,EAAE,EAAE,EAAE,KAAK,CAAqB,CAApB,CAAsB,EAAE,GAAG,CAAqB,CAApB,CAAsB,EAAE,MAAM,CAAC,EAAM,KAAK,IAAT,EAAW,SAAS,CAAC,EAAE,OAAO,CAAC,EAAE,EAAE,EAAE,EAAE,SAAS,CAAsB,CAArB,CAAuB,EAAE,QAAQ,CAAuB,CAAtB,CAAwB,IAAI,MAAM,CAAC,EAA7B,KAAK,IAAT,EAAW,AAAmC,GAAhC,GAAmC,OAAW,EAAE,IAAI,MAAM,CAAC,EAA3G,AAAI,KAAK,MAA+G,AAA7G,MAAM,GAA0G,KAAS,EAA9O,AAAgP,KAA3O,IAAE,AAAX,GAAgB,EAAsO,IAAI,GAAW,EAAE,EAAM,CAAJ,CAAM,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,EAAtB,AAAwB,CAAC,CAAC,EAAE,CAAC,GAAc,UAAS,AAApB,OAAO,EAAc,GAAG,EAAa,EAAE,QAAQ,CAAC,IAAI,EAAE,EAAa,EAAE,EAAE,MAAM,GAAO,EAAE,EAAa,EAAE,EAAE,MAAM,GAAG,GAAG,EAAE,OAAO,CAAiB,CAAhB,EAAI,GAAE,EAAE,IAAI,CAAC,GAAM,GAAG,EAAG,CAAD,EAAiB,MAAb,EAAE,QAAQ,EAAqB,MAAb,EAAE,QAAQ,CAAO,CAAC,IAAI,EAAe,MAAb,EAAE,QAAQ,CAAO,IAAI,GAAG,GAAG,MAAM,MAAM,CAAC,EAAE,QAAQ,MAAM,CAAC,EAAE,OAAO,CAAC,QAAQ,MAAM,CAAC,GAAG,MAAM,CAAC,EAAE,OAAO,MAAM,CAAC,EAAE,OAAO,CAAC,QAAQ,MAAM,CAAC,EAAE,KAAK,MAAM,CAAC,EAAE,MAAM,CAAD,EAAI,MAAM,MAAM,CAAC,EAAE,KAAK,MAAM,CAAC,EAAE,OAAO,CAAC,KAAK,MAAM,CAAC,EAAE,KAAK,MAAM,CAAC,EAAE,QAAQ,MAAO,CAAC,GAAgB,MAAb,EAAE,QAAQ,EAAqB,KAAI,CAAjB,EAAE,QAAQ,CAAQ,MAAM,AAAI,UAAU,mBAAmB,MAAM,CAAC,EAAE,IAAI,CAAC,kCAAkC,GAAG,IAAI,MAAM,CAAC,EAAE,OAAO,CAAC,KAAK,MAAM,CAAC,EAAE,QAAQ,CAAC,MAAO,GAAG,MAAM,MAAM,CAAC,GAAG,MAAM,CAAC,EAAE,KAAK,MAAM,CAAC,EAAE,QAAQ,CAAE,CAAC,CAAC,GAA36B,AAAI,CAA06B,GAAE,CAAv6B,IAAE,GAAK,EAAo6B,AAAC,IAAE,GAAG,GAAG,MAAM,CAAC,EAAE,IAAA,EAAK,GAAG,AAAC,EAAE,QAAQ,CAAK,MAAM,MAAM,CAAC,EAAE,KAAnB,QAA4B,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,MAAM,CAAC,EAAE,CAAK,EAAa,UAAX,OAAO,EAAa,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,EAAE,EAAE,CAAC,OAAM,IAAJ,CAAiB,CAAC,GAAE,CAAC,GAAG,MAAM,MAAM,CAAC,EAAE,OAAO,MAAM,CAAC,EAAE,MAAA,EAAU,AAAC,GAAE,CAAC,GAAG,MAAM,MAAM,CAAC,EAAE,KAAK,MAAM,CAAC,EAAE,IAAA,CAAK,CAAC,OAAO,IAAI,OAAO,EAAE,EAAM,GAAG,CAAiC,SAAS,EAAa,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,aAAa,OAAc,CAAP,MAA/yD,GAAG,CAAC,AAAm0D,EAAj0D,OAAO,EAAiE,IAA/D,IAAI,EAAE,0BAA8B,EAAE,EAAM,EAAE,EAAE,IAAI,CAAkwD,AAAjwD,EAAE,MAAM,EAAQ,EAAE,CAAC,EAAE,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,EAAE,IAAI,OAAO,GAAG,OAAO,GAAG,SAAS,GAAG,QAAQ,EAAE,GAAG,EAAE,EAAE,IAAI,CAAC,EAAE,MAAM,EAAE,OAAO,CAAkpD,QAAG,AAAG,MAAM,OAAO,CAAC,IAAloD,AAAqoD,EAAqB,AAAxpD,EAAE,GAAG,AAAqoD,CAAnoD,SAAS,CAAC,EAAE,OAAO,EAAa,EAAmnD,CAAjnD,GAAE,CAAG,MAAM,GAAW,IAAI,OAAO,MAAM,MAAM,CAAC,EAAE,IAAI,CAAC,KAAK,KAAK,EAAojD,IAA9iD,CAA0C,EAAe,EAA8gD,EAAI,EAA5gD,CAA0gD,EAAxgD,EAA4gD,CAA79N,CAAo9K,GAAE,GAA/8K,cAAc,CAAC,EAAE,aAAa,CAAC,OAAM,CAAI,GAAG,EAAE,YAAY,CAAC,EAAE,cAAc,CAAC,EAAE,gBAAgB,CAAC,EAAE,KAAK,CAAC,EAAE,gBAAgB,CAAC,EAAE,OAAO,CAAC,EAAE,KAAK,CAAC,KAAK,EAAg0F,EAAE,KAAK,CAAC,EAAkE,EAAE,OAAO,CAArE,EAAsE,OAA7D,AAAQ,CAAC,CAAC,CAAC,EAAE,OAAO,EAAiB,EAAM,EAAE,GAAG,EAAE,EAAovC,EAAE,gBAAgB,CAAC,EAAuG,EAAE,KAAK,CAA7F,EAA8F,OAA/E,AAAN,CAAO,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAA2B,OAAO,EAA3B,EAAa,EAAE,EAAE,GAA6B,EAAE,EAAE,EAAN,AAAigB,EAAE,gBAAgB,CAAC,EAAs4D,AAApyN,EAAsyN,cAAc,CAAC,EAA2K,EAAE,YAAY,CAAC,EAAY,CAAC,GAAI,EAAO,OAAO,CAAC,EAAC,CAAC,oBCc1oOG,EAAOC,OAAO,CAPqB,CACjC,CAMeC,YALf,WACA,cACA,cACD,+BCDD,IAAI,EAAuB,CAAE,EAAG,KAAM,EAAG,IAAK,EAC9C,SAAS,EAAuB,CAAI,EAClC,IAAI,EAAM,4BAA8B,EACxC,GAAI,EAAI,UAAU,MAAM,CAAE,CACxB,GAAO,WAAa,mBAAmB,SAAS,CAAC,EAAE,EACnD,IAAK,IAAI,EAAI,EAAG,EAAI,UAAU,MAAM,CAAE,IACpC,GAAO,WAAa,mBAAmB,SAAS,CAAC,EAAE,CACvD,CACA,MACE,yBACA,EACA,WACA,EACA,gHAEJ,CACA,IAAI,EAAc,MAAM,OAAO,CAC/B,SAAS,IAAQ,CACjB,IAAI,EAAqB,OAAO,GAAG,CAAC,8BAClC,EAAoB,OAAO,GAAG,CAAC,gBAC/B,EAAsB,OAAO,GAAG,CAAC,kBACjC,EAAyB,OAAO,GAAG,CAAC,qBACpC,EAAsB,OAAO,GAAG,CAAC,kBACjC,EAAyB,OAAO,GAAG,CAAC,qBACpC,EAAsB,OAAO,GAAG,CAAC,kBACjC,EAAkB,OAAO,GAAG,CAAC,cAC7B,EAAkB,OAAO,GAAG,CAAC,cAC7B,EAAsB,OAAO,GAAG,CAAC,kBACjC,EAA6B,OAAO,GAAG,CAAC,yBACxC,EAAwB,OAAO,QAAQ,CAQrC,EAAiB,OAAO,SAAS,CAAC,cAAc,CAClD,EAAS,OAAO,MAAM,CACxB,SAAS,EAAa,CAAI,CAAE,CAAG,CAAE,CAAK,EACpC,IAAI,EAAU,EAAM,GAAG,CACvB,MAAO,CACL,SAAU,EACV,KAAM,EACN,IAAK,EACL,IAAK,KAAK,IAAM,EAAU,EAAU,KACpC,MAAO,CACT,CACF,CAIA,SAAS,EAAe,CAAM,EAC5B,MACE,UAAa,OAAO,GACpB,OAAS,GACT,EAAO,QAAQ,GAAK,CAExB,CAUA,IAAI,EAA6B,OACjC,SAAS,EAAc,CAAO,CAAE,CAAK,MAVrB,GAAG,CAWjB,MAAO,UAAa,OAAO,GAAW,OAAS,GAAW,MAAQ,EAAQ,GAAG,GACzE,CAAO,GAAK,EAAQ,GAAG,CAXvB,EAAgB,CAAE,IAAK,KAAM,IAAK,IAAK,EAEzC,IACA,EAAI,OAAO,CAAC,QAAS,SAAU,CAAK,EAClC,OAAO,CAAa,CAAC,EAAM,AAC7B,IAOE,EAAM,QAAQ,CAAC,GACrB,CA+IA,SAAS,EAAY,CAAQ,CAAE,CAAI,CAAE,CAAO,EAC1C,GAAI,MAAQ,EAAU,OAAO,EAC7B,IAAI,EAAS,EAAE,CACb,EAAQ,EAIV,OArHF,AAkHE,SAlHO,EAAa,CAAQ,CAAE,CAAK,CAAE,CAAa,CAAE,CAAS,CAAE,CAAQ,EACvE,IA1D0B,EAAY,IA0DlC,EAAO,AA1DiC,EAAR,KA0DlB,GACd,cAAgB,GAAQ,YAAc,CAAA,IAAM,EAAW,IAAA,EAC3D,IAAI,EAAiB,CAAC,EACtB,GAAI,OAAS,EAAU,EAAiB,CAAC,OAEvC,OAAQ,GACN,IAAK,SACL,IAAK,SACL,IAAK,SACH,EAAiB,CAAC,EAClB,KACF,KAAK,SACH,OAAQ,EAAS,QAAQ,EACvB,KAAK,EACL,KAAK,EACH,EAAiB,CAAC,EAClB,KACF,MAAK,EACH,OAEE,EACE,CAFD,EAAiB,EAAS,KAAA,AAAK,EAEf,EAAS,QAAQ,EAChC,EACA,EACA,EACA,EAGR,CACJ,CACF,GAAI,EACF,OACG,EAAW,EAAS,GACpB,EACC,KAAO,EAAY,IAAM,EAAc,EAAU,GAAK,EACxD,EAAY,IACN,EAAgB,GAClB,GADA,GACQ,IACL,EACC,EAAe,OAAO,CAAC,EADzB,AACqD,OAAS,GAAA,CAAG,CACnE,EAAa,EAAU,EAAO,EAAe,GAAI,SAAU,CAAC,EAC1D,OAAO,CACT,EAAA,CAAE,CACF,MAAQ,IACP,EAAe,MAAhB,CAEI,IACA,EAFF,CAGK,MAAQ,EAAS,GAAG,EAArB,AACC,GAAY,EAAS,GAAG,GAAK,EAAS,GAAG,CACtC,GACA,CAAC,GAAK,EAAS,GAAA,AAAG,EAAE,OAAO,CACzB,EACA,OACE,GAAA,CAAG,CACX,EAVH,EAtGJ,EAAa,EAAW,IAAI,CAsGb,AAtGe,EAAQ,AAiHlC,EAjH6C,KAAK,GAkHrD,EAAM,IAAI,CAAC,EAAA,CAAS,CACxB,EAEJ,EAAiB,EACjB,IAAI,EAAiB,KAAO,EAAY,IAAM,EAAY,IAC1D,GAAI,EAAY,GACd,IAAK,IAAI,EAAI,EAAG,EAAI,EAAS,MAAM,CAAE,IAEhC,EAAO,EAAiB,EAD1B,EAAY,CAAQ,CAAC,EAAE,CAC4B,GACjD,EADsC,CACpB,EACjB,EACA,EACA,EACA,EACA,QAEH,GAAM,AAA8B,IAA1B,QAAyC,OAAO,EArJ/D,AAAI,QADiB,CACR,CAqJgB,IArJC,OADI,GACS,OAAO,EAAsB,KAIjE,QAJ0D,IAI3C,OAHtB,AAG6B,EAF1B,GAAyB,CAAa,CAAC,EAAsB,EAC9D,CAAa,CAAC,aAAa,AAAb,EAC6B,EAAgB,IAiJhC,EAC3B,IACE,EAAW,EAAE,IAAI,CAAC,GAAW,EAAI,EACjC,CAAC,CAAC,EAAY,EAAS,IAAI,EAAA,CAAE,CAAE,IAAI,EAGlC,AACE,EAAO,EAAiB,IADd,EAAU,KAAK,CACwB,EAAX,GACtC,GAAkB,EACjB,EACA,EACA,EACA,EACA,QAEH,GAAI,WAAa,EAAM,CAC1B,GAAI,YAAe,OAAO,EAAS,IAAI,CACrC,OAAO,EA3Hb,AA4HQ,SA5HC,AAAgB,CAAQ,EAC/B,OAAQ,EAAS,MAAM,EACrB,IAAK,YACH,OAAO,EAAS,KAClB,AADuB,KAClB,WACH,MAAM,EAAS,MAAM,AACvB,SACE,OACG,UAAa,OAAO,EAAS,MAAM,CAChC,EAAS,IAAI,CAAC,EAAM,IAClB,EAAS,EAAX,IAAiB,CAAG,UACpB,EAAS,IAAI,CACX,SAAU,CAAc,EACtB,YAAc,EAAS,MAAM,EACzB,EAAF,CAAW,MAAM,CAAG,YACnB,EAAS,KAAK,CAAG,CAAA,CAAe,AACrC,EACA,SAAU,CAAK,EACb,YAAc,EAAS,MAAM,GACzB,CAAF,CAAW,MAAM,CAAG,WAAc,EAAS,MAAM,CAAG,CAAA,CAAM,AAC9D,EAAA,CACD,CACL,EAAS,MAAM,EAEf,IAAK,YACH,OAAO,EAAS,KAAK,AACvB,KAAK,WACH,MAAM,EAAS,MAAM,AACzB,CACJ,CACA,MAAM,CACR,EA6FwB,GAChB,EACA,EACA,EACA,EAGJ,OAAM,MACJ,EACE,GACA,qBAJJ,CAI0B,CAJlB,OAAO,EAAA,EAKP,qBAAuB,OAAO,IAAI,CAAC,GAAU,IAAI,CAAC,MAAQ,IAC1D,GAGV,CACA,OAAO,CACT,EAKe,EAAU,EAAQ,GAAI,GAAI,SAAU,CAAK,EACpD,OAAO,EAAK,IAAI,CAAC,EAAS,EAAO,IACnC,GACO,CACT,CACA,SAAS,EAAgB,CAAO,EAC9B,GAAI,CAAC,IAAM,EAAQ,OAAO,CAAE,CAC1B,IAAI,EAAO,EAAQ,OAAO,CAE1B,CADA,EAAO,GAAA,EACF,IAAI,CACP,SAAU,CAAY,GAChB,IAAM,EAAQ,OAAO,EAAI,CAAC,IAAM,EAAQ,OAAO,AAAP,IACzC,EAAQ,OAAO,CAAG,EAAK,EAAQ,OAAO,CAAG,CAAA,CAC9C,EACA,SAAU,CAAK,GACT,IAAM,EAAQ,OAAO,EAAI,CAAC,IAAM,EAAQ,OAAA,AAAO,IAChD,EAAQ,OAAO,CAAG,EAAK,EAAQ,OAAO,CAAG,CAAA,CAC9C,GAEF,CAAC,IAAM,EAAQ,OAAO,GAAM,CAAF,CAAU,OAAO,CAAG,EAAK,EAAQ,OAAO,CAAG,CAAA,CAAK,AAC5E,CACA,GAAI,IAAM,EAAQ,OAAO,CAAE,OAAO,EAAQ,OAAO,CAAC,OAAO,AACzD,OAAM,EAAQ,OAChB,AADuB,CAEvB,SAAS,IACP,OAAO,IAAI,OACb,CACA,SAAS,IACP,MAAO,CAAE,EAAG,EAAG,EAAG,KAAK,EAAG,EAAG,KAAM,EAAG,IAAK,CAC7C,CA+BA,EAAQ,QAAQ,CAAG,EACnB,EAAQ,QAAQ,CA/BD,CACb,CA8BiB,GA9BZ,EACL,QAAS,SAAU,CAAQ,CAAE,CAAW,CAAE,CAAc,EACtD,EACE,EACA,WACE,EAAY,KAAK,CAAC,IAAI,CAAE,UAC1B,EACA,EAEJ,EACA,MAAO,SAAU,CAAQ,EACvB,IAAI,EAAI,EAIR,OAHA,EAAY,EAAU,WACpB,GACF,GACO,CACT,EACA,QAAS,SAAU,CAAQ,EACzB,OACE,EAAY,EAAU,SAAU,CAAK,EACnC,OAAO,CACT,IAAM,EAAE,AAEZ,EACA,KAAM,SAAU,CAAQ,EACtB,GAAI,CAAC,EAAe,GAAW,MAAM,MAAM,EAAuB,MAClE,OAAO,CACT,CACF,EAGA,EAAQ,QAAQ,CAAG,EACnB,EAAQ,QAAQ,CAAG,EACnB,EAAQ,UAAU,CAAG,EACrB,EAAQ,QAAQ,CAAG,EACnB,EAAQ,cAAc,CAAG,EACzB,EAAQ,+DAA+D,CACrE,EACF,EAAQ,KAAK,CAAG,SAAU,CAAE,EAC1B,OAAO,WACL,IAAI,EAAa,EAAqB,CAAC,CACvC,GAAI,CAAC,EAAY,OAAO,EAAG,KAAK,CAAC,KAAM,WACvC,IAAI,EAAQ,EAAW,eAAe,CAAC,EAEvC,MAAK,KADL,CACW,CADE,EAAM,GAAG,CAAC,EAAA,IAEnB,CAAF,CAAe,IAAoB,EAAM,GAAG,CAAC,EAAI,EAAA,CAAW,CAC9D,EAAQ,EACR,IAAK,IAAI,EAAI,UAAU,MAAM,CAAE,EAAQ,EAAG,IAAS,CACjD,IAAI,EAAM,SAAS,CAAC,EAAM,CAC1B,GACE,YAAe,OAAO,GACrB,UAAa,OAAO,GAAO,OAAS,EACrC,CACA,IAAI,EAAc,EAAW,CAC7B,AAD8B,QACrB,IAAgB,EAAW,CAAC,CAAG,EAAc,IAAI,CAAlC,MAAkC,CAAS,CAEnE,KAAK,KADL,CACW,CADE,EAAY,GAAG,CAAC,EAAA,IAEzB,CAAF,CAAe,IAAoB,EAAY,GAAG,CAAC,EAAK,EAAA,CAC5D,AADuE,MAGnE,QADD,CACU,CADI,GAAW,AAAC,IACA,EAAW,CAAC,CAAG,EAAc,CAA9B,GAAkC,GAAA,CAAK,CAE/D,KAAK,IADJ,EACU,CADG,EAAY,GAAG,CAAC,EAAA,IAE1B,CAAF,CAAe,IACf,EAAY,GAAG,CAAC,EAAK,EAAA,CAAW,AACxC,CACA,GAAI,IAAM,EAAW,CAAC,CAAE,OAAO,EAAW,CAAC,CAC3C,GAAI,IAAM,EAAW,CAAC,CAAE,MAAM,EAAW,CAAC,CAC1C,GAAI,CACF,IAAI,EAAS,EAAG,KAAK,CAAC,KAAM,WAG5B,MADA,AADA,GAAQ,CAAA,EACF,CAAC,CAAG,EACF,EAAM,CAAC,CAAG,CACpB,CAAE,MAAO,EAAO,CACd,KAA+B,CAAvB,EAAS,CAAA,EAAqB,CAAC,CAAG,EAAK,EAAO,CAAC,CAAG,EAAQ,CACpE,CACF,CACF,EACA,EAAQ,WAAW,CAAG,WACpB,IAAI,EAAa,EAAqB,CAAC,CACvC,OAAO,EAAa,EAAW,WAAW,GAAK,IACjD,EACA,EAAQ,iBAAiB,CAAG,WAC1B,OAAO,IACT,EACA,EAAQ,YAAY,CAAG,SAAU,CAAO,CAAE,CAAM,CAAE,CAAQ,EACxD,GAAI,MAAS,EACX,MAAM,GADgB,GACV,EADe,AACQ,IAAK,EADP,EAEnC,IAAI,EAAQ,EAAO,CAAC,EAAG,EAAQ,KAAK,EAClC,EAAM,EAAQ,GAAG,CACnB,GAAI,MAAQ,EACV,IAAK,KAAa,KAAK,IAAM,EAAO,GAAG,GAAK,CAAD,CAAO,GAAK,EAAO,GAAA,AAAG,EAAG,EAClE,AAAC,EAAe,IAAI,CAAC,EAAQ,IAC3B,QAAU,GACV,WAAa,GACb,aAAe,IACd,QAAU,GAAY,KAAK,IAAM,EAAO,GAAG,AAAH,IACxC,AAAD,CAAM,CAAC,EAAS,CAAG,CAAM,CAAC,EAAA,AAAS,EACzC,IAAI,EAAW,UAAU,MAAM,CAAG,EAClC,GAAI,IAAM,EAAU,EAAM,QAAQ,CAAG,OAChC,GAAI,EAAI,EAAU,CACrB,IAAK,IAAI,EAAa,MAAM,GAAW,EAAI,EAAG,EAAI,EAAU,IAC1D,CAAU,CAAC,EAAE,CAAG,SAAS,CAAC,EAAI,EAAE,AAClC,GAAM,QAAQ,CAAG,CACnB,CACA,OAAO,EAAa,EAAQ,IAAI,CAAE,EAAK,EACzC,EACA,EAAQ,aAAa,CAAG,SAAU,CAAI,CAAE,CAAM,CAAE,CAAQ,EACtD,IAAI,EACF,EAAQ,CAAC,EACT,EAAM,KACR,GAAI,MAAQ,EACV,IAAK,KAAa,KAAK,IAAM,EAAO,GAAG,GAAK,CAAD,CAAO,GAAK,EAAO,GAAA,AAAG,EAAG,EAClE,EAAe,IAAI,CAAC,EAAQ,IAC1B,QAAU,GACV,WAAa,GACb,aAAe,IACd,CAAK,CAAC,EAAS,CAAG,CAAM,CAAC,CAA1B,CAAmC,AAAT,EAChC,IAAI,EAAiB,UAAU,MAAM,CAAG,EACxC,GAAI,IAAM,EAAgB,EAAM,QAAQ,CAAG,OACtC,GAAI,EAAI,EAAgB,CAC3B,IAAK,IAAI,EAAa,MAAM,GAAiB,EAAI,EAAG,EAAI,EAAgB,IACtE,CAAU,CAAC,EAAE,CAAG,SAAS,CAAC,EAAI,EAAE,CAClC,EAAM,QAAQ,CAAG,CACnB,CACA,GAAI,GAAQ,EAAK,YAAY,CAC3B,IAAK,KAAc,EAAiB,EAAK,YAAY,CACnD,CADsD,IACjD,IAAM,CAAK,CAAC,EAAS,GACvB,CAAK,AAAN,CAAO,EAAS,CAAG,CAAc,CAAC,EAAA,AAAS,EACjD,OAAO,EAAa,EAAM,EAAK,EACjC,EACA,EAAQ,SAAS,CAAG,WAClB,MAAO,CAAE,QAAS,IAAK,CACzB,EACA,EAAQ,UAAU,CAAG,SAAU,CAAM,EACnC,MAAO,CAAE,SAAU,EAAwB,OAAQ,CAAO,CAC5D,EACA,EAAQ,cAAc,CAAG,EACzB,EAAQ,IAAI,CAAG,SAAU,CAAI,EAC3B,MAAO,CACL,SAAU,EACV,SAAU,CAAE,QAAS,CAAC,EAAG,QAAS,CAAK,EACvC,MAAO,CACT,CACF,EACA,EAAQ,IAAI,CAAG,SAAU,CAAI,CAAE,CAAO,EACpC,MAAO,CACL,SAAU,EACV,KAAM,EACN,QAAS,KAAK,IAAM,EAAU,KAAO,CACvC,CACF,EACA,EAAQ,GAAG,CAAG,SAAU,CAAM,EAC5B,OAAO,EAAqB,CAAC,CAAC,GAAG,CAAC,EACpC,EACA,EAAQ,WAAW,CAAG,SAAU,CAAQ,CAAE,CAAI,EAC5C,OAAO,EAAqB,CAAC,CAAC,WAAW,CAAC,EAAU,EACtD,EACA,EAAQ,aAAa,CAAG,WAAa,EACrC,EAAQ,KAAK,CAAG,WACd,OAAO,EAAqB,CAAC,CAAC,KAAK,EACrC,EACA,EAAQ,OAAO,CAAG,SAAU,CAAM,CAAE,CAAI,EACtC,OAAO,EAAqB,CAAC,CAAC,OAAO,CAAC,EAAQ,EAChD,EACA,EAAQ,OAAO,CAAG,gECxahB,EAAO,OAAO,CAAA,EAAA,CAAA,CAAA,0YkDAZ,EFDA,E9BDA,EgCsOM,CvBvOH,OAAM,UAAuB,MAChC,YAAY,CAAO,CAAE,CAAO,CAAC,CACzB,KAAK,CAAC,CAAC,WAAW,EAAE,EAAQ,QAAQ,CAAC,KAAO,EAAU,EAAU,IAAI,0BAA0B,CAAC,CAAE,GACjG,IAAI,CAAC,IAAI,CAAG,gBAChB,CACJ,CmCFW,CnCIX,QmCJoB,EAAmB,CAAI,EACvC,OAAO,EAAK,UAAU,CAAC,KAAO,EAAO,CAAC,CAAC,CnCGA,CmCHE,EAAA,CAAM,AACnD,CkDeW,ClDbX,QkDaoB,EAAiB,CAAK,EACtC,OAAO,EAAmB,EAAM,KAAK,CAAC,KAAK,MAAM,CAAC,CAAC,EAAU,EAAS,ClDd1B,CkDciC,IAEzE,AAAK,E5FlBa,A4FsBlB,EAJI,EAIA,EAAe,A5FtBhB,C4FkBW,A5FlBJ,CAAC,EAAE,EAAY,EAAQ,E4FsBJ,M5FtBY,CAAC,M4F0BvB,KAAK,CAApB,CAAO,CAAC,EAAE,EAIV,CAAa,SAAZ,GAAkC,UAAZ,CAAY,CAAO,EAAK,IAAU,EAAS,MAAM,CAAG,EAPpE,CAOuE,CAG3E,CAAA,EAAG,EAAS,CAAC,EAAE,EAAA,CAAS,CAdpB,EAeZ,IACP,CAIW,SAAS,EAAgB,CAAG,EACnC,OAAO,EAAI,OAAO,CAAC,cACnB,KACJ,CjC3CW,CiC6CX,QjC7CoB,EAAU,CAAI,EAC9B,IAAM,EAAY,EAAK,OAAO,CAAC,KACzB,EAAa,CiC2Cc,CjC3CT,OAAO,CAAC,KAC1B,EAAW,EAAa,CAAC,IAAM,CAAD,CAAa,GAAK,EAAa,CAAA,CAAS,QAC5E,AAAI,GAAY,EAAY,CAAC,EAClB,CADqB,AAExB,SAAU,EAAK,SAAS,CAAC,EAAG,EAAW,EAAa,GACpD,MAAO,EAAW,EAAK,SAAS,CAAC,EAAY,EAAY,CAAC,EAAI,OAAY,GAAa,GACvF,KAAM,EAAY,CAAC,EAAI,EAAK,KAAK,CAAC,GAAa,EACnD,EAEG,CACH,SAAU,EACV,MAAO,GACP,KAAM,EACV,CACJ,CqBbW,CrBeX,QqBfoB,EAAc,CAAI,CAAE,CAAM,EAC1C,GAAoB,UAAhB,AAA0B,OAAnB,EACP,CrBa8B,KqBbvB,GAEX,GAAM,UAAE,CAAQ,CAAE,CAAG,EAAU,GAC/B,OAAO,IAAa,GAAU,EAAS,UAAU,CAAC,EAAS,IAC/D,CCLW,CDOX,QCPoB,EAAiB,CAAI,CAAE,CAAM,EAa7C,GAAI,CAAC,EAAc,EAAM,GACrB,MAD8B,CACvB,EAGX,IAAM,EAAgB,EDViB,ACUZ,KAAK,CAAC,EAAO,MAAM,SAE9C,AAAI,EAAc,UAAU,CAAC,KAClB,CADwB,CAK5B,CAAC,CAAC,EAAE,EAAA,CAAe,AAC9B,EAEA,8CAA8C,2HpGnC9C,QG0B4C,EAQI,EAkCH,EAIL,EAQG,EAOH,EAIF,EAjEoB,AAqEH,EAvBL,GAJU,CAlCM,AAqDhB,AAIJ,AiB3FM,CjBgFI,CiBvEC,EGTX,IV2Pb,IN7O7B,CgBdmD,CvBAvD,Aa2PuC,CO3P4B,CpBAnE,EAAA,CG+FgF,AH/FhF,CAAA,EoBS6E,KpBRtE,IAAM,EAA2B,CAAA,EAAA,EAAA,uBAAA,AAAuB,KAE/D,gDkFKA,IAAM,EAAsB,ClFL2B,MkFKpB,GAAG,CAAC,yBACjC,EAA0B,WA8KzB,SAAS,EAAsB,MAAE,CAAI,yBAAE,CAAuB,uBAAE,CAAqB,CAAE,EAC1F,IAAM,EAAoB,CAAuB,CAAC,EAAoB,CACtE,GAAI,EACA,EAAkB,eADC,iBAC+B,CAAC,GAAG,CAAC,EAAiB,GAAO,GAC/E,EAAkB,qBAAqB,CAAG,MACvC,CACH,MAAM,EAAmC,IAAI,IAAI,CAC7C,CACI,EAAiB,GACjB,EACH,CACJ,EACK,GAxIJ,EAAiB,IAAI,IACpB,IAAI,MAAM,CAAC,EAAG,CACjB,IAAK,CAAC,CAAE,AAsI+B,CAtI3B,EACR,IAAM,EAAY,EAAiB,QAAQ,GAC3C,OAAO,GACH,IAAK,gBACL,IAAK,gBACL,IAAK,eACD,CACI,GAAI,CAAC,EACD,MAAM,GADM,IACC,cAAc,CAAC,IAAI,EAAe,CAAC,eAAe,EAAE,EAAK,uBAAuB,CAAC,EAAG,oBAAqB,CAClH,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,GAEJ,IAAM,EAAkB,EAAiC,GAAG,CAAC,EAAU,KAAK,EAC5E,GAAI,CAAC,EACD,MAAM,OAAO,EADK,YACS,CAAC,IAAI,EAAe,CAAC,yCAAyC,EAAE,EAAU,KAAK,CAAC,iBAAiB,CAAC,EAAG,oBAAqB,CACjJ,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,GAEJ,OAAO,CAAe,CAAC,EAAK,AAChC,CACJ,IAAK,gBACL,IAAK,mBACL,IAAK,uBACL,IAAK,mBACL,IAAK,uBACD,CACI,IAAI,EAAQ,EAAe,GAAG,CAAC,EAC3B,EAAC,IACD,EAjFb,CAgFqB,GAhFjB,EAiFiB,IAjFX,CAAC,EAAG,CACjB,IAAK,CAAC,CAAE,CAAE,EACN,IAAM,EAAY,EAAiB,QAAQ,GAC3C,GAAI,EAAW,CACX,IAAM,EAAkB,EAAiC,GAAG,CAAC,EAAU,KAAK,EAC5E,GAAuB,MAAnB,EAA0B,KAAK,EAAI,CAAe,CAAC,EAAK,CAAC,EAAG,CAC5D,CAD8D,MACvD,CAAe,CAAC,AA2EQ,EA3EH,CAAC,EAAG,AAuBxC,MAOI,CAPG,GAOE,IAAM,KAmJqD,AAnJzC,EAAiC,MAAM,GAAG,CAC7D,IAAM,EAAQ,CAAQ,CAAC,EAAK,CAAC,EAAG,CAChC,QAAc,IAAV,EACA,KADqB,EACd,CAEf,CAGR,CACJ,GAqCoB,EAAe,GAAG,CAAC,EAAM,IAE7B,OAAO,CACX,CACJ,QAEQ,MAAM,OAAO,cAAc,CAAC,IAAI,EAAe,CAAC,2DAA2D,EAAE,OAAO,GAAM,iBAAiB,CAAC,EAAG,oBAAqB,CAChK,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAEZ,CACJ,CACJ,IAwFI,CAAuB,CAAC,EAAoB,CAAG,kCAC3C,iCACA,wBACA,EACA,gBApFD,CAoFkB,GApFd,MAAM,CAAC,EAAG,CACjB,IAAK,CAAC,EAAG,SACD,EAA+B,QAM/B,EALE,EAA8H,OAAnH,AAA0H,CAA3H,CAA8B,AAqF1D,AAeW,GApGiJ,MAqFnJ,EACL,IAAM,EAAoB,CAAuB,CAAC,EAAoB,CACtE,GAAI,CAAC,AAvF2E,CAAC,CAwF7E,MAAM,OAAO,IADO,UACO,CAAC,IAAI,EAAe,gDAAiD,oBAAqB,CACjH,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,OAAO,CACX,IAKmC,qBAAqB,CApGmE,IAAgB,AAAP,GAA4B,AAAoE,EAAhG,KAA6B,EAAgC,CAA0B,CAAC,EAAA,AAAG,EAAY,KAAK,EAAI,EAA8B,OAAO,CAC7Q,GAAI,CAAC,EACD,OADU,AACH,AAEX,IAAM,EAAY,EAAiB,QAAQ,GAc3C,GAAI,CAAC,CAXD,EADA,EACc,CAAO,CA4BjC,AAAI,AA5B8B,EA2BD,EA3ByB,EAAU,AAW1C,CAZH,GA4BkB,AA3B+B,CA4B5C,GAAV,IACP,CADyB,CAG7B,MAAQ,EA/B2D,CAShD,OAAO,MAAM,CAAC,GAAS,EAAE,CAAC,IAGxC,OAAO,AAEX,GAAM,UAAE,CAAQ,OAAE,CAAK,CAAE,CAAG,EAC5B,MAAO,CACH,GAAI,EACJ,KAAM,EACN,OAAQ,EAAE,OACV,CACJ,CACJ,CACJ,EAqDI,CACJ,CACJ,2C1D3MO,OAAM,UAA2B,MACpC,YAAY,MAAE,CAAI,CAAE,CAAC,CACjB,KAAK,CAAC,CAAC,gBAAgB,EAAE,EAAK;;;;;;;EAOpC,CAAC,CACC,CACJ,CACO,MAAM,UAAyB,MAClC,aAAa,CACT,KAAK,CAAC,CAAC;;EAEb,CAAC,CACC,CACJ,CACO,MAAM,UAAuB,MAChC,aAAa,CACT,KAAK,CAAC,CAAC;;EAEb,CAAC,CACC,CACJ,EAEA,iCAAiC,sDU1B1B,IAAM,EAA2B,2BAE3B,EAA0B,OAC1B,EAAkC,OAElC,EAA8B,yBAC9B,EAA6C,sCAC7C,EAA0B,YAC1B,EAAqB,eACrB,EAAa,OAEb,EAAmB,QACnB,EAAmB,QAEnB,EAAyB,oBACzB,EAAqC,0BACrC,EAAyC,8BAOzC,EAA6B,QAwDhC,EAAuB,CAG3B,OAAQ,SAIR,sBAAuB,MAGvB,oBAAqB,MAGrB,cAAe,iBAGf,QAAS,WAGT,QAAS,WAGT,WAAY,aAGZ,WAAY,aAGZ,UAAW,aAGX,gBAAiB,oBAGjB,gBAAiB,oBAGjB,aAAc,iBAGd,aAAc,gBACpB,EqEhHW,SAAS,GAA4B,CAAW,EACvD,IAAM,EAAU,IAAI,QACpB,IAAK,GAAI,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,GAIpC,IAAK,IAAI,EAJwC,GAInC,AAHC,MAAM,CAGA,MAHO,CAAC,GAAS,EAAQ,CAC1C,EACH,CAEoB,SAAN,IAAmB,AACb,UAAb,AAAuB,OAAhB,IACP,EAAI,EAAE,QAAQ,EAAA,EAElB,EAAQ,MAAM,CAAC,EAAK,IAG5B,OAAO,CACX,CAUU,SAAS,GAAmB,CAAa,EAC/C,IAEI,EACA,EACA,EACA,EACA,EANA,EAAiB,EAAE,CACnB,EAAM,EAMV,SAAS,IACL,KAAM,EAAM,EAAc,MAAM,EAAI,KAAK,IAAI,CAAC,EAAc,MAAM,CAAC,KAC/D,CADqE,EAC9D,EAEX,OAAO,EAAM,EAAc,MAAM,AACrC,CAKA,KAAM,EAAM,EAAc,MAAM,EAAC,CAG7B,IAFA,EAAQ,EACR,GAAwB,EAClB,KAEF,GAAI,AAAO,MADX,GADmB,AACd,EAAc,MAAM,CAAC,EAAA,EACV,CAMZ,IAJA,EAAY,EACZ,GAAO,EACP,IACA,EAAY,EACN,EAAM,EAAc,MAAM,EAbjC,AAAO,EAa8B,KAd5C,EAAK,EAAc,MAAM,CAAC,CAcmC,CAdnC,GACE,MAAP,GAAc,AAAO,SAc9B,GAAO,CAGP,GAAM,EAAc,MAAM,EAAkC,KAAK,CAAnC,EAAc,MAAM,CAAC,IAEnD,EAAwB,GAExB,EAAM,EACN,EAAe,IAAI,CAAC,EAAc,SAAS,CAAC,EAAO,IACnD,EAAQ,GAIR,EAAM,EAAY,CAE1B,MACI,CADG,EACI,GAGX,CAAC,GAAyB,GAAO,EAAc,MAAA,AAAM,EAAE,CACvD,EAAe,IAAI,CAAC,EAAc,SAAS,CAAC,EAAO,EAAc,MAAM,EAE/E,CACA,OAAO,CACX,CAOW,SAAS,GAA0B,CAAO,EACjD,IAAM,EAAc,CAAC,EACf,EAAU,EAAE,CAClB,GAAI,EACA,IAAK,GADI,AACE,CAAC,EAAK,EAAM,GAAI,EAAQ,OAAO,GAAG,AACf,cAAc,CAApC,EAAI,WAAW,IAIf,EAAQ,IAAI,IAAI,GAAmB,IACnC,CAAW,CAAC,EAAI,CAAsB,IAAnB,EAAQ,MAAM,CAAS,CAAO,CAAC,EAAE,CAAG,GAEvD,CAAW,CAAC,EAAI,CAAG,EAI/B,OAAO,CACX,CAGW,SAAS,GAAY,CAAG,EAC/B,GAAI,CACA,OAAO,OAAO,IAAI,IAAI,OAAO,IACjC,CAAE,MAAO,EAAO,CACZ,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,kBAAkB,EAAE,OAAO,GAAK,4FAA4F,CAAC,CAAE,CAClK,MAAO,CACX,GAAI,oBAAqB,CACrB,MAAO,MACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACJ,CAIW,SAAS,GAAwB,CAAG,EAK3C,IAAK,IAAM,IAJM,CACb,EACA,EACH,CAEG,AADiB,GACb,IAAQ,EADc,CACJ,EAAI,UAAU,CAAC,GACjC,MAD0C,CACnC,EAAI,SAAS,CAAC,EAAO,MAAM,EAG1C,OAAO,IACX,CpE9IO,CoEgJP,QpEhJgB,GAAmB,CAAW,CAAE,CAAQ,CAAE,CAAc,EACpE,GAAK,CAAD,EAIJ,IAAK,IAAM,CoE2IkB,CpE/IX,GACd,GACA,GAAiB,EAAe,QADhB,GAC2B,EAAA,EAE5B,GAGf,GAAI,IADmB,EAFI,AAEC,MAAM,CACjB,CADmB,MAAM,IAAK,EAAE,CAAC,EAAE,CAAC,eAClB,IAAmB,EAAK,aAAa,CAAC,WAAW,IAAM,EAAK,OAAO,EAAE,KAAK,AAAC,GAAS,EAAO,WAAW,KAAO,GAC5I,OAAO,CAEf,CACJ,C4DNW,C5DQX,GANyK,K4DFrJ,GAAoB,CAAK,EACzC,OAAO,EAAM,OAAO,CAAC,MAAO,KAAO,GACvC,CnBJW,CmBMX,C5DIgD,OyCV5B,GAAc,CAAI,CAAE,CAAM,EAC1C,GAAI,CAAC,EAAK,UAAU,CAAC,MAAQ,CAAC,EAC1B,MADkC,CmBKO,AnBJlC,EAEX,GAAM,UAAE,CAAQ,OAAE,CAAK,MAAE,CAAI,CAAE,CAAG,EAAU,GAC5C,MAAO,CAAA,EAAG,EAAA,EAAS,EAAA,EAAW,EAAA,EAAQ,EAAA,CAAM,AAChD,CgBLW,ChBOX,QgBPoB,GAAc,CAAI,CAAE,CAAM,EAC1C,GAAI,CAAC,EAAK,UAAU,CAAC,MAAQ,CAAC,EAC1B,ChBKmC,KgBND,CAC3B,EAEX,GAAM,UAAE,CAAQ,OAAE,CAAK,MAAE,CAAI,CAAE,CAAG,EAAU,GAC5C,MAAO,CAAA,EAAG,EAAA,EAAW,EAAA,EAAS,EAAA,EAAQ,EAAA,CAAM,AAChD,CHNW,CGQX,QHRoB,GAAY,CAAM,CAAE,CAAO,EAG3C,IAAI,EACJ,GAAI,GAAS,MAAQ,CAAC,MAAM,EGIW,KHJJ,CAAC,EAAQ,IAAI,EAC5C,CAD+C,CACpC,EAAQ,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC,IAAK,EAAE,CAAC,EAAE,MAChD,IAAI,EAAO,QAAQ,CAEnB,CAFqB,MACxB,EAAW,EAAO,QAAQ,CAE9B,OAAO,EAAS,WAAW,EAC/B,CvD+GY,CuD7GZ,CvD6GiC,qBAAqB,CAC1C,EAAqB,aAAa,CAGlC,CuDjH4B,CvDiHP,qBAAqB,CAC1C,EAAqB,aAAa,CAClC,EAAqB,UAAU,CAC/B,EAAqB,UAAU,CAI/B,EAAqB,OAAO,CAC5B,EAAqB,OAAO,CAG5B,EAAqB,mBAAmB,CACxC,EAAqB,eAAe,CAGpC,EAAqB,qBAAqB,CAC1C,EAAqB,aAAa,CAClC,EAAqB,mBAAmB,CACxC,EAAqB,eAAe,CACpC,EAAqB,MAAM,CAC3B,EAAqB,UAAU,CAC/B,EAAqB,UAAU,CAI/B,EAAqB,qBAAqB,CAC1C,EAAqB,mBAAmB,CACxC,EAAqB,eAAe,CACpC,EAAqB,aAAa,+QAzIN,slBjCjBpC,IAAM,GAAQ,IAAI,QASX,SAAS,GAAoB,CAAQ,CAAE,CAAO,MAWjD,EATJ,GAAI,CAAC,EAAS,MAAO,UACjB,CACJ,EAEA,IAAI,EAAoB,GAAM,GAAG,CAAC,GAC7B,IACD,EAAoB,EAAQ,GAAG,CAAC,AAAC,GAAS,EAAO,EAD7B,SACwC,IAC5D,GAAM,GAAG,CAAC,EAAS,IAKvB,IAAM,EAAW,EAAS,KAAK,CAAC,IAAK,GAGrC,GAAI,CAAC,CAAQ,CAAC,EAAE,CAAE,MAAO,UACrB,CACJ,EAEA,IAAM,EAAU,CAAQ,CAAC,EAAE,CAAC,WAAW,GAGjC,EAAQ,EAAkB,OAAO,CAAC,UACxC,AAAI,EAAQ,EAAU,CAAP,SACX,CACJ,GAEA,EAAiB,CAAO,CAAC,EAAM,CAGxB,CACH,SAFJ,EAAW,EAAS,KAAK,CAAC,EAAe,MAAM,CAAG,IAAM,mBAGpD,CACJ,EACJ,EAEA,yCmE/CA,IAAM,GAA2B,CnE+CgB,0FmE9CjD,SAAS,GAAS,CAAG,CAAE,CAAI,EACvB,OAAO,IAAI,IAAI,OAAO,GAAK,OAAO,CAAC,GAA0B,aAAc,GAAQ,OAAO,GAAM,OAAO,CAAC,GAA0B,aACtI,CACA,IAAM,GAAW,OAAO,kBACjB,OAAM,GACT,YAAY,CAAK,CAAE,CAAU,CAAE,CAAI,CAAC,CAChC,IAAI,EACA,EACsB,UAAtB,OAAO,GAA2B,aAAc,GAAoC,UAAtB,AAAgC,OAAzB,GACrE,EAAO,EACP,EAAU,GAAQ,CAAC,GAEnB,EAAU,GAAQ,GAAc,CAAC,EAErC,IAAI,CAAC,GAAS,CAAG,CACb,IAAK,GAAS,EAAO,GAAQ,EAAQ,IAAI,EACzC,QAAS,EACT,SAAU,EACd,EACA,IAAI,CAAC,OAAO,EAChB,CACA,SAAU,CACN,IAAI,EAAwC,EAAmC,EAA6B,EAAyC,EACrJ,IAAM,ETzBP,ASyBc,STzBL,AAAoB,CAAQ,CAAE,CAAO,EACjD,GAAM,UAAE,CAAQ,MAAE,CAAI,eAAE,CAAa,CAAE,CAAG,EAAQ,UAAU,EAAI,CAAC,EAC3D,EAAO,UACT,EACA,cAA4B,MAAb,EAAmB,EAAS,QAAQ,CAAC,KAAO,CAC/D,EACI,GAAY,EAAc,EAAK,QAAQ,CAAE,KACzC,EAAK,IAD+C,IACvC,CAAG,EAAiB,EAAK,QAAQ,CAAE,GAChD,EAAK,QAAQ,CAAG,GAEpB,IAAI,EAAuB,EAAK,QAAQ,CACxC,GAAI,EAAK,QAAQ,CAAC,UAAU,CAAC,iBAAmB,EAAK,QAAQ,CAAC,QAAQ,CAAC,SAAU,CAC7E,IAAM,EAAQ,EAAK,QAAQ,CAAC,OAAO,CAAC,mBAAoB,IAAI,OAAO,CAAC,UAAW,IAAI,KAAK,CAAC,KAEzF,EAAK,OAAO,CADI,CAAK,CAAC,AACP,EADS,CAExB,EAAoC,UAAb,CAAK,CAAC,EAAE,CAAe,CAAC,CAAC,EAAE,EAAM,KAAK,CAAC,GAAG,IAAI,CAAC,KAAA,CAAM,CAAG,IAGrD,KAAtB,CAA4B,CAApB,SAAS,GACjB,EAAK,QAAQ,CAAG,CAAA,CAExB,CAGA,GAAI,EAAM,CACN,IAAI,EAAS,EAAQ,YAAY,CAAG,EAAQ,YAAY,CAAC,OAAO,CAAC,EAAK,QAAQ,EAAI,GAAoB,EAAK,QAAQ,CAAE,EAAK,OAAO,EACjI,EAAK,MAAM,CAAG,EAAO,cAAc,CACnC,EAAK,QAAQ,CAAG,EAAO,QAAQ,EAAI,EAAK,QAAQ,CAC5C,CAAC,EAAO,cAAc,EAAI,EAAK,OAAO,EAElC,AAFoC,CACxC,EAAS,EAAQ,YAAY,CAAG,EAAQ,YAAY,CAAC,OAAO,CAAC,GAAwB,GAAoB,EAAsB,EAAK,QAAO,EAChI,cAAc,EAAE,CACvB,EAAK,MAAM,CAAG,EAAO,cAAA,AAAc,CAG/C,CACA,OAAO,CACX,EAEA,ASbyC,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CAAE,CAC1D,WAAY,IAAI,CAAC,GAAS,CAAC,OAAO,ATYI,CSZH,UAAU,CAC7C,WAAW,EACX,aAAc,IAAI,CAAC,GAAS,CAAC,OAAO,CAAC,YAAY,AACrD,GACM,EAAW,GAAY,IAAI,CAAC,GAAS,CAAC,GAAG,CAAE,IAAI,CAAC,GAAS,CAAC,OAAO,CAAC,OAAO,EAC/E,IAAI,CAAC,GAAS,CAAC,YAAY,CAAG,IAAI,CAAC,GAAS,CAAC,OAAO,CAAC,YAAY,CAAG,IAAI,CAAC,GAAS,CAAC,OAAO,CAAC,YAAY,CAAC,kBAAkB,CAAC,GAAY,GAA8F,MAA1E,CAAiF,EAA7C,GAAkD,CAA9C,CAAC,EAA1C,CAAmD,CAAC,OAAO,CAAC,UAAA,AAAU,GAAqB,AAAqF,OAApF,EAAyC,EAAkC,IAAA,AAAI,EAAY,KAAK,EAAI,EAAuC,OAAO,CAAE,GAC1Y,IAAM,EAAgB,CAAC,AAA+D,OAA9D,EAA8B,IAAI,CAAC,GAAS,CAAC,YAAA,AAAY,EAAY,KAAK,EAAI,EAA4B,aAAA,AAAa,IAAkF,CAA7E,CAAC,KAAC,AAAkF,EAA7C,GAAkD,CAA9C,CAAC,GAAS,CAAC,OAAO,CAAC,UAAA,AAAU,GAAqB,AAAuF,OAAtF,EAA0C,EAAmC,IAAA,AAAI,EAAY,KAAK,EAAI,EAAwC,aAAa,CAC7Y,KAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CAAG,EAAK,QAAQ,CAC3C,IAAI,CAAC,GAAS,CAAC,aAAa,CAAG,EAC/B,IAAI,CAAC,GAAS,CAAC,QAAQ,CAAG,EAAK,QAAQ,EAAI,GAC3C,IAAI,CAAC,GAAS,CAAC,OAAO,CAAG,EAAK,OAAO,CACrC,IAAI,CAAC,GAAS,CAAC,MAAM,CAAG,EAAK,MAAM,EAAI,EACvC,IAAI,CAAC,GAAS,CAAC,aAAa,CAAG,EAAK,aAAa,AACrD,CACA,gBAAiB,KEvCkB,IAAI,EACnC,EFuCA,OAAO,EEvCI,AwBCR,SAAS,AAAU,CAAI,CAAE,CAAM,CAAE,CAAa,CAAE,CAAY,EAGnE,GAAI,CAAC,GAAU,IAAW,EAAe,OAAO,EAChD,IAAM,EAAQ,EAAK,WAAW,SAG9B,AAAI,CAAC,IACG,EAAc,EAAO,MADV,GAEX,AAD8B,EAChB,EAAO,CAAC,CAAC,EAAE,EAAO,WAAW,GAAA,CAAI,GAAG,AADb,EAItC,GAAc,EAH4C,AAGtC,CAAC,CAAC,EAAE,EAAA,CAAQ,CAC3C,EAEA,AxBhB6B,GFuCS,CAC1B,SAAU,IAAI,CAAC,GAAS,CAAC,QAAQ,CACjC,O0BzB0B,C1ByBjB,IAAI,CAAC,GAAS,CAAC,OAAO,CAC/B,cAAe,AAAC,IAAI,CAAC,GAAS,CAAC,OAAO,CAAC,WAAW,MAAkC,EAA/B,IAAI,CAAC,GAAS,CAAC,aAAa,CACjF,OAAQ,IAAI,CAAC,GAAS,CAAC,MAAM,CAC7B,SAAU,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CACrC,cAAe,IAAI,CAAC,GAAS,CAAC,aAAa,AAC/C,GE9C0B,QAAQ,CAAE,EAAK,MAAM,CAAE,EAAK,OAAO,MAAG,EAAY,EAAK,aAAa,CAAE,EAAK,YAAY,GACjH,EAAK,OAAO,EAAI,CAAC,EAAK,aAAA,AAAa,EAAE,CACrC,GAAW,GAAoB,EAAA,EAE/B,EAAK,OAAO,EAAE,CACd,EAAW,GAAc,GAAc,EAAU,CAAC,YAAY,EAAE,EAAK,OAAO,CAAA,CAAE,EAAqB,MAAlB,EAAK,QAAQ,CAAW,aAAe,QAAA,EAE5H,EAAW,GAAc,EAAU,EAAK,QAAQ,EACzC,CAAC,EAAK,OAAO,EAAI,EAAK,aAAa,CAAG,AAAC,EAAS,QAAQ,CAAC,KAAsC,EAA/B,GAAc,EAAU,KAAkB,GAAoB,EFuCrI,CACA,cAAe,CACX,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,MAAM,AACpC,CACA,IAAI,SAAU,CACV,OAAO,IAAI,CAAC,GAAS,CAAC,OAC1B,AADiC,CAEjC,IAAI,QAAQ,CAAO,CAAE,CACjB,IAAI,CAAC,GAAS,CAAC,OAAO,CAAG,CAC7B,CACA,IAAI,QAAS,CACT,OAAO,IAAI,CAAC,GAAS,CAAC,MAAM,EAAI,EACpC,CACA,IAAI,OAAO,CAAM,CAAE,CACf,IAAI,EAAwC,EAC5C,GAAI,CAAC,IAAI,CAAC,GAAS,CAAC,MAAM,EAAI,CAAC,CAAC,AAA2E,OAAO,AAAjF,EAAoC,GAAkD,CAA9C,CAAC,GAAS,CAAC,OAAO,CAAC,UAAU,AAAV,GAAoH,AAArF,OAAC,EAAyC,EAAkC,IAAA,AAAI,EAAY,KAAK,EAAI,EAAuC,OAAO,CAAC,QAAQ,CAAC,IACpR,GAD2R,GAAG,AACxR,OAAO,cAAc,CAAC,AAAI,UAAU,CAAC,8CAA8C,EAAE,EAAO,CAAC,CAAC,EAAG,oBAAqB,CACxH,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAI,CAAC,GAAS,CAAC,MAAM,CAAG,CAC5B,CACA,IAAI,eAAgB,CAChB,OAAO,IAAI,CAAC,GAAS,CAAC,aAAa,AACvC,CACA,IAAI,cAAe,CACf,OAAO,IAAI,CAAC,GAAS,CAAC,YAAY,AACtC,CACA,IAAI,cAAe,CACf,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,YAAY,AAC1C,CACA,IAAI,MAAO,CACP,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,IAAI,AAClC,CACA,IAAI,KAAK,CAAK,CAAE,CACZ,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,IAAI,CAAG,CAC9B,CACA,IAAI,UAAW,CACX,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,AACtC,CACA,IAAI,SAAS,CAAK,CAAE,CAChB,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CAAG,CAClC,CACA,IAAI,MAAO,CACP,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,IAAI,AAClC,CACA,IAAI,KAAK,CAAK,CAAE,CACZ,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,IAAI,CAAG,CAC9B,CACA,IAAI,UAAW,CACX,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,AACtC,CACA,IAAI,SAAS,CAAK,CAAE,CAChB,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CAAG,CAClC,CACA,IAAI,MAAO,CACP,IAAM,EAAW,IAAI,CAAC,cAAc,GAC9B,EAAS,IAAI,CAAC,YAAY,GAChC,MAAO,CAAA,EAAG,IAAI,CAAC,QAAQ,CAAC,EAAE,EAAE,IAAI,CAAC,IAAI,CAAA,EAAG,EAAA,EAAW,EAAA,EAAS,IAAI,CAAC,IAAI,CAAA,CACzE,AAD2E,CAE3E,IAAI,KAAK,CAAG,CAAE,CACV,IAAI,CAAC,GAAS,CAAC,GAAG,CAAG,GAAS,GAC9B,IAAI,CAAC,OAAO,EAChB,CACA,IAAI,QAAS,CACT,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,MAAM,AACpC,CACA,IAAI,UAAW,CACX,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,AACtC,CACA,IAAI,SAAS,CAAK,CAAE,CAChB,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CAAG,CAClC,CACA,IAAI,MAAO,CACP,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,IAAI,AAClC,CACA,IAAI,KAAK,CAAK,CAAE,CACZ,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,IAAI,CAAG,CAC9B,CACA,IAAI,QAAS,CACT,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,MAAM,AACpC,CACA,IAAI,OAAO,CAAK,CAAE,CACd,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,MAAM,CAAG,CAChC,CACA,IAAI,UAAW,CACX,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,AACtC,CACA,IAAI,SAAS,CAAK,CAAE,CAChB,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CAAG,CAClC,CACA,IAAI,UAAW,CACX,OAAO,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,AACtC,CACA,IAAI,SAAS,CAAK,CAAE,CAChB,IAAI,CAAC,GAAS,CAAC,GAAG,CAAC,QAAQ,CAAG,CAClC,CACA,IAAI,UAAW,CACX,OAAO,IAAI,CAAC,GAAS,CAAC,QAAQ,AAClC,CACA,IAAI,SAAS,CAAK,CAAE,CAChB,IAAI,CAAC,GAAS,CAAC,QAAQ,CAAG,EAAM,UAAU,CAAC,KAAO,EAAQ,CAAC,CAAC,EAAE,EAAA,CAAO,AACzE,CACA,UAAW,CACP,OAAO,IAAI,CAAC,IAChB,AADoB,CAEpB,QAAS,CACL,OAAO,IAAI,CAAC,IAAI,AACpB,CACA,CAAC,OAAO,GAAG,CAAC,+BAA+B,EAAG,CAC1C,MAAO,CACH,KAAM,IAAI,CAAC,IAAI,CACf,OAAQ,IAAI,CAAC,MAAM,CACnB,SAAU,IAAI,CAAC,QAAQ,CACvB,SAAU,IAAI,CAAC,QAAQ,CACvB,SAAU,IAAI,CAAC,QAAQ,CACvB,KAAM,IAAI,CAAC,IAAI,CACf,SAAU,IAAI,CAAC,QAAQ,CACvB,KAAM,IAAI,CAAC,IAAI,CACf,SAAU,IAAI,CAAC,QAAQ,CACvB,OAAQ,IAAI,CAAC,MAAM,CACnB,aAAc,IAAI,CAAC,YAAY,CAC/B,KAAM,IAAI,CAAC,IAAI,AACnB,CACJ,CACA,OAAQ,CACJ,OAAO,IAAI,GAAQ,OAAO,IAAI,EAAG,IAAI,CAAC,GAAS,CAAC,OAAO,CAC3D,CACJ,EAEA,6BlExLA,IAAA,GkEwLoC,AlExLpC,EAAA,CAAA,CAAA,QAEA,aqEEO,IAAM,GAAY,OAAO,QrEFG,WqEOxB,OAAM,WAAoB,QACjC,YAAY,CAAK,CAAE,EAAO,CAAC,CAAC,CAAC,CACzB,MAAM,EAAuB,UAAjB,OAAO,GAAsB,QAAS,EAAQ,EAAM,GAAG,CAAG,OAAO,GAC7E,GAAY,GAUR,aAAiB,QAAS,KAAK,CAAC,EAAO,GACtC,KAAK,CAAC,EAAK,GAChB,MAAM,EAAU,IAAI,GAAQ,EAAK,CAC7B,QAAS,GAA0B,IAAI,CAAC,OAAO,EAC/C,WAAY,EAAK,UAAU,AAC/B,GACA,IAAI,CAAC,GAAU,CAAG,CACd,QAAS,IAAI,GAAA,cAAc,CAAC,IAAI,CAAC,OAAO,UACxC,EACA,IAA4D,CAAvD,CAA+D,QAAQ,EAChF,CACJ,CACA,CAAC,OAAO,GAAG,CAAC,aAHkD,kBAGnB,EAAG,CAC1C,MAAO,CACH,QAAS,IAAI,CAAC,OAAO,CACrB,QAAS,IAAI,CAAC,OAAO,CACrB,IAAK,IAAI,CAAC,GAAG,CAEb,SAAU,IAAI,CAAC,QAAQ,CACvB,MAAO,IAAI,CAAC,KAAK,CACjB,YAAa,IAAI,CAAC,WAAW,CAC7B,YAAa,IAAI,CAAC,WAAW,CAC7B,QAAS,OAAO,WAAW,CAAC,IAAI,CAAC,OAAO,EACxC,UAAW,IAAI,CAAC,SAAS,CACzB,UAAW,IAAI,CAAC,SAAS,CACzB,OAAQ,IAAI,CAAC,MAAM,CACnB,KAAM,IAAI,CAAC,IAAI,CACf,SAAU,IAAI,CAAC,QAAQ,CACvB,SAAU,IAAI,CAAC,QAAQ,CACvB,eAAgB,IAAI,CAAC,cAAc,CACnC,OAAQ,IAAI,CAAC,MAAM,AACvB,CACJ,CACA,IAAI,SAAU,CACV,OAAO,IAAI,CAAC,GAAU,CAAC,OAAO,AAClC,CACA,IAAI,SAAU,CACV,OAAO,IAAI,CAAC,GAAU,CAAC,OAAO,AAClC,CAKE,IAAI,MAAO,CACT,MAAM,IAAI,CACd,CAKE,IAAI,IAAK,CACP,MAAM,IAAI,CACd,CACA,IAAI,KAAM,CACN,OAAO,IAAI,CAAC,GAAU,CAAC,GAAG,AAC9B,CACJ,EAEA,gC9ChFO,G8CgF4B,I9ChFtB,GACT,OAAO,IAAI,CAAM,CAAE,CAAI,CAAE,CAAQ,CAAE,CAC/B,IAAM,EAAQ,QAAQ,GAAG,CAAC,EAAQ,EAAM,SACnB,AAArB,YAAiC,AAA7B,OAAO,EACA,EAAM,IAAI,CAAC,GAEf,CACX,CACA,OAAO,IAAI,CAAM,CAAE,CAAI,CAAE,CAAK,CAAE,CAAQ,CAAE,CACtC,OAAO,QAAQ,GAAG,CAAC,EAAQ,EAAM,EAAO,EAC5C,CACA,OAAO,IAAI,CAAM,CAAE,CAAI,CAAE,CACrB,OAAO,QAAQ,GAAG,CAAC,EAAQ,EAC/B,CACA,OAAO,eAAe,CAAM,CAAE,CAAI,CAAE,CAChC,OAAO,QAAQ,cAAc,CAAC,EAAQ,EAC1C,CACJ,EAEA,mCAAmC,CEb5B,IAAM,GAA8B,uBAU9B,GAAiB,OAXe,yBAczC,GAPmC,mBADY,+BAWlD,wBArB4B,mEAyBa,0DACC,uFAJP,sBAvBV,asCGf,OAAM,WAA6B,MAC1C,aAAa,CACT,KAAK,CAAC,qGACV,CACA,OAAO,UAAW,CACd,MAAM,IAAI,EACd,CACJ,CACO,MAAM,WAAuB,QAChC,YAAY,CAAO,CAAC,CAGhB,KAAK,GACL,IAAI,CAAC,OAAO,CAAG,IAAI,MAAM,EAAS,CAC9B,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EAIvB,GAAoB,UAAhB,AAA0B,OAAnB,EACP,OAAO,GAAe,GAAG,CAAC,EAAQ,EAAM,GAE5C,IAAM,EAAa,EAAK,WAAW,GAI7B,EAAW,OAAO,IAAI,CAAC,GAAS,IAAI,CAAE,AAAD,GAAK,EAAE,WAAW,KAAO,GAEpE,GAAI,KAAoB,IAAb,EAEX,OAFqC,AAE9B,GAAe,GAAG,CAAC,EAAQ,EAAU,EAChD,EACA,IAAK,CAAM,CAAE,CAAI,CAAE,CAAK,CAAE,CAAQ,EAC9B,GAAoB,UAAhB,AAA0B,OAAnB,EACP,OAAO,GAAe,GAAG,CAAC,EAAQ,EAAM,EAAO,GAEnD,IAAM,EAAa,EAAK,WAAW,GAI7B,EAAW,OAAO,IAAI,CAAC,GAAS,IAAI,CAAE,AAAD,GAAK,EAAE,WAAW,KAAO,GAEpE,OAAO,GAAe,GAAG,CAAC,EAAQ,GAAY,EAAM,EAAO,EAC/D,EACA,IAAK,CAAM,CAAE,CAAI,EACb,GAAI,AAAgB,iBAAT,EAAmB,OAAO,GAAe,GAAG,CAAC,EAAQ,GAChE,IAAM,EAAa,EAAK,WAAW,GAI7B,EAAW,OAAO,IAAI,CAAC,GAAS,IAAI,CAAC,AAAC,GAAI,EAAE,WAAW,KAAO,UAE5C,AAAxB,IAAI,KAAO,GAEJ,CAF8B,EAEf,GAAG,CAAC,CAFkB,CAEV,EACtC,EACA,eAAgB,CAAM,CAAE,CAAI,EACxB,GAAoB,UAAhB,OAAO,EAAmB,OAAO,GAAe,cAAc,CAAC,EAAQ,GAC3E,IAAM,EAAa,EAAK,WAAW,GAI7B,EAAW,OAAO,IAAI,CAAC,GAAS,IAAI,CAAC,AAAC,GAAI,EAAE,WAAW,KAAO,UAEpE,IAAI,CAAoB,IAAb,GAEJ,GAAe,GAFe,OAAO,IAER,CAAC,EAAQ,EACjD,CACJ,EACJ,CAIE,OAAO,KAAK,CAAO,CAAE,CACnB,OAAO,IAAI,MAAM,EAAS,CACtB,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GACH,IAAK,SACL,IAAK,SACL,IAAK,MACD,OAAO,GAAqB,QAAQ,AACxC,SACI,OAAO,GAAe,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EACJ,CAOE,MAAM,CAAK,CAAE,QACX,AAAI,MAAM,OAAO,CAAC,GAAe,EAAM,IAAb,AAAiB,CAAC,MACrC,CACX,CAME,OAAO,KAAK,CAAO,CAAE,QACnB,AAAI,aAAmB,QAAgB,CAAP,CACzB,IAAI,GAAe,EAC9B,CACA,OAAO,CAAI,CAAE,CAAK,CAAE,CAChB,IAAM,EAAW,IAAI,CAAC,OAAO,CAAC,EAAK,CACX,UAApB,AAA8B,OAAvB,EACP,IAAI,CAAC,OAAO,CAAC,EAAK,CAAG,CACjB,EACA,EACH,CACM,MAAM,OAAO,CAAC,GACrB,EAAS,IAAI,CAAC,CADkB,EAGhC,IAAI,CAAC,OAAO,CAAC,EAAK,CAAG,CAE7B,CACA,OAAO,CAAI,CAAE,CACT,OAAO,IAAI,CAAC,OAAO,CAAC,EACxB,AAD6B,CAE7B,IAAI,CAAI,CAAE,CACN,IAAM,EAAQ,IAAI,CAAC,OAAO,CAAC,EAAK,QAChC,AAAI,KAAiB,IAAV,EAA8B,IAAI,CAAC,EAAZ,GAAiB,CAAC,GAC7C,IACX,CACA,IAAI,CAAI,CAAE,CACN,OAAO,KAA8B,IAAvB,IAAI,CAAC,OAAO,CAAC,EAAK,AACpC,CACA,IAAI,CAAI,CAAE,CAAK,CAAE,CACb,IAAI,CAAC,OAAO,CAAC,EAAK,CAAG,CACzB,CACA,QAAQ,CAAU,CAAE,CAAO,CAAE,CACzB,IAAK,GAAM,CAAC,EAAM,EAAM,GAAI,IAAI,CAAC,OAAO,GAAG,AACvC,EAAW,IAAI,CAAC,EAAS,EAAO,EAAM,IAAI,CAElD,CACA,CAAC,SAAU,CACP,IAAK,IAAM,KAAO,OAAO,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CACxC,IAAM,EAAO,EAAI,WAAW,GAGtB,EAAQ,IAAI,CAAC,GAAG,CAAC,EACvB,MAAM,CACF,EACA,EACH,AACL,CACJ,CACA,CAAC,MAAO,CACJ,IAAK,IAAM,KAAO,OAAO,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CACxC,IAAM,EAAO,EAAI,WAAW,EAC5B,OAAM,CACV,CACJ,CACA,CAAC,QAAS,CACN,IAAK,IAAM,KAAO,OAAO,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CAGxC,IAAM,EAAQ,IAAI,CAAC,GAAG,CAAC,EACvB,OAAM,CACV,CACJ,CACA,CAAC,OAAO,QAAQ,CAAC,EAAG,CAChB,OAAO,IAAI,CAAC,OAAO,EACvB,CACJ,EAEA,mCAAmC,AiCpKxB,OAAM,WAAoC,MACjD,aAAa,CACT,KAAK,CAAC,mJACV,CACA,OAAO,UAAW,CACd,MAAM,IAAI,EACd,CACJ,CACO,MAAM,GACT,OAAO,KAAK,CAAO,CAAE,CACjB,OAAO,IAAI,MAAM,EAAS,CACtB,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GACH,IAAK,QACL,IAAK,SACL,IAAK,MACD,OAAO,GAA4B,QAAQ,AAC/C,SACI,OAAO,GAAe,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EACJ,CACJ,CACA,IAAM,GAA8B,OAAO,GAAG,CAAC,wBAQxC,SAAS,GAAqB,CAAO,CAAE,CAAc,EACxD,MAAM,EANF,CADE,AACD,EAMgD,AAPpC,CAAO,CAAC,GAA4B,GACnC,EAAD,IAAO,IAMK,GANE,CAAC,IAAiC,GAAG,CAAvB,EAAS,MAAM,CAGrD,EAFI,EAAE,CAMb,GAAoC,GAAG,CAAnC,EAAqB,MAAM,CAC3B,MAAO,GAKX,IAAM,EAAa,IAAI,GAAA,eAAe,CAAC,GACjC,EAAkB,EAAW,MAAM,GAEzC,IAAK,IAAM,KAAU,EACjB,EAAW,GAAG,CAAC,GAGnB,IAAK,IAAM,EAJ+B,GAIrB,EACjB,EAAW,GAAG,CAAC,GAEnB,KAHqC,EAG9B,CACX,CACO,MAAM,GACT,OAAO,KAAK,CAAO,CAAE,CAAe,CAAE,CAClC,IAAM,EAAkB,IAAI,GAAA,eAAe,CAAC,IAAI,SAChD,IAAK,IAAM,KAAU,EAAQ,MAAM,GAAG,AAClC,EAAgB,GAAG,CAAC,GAExB,IAAI,EAAiB,EAAE,CACjB,EAAkB,IAAI,IACtB,EAAwB,KAE1B,IAAM,EAAY,EAAiB,QAAQ,GAM3C,GALI,IACA,EAAU,KADC,aACiB,CnEtEO,CmEsEJ,CAAA,CAGnC,EADmB,AACF,EADkB,MAAM,GACb,MAAM,CAAC,AAAC,GAAI,EAAgB,GAAG,CAAC,EAAE,IAAI,GAC9D,EAAiB,CACjB,IAAM,EAAoB,EAAE,CAC5B,IAAK,IAAM,KAAU,EAAe,CAChC,IAAM,EAAc,IAAI,GAAA,eAAe,CAAC,IAAI,SAC5C,EAAY,GAAG,CAAC,GAChB,EAAkB,IAAI,CAAC,EAAY,QAAQ,GAC/C,CACA,EAAgB,EACpB,CACJ,EACM,EAAiB,IAAI,MAAM,EAAiB,CAC9C,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GAEH,KAAK,GACD,OAAO,CAGX,KAAK,SACD,OAAO,SAAS,GAAG,CAAI,EACnB,EAAgB,GAAG,CAAoB,UAAnB,OAAO,CAAI,CAAC,EAAE,CAAgB,CAAI,CAAC,EAAE,CAAG,CAAI,CAAC,EAAE,CAAC,IAAI,EACxE,GAAI,CAEA,OADA,EAAO,MAAM,IAAI,GACV,CACX,QAAS,CACL,GACJ,CACJ,CACJ,KAAK,MACD,OAAO,SAAS,GAAG,CAAI,EACnB,EAAgB,GAAG,CAAoB,UAAnB,OAAO,CAAI,CAAC,EAAE,CAAgB,CAAI,CAAC,EAAE,CAAG,CAAI,CAAC,EAAE,CAAC,IAAI,EACxE,GAAI,CAEA,OADA,EAAO,GAAG,IAAI,GACP,CACX,QAAS,CACL,GACJ,CACJ,CACJ,SACI,OAAO,GAAe,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,GACA,OAAO,CACX,CACJ,CACO,SAAS,GAAoC,CAAY,EAC5D,IAAM,EAAiB,IAAI,MAAM,EAAa,cAAc,CAAE,CAC1D,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GACH,IAAK,SACD,OAAO,SAAS,GAAG,CAAI,EAGnB,OAFA,GAA6B,EAAc,oBAC3C,EAAO,MAAM,IAAI,GACV,CACX,CACJ,KAAK,MACD,OAAO,SAAS,GAAG,CAAI,EAGnB,OAFA,GAA6B,EAAc,iBAC3C,EAAO,GAAG,IAAI,GACP,CACX,CACJ,SACI,OAAO,GAAe,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,GACA,OAAO,CACX,CAUM,SAAS,GAA6B,CAAY,CAAE,CAAkB,EACxE,GAT8B,CAS1B,CAAC,SATE,AAS8B,EATjB,KAAK,CAWrB,MAAM,CAF0C,GAEtC,EAElB,8J/FxJA,IAAI,IACA,CADwC,EAc1C,IAAkB,CAAC,GAbF,EADE,CACH,CADwC,SAA1B,AACG,CAAG,EADH,yBAE/B,EAAe,GAAM,CAAG,QAAV,SACd,EAAe,IAAO,CAAG,OAAX,WACd,EAAe,YAAD,CAAiB,CAAG,2BAClC,EAAe,MAAS,CAAG,KAAb,eACd,EAAe,YAAD,kBAAkC,CAAG,4CACnD,EAAe,YAAD,IAAoB,CAAG,8BACrC,EAAe,YAAD,AAAgB,CAAG,0BACjC,EAAe,WAAc,CAAf,AAAkB,yBAChC,EAAe,YAAD,SAAyB,CAAG,mCAC1C,EAAe,YAAD,KAAqB,CAAG,+BACtC,EAAe,SAAY,CAAG,EAAhB,qBACP,GAEP,IACA,CAD4C,EAI9C,IAAsB,CAAC,GAHF,MADE,CACH,CAD4C,SAA9B,GAAG,MACa,CAAG,4CACnD,EAAmB,cAAiB,CAAG,CAArB,+BACX,GAEP,IACA,GAMF,IAAkB,CAAC,GANF,EADE,CACH,UADc,GAAG,CACI,CAAG,+BACtC,EAAe,YAAD,iBAAiC,CAAG,2CAClD,EAAe,SAAY,CAAG,EAAhB,qBACd,EAAe,YAAD,WAA2B,CAAG,qCAC5C,EAAe,YAAD,AAAgB,CAAG,4BAC1B,GAEP,IACA,GAgCF,IAAsB,CAAC,GAhCF,MADE,CACH,IAAe,CAAG,KADJ,GAAG,qBAEnC,EAAmB,UAAa,CAAG,KAAjB,uBAClB,EAAmB,gBAAD,GAAuB,CAAG,qCAC5C,EAAmB,gBAAD,MAA0B,CAAG,wCAC/C,EAAmB,gBAAD,KAAyB,CAAG,uCAC9C,EAAmB,gBAAD,IAAwB,CAAG,sCAC7C,EAAmB,gBAAD,MAA0B,CAAG,wCAC/C,EAAmB,gBAAD,IAAwB,CAAG,sCAC7C,EAAmB,gBAAD,GAAuB,CAAG,2CAC5C,EAAmB,gBAAD,AAAoB,CAAG,kCACzC,EAAmB,YAAe,CAAG,GAAnB,2BAClB,EAAmB,MAAS,CAAG,SAAb,eAClB,EAAmB,MAAS,CAAG,SAAb,eAClB,EAAmB,UAAa,CAAG,KAAjB,uBAClB,EAAmB,cAAiB,CAAG,CAArB,+BAClB,EAAmB,WAAc,CAAG,IAAlB,yBAClB,EAAmB,gBAAD,CAAqB,CAAG,mCAC1C,EAAmB,gBAAD,EAAsB,CAAG,oCAC3C,EAAmB,eAAkB,CAAnB,AAAsB,iCACxC,EAAmB,gBAAD,UAA8B,CAAG,4CACnD,EAAmB,gBAAD,CAAqB,CAAG,mCAC1C,EAAmB,YAAe,CAAG,GAAnB,2BAClB,EAAmB,WAAc,CAAG,IAAlB,yBAClB,EAAmB,gBAAD,CAAqB,CAAG,mCAC1C,EAAmB,SAAY,CAAG,MAAhB,qBAClB,EAAmB,aAAgB,CAAG,EAApB,6BAElB,EAAmB,KAAQ,CAAG,QAC9B,EAAmB,AADD,UACc,CAAG,KAAjB,QAClB,EAAmB,WAAc,CAAG,IAAlB,UAClB,EAAmB,aAAgB,CAAG,EAApB,cACX,GAEP,IACA,GAEF,IAAmB,CAAC,GAFF,GADE,CACH,OAAe,CAAG,EADJ,GAAG,qBAEzB,GAEP,IACA,GAMF,IAAc,CAAC,CAPA,CACH,CAAC,SADa,GAAG,MACK,CAAG,4BACnC,EAAW,QAAD,MAAkB,CAAG,wBAC/B,EAAW,QAAD,MAAkB,CAAG,wBAC/B,EAAW,QAAD,MAAkB,CAAG,wBAC/B,EAAW,QAAD,QAAoB,CAAG,0BAC1B,GAEP,IACA,GAKF,IAAiB,CAAC,GALF,CADE,CACH,UADc,EACI,CAAG,AADJ,2BAE9B,EAAc,WAAD,WAA0B,CAAG,mCAC1C,EAAc,WAAD,EAAiB,CAAG,0BACjC,EAAc,KAAQ,CAAG,KAAZ,aACN,GAEP,IACA,GAEF,IAAc,CAAC,CAHA,CACH,CAAC,SADa,GAAG,AACD,CAAG,sBACtB,GAEP,IACA,GAEF,IAAY,AAHC,CACH,AAEG,GAFF,OADa,GACA,AADG,CACA,kBAClB,GAEP,IACA,GAEF,IAA6B,CAAC,GAFF,UAAa,CAAG,EADd,CACH,UADc,GAAG,mBAEnC,GAEP,IACA,CAD6C,EAI/C,IAAuB,CAAC,GAHF,OADE,CACH,CAD6C,OACzB,CAAG,CADT,GAAG,+BAEpC,EAAoB,gBAAmB,CAAG,AAAvB,mCACZ,GAEP,IACA,CADwC,EAG1C,IAAkB,CAAC,GAFF,EADE,CACH,CADwC,GAC7B,CAAG,KADA,GAAG,aAExB,GAGJ,IAAM,GAA2B,IAAI,IAAI,CAC5C,qBACA,2BACA,4BACA,wBACA,kBACA,0BACA,wBACA,kBACA,mCACA,mCACA,mCACA,qCACA,oCACA,uCACA,+BACA,wCACH,EAGY,GAAmB,IAAI,IAAI,CACpC,oCACA,qCACA,wCACH,EmFhIU,SAAS,GAAW,CAAO,EAClC,OAAmB,OAAZ,GAAoB,AAAmB,iBAAZ,GAAwB,SAAU,GAAmC,YAAxB,OAAO,EAAQ,IAAI,AACtG,EAEA,uCAAuC,mKrCPvC,IAAM,GAA+B,QAAQ,GAAG,CAAC,4BAA4B,CAkBvE,SAAE,EAAO,aAAE,EAAW,OAAE,EAAK,gBAAE,EAAc,CAAE,WAAQ,cAAE,EAAY,CAAE,CARzE,EAQ4E,AAR5E,EAAA,CAAA,CAAA,MASG,OAAM,WAAqB,MAC9B,YAAY,CAAM,CAAE,CAAM,CAAC,CACvB,KAAK,GAAI,IAAI,CAAC,MAAM,CAAG,EAAQ,IAAI,CAAC,MAAM,CAAG,CACjD,CACJ,CAKA,IAAM,GAAqB,CAAC,EAAM,KAC1B,AAJiB,UAAjB,OAAO,GAAsB,AAAU,MAAM,IAC1C,AAGY,GAJqC,UAChC,IAGK,EAAM,MAAM,CACrC,CADuC,CAClC,YAAY,CAAC,eAAe,IAE7B,IACA,EAAK,CADE,cACa,CAAC,GACrB,EAAK,YAAY,CAAC,aAAc,EAAM,IAAI,GAE9C,EAAK,SAAS,CAAC,CACX,KAAM,GAAe,KAAK,CAC1B,QAAkB,MAAT,EAAgB,KAAK,EAAI,EAAM,OAAO,AACnD,IAEJ,EAAK,GAAG,EACZ,EACuF,GAA0B,IAAI,IAC/G,GAAgB,EAAI,gBAAgB,CAAC,mBACvC,GAAa,EAEX,GAAwB,CAC1B,IAAK,CAAO,CAAE,CAAG,CAAE,CAAK,EACpB,EAAQ,IAAI,CAAC,KACT,EACA,MAAA,CACJ,EACJ,CACJ,EA8KM,MACa,IA9KnB,AA8KuB,EADL,CAAC,GA7Kb,EAKA,mBAAoB,CAClB,OAAO,GAAM,SAAS,CAAC,UAAW,QACtC,CACA,YAAa,CACT,OAAO,EACX,CACA,yBAA0B,CACtB,IAAM,EAAgB,GAAQ,MAAM,GAC9B,EAAU,EAAE,CAElB,OADA,GAAY,MAAM,CAAC,EAAe,EAAS,IACpC,CACX,CACA,oBAAqB,CACjB,OAAO,GAAM,OAAO,CAAY,MAAX,GAAkB,KAAK,EAAI,GAAQ,MAAM,GAClE,CACA,sBAAsB,CAAO,CAAE,CAAE,CAAE,CAAM,CAAE,CACvC,IAAM,EAAgB,GAAQ,MAAM,GACpC,GAAI,GAAM,cAAc,CAAC,GAErB,OAAO,IAEX,EAJyC,EAInC,EAAgB,GAAY,OAAO,CAAC,EAAe,EAAS,GAClE,OAAO,GAAQ,IAAI,CAAC,EAAe,EACvC,CACA,MAAM,GAAG,CAAI,CAAE,CACX,GAAM,CAAC,EAAM,EAAa,EAAU,CAAG,EAEjC,IAAE,CAAE,SAAE,CAAO,CAAE,CAA0B,YAAvB,OAAO,EAA6B,CACxD,GAAI,EACJ,QAAS,CAAC,CACd,EAAI,CACA,GAAI,EACJ,QAAS,CACL,GAAG,CAAW,AAClB,CACJ,EACM,EAAW,EAAQ,QAAQ,EAAI,EACrC,GAAI,CAAC,GAAyB,GAAG,CAAC,IAA2C,MAAlC,QAAQ,GAAG,CAAC,iBAAiB,EAAY,EAAQ,QAAQ,CAChG,CADkG,MAC3F,IAGX,IAAI,EAAc,IAAI,CAAC,cAAc,CAAC,CAAY,MAAX,EAAkB,KAAK,EAAI,EAAQ,UAAA,AAAU,GAAK,IAAI,CAAC,kBAAkB,GAC5G,CAAC,IACD,EAAc,CAAY,MADZ,AACC,GAAkB,KAAK,EAAI,GAAQ,MAAM,EAAA,CAAE,EAAK,EAAA,EAMnE,IAAM,EAAqB,EAAY,QAAQ,CAAC,IAC1C,EAAa,AAA8B,iBAAvB,GAAmC,CAAC,GAAwB,GAAG,CAAC,GACpF,EAjEQ,KAuEd,EANe,KACf,EAAQ,UAAU,CAAG,CACjB,iBAAkB,EAClB,iBAAkB,EAClB,GAAG,EAAQ,UAAU,AACzB,EACO,GAAQ,IAAI,CAAC,EAAY,QAAQ,CAAC,GAAe,GAAS,IAAI,IAAI,CAAC,iBAAiB,GAAG,eAAe,CAAC,EAAU,EAAS,AAAC,QACtH,EACA,IAAgC,GAAQ,GAAiB,GAAG,CAAC,KAC7D,EADoE,AACxD,gBAAiB,YAAc,YAAa,YAAc,WAAW,WAAW,CAAC,GAAG,QAAK,CAAA,EAEzG,IAAI,GAAY,EACV,EAAY,MACV,IACJ,EAAY,GACZ,EAFe,CAES,MAAM,CAAC,GAC3B,GACA,QADW,IACC,OAAO,CAAC,CAAA,EAAG,GAA6B,MAAM,EAAE,CAAC,EAAK,KAAK,CAAC,KAAK,GAAG,IAAM,EAAA,CAAE,CAAE,OAAO,CAAC,SAAU,AAAC,GAAQ,IAAM,EAAM,WAAW,IAAA,CAAK,CAAE,CAC/I,MAAO,EACP,IAAK,YAAY,GAAG,EACxB,GAER,EAIA,GAHI,GACA,GAAwB,GAAG,CAAC,EADhB,AACwB,IAAI,IAAI,OAAO,OAAO,CAAC,EAAQ,UAAU,EAAI,CAAC,KAElF,EAAG,MAAM,CAAG,EACZ,CADe,EACX,CACA,OAAO,EAAG,EAAO,AAAD,GAAO,GAAmB,EAAM,GACpD,CAAE,MAAO,EAAK,CAEV,MADA,GAAmB,EAAM,GACnB,CACV,QAAS,CACL,GACJ,CAEJ,GAAI,CACA,IAAM,EAAS,EAAG,GAClB,GAAI,GAAW,GAEX,MAFoB,CAEb,EAAO,IAAI,CAAC,AAAC,IAChB,EAAK,GAAG,GAGD,IACR,KAAK,CAAC,AAAC,IAEN,MADA,GAAmB,EAAM,GACnB,CACV,GAAG,OAAO,CAAC,GAKf,OAHI,EAAK,GAAG,GACR,IAEG,CACX,CAAE,MAAO,EAAK,CAGV,MAFA,GAAmB,EAAM,GACzB,IACM,CACV,CACJ,GACR,CACA,KAAK,GAAG,CAAI,CAAE,CACV,IAAM,EAAS,IAAI,CACb,CAAC,EAAM,EAAS,EAAG,CAAmB,IAAhB,EAAK,MAAM,CAAS,EAAO,CACnD,CAAI,CAAC,EAAE,CACP,CAAC,EACD,CAAI,CAAC,EAAE,CACV,QACD,AAAI,AAAC,GAAyB,GAAG,CAAC,IAAS,AAAkC,KAAK,SAA/B,GAAG,CAAC,iBAAiB,CAGjE,WACH,IAAI,EAAa,CACb,CAAsB,mBAAf,GAA2C,YAAd,AAA0B,OAAnB,IAC3C,EAAa,EAAW,KAAK,CAAC,IAAI,CAAE,UAAA,EAExC,IAAM,EAAY,UAAU,MAAM,CAAG,EAC/B,EAAK,SAAS,CAAC,EAAU,CAC/B,GAAkB,YAAd,OAAO,EAUP,OAAO,EAAO,KAAK,CAAC,EAAM,EAAY,IAAI,EAAG,KAAK,CAAC,IAAI,CAAE,WAV/B,EAC1B,IAAM,EAAe,EAAO,UAAU,GAAG,IAAI,CAAC,GAAQ,MAAM,GAAI,GAChE,OAAO,EAAO,KAAK,CAAC,EAAM,EAAY,CAAC,EAAO,KAC1C,SAAS,CAAC,EAAU,CAAG,SAAS,CAAG,EAE/B,OADQ,MAAR,CAAe,EAAS,EAAK,CAAT,EACb,EAAa,KAAK,CAAC,IAAI,CAAE,UACpC,EACO,EAAG,KAAK,CAAC,IAAI,CAAE,YAE9B,CAGJ,EArBW,CAsBf,CACA,EALe,QAKL,GAAG,CAAI,CAAE,CACf,GAAM,CAAC,EAAM,EAAQ,CAAG,EAClB,EAAc,IAAI,CAAC,cAAc,CAAC,CAAY,MAAX,EAAkB,KAAK,EAAI,EAAQ,UAAU,AAAV,GAAe,IAAI,CAAC,kBAAkB,IAClH,OAAO,IAAI,CAAC,iBAAiB,GAAG,SAAS,CAAC,EAAM,EAAS,EAC7D,CACA,eAAe,CAAU,CAAE,CAEvB,OADoB,AACb,EAD0B,GAAM,OAAO,CAAC,GAAQ,MAAM,GAAI,QAAc,CAEnF,CACA,uBAAwB,CACpB,IAAM,EAAS,GAAQ,MAAM,GAAG,QAAQ,CAAC,IACzC,OAAO,GAAwB,GAAG,CAAC,EACvC,CACA,qBAAqB,CAAG,CAAE,CAAK,CAAE,CAC7B,IAAM,EAAS,GAAQ,MAAM,GAAG,QAAQ,CAAC,IACnC,EAAa,GAAwB,GAAG,CAAC,GAC3C,GAAc,CAAC,EAAW,GAAG,CAAC,IAC9B,EAAW,AADyB,GACtB,CAAC,EAAK,EAE5B,CACA,SAAS,CAAI,CAAE,CAAE,CAAE,CACf,IAAM,EAAc,GAAM,OAAO,CAAC,GAAQ,MAAM,GAAI,GACpD,OAAO,GAAQ,IAAI,CAAC,EAAa,EACrC,CACJ,EAGW,IAAI,GuB3LR,SAAS,GAA0B,CAAG,CAAE,CAAY,EACvD,IAAM,EAAU,GAAe,IAAI,CAAC,EAAI,OAAO,EAI/C,MAAO,CACH,qBAHyB,AADP,EAAQ,GAAG,CAAC,KACa,EAAa,aAAa,CAIrE,wBAH4B,EAAQ,GAAG,CAAC,EAI5C,CACJ,mDACO,IAAM,GAA+B,CAAC,kBAAkB,CAAC,CAG7B,OAAO,AAFA,CAAC,mBAAmB,CAAC,EAGxD,IAAM,GAAyB,OAAO,oH3B1DtC,OAAM,GACT,YAAY,CAAY,CAAE,CAAG,CAAE,CAAO,CAAE,CAAc,CAAC,CACnD,IAAI,EAGJ,MAAM,EAAuB,GAAgB,GAA0B,EAAK,GAAc,oBAAoB,CACxG,EAA4E,AAA9D,OAAC,EAAe,EAAQ,GAAG,CAAC,GAAA,CAA6B,CAAY,KAAK,EAAI,EAAa,KAAK,AACpH,KAAI,CAAC,UAAU,EAAG,EAAQ,CAAC,GAAwB,GAAe,GAAiB,IAAgB,EAAa,OAA9B,MAA2C,AACrC,EACxF,EAFiI,EAE7H,CAAC,cAAc,CAAG,AAAgB,QAAO,KAAK,EAAI,EAAa,aAAa,CAChF,IAAI,CAAC,eAAe,CAAG,CAC3B,CACA,IAAI,WAAY,CACZ,OAAO,IAAI,CAAC,UAAU,AAC1B,CACA,IARwP,IAQ/O,CACL,GAAI,CAAC,IAAI,CAAC,cAAc,CACpB,CADsB,KAChB,OAAO,cAAc,CAAC,AAAI,MAAM,0EAA2E,oBAAqB,CAClI,MAAO,MACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAI,CAAC,eAAe,CAAC,GAAG,CAAC,CACrB,KAAM,GACN,MAAO,IAAI,CAAC,cAAc,CAC1B,UAAU,EACV,SAAmD,CAAzC,MACV,EAD4D,MACpD,EACR,KAAM,GACV,GACA,IAAI,CAAC,UAAU,EAAG,CACtB,CACA,SAAU,CAIN,IAAI,CAAC,IATgC,WASjB,CAAC,GAAG,CAAC,CACrB,KAAM,GACN,MAAO,GACP,SAAU,GACV,SAAmD,CAAzC,MACV,EAD4D,MACpD,EACR,KAAM,IACN,QAAS,IAAI,KAAK,EACtB,GACA,IAAI,CAAC,UAAU,EAAG,CAJmB,AAKzC,CACJ,CgD5BI,ChD8BJ,QgD9Ba,GAAuB,CAAG,CAAE,CAAe,EACpD,GAAI,4BhD6BuC,AgD7BV,EAAI,OAAO,EAAI,AAAkD,iBAA3C,EAAI,OAAO,CAAC,0BAA0B,CAAe,CACxG,IAAM,EAAiB,EAAI,OAAO,CAAC,0BAA0B,CACvD,EAAkB,IAAI,QAC5B,IAAK,IAAM,KAAU,GAAmB,GACpC,EAAgB,MAAM,CAAC,IAD6B,SACf,GAIzC,IAAK,IAAM,KAAU,AAFG,IAAI,GAAA,eAAe,CAAC,GAEP,MAAM,GAAG,AAC1C,EAAgB,GAAG,CAAC,EAE5B,CACJ,CAKO,SAAS,GAAyB,CAAG,CAAE,CAAG,CAAE,CAAY,CAAE,CAAe,CAAE,CAAY,EAC1F,OAAO,AAGX,SAAS,AAAuB,CAAK,CAAE,CAAG,CAAE,CAAG,CAAE,CAAG,CAAE,CAAU,CAAE,CAAY,CAAE,CAAe,CAAE,CAAqB,CAAE,CAAY,CAAE,CAAY,CAAE,CAAwB,CAAE,CAAiB,EAC3L,SAAS,EAAuB,CAAO,EAC/B,GACA,EADK,AACD,SAAS,CAAC,aAAc,EAEpC,CACA,IAAM,EAAQ,CAAC,EACf,MAAO,CACH,KAAM,gBACN,eACA,EAIA,IAAK,CACD,SAAU,EAAI,QAAQ,CACtB,OAAQ,EAAI,MAAM,EAAI,EAC1B,aACA,EACA,IAAI,SAAW,CAMX,OALI,AAAC,EAAM,OAAO,EAAE,CAGhB,EAAM,OAAO,CA5D7B,AA4DgC,SA5DvB,AAAW,CAAO,EACvB,IAAM,EAAU,GAAe,IAAI,CAAC,GACpC,IAAK,IAAM,KAAU,GACjB,EAAQ,MAAM,CAAC,GAEnB,AAHoC,OAG7B,GAAe,IAAI,CAAC,EAC/B,EAsD2C,EAAI,QAAO,EAEnC,EAAM,OAAO,AACxB,EACA,IAAI,SAAW,CACX,GAAI,CAAC,EAAM,OAAO,CAAE,CAGhB,IAAM,EAAiB,IAAI,GAAA,cAAc,CAAC,GAAe,IAAI,CAAC,EAAI,OAAO,GACzE,GAAuB,EAAK,GAG5B,EAAM,OAAO,CAAG,GAAsB,IAAI,CAAC,EAC/C,CACA,OAAO,EAAM,OAAO,AACxB,EACA,IAAI,QAAS,MAAM,CACf,EAAM,OAAO,CAAG,KACpB,EACA,IAAI,gBAAkB,CAClB,GAAI,CAAC,EAAM,cAAc,CAAE,eACjB,GA1EK,EA0E8B,EAAI,GA1E3B,IA0EkC,CA1EhC,EA0EG,AAA+B,IAAoB,EAAM,OAAyB,AA1EtE,CA0EsE,CAAS,CAzExH,EAAU,CAyEqE,GAzEjE,GAAA,cAAc,CAAC,GAAe,IAAI,CAAC,IAChD,GAA6B,IAAI,CAAC,EAAS,IAyEtC,GAAuB,EAAK,GAC5B,EAAM,cAAc,CAAG,CAC3B,CACA,OAAO,EAAM,cACjB,AAD+B,EAE/B,IAAI,yBAA2B,CAK3B,OAJK,EAAM,uBAAuB,EAAE,CAEhC,EAAM,uBAAuB,CADG,EACA,CADoC,IAAI,CACxC,EAE7B,EAAM,uBAAuB,AACxC,EACA,IAAI,WAAa,CAIb,OAHI,AAAC,EAAM,SAAS,EAAE,CAClB,EAAM,SAAS,CAAG,IAAI,GAAkB,EAAc,EAAK,IAAI,CAAC,OAAO,CAAE,IAAI,CAAC,cAAc,GAEzF,EAAM,SAAS,AAC1B,EACA,sBAAgD,CAAzB,iBACvB,EACA,yBAA0B,GAA4B,WAAW,0BAA0B,CAC3F,sBACJ,CACJ,EAtEI,SAAU,EAAK,OAAW,EAAK,CAAC,EAAG,EAAc,EAAiB,KAAM,GAAc,OAAO,EAAW,KAC5G,gDpDzCO,IAAM,GAA+B,CAAA,EAAA,EAAA,uBAAA,AAAuB,IwDa5D,CxDXP,QwDWgB,KACZ,MAAM,OAAO,cAAc,CAAC,IAAI,EAAe,axDZS,qCwDY0C,oBAAqB,CACnH,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACO,SAAS,GAA4B,CAAa,EACrD,OAAO,EAAc,IAAI,EACrB,IAAK,YACL,IAAK,oBACL,IAAK,gBAEL,IAAK,mBADD,OAAO,EAAc,wBAKzB,AALiD,KAK5C,UAGG,GAAI,EAAc,wBAAwB,CACtC,CADwC,MACjC,EAAc,wBAAwB,AAIzD,KAAK,mBACL,IAAK,QACL,IAAK,gBACL,IAAK,iBACD,OAAO,IACX,SACI,OAAO,CACf,CACJ,CACO,SAAS,GAAyB,CAAa,EAClD,OAAO,EAAc,IAAI,EACrB,IAAK,UACL,IAAK,YACL,IAAK,oBACL,IAAK,mBACD,GAAI,EAAc,qBAAqB,CAGnC,CAHqC,MAG9B,EAAc,qBAAqB,AAGlD,KAAK,gBAGD,OAAO,EAAc,wBAAwB,EAAI,IACrD,KAAK,QACL,IAAK,gBACL,IAAK,iBACL,IAAK,mBACD,OAAO,IACX,SACI,OAAO,CACf,CACJ,CAqFO,SAAS,GAAe,CAAa,EACxC,OAAO,EAAc,IAAI,EACrB,IAAK,YACL,IAAK,mBACL,IAAK,oBACD,OAAO,EAAc,WAAW,AACpC,KAAK,UAGG,GAAI,EAAc,WAAW,CACzB,CAD2B,MACpB,EAAc,WAIjC,AAJ4C,KAIvC,gBACL,IAAK,mBACL,IAAK,QACL,IAAK,gBACL,IAAK,iBACD,OAAO,IACX,SACI,OAAO,CACf,CACJ,6L7FpLA,IAAA,GAAA,EAAA,CAAA,CAAA,OkGkF4B,GAAA,EAAA,CAAA,CAAA,MjG/ExB,OAAM,GACN,YAAY,CAAG,CAAE,CAAI,CAAE,CAAI,CAAC,CACxB,IAAI,CAAC,IAAI,CAAG,KACZ,IAAI,CAAC,IAAI,CAAG,KACZ,IAAI,CAAC,GAAG,CAAG,EACX,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,IAAI,CAAG,CAChB,CACJ,CAII,MAAM,GACN,aAAa,CACT,IAAI,CAAC,IAAI,CAAG,KACZ,IAAI,CAAC,IAAI,CAAG,IAChB,CACJ,CAkBW,MAAM,GACb,YAAY,CAAO,CAAE,CAAa,CAAE,CAAO,CAAC,CACxC,IAAI,CAAC,KAAK,CAAG,IAAI,IACjB,IAAI,CAAC,SAAS,CAAG,EACjB,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,aAAa,CAAG,EACrB,IAAI,CAAC,OAAO,CAAG,EAGf,IAAI,CAAC,IAAI,CAAG,IAAI,GAChB,IAAI,CAAC,IAAI,CAAG,IAAI,GAChB,IAAI,CAAC,IAAI,CAAC,IAAI,CAAG,IAAI,CAAC,IAAI,CAC1B,IAAI,CAAC,IAAI,CAAC,IAAI,CAAG,IAAI,CAAC,IAAI,AAC9B,CAKE,UAAU,CAAI,CAAE,CACd,EAAK,IAAI,CAAG,IAAI,CAAC,IAAI,CACrB,EAAK,IAAI,CAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAE1B,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAG,EACtB,IAAI,CAAC,IAAI,CAAC,IAAI,CAAG,CACrB,CAKE,WAAW,CAAI,CAAE,CAEf,EAAK,IAAI,CAAC,IAAI,CAAG,EAAK,IAAI,CAC1B,EAAK,IAAI,CAAC,IAAI,CAAG,EAAK,IAC1B,AAD8B,CAK5B,WAAW,CAAI,CAAE,CACf,IAAI,CAAC,UAAU,CAAC,GAChB,IAAI,CAAC,SAAS,CAAC,EACnB,CAKE,YAAa,CACX,IAAM,EAAW,IAAI,CAAC,IAAI,CAAC,IAAI,CAG/B,OADA,IAAI,CAAC,UAAU,CAAC,GACT,CACX,CASE,IAAI,CAAG,CAAE,CAAK,CAAE,CACd,IAAM,EAAO,CAAuB,MAAtB,IAAI,CAAC,aAAa,CAAW,KAAK,EAAI,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,IAAI,CAAE,EAAA,CAAM,EAAK,EAC7F,GAAI,EAAO,IAAI,CAAC,OAAO,CAAE,YACrB,QAAQ,IAAI,CAAC,oCAGjB,IAAM,EAAW,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,GAChC,GAAI,EAEA,EAAS,IAAI,CAAG,CAFN,CAGV,IAAI,CAAC,SAAS,CAAG,IAAI,CAAC,SAAS,CAAG,EAAS,IAAI,CAAG,EAClD,EAAS,IAAI,CAAG,EAChB,IAAI,CAAC,UAAU,CAAC,OACb,CAEH,IAAM,EAAU,IAAI,GAAQ,EAAK,EAAO,GACxC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,EAAK,GACpB,IAAI,CAAC,SAAS,CAAC,GACf,IAAI,CAAC,SAAS,EAAI,CACtB,CAEA,KAAM,IAAI,CAAC,SAAS,CAAG,IAAI,CAAC,OAAO,EAAI,IAAI,CAAC,KAAK,CAAC,IAAI,CAAG,GAAE,CACvD,IAAM,EAAO,IAAI,CAAC,UAAU,GAC5B,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,EAAK,GAAG,EAC1B,IAAI,CAAC,SAAS,EAAI,EAAK,IAAI,CAC3B,AAAgB,OAAO,GAAnB,CAAC,CAAuB,MAAhB,EAAoB,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAE,EAAK,GAAG,CAAE,EAAK,IAAI,CAC/E,CACJ,CAME,IAAI,CAAG,CAAE,CACP,OAAO,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,EAC1B,CAME,IAAI,CAAG,CAAE,CACP,IAAM,EAAO,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,GAC5B,GAAK,CAAD,CAGJ,IAHW,GAEX,IAFkB,AAEd,CAAC,UAAU,CAAC,GACT,EAAK,IAAI,AACpB,CAIE,CAAC,CAAC,OAAO,QAAQ,CAAC,EAAG,CACnB,IAAI,EAAU,IAAI,CAAC,IAAI,CAAC,IAAI,CAC5B,KAAM,GAAW,IAAY,IAAI,CAAC,IAAI,EAAC,CAEnC,IAAM,EAAO,CACb,MAAM,CACF,EAAK,GAAG,CACR,EAAK,IAAI,CACZ,CACD,EAAU,EAAQ,IAAI,AAC1B,CACJ,CAUE,OAAO,CAAG,CAAE,CACV,IAAM,EAAO,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,GACvB,IACL,EADW,EACP,CAAC,UAAU,CAAC,GAChB,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,GAClB,IAAI,CAAC,SAAS,EAAI,EAAK,IAAI,CAC/B,CAGE,IAAI,MAAO,CACT,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,AAC1B,CAIE,IAAI,aAAc,CAChB,OAAO,IAAI,CAAC,SAChB,AADyB,CAE7B,CkDzLO,ClD2LP,GkD3La,GAAe,IAAI,IACnB,GAAiB,CAAC,EAAM,KACjC,IAAK,IAAM,IlDyLsB,CkDzLf,EAAK,CACnB,IAAM,EAAQ,GAAa,GAAG,CAAC,GACzB,EAAqB,MAAT,EAAgB,KAAK,EAAI,EAAM,OAAO,CACxD,GAAyB,UAArB,AAA+B,OAAxB,GAIsB,GAHjB,KAAK,GAAG,EAGsB,EAAO,EAAY,EAEzD,OAAO,CAGnB,CACA,MAAO,EACX,EACa,GAAe,CAAC,EAAM,KAC/B,IAAK,IAAM,KAAO,EAAK,CACnB,IAAM,EAAQ,GAAa,GAAG,CAAC,GACzB,EAAU,AAAC,CAAS,QAAO,KAAK,EAAI,EAAM,KAAK,AAAL,GAAU,EAC1D,GAAuB,UAAnB,OAAO,GAAwB,EAAU,EACzC,OAAO,CAEf,CAH4D,AAI5D,OAAO,CACX,EhB3Bc,CgB6Bd,OhB7BsB,GAAG,CAAC,wBAAwB,CAG3B,EAH8B,CAAC,IAGxB,GAAG,CAAC,CAH6B,EgB6Bb,ChB7BgB,oBAIlE,IAAM,GAAoB,OAAO,GAAG,CAAC,4BAC/B,GAAoB,OAAO,GAAG,CAAC,4BAK3B,GAAY,WA+DX,SAAS,KAChB,GAAK,CAAD,CAAU,CAAC,GAAkB,CAGjC,CAHmC,MAG5B,EAAS,CAAC,GAAkB,CAAC,MAAM,EAC9C,CAMW,SAAS,KAChB,GAAK,CAAD,CAAU,CAAC,GAAkB,CAGjC,CAHmC,MAG5B,EAAS,CAAC,GAAkB,CAAC,OAAO,EAC/C,COzF4F,eAAe,GAAuB,CAAK,CAAE,CAAQ,EAC7I,GAAI,CAAC,EACD,KADQ,EACD,IAIX,IAAM,EAAyB,GAAuB,GACtD,GAAI,CACA,OAAO,MAAM,GACjB,QAAS,iBAEC,GAiBiB,EAjBsB,EAiBlB,AAAE,EAjBwC,EAiBpC,CAjB2D,GAkB1F,EAlBqB,AAkBC,IAAI,IAAI,EAAK,sBAAsB,CAAC,GAAG,CAAC,AAAC,IACjE,IAAM,EAAa,AAAwB,iBAAjB,EAAK,OAAO,CAAgB,KAAK,SAAS,CAAC,EAAK,OAAO,EAAI,EAAK,OAAO,EAAI,GACrG,MAAO,CAAA,EAAG,EAAK,GAAG,CAAC,CAAC,EAAE,EAAA,CAC1B,AADsC,IAEhC,EAAuB,IAAI,IAAI,EAAK,uBAAuB,EAC1D,CACH,uBAAwB,EAAK,sBAAsB,CAAC,MAAM,CAAC,AAAC,IACxD,IAAM,EAAqC,UAAxB,OAAO,EAAK,OAAO,CAAgB,KAAK,SAAS,CAAC,EAAK,OAAO,EAAI,EAAK,OAAO,EAAI,GACrG,MAAO,CAAC,EAAoB,GAAG,CAAC,CAAA,EAAG,EAAK,GAAG,CAAC,CAAC,EAAE,EAAA,CAAY,CAC/D,GACA,mBAAoB,OAAO,WAAW,CAAC,OAAO,OAAO,CAAC,EAAK,kBAAkB,EAAE,MAAM,CAAC,CAAC,CAAC,EAAI,GAAG,CAAC,CAAC,KAAO,EAAK,kBAAkB,AAAlB,IAC7G,wBAAyB,EAAK,uBAAuB,CAAC,MAAM,CAAC,AAAC,GAAU,CAAC,EAAqB,GAAG,CAAC,GACtG,EA7BI,OAAM,GAAmB,EAAO,EACpC,CACJ,CACA,SAAS,GAAuB,CAAK,EACjC,MAAO,CACH,uBAAwB,EAAM,sBAAsB,CAAG,IAChD,EAAM,sBAAsB,CAClC,CAAG,EAAE,CACN,mBAAoB,CAChB,GAAG,EAAM,kBACb,AAD+B,EAE/B,wBAAyB,EAAM,uBAAuB,CAAG,IAClD,EAAM,uBAAuB,CACnC,CAAG,EAAE,AACV,CACJ,CAgBA,eAAe,GAAe,CAAe,CAAE,CAAgB,CAAE,CAAS,EACtE,GAA+B,GAAG,CAA9B,EAAgB,MAAM,CACtB,OAEJ,IAAM,EAAW,KACX,EAAW,EAAE,CAEb,EAAgB,IAAI,IAC1B,IAAK,IAAM,KAAQ,EAAgB,CAC/B,IAEI,EAFE,EAAU,EAAK,OAAO,CAEV,AAClB,IAAK,GAAM,CAAC,EAAI,GAAI,EAChB,GAAmB,SADW,CAC1B,OAAO,GAAuC,UAAnB,OAAO,GAAwB,IAAQ,GAInD,UAAf,OAAO,GAAuC,UAAnB,OAAO,GAAwB,KAAK,SAAS,CAAC,KAAS,KAAK,SAAS,CAAC,IAIjG,IAAQ,EAJmG,AAJhC,CAC3E,EAAc,EACd,EAMiB,GALrB,CAUJ,IAAM,EAAa,GAAe,CAC9B,CAAC,EAAc,GAAG,CAAC,IACnB,EAAc,GAAG,CAAC,EAAY,CADE,CACA,EAEpC,EAAc,GAAG,CAAC,GAAY,IAAI,CAAC,EAAK,GAAG,CAC/C,CAEA,IAAK,GAAM,CAAC,EAAS,EAAe,GAAI,EAAc,CAElD,IAAI,EACJ,GAAI,EAAS,CACT,IAAI,EACJ,GAAuB,UAAnB,AAA6B,OAAtB,EAEP,EAAY,OACT,GAAuB,UAAnB,OAAO,EAAsB,CACpC,IAAI,EAGJ,GAAI,CAAC,CADL,EAAyB,MAAb,CAAoB,CAChB,CADyB,AAAgE,GAApE,IAAK,EAA+B,EAAU,iBAAA,AAAiB,EAAY,KAAK,EAAI,CAA4B,CAAC,EAAA,AAAQ,EAE1J,MAAM,OAAO,cAAc,CAAK,AAAJ,MAAU,CAAC,0BAA0B,EAAE,EAAQ,+DAA+D,CAAC,EAAG,oBAAqB,CAC/J,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,EAER,CACI,GACA,GAAY,CACR,IAFO,GAEC,EAAU,MAAM,CAC5B,CAER,CAGA,IAAK,IAAM,KAAW,GAAY,EAAE,CAAC,AAC7B,EACA,EAAS,IAAI,CAAC,AAAsB,AAD3B,QACa,UAAU,CAAW,KAAK,EAAI,EAAQ,UAAU,CAAC,IAAI,CAAC,EAAS,EAAgB,IAErG,EAAS,IAAI,CAAuB,MAAtB,EAAQ,UAAU,CAAW,KAAK,EAAI,EAAQ,UAAU,CAAC,IAAI,CAAC,EAAS,IAGzF,GACA,EAAS,IAAI,CAAC,EAAiB,MADb,OAC0B,CAAC,EAAgB,GAErE,CACA,MAAM,QAAQ,GAAG,CAAC,EACtB,CACO,eAAe,GAAmB,CAAS,CAAE,CAAK,EACrD,IAAM,EAAyB,CAAU,MAAT,EAAgB,KAAK,EAAI,EAAM,sBAAA,AAAsB,GAAK,EAAU,sBAAsB,EAAI,EAAE,CAC1H,EAAqB,CAAU,MAAT,EAAgB,KAAK,EAAI,EAAM,kBAAA,AAAkB,GAAK,EAAU,kBAAkB,EAAI,CAAC,EAC7G,EAA0B,CAAU,MAAT,EAAgB,KAAK,EAAI,EAAM,uBAAA,AAAuB,GAAK,EAAU,uBAAuB,EAAI,EAAE,CACnI,OAAO,QAAQ,GAAG,CAAC,CACf,GAAe,EAAwB,EAAU,gBAAgB,CAAE,MAChE,OAAO,MAAM,CAAC,MACd,EACN,CACL,EAEA,8CAA8C,iGxCjI9C,IAAM,GAA2C,OAAO,cAAc,CAAC,AAAI,MAAM,8EAA+E,oBAAqB,CACjL,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,EACA,OAAM,GACF,SAAU,CACN,MAAM,EACV,CACA,UAAW,CAGX,CACA,KAAM,CACF,MAAM,EACV,CACA,MAAO,CACH,MAAM,EACV,CACA,WAAY,CACR,MAAM,EACV,CACA,OAAO,KAAK,CAAE,CAAE,CACZ,OAAO,CACX,CACJ,CACA,IAAM,GAA+B,AAAsB,WAAf,YAA8B,WAAW,iBAAiB,CAO/F,SAAS,GAChB,CAAE,SACE,AAAI,GACO,GAA6B,IAAI,CAAC,GAEtC,GAAsB,IAAI,CAAC,EACtC,CACO,KAL+B,IAKtB,YACZ,AAAI,GACO,GAA6B,QAAQ,GAEzC,SAAS,CAAE,CAAE,EAHc,CAGX,CAAI,EACvB,OAAO,KAAM,EACjB,CACJ,EAEA,+CAA+C,WkChDxC,IAAM,GAAgC,CAAA,EAAA,EAAA,uBAAA,AAAuB,GpCO7D,EoCLP,KpCKa,GACT,YAAY,WAAE,CAAS,SAAE,CAAO,aAAE,CAAW,CAAE,CAAC,CAC5C,EoCPqD,EpCOjD,CAAC,cAAc,CAAG,IAAI,IAC1B,IAAI,CAAC,SAAS,CAAG,EACjB,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,aAAa,CAAG,IAAI,GAAA,OAAY,CACrC,IAAI,CAAC,aAAa,CAAC,KAAK,EAC5B,CACA,MAAM,CAAI,CAAE,CACR,GAAI,GAAW,GACN,AAAD,IAAK,AADS,CACR,SAAS,EAAE,AACjB,KAEJ,IAAI,CAAC,SAAS,CAAC,EAAK,KAAK,CAAC,AAAC,GAAQ,IAAI,CAAC,eAAe,CAAC,UAAW,UAChE,GAAI,AAAgB,YAAY,OAArB,EAEd,IAAI,CAAC,WAAW,CAAC,QAEjB,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,uDAAwD,oBAAqB,CAC/G,MAAO,MACP,YAAY,EACZ,cAAc,CAClB,EAER,CACA,YAAY,CAAQ,CAAE,CAEd,AAAC,IAAI,CAAC,SAAS,EAAE,AACjB,KAEJ,IAAM,EAAgB,GAAqB,QAAQ,EAC/C,IACA,IAAI,CAAC,MADU,QACI,CAAC,GAAG,CAAC,GAE5B,IAAM,EAAiB,GAAsB,QAAQ,GAK/C,EAAqB,EAAiB,EAAe,kBAAkB,CAAC,AAC1D,MAAjB,EAAwB,KAAK,EAD6D,AACzD,EAAc,KAAK,CAGlD,AAHmD,IAG/C,CAAC,WAH8D,eAGpC,EAAE,CAClC,IAAI,CAAC,0BAA0B,CAAG,IAAI,CAAC,mBAAmB,GAC1D,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,0BAA0B,GAOlD,IAAM,EAAkB,GAExB,UACI,AAFJ,GAEQ,CACA,MAAM,GAAsB,GAAG,CAAC,CAC5B,oBACJ,EAAG,IAAI,IACX,CAAE,GAN8C,GAMvC,EAAO,CACZ,IAAI,CAAC,eAAe,CAAC,WAAY,EACrC,CACJ,GACA,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,EAC3B,CACA,MAAM,qBAAsB,CAExB,OADA,MAAM,IAAI,QAAQ,AAAC,GAAU,IAAI,CAAC,OAAO,CAAC,IACnC,IAAI,CAAC,YAAY,EAC5B,CACA,MAAM,cAAe,CACjB,GAAgC,IAA5B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAQ,OACnC,IAAK,IAAM,KAAiB,IAAI,CAAC,cAAc,CAAC,AAC5C,EAAc,KAAK,CAAG,QAE1B,IAAM,EAAY,EAAiB,QAAQ,GAC3C,GAAI,CAAC,EACD,MAAM,GADM,IACC,cAAc,CAAC,IAAI,EAAe,kDAAmD,oBAAqB,CACnH,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,OAAO,GAAuB,EAAW,KACrC,IAAI,CAAC,aAAa,CAAC,KAAK,GACjB,IAAI,CAAC,aAAa,CAAC,MAAM,IAExC,CACA,gBAAgB,CAAQ,CAAE,CAAK,CAAE,CAI7B,GADA,QAAQ,KAAK,CAAc,YAAb,EAAyB,CAAC,yCAAyC,AAAI,CAAC,AAAJ,sDAA0D,AAAG,CAAF,EACzI,IAAI,CAAC,WAAW,CAEhB,CAFkB,EAEd,CACoB,MAApB,CAA2B,GAAvB,CAAC,CAA2B,UAAhB,EAAoB,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,IAAI,CAAE,EACpE,CAAE,MAAO,EAAc,CACnB,QAAQ,KAAK,CAAC,OAAO,cAAc,CAAC,IAAI,EAAe,0EAA2E,CAC9H,MAAO,CACX,GAAI,oBAAqB,CACrB,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GACJ,CAER,CACJ,CACA,SAAS,KACL,MAAM,OAAO,cAAc,CAAK,AAAJ,MAAU,uGAAwG,oBAAqB,CAC/J,MAAO,MACP,YAAY,EACZ,cAAc,CAClB,EACJ,CuEtHW,CvEwHX,QuExHoB,GAAiB,CAAE,EAEnC,IADI,EACE,EAAS,MACX,CAAM,EAAa,KACX,AAAC,IADQ,AAET,CAFqB,AvEqHI,CuEnHT,QAAQ,CADR,MACe,CAAC,IAAA,EAEpC,EAAc,IAAI,CAAC,AAAC,IAChB,EAAO,KAAK,CAAG,CACnB,GAAG,KAAK,CAAC,KAIT,GACO,EAAc,IAAI,CAAC,EAAa,GAE/C,EACA,OAAO,CACX,CSjBO,SAAS,GAAgB,CAAE,MAAI,CAAE,YAAU,mBAAE,CAAiB,SAAE,CAAO,CAAE,2BAAyB,OAAE,CAAK,CAAE,EAiB5G,IAAM,EAAqB,CAAC,EAAW,oBAAoB,EAAI,CAAC,EAAW,uBAAuB,EAAI,CAAC,EAAW,WAAW,EAAI,CAAC,EAAW,sBAAsB,CAC/J,EAAgB,EAAW,GAAG,GAAI,EAClC,EAA0B,GAGhC,IAAuB,CAAC,CAAC,QAAQ,AAHgB,GAGb,CAAC,IAAf,YAA+B,EAAI,AAAuC,cAA/B,GAAG,CAAC,sBAAsB,AAAK,CAAG,CAC7F,EAAQ,QAJ6G,YAKvH,OACA,EACA,MAAO,EAAiB,GACxB,iBAEA,CADA,CACW,gBAAgB,EAAI,WAAW,kBAAkB,CAC5D,EAFmD,gBAEhC,EAAW,iBAAiB,CAC/C,wBAAyB,EAAW,UAAU,CAC9C,uBAAwB,EAAW,sBAAsB,CACzD,WAAY,EAAW,UAAU,CACjC,qBAAsB,EAAW,oBAAoB,CACrD,YAAa,EAAW,WAAW,mBACnC,UACA,EACA,sBAAuB,CAAe,MAAd,EAAqB,KAAK,EAAI,EAAW,qBAAA,AAAqB,GAAK,CAAC,EAC5F,YAAa,CAAe,AAAd,QAAqB,KAAK,EAAI,EAAW,WAAA,AAAW,GAAK,SACvE,EACA,aAAc,AAatB,SAAS,AAAmB,CAAU,EAClC,GAAM,WAAE,CAAS,SAAE,CAAO,CAAE,kBAAgB,CAAE,CAAG,EACjD,OAAO,IAAI,GAAa,WACpB,UACA,EACA,YAAa,CACjB,EACJ,EApByC,GACjC,uBAAwB,EAAW,eAAe,CAClD,IAAK,4BACL,EACA,uBAAwB,AAoB5B,SAAS,EACT,IAAM,EAAyB,IAAI,IAC7B,EAAgB,KACtB,GAAI,EACA,IAAK,GAAM,CAAC,EAAM,EAAa,CADhB,EACoB,EAC3B,YADyC,IACxB,GACjB,EAAuB,GAAG,CAAC,EAAM,GADF,AACmB,SAAU,EAAa,WAAW,KAIhG,OAAO,CACX,EAEA,EAhCQ,mBAAoB,iBAgCU,YA/B9B,EACA,0BAA2B,IAAI,GACnC,EAGA,OADA,EAAW,KAAK,CAAG,EACZ,CACX,C1BnBO,eAAe,GAAgB,CAAI,CAAE,CAAG,CAAE,CAAmB,EAChE,IAAM,EAAO,IAAI,IAGjB,IAAK,IAAI,IADW,CAvCD,AAAC,EAwCJ,EAvChB,IAAM,EAAc,CAChB,CAAC,EAsCuB,KAtChB,CAAC,CACZ,CAGD,GAAI,EAAS,UAAU,CAAC,KAAM,CAC1B,IAAM,EAAgB,EAAS,KAAK,CAAC,KACrC,IAAI,IAAI,EAAI,EAAG,EAAI,EAAc,MAAM,CAAG,EAAG,IAAI,CAC7C,IAAI,EAAc,EAAc,KAAK,CAAC,EAAG,GAAG,IAAI,CAAC,KAC7C,IAEI,AAAC,EAAY,OAFJ,CAEY,CAAC,UAAa,EAAD,AAAa,QAAQ,CAAC,WAAW,CACnE,EAAc,CAAA,EAAG,EAAA,EAAc,CAAC,EAAY,QAAQ,CAAC,KAAO,IAAM,GAAG,OAAO,AAAD,EAE/E,EAAY,IAAI,CAAC,GAEzB,CACJ,CACA,OAAO,EACX,EAmBuC,GAE/B,EAAM,CAAA,EAAG,EAAA,EAA6B,EAAA,CAAK,CAC3C,EAAK,GAAG,CAAC,GAIb,GAAI,EAAI,QAAQ,EAAK,EAAD,AAAE,OAAuB,EAAoB,IAAI,AAAK,CAAC,CAAG,CAC1E,IAAM,EAAM,CAAA,EAAG,EAAA,EAA6B,EAAI,QAAQ,CAAA,CAAE,CAC1D,EAAK,GAAG,CAAC,EACb,CACI,EAAK,GAAG,CAAC,CAAA,EAAG,EAA2B,CAAC,CAAC,GAAG,AAC5C,EAAK,GAAG,CAAC,CAAA,EAAG,EAA2B,MAAM,CAAC,EAE9C,EAAK,GAAG,CAAC,CAAA,EAAG,EAA2B,MAAM,CAAC,GAAG,AACjD,EAAK,GAAG,CAAC,CAAA,EAAG,EAA2B,CAAC,CAAC,EAE7C,IAAM,EAAY,MAAM,IAAI,CAAC,GAC7B,MAAO,CACH,KAAM,EACN,uBAAwB,AAnC5B,SAAS,AAAiC,CAAI,EAC9C,IAAM,EAAyB,IAAI,IAC7B,EAAgB,KACtB,GAAI,EACA,IAAK,GAAM,CAAC,EAAM,EAAa,CADhB,EACoB,EAC3B,YADyC,MACtB,GACnB,EAAuB,GAAG,CAAC,EAAM,GADA,AACiB,SAAU,EAAa,aAAa,CAAC,KAInG,OAAO,CACX,EAwBiE,EAC7D,CACJ,EAEA,yCAAyC,iCgC7D9B,OAAM,GACb,aAAa,CACT,IAAI,EACA,EAEJ,IAAI,CAAC,OAAO,CAAG,IAAI,QAAQ,CAAC,EAAK,KAC7B,EAAU,EACV,EAAS,CACb,GAGA,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,MAAM,CAAG,CAClB,CACJ,EAEA,oCbjBW,OAAM,CaiB2B,EbhBxC,YAAY,CAAU,CAIlB,CAJoB,CAIN,AAAC,GAAK,GAAI,CAAC,CACzB,IAAI,CAAC,UAAU,CAAG,EAClB,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,OAAO,CAAG,IAAI,GACvB,CACA,OAAO,OAAO,CAAO,CAAE,CACnB,OAAO,IAAI,GAAQ,AAAW,QAAO,KAAK,EAAI,EAAQ,UAAU,CAAa,MAAX,EAAkB,KAAK,EAAI,EAAQ,WAAW,CACpH,CAUE,MAAM,MAAM,CAAG,CAAE,CAAE,CAAE,CACnB,IAAM,EAAW,IAAI,CAAC,UAAU,CAAG,MAAM,IAAI,CAAC,UAAU,CAAC,GAAO,EAChE,GAAiB,MAAM,CAAnB,EACA,OAAO,EAAG,CACN,QAAS,AAAC,GAAQ,QAAQ,OAAO,CAAC,OAClC,CACJ,GAEJ,IAAM,EAAU,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,GACjC,GAAI,EAAS,OAAO,EACpB,GAAM,SAAE,CAAO,SAAE,CAAO,QAAE,CAAM,CAAE,CAAG,IAAI,GAiBzC,OAhBA,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,EAAU,GAC3B,IAAI,CAAC,WAAW,CAAC,UACb,GAAI,CACA,IAAM,EAAS,MAAM,EAAG,SACpB,MACA,CACJ,GAGA,EAAQ,EACZ,CAAE,MAAO,EAAK,CACV,EAAO,EACX,QAAS,CACL,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,EACxB,CACJ,GACO,CACX,CACJ,CtExCA,CsE0CA,EtE1CM,KAAE,EAAG,QAAE,EAAM,CAAE,CAAG,CAAC,AAA8B,OAA7B,EAAc,IsE0CL,MtE1CK,CAAU,CAAY,KAAK,EAAI,EAAY,OAAA,AAAO,GAAK,CAAC,EAC1F,GAAU,IAAO,CAAC,GAAI,QAAQ,GAAK,CAAD,EAAK,WAAW,EAAI,CAAC,AAAU,SAAO,KAAK,EAAI,GAAO,KAAA,AAAK,GAAK,CAAC,GAAI,EAAE,EAAI,AAAa,YAAT,IAAI,AAAK,CAAM,CAChI,GAAe,CAAC,EAAK,EAAO,EAAS,KACvC,IAAM,EAAQ,EAAI,SAAS,CAAC,EAAG,GAAS,EAClC,EAAM,EAAI,SAAS,CAAC,EAAQ,EAAM,MAAM,EACxC,EAAY,EAAI,OAAO,CAAC,GAC9B,MAAO,CAAC,EAAY,EAAQ,GAAa,EAAK,EAAO,EAAS,GAAa,EAAQ,CACvF,EACM,GAAY,CAAC,EAAM,EAAO,EAAU,CAAI,GAC1C,AAAK,GACE,AAAC,CADJ,GAEA,EAFU,EAEJ,EAAS,GAAK,EACd,EAAQ,EAAO,OAAO,CAAC,EAAO,EAAK,MAAM,EAC/C,MAAO,CAAC,EAAQ,EAAO,GAAa,EAAQ,EAAO,EAAS,GAAS,EAAQ,EAAO,EAAS,CACjG,EALqB,OAQZ,GAAO,GAAU,UAAW,WAAY,mBAClC,GAAU,UAAW,WAAY,mBAC9B,GAAU,UAAW,YAClB,GAAU,UAAW,YACvB,GAAU,UAAW,YACtB,GAAU,UAAW,YACd,GAAU,UAAW,YAC7B,GAAU,WAAY,YACpC,IAAM,GAAM,GAAU,WAAY,YAC5B,GAAQ,GAAU,WAAY,YAC9B,GAAS,GAAU,WAAY,YACxB,GAAU,WAAY,YACnC,IAAM,GAAU,GAAU,WAAY,YACvB,GAAU,yBAA0B,YACtC,GAAU,WAAY,YACnC,IAAM,GAAQ,GAAU,WAAY,YACvB,GAAU,WAAY,YACnB,GAAU,WAAY,YACxB,GAAU,WAAY,YACpB,GAAU,WAAY,YACrB,GAAU,WAAY,YACxB,GAAU,WAAY,YACnB,GAAU,WAAY,YACzB,GAAU,WAAY,YACrB,GAAU,WAAY,Y+CtDtC,C/CwDP,G+CxDa,GAAW,CACpB,KAAM,GAAM,GAAK,MACjB,MAAO,GAAI,GAAK,E/CsDkB,I+CrDlC,KAAM,GAAO,GAAK,MAClB,MAAO,IACP,KAAM,GAAM,GAAK,MACjB,MAAO,GAAM,GAAK,MAClB,MAAO,GAAQ,GAAK,KACxB,EACM,GAAiB,CACnB,IAAK,MACL,KAAM,OACN,MAAO,OACX,EA4CM,GAAgB,IAAI,GAAS,IAAO,AAAC,GAAQ,EAAM,MAAM,EACxD,SAAS,GAAS,GAAG,CAAO,EAC/B,IAAM,EAAM,EAAQ,IAAI,CAAC,KACpB,GAAc,GAAG,CAAC,KACnB,CADyB,EACX,GAAG,CAAC,EAAK,GACvB,AApBD,SAAc,AAAL,GAAQ,CAAO,GAC3B,AA7BJ,SAAS,AAAY,CAAU,CAAE,GAAG,CAAO,EACnC,CAAgB,AAAf,MAAO,CAAC,EAAE,OAA0B,IAAf,CAAO,CAAC,EAAE,AAAK,CAAS,EAAwB,GAAG,CAAtB,EAAQ,MAAM,EACjE,EAAQ,KAAK,GAEjB,IAAM,EAAgB,KAAc,GAAiB,EAAc,CAAC,EAAW,CAAG,MAC5E,EAAS,EAAQ,CAAC,EAAW,CAEZ,GAAG,CAAtB,EAAQ,MAAM,CACd,OAAO,CAAC,EAAc,CAAC,IAIA,IAAnB,EAAQ,MAAM,EAAgC,UAAtB,AAAgC,OAAzB,CAAO,CAAC,EAAE,CACzC,OAAO,CAAC,EAAc,CAAC,EAAS,IAAM,CAAO,CAAC,EAAE,EAEhD,OAAO,CAAC,EAAc,CAAC,KAAW,EAG9C,EAWgB,UAAW,EAC3B,KAkBgB,GAEhB,CACuB,IAAI,GAAS,IAAO,AAAC,GAAQ,EAAM,MAAM,iCqC9DrD,IAAM,GAAqB,AAAC,IAOnC,QAAQ,OAAO,GAAG,IAAI,CAAC,KAEf,WAAW,EAAI,EAIvB,EACJ,6BAMqC,AAAC,IAE9B,WAAW,EAAI,EAIvB,oCvE/BO,IAAI,IACP,GAOF,CAAC,GAPiB,OADS,CACV,AAAY,CAAG,SADM,EAEpC,CAFuC,CAEvB,SAAY,CAAG,GAAhB,SACf,EAAgB,KAAQ,CAAG,OAAZ,CACf,EAAgB,KAAQ,CAAG,OAAZ,CACf,EAAgB,QAAW,CAAG,IAAf,OACf,EAAgB,KAAQ,CAAG,OAAZ,CACR,GAEA,IACP,GAMF,CAAC,GANsB,CAQzB,OARoC,CAAG,GADL,CACV,OACpB,EAAqB,CAFoB,GAAG,KAEX,CAAG,EAOP,MAPT,IACpB,EAAqB,KAAQ,CAAG,QAChC,EAAqB,EADD,GACS,CAAG,QAChC,EAAqB,EADD,GACS,CAAG,QACzB,GoFLX,CpFIwB,QoFJf,KAIT,qEnFVc,IAAI,WAAW,CACjB,GACA,IACA,IACA,IACA,IACH,EAEK,IAAI,WAAW,CACjB,GACA,GACA,IACA,IACA,IACH,EAIK,IAAI,WAAW,CACjB,GACA,GACA,IACA,IACA,GACA,IACA,GACH,EAEK,IAAI,WAAW,CACjB,GACA,GACA,GACA,IACA,IACA,IACA,GACH,EAEK,IAAI,WAAW,CACjB,GACA,GACA,IACA,IACA,IACA,IACA,GACH,EAEc,IAAI,WAAW,CAC1B,GACA,GACA,GACA,IACA,IACA,IACA,GACA,GACA,GACA,IACA,IACA,IACA,IACA,GACH,EAEC,IAIa,WAAW,CACtB,GACA,IACA,IACA,IACA,GACA,GACA,IACA,GACA,IACA,IACA,GACA,GACA,IACA,IACA,IACA,IACA,IACA,GACA,IACA,GACA,IACA,IACA,IACA,IACA,GACH,EmFjFT,IAAM,GAAU,IAAI,YAqCb,SAAS,GAAiB,CAAG,EAChC,OAAO,IAAI,eAAe,CACtB,MAAO,CAAU,EACb,EAAW,OAAO,CAAC,GAAQ,MAAM,CAAC,IAClC,EAAW,KAAK,EACpB,CACJ,EACJ,CACO,SAAS,GAAiB,CAAK,EAClC,OAAO,IAAI,eAAe,CACtB,MAAO,CAAU,EACb,EAAW,OAAO,CAAC,GACnB,EAAW,KAAK,EACpB,CACJ,EACJ,CA6BO,eAAe,GAAe,CAAM,CAAE,CAAM,EAC/C,IAAM,EAAU,IAAI,YAAY,QAAS,CACrC,OAAO,CACX,GACI,EAAS,GACb,UAAW,IAAM,KAAS,EAAO,CAC7B,GAAc,MAAV,EAAiB,KAAK,EAAI,EAAO,OAAO,CACxC,CAD0C,MACnC,EAEX,GAAU,EAAQ,MAAM,CAAC,EAAO,CAC5B,QAAQ,CACZ,EACJ,CAEA,OADA,AACO,EADG,EAAQ,MAAM,EAE5B,C7DjHO,IAAM,GAAoB,OAAO,GAAG,CAAC,2BACrC,SAAS,GAAe,CAAG,CAAE,CAAG,EACnC,IAAM,EAAO,CAAG,CAAC,GAAkB,EAAI,CAAC,EACxC,MAAsB,UAAf,OAAO,EAAmB,CAAI,CAAC,EAAI,CAAG,CACjD,CAkBW,SAAS,GAAe,CAAO,CAAE,CAAG,CAAE,CAAK,EAClD,IAAM,EAAO,GAAe,GAE5B,OADA,AACO,CADH,CAAC,EAAI,CAAG,EAZZ,AAasB,CAbnB,CAAC,GAAkB,GAaS,AAbN,CAc7B,uF+DjBW,IAAM,GAAmB,AAAC,IAAM,6BAYL,AAAD,IAAO,YAZ4B,aAkBlC,AAAC,GAAM,iBAN4B,kBjClBlE,IAAM,GAAsB,GiCwBuC,QAE1E,MjCzBO,OAAM,WAAwB,MACjC,KiCwB+B,OjCxBnB,GAAG,CAAI,CAAC,CAChB,KAAK,IAAI,GAAO,IAAI,CAAC,IAAI,CAAG,EAChC,CACJ,CAOW,SAAS,GAAsB,CAAQ,EAC9C,IAAM,EAAa,IAAI,gBAQvB,OAJA,EAAS,IAAI,CAAC,QAAS,KACf,EAAS,gBAAgB,EAAE,AAC/B,EAAW,KAAK,CAAC,IAAI,GACzB,GACO,CACX,CAQW,SAAS,GAAuB,CAAQ,EAC/C,GAAM,SAAE,CAAO,WAAE,CAAS,CAAE,CAAG,EAC/B,GAAI,GAAW,EACX,OAAO,EADe,UACH,KAAK,CAAC,GAAW,IAAI,IAE5C,GAAM,QAAE,CAAM,CAAE,CAAG,GAAsB,GACzC,OAAO,CACX,CACO,MAAM,GACT,OAAO,oBAAoB,CAAO,CAAE,CAAM,CAAE,CACxC,GAEuC,CADvC,EACwD,GACpD,OAD8D,AACvD,GAAmB,kBAAkB,CAAC,EAM7C,OAAM,OAAO,WAR4C,GAQ9B,CAAC,AAAI,MAAM,2CAA4C,oBAAqB,CACnG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAER,CACA,OAAO,oBAAoB,CAAO,CAAE,CAAM,CAAE,CAExC,IAKI,EALA,EAAO,KAMX,GALuB,QAAnB,EAAQ,MAAM,EAAiC,SAAnB,EAAQ,MAAM,EAAe,EAAQ,IAAI,EAAE,AAEvE,GAAO,EAAQ,IAAA,AAAI,EAGnB,EAAQ,GAAG,CAAC,UAAU,CAAC,QACvB,CADgC,CAC1B,IAAI,IAAI,EAAQ,GAAG,MACtB,CAEH,IAAM,EAAO,GAAe,EAAS,WAOjC,EANA,AAAC,GAAS,EAAK,GAAN,OAAgB,CAAC,QAMpB,CAN6B,GAMzB,IAAI,EAAQ,GAAG,CAAE,GAFrB,IAAI,IAAI,EAAQ,GAAG,CAAE,WAInC,CACA,OAAO,IAAI,GAAY,EAAK,CACxB,OAAQ,EAAQ,MAAM,CACtB,QAAS,GAA4B,EAAQ,OAAO,EACpD,OAAQ,cACR,EAMA,GAAG,EAAO,OAAO,CAAG,CAAC,EAAI,MACrB,CACJ,CAAC,AACL,EACJ,CACA,OAAO,mBAAmB,CAAO,CAAE,CAE/B,IAAI,EAAO,KAIX,MAHuB,QAAnB,EAAQ,MAAM,EAAiC,QAAQ,CAA3B,EAAQ,MAAM,GAC1C,EAAO,EAAQ,IAAA,AAAI,EAEhB,IAAI,GAAY,EAAQ,GAAG,CAAE,CAChC,OAAQ,EAAQ,MAAM,CACtB,QAAS,GAA4B,EAAQ,OAAO,EACpD,OAAQ,OACR,OAAQ,EAAQ,OAAO,CAAC,MAAM,CAM9B,GAAG,EAAQ,OAAO,CAAC,MAAM,CAAC,OAAO,CAAG,CAAC,EAAI,MACrC,CACJ,CAAC,AACL,EACJ,CACJ,EAEA,wCAAwC,0FhEvHxC,IAAI,GAA2B,EAC3B,GAA2B,EAC3B,GAA2B,E4EExB,SAAS,GAAa,CAAC,EAC1B,MAAO,CAAM,MAAL,EAAY,KAAK,EAAI,EAAE,IAAI,AAAJ,IAAU,cAAgB,CAAM,MAAL,EAAY,KAAK,EAAI,EAAE,IAAA,AAAI,IAAM,EAC/F,CAqFO,eAAe,GAAmB,CAAQ,CAAE,CAAG,CAAE,CAAe,EACnE,GAAI,CAEA,GAAM,SAAE,CAAO,WAAE,CAAS,CAAE,CAAG,EAC/B,GAAI,GAAW,EAAW,OAG1B,IAAM,EAAa,GAAsB,GACnC,EA5Fd,AA4FuB,SA5Fd,AAAyB,CAAG,CAAE,CAAe,EAClD,IAAI,GAAU,EAGV,EAAU,IAAI,GAClB,SAAS,IACL,EAAQ,OAAO,EACnB,CACA,EAAI,EAAE,CAAC,QAAS,GAGhB,EAAI,IAAI,CAAC,QAAS,KACd,EAAI,GAAG,CAAC,QAAS,GACjB,EAAQ,OAAO,EACnB,GAGA,IAAM,EAAW,IAAI,GAKrB,OAJA,EAAI,IAAI,CAAC,SAAU,KACf,EAAS,OAAO,EACpB,GAEO,IAAI,eAAe,CACtB,MAAO,MAAO,IAIV,GAAI,CAAC,EAAS,CAEV,GADA,EAAU,GACN,gBAAiB,YAAc,QAAQ,GAAG,CAAC,4BAA4B,CAAE,CACzE,IAAM,EAAU,A5EL7B,SAAS,AAAgC,EAAU,CAAC,CAAC,EACxD,IAAM,EAAU,AAA6B,YAAI,EAAY,0BACzD,4BACA,GACA,2BACJ,EAMA,OALI,EAAQ,KAAK,EAAE,CACf,GAA2B,EAC3B,GAA2B,EAC3B,GAA2B,GAExB,CACX,EAEA,E4ERwB,GACA,MADS,MACG,OAAO,CAAC,CAAA,EAAG,QAAQ,GAAG,CAAC,oB5EOC,Q4EP2B,CAAC,8BAA8B,CAAC,CAAE,CAC7F,MAAO,EAAQ,wBAAwB,CACvC,IAAK,EAAQ,wBAAwB,CAAG,EAAQ,wBAAwB,AAC5E,EAER,CACA,EAAI,YAAY,GAChB,KAAY,KAAK,CAAC,GAAmB,aAAa,CAAE,CAChD,SAAU,gBACd,EAAG,SAAI,EACX,CACA,GAAI,CACA,IAAM,EAAK,EAAI,KAAK,CAAC,GAGjB,UAAW,GAA4B,YAArB,AAAiC,OAA1B,EAAI,KAAK,EAClC,EAAI,KAAK,GAIR,IAAI,AACL,MAAM,EAAQ,OAAO,CAErB,EAAU,IAAI,GAEtB,CAAE,MAAO,EAAK,CAEV,MADA,EAAI,GAAG,GACD,OAAO,cAAc,CAAC,AAAI,MAAM,oCAAqC,CACvE,MAAO,CACX,GAAI,oBAAqB,CACrB,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACJ,EACA,MAAO,AAAC,IACA,EAAI,gBAAgB,EAAE,AAC1B,EAAI,OAAO,CAAC,EAChB,EACA,MAAO,UAMH,GAHI,GACA,MAAM,GAEN,EAAI,GAHa,aAGG,CAExB,CAF0B,MAC1B,EAAI,GAAG,GACA,EAAS,OAAO,AAC3B,CACJ,EACJ,EASgD,EAAK,EAC7C,OAAM,EAAS,MAAM,CAAC,EAAQ,CAC1B,OAAQ,EAAW,MAAM,AAC7B,EACJ,CAAE,MAAO,EAAK,CAEV,GAAI,GAAa,GAAM,MACvB,OAAM,OAAO,cAAc,CAAC,AAAI,MAAM,0BAA2B,CAC7D,MAAO,CACX,GAAI,oBAAqB,CACrB,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACJ,EAEA,yCAAyC,kBnBlH1B,OAAM,GACjB,QAAO,CAAA,AAAE,CAGP,EAHU,EAGN,CAAC,KAAK,CAAG,IAAI,GAAa,KAAM,CAClC,SAAU,CAAC,EACX,YAAa,IACjB,EAAG,AAOD,QAAO,WAAW,CAAK,CAAE,CAAW,CAAE,CACpC,OAAO,IAAI,GAAa,EAAO,CAC3B,SAAU,CAAC,cACX,CACJ,EACJ,CACA,YAAY,CAAQ,CAAE,aAAE,CAAW,WAAE,CAAS,UAAE,CAAQ,CAAE,CAAC,CACvD,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,SAAS,CAAG,CACrB,CACA,eAAe,CAAQ,CAAE,CACrB,OAAO,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAE,EACjC,CAIE,IAAI,QAAS,CACX,OAAyB,OAAlB,IAAI,CAAC,QAAQ,AACxB,CAIE,IAAI,WAAY,CACd,MAAO,AAAyB,iBAAlB,IAAI,CAAC,QAAQ,AAC/B,CACA,kBAAkB,GAAS,CAAK,CAAE,CAC9B,GAAsB,MAAM,CAAxB,IAAI,CAAC,QAAQ,CAGb,MAAO,GAEX,GAA6B,UAAzB,OAAO,IAAI,CAAC,QAAQ,CAAe,CACnC,GAAI,CAAC,EACD,MADS,AACH,OAAO,cAAc,CAAC,IAAI,EAAe,mEAAoE,oBAAqB,CACpI,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,OAAO,GAAe,IAAI,CAAC,QAAQ,CACvC,CACA,OAAO,IAAI,CAAC,QAAQ,AACxB,CAGE,IAAI,UAAW,QACb,AAAsB,MAAM,CAAxB,IAAI,CAAC,QAAQ,CAGN,IAAI,eAAe,CACtB,MAAO,CAAU,EACb,EAAW,KAAK,EACpB,CACJ,GAEA,AAAyB,UAAU,OAA5B,IAAI,CAAC,QAAQ,CACb,GAAiB,IAAI,CAAC,QAAQ,EAErC,GAAA,MAAM,CAAC,QAAQ,CAAC,IAAI,CAAC,QAAQ,EACtB,CADyB,EACR,IAAI,CAAC,QAAQ,EAGrC,MAAM,OAAO,CAAC,IAAI,CAAC,QAAQ,EsC9DhC,AtC+DY,CADuB,QsC9D1B,AAAa,GAAG,CAAO,EAGnC,GAAuB,GAAG,CAAtB,EAAQ,MAAM,CACd,OAAO,IAAI,eAAe,CACtB,MAAO,CAAU,EACb,EAAW,KAAK,EACpB,CACJ,GAGJ,GAAuB,GAAG,CAAtB,EAAQ,MAAM,CACd,OAAO,CAAO,CAAC,EAAE,CAErB,GAAM,UAAE,CAAQ,UAAE,CAAQ,CAAE,CAAG,IAAI,gBAG/B,EAAU,CAAO,CAAC,EAAE,CAAC,MAAM,CAAC,EAAU,CACtC,cAAc,CAClB,GACI,EAAI,EACR,KAAM,EAAI,EAAQ,MAAM,CAAG,EAAG,IAAI,CAC9B,IAAM,EAAa,CAAO,CAAC,EAAE,CAC7B,EAAU,EAAQ,IAAI,CAAC,IAAI,EAAW,MAAM,CAAC,EAAU,CAC/C,cAAc,CAClB,GACR,CAGA,IAAM,EAAa,CAAO,CAAC,EAAE,CAK7B,MADA,CAHA,EAAU,EAAQ,IAAI,CAAC,IAAI,EAAW,MAAM,CAAC,GAAA,EAGrC,KAAK,CAAC,IACP,CACX,KtC4BmC,IAAI,CAAC,QAAQ,EAEjC,IAAI,CAAC,QAAQ,AACxB,CAME,QAAS,QACP,AAAsB,MAAM,CAAxB,IAAI,CAAC,QAAQ,CAGN,EAAE,CAEgB,UAAU,AAAnC,OAAO,IAAI,CAAC,QAAQ,CACb,CACH,GAAiB,IAAI,CAAC,QAAQ,EACjC,CACM,MAAM,OAAO,CAAC,IAAI,CAAC,QAAQ,EAC3B,CAD8B,GAC1B,CAAC,QAAQ,CACb,GAAA,MAAM,CAAC,QAAQ,CAAC,IAAI,CAAC,QAAQ,EAC7B,CADgC,AAEnC,GAAiB,IAAI,CAAC,QAAQ,EACjC,CAEM,CACH,IAAI,CAAC,QAAQ,CAChB,AAET,CAQE,QAAQ,CAAQ,CAAE,CAEhB,IAAI,CAAC,QAAQ,CAAG,IAAI,CAAC,MAAM,GAE3B,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,EAC1B,CAQE,KAAK,CAAQ,CAAE,CAEb,IAAI,CAAC,QAAQ,CAAG,IAAI,CAAC,MAAM,GAE3B,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,EACvB,CAOE,MAAM,OAAO,CAAQ,CAAE,CACrB,GAAI,CACA,MAAM,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,EAAU,CAKjC,cAAc,CAClB,GAGI,IAAI,CAAC,SAAS,EAAE,MAAM,IAAI,CAAC,SAAS,CAExC,MAAM,EAAS,KAAK,EACxB,CAAE,MAAO,EAAK,CAIV,GAAI,GAAa,GAAM,YAEnB,MAAM,EAAS,KAAK,CAAC,EAMzB,OAAM,CACV,CACJ,CAME,MAAM,mBAAmB,CAAG,CAAE,CAC5B,MAAM,GAAmB,IAAI,CAAC,QAAQ,CAAE,EAAK,IAAI,CAAC,SAAS,CAC/D,CACJ,C3CtLO,C2CwLP,G3CxLW,IAGL,GAgBJ,CAAC,GAhBa,CAHO,AAqBvB,CAlBe,GAAS,CAAG,MAHO,EAM5B,CAN+B,CAMrB,OAAD,EAAa,CAAG,C2CkLU,W3C9KnC,CAWgC,CAXtB,OAAD,CAAY,CAAG,WAIxB,EAAU,OAAD,EAAa,CAAG,YAGzB,EAAU,KAAQ,CAAG,CAAZ,OACJ,G8CdJ,eAAe,GAAuB,CAAU,EACnD,IAAI,EAAmB,EACvB,MAAO,CACH,GAAG,CAAU,CACb,MAAO,CAA2C,AAA1C,OAAC,EAAoB,EAAW,KAAK,AAAL,EAAiB,KAAK,EAAI,EAAkB,IAAA,AAAI,IAAM,GAAgB,KAAK,CAAG,CAClH,KAAM,GAAgB,KAAK,CAC3B,KAAM,MAAM,EAAW,KAAK,CAAC,IAAI,CAAC,iBAAiB,CAAC,IACpD,SAAU,EAAW,KAAK,CAAC,QAAQ,CACnC,QAAS,EAAW,KAAK,CAAC,OAAO,CACjC,OAAQ,EAAW,KAAK,CAAC,MAAM,AACnC,EAAI,CAA4C,AAA3C,OAAC,EAAqB,EAAW,KAAK,AAAL,EAAiB,KAAK,EAAI,EAAmB,IAAA,AAAI,IAAM,GAAgB,QAAQ,CAAG,CACpH,KAAM,GAAgB,QAAQ,CAC9B,KAAM,MAAM,EAAW,KAAK,CAAC,IAAI,CAAC,iBAAiB,EAAC,GACpD,UAAW,EAAW,KAAK,CAAC,SAAS,CACrC,QAAS,EAAW,KAAK,CAAC,OAAO,CACjC,QAAS,EAAW,KAAK,CAAC,OAAO,CACjC,OAAQ,EAAW,KAAK,CAAC,MAAM,CAC/B,YAAa,EAAW,KAAK,CAAC,WAAW,AAC7C,EAAI,EAAW,KAAK,AACxB,CACJ,CACO,eAAe,GAAqB,CAAQ,EAC/C,IAAI,EAAiB,SACrB,AAAK,EACE,CACH,CAFA,MAEQ,AAFG,EAEM,MAAM,CACvB,QAAS,EAAS,OAAO,CACzB,aAAc,EAAS,YAAY,CACnC,MAAO,CAAC,AAAsC,OAArC,EAAkB,EAAS,KAAA,AAAK,EAAY,KAAK,EAAI,EAAgB,IAAA,AAAI,IAAM,GAAgB,KAAK,CAAG,CAC5G,KAAM,GAAgB,KAAK,CAC3B,KAAM,GAAa,UAAU,CAAC,EAAS,KAAK,CAAC,IAAI,CAAE,GACnD,SAAU,EAAS,KAAK,CAAC,QAAQ,CACjC,QAAS,EAAS,KAAK,CAAC,OAAO,CAC/B,OAAQ,EAAS,KAAK,CAAC,MAAM,AACjC,EAAI,CAAC,AAAuC,OAAtC,EAAmB,EAAS,KAAA,AAAK,EAAY,KAAK,EAAI,EAAiB,IAAA,AAAI,IAAM,GAAgB,QAAQ,CAAG,CAC9G,KAAM,GAAgB,QAAQ,CAC9B,KAAM,GAAa,UAAU,CAAC,EAAS,KAAK,CAAC,IAAI,CAAE,GACnD,QAAS,EAAS,KAAK,CAAC,OAAO,CAC/B,QAAS,EAAS,KAAK,CAAC,OAAO,CAC/B,OAAQ,EAAS,KAAK,CAAC,MAAM,CAC7B,UAAW,EAAS,KAAK,CAAC,SAAS,CACnC,YAAa,EAAS,KAAK,CAAC,WAAW,AAC3C,EAAI,EAAS,KAAK,AACtB,EApBsB,IAqB1B,CcxCI,SAAS,GAAiB,CAAQ,CAAE,CAAQ,EAC5C,GAAI,CAAC,EAAU,OAAO,EACtB,IAAM,EAAS,SAAS,EAAU,IAClC,OAAO,OAAO,QAAQ,CAAC,IAAW,EAAS,EAAI,EAAS,CAC5D,iCAWI,IAAM,GAAiB,GAAiB,QAAQ,GAAG,CAAC,+BAA+B,CAAE,KAI/E,GAAmB,GAAiB,QAAQ,GAAG,CAAC,oCAAoC,CAAE,KAQtF,GAAe,mBAGrB,SAAS,GAAe,CAAQ,CAAE,CAAY,EAC9C,MAAO,GAAG,MAA2B,GAAgB,EAAhC,EAA8C,AACvE,CAWe,MAAM,GACjB,YAAY,CAAY,CAAE,EAAU,EAAgB,CAAE,EAAM,EAAc,CAAC,CACvE,IAAI,CAAC,UAAU,CAAG,GAAQ,MAAM,CAAC,CAG7B,WAAY,CAAC,KAAE,CAAG,sBAAE,CAAoB,CAAE,GAAG,CAAA,EAAG,EAAI,CAAC,EAAE,EAAuB,IAAM,IAAA,CAAK,CAIzF,YAAa,EACjB,GACA,IAAI,CAAC,iBAAiB,CAAG,GAAQ,MAAM,CAAC,CAIpC,YAAa,EACjB,GAKF,IAAI,CAAC,oBAAoB,CAAG,IAAI,IAC9B,IAAI,CAAC,YAAY,CAAG,EACpB,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,GAAG,CAAG,EAEX,IAAI,CAAC,KAAK,CAAG,IAAI,GAAS,OAAS,EAAW,AAAC,IAC3C,IAAM,EAAe,AAlC7B,SAAS,AAAoB,CAAW,EACxC,IAAM,EAAiB,EAAY,WAAW,CAAC,AAdzB,MAetB,GAAI,AAAmB,CAAC,MAAG,OAAO,AAClC,IAAM,EAAe,EAAY,KAAK,CAAC,EAAiB,GACxD,OAAO,IAAiB,QAAe,EAAY,CACvD,EA6BqD,GACzC,GAAI,EAAc,CASd,GAAI,IAAI,CAAC,oBAAoB,CAAC,IAAI,EAAI,IAAK,CACvC,IAAM,EAAQ,IAAI,CAAC,oBAAoB,CAAC,MAAM,GAAG,IAAI,GAAG,KAAK,AACzD,IAAO,IAAI,CAAC,oBAAoB,CAAC,MAAM,CAAC,EAChD,CACA,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,EAClC,CACJ,EACJ,CAQE,MAAM,IAAI,CAAG,CAAE,CAAiB,CAAE,CAAO,CAAE,CAGzC,GAAI,CAAC,EACD,GADM,IACC,EAAkB,CACrB,aAAa,EACb,mBAAoB,IACxB,GAGJ,GAAI,IAAI,CAAC,YAAY,CAAE,CACnB,IAAM,EAAW,GAAe,EAAK,EAAQ,YAAY,EACnD,EAAa,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,GAClC,GAAI,EAAY,CAGZ,QAA6B,IAAzB,EAAQ,KAA4B,OAAhB,CACpB,OAAO,GAAqB,EAAW,KAAK,EAGhD,IAAM,EAAM,KAAK,GAAG,GACpB,GAAI,EAAW,SAAS,CAAG,EACvB,GAD4B,IACrB,GAAqB,EAAW,KAAK,EAGhD,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,EACtB,CAEI,EAAQ,YAAY,EAAI,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,EAAQ,YAAY,GAC1E,AAD6E,GACpE,CAAC,gDAAgD,EAAE,EAAQ,YAAY,CAAC,AAAO,EAAL,mEAAwE,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE,CAAxF,AAAyF,CAErL,CACA,CAH+F,EAGzF,kBAAE,CAAgB,sBAAE,EAAuB,EAAK,YAAE,GAAa,CAAK,mBAAE,GAAoB,CAAK,YAAE,GAAa,CAAK,WAAE,CAAS,WAAE,CAAS,cAAE,CAAY,CAAE,CAAG,EAC5J,EAAW,MAAM,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,KACzC,uBACA,CACJ,EAAG,CAAC,SAAE,CAAO,CAAE,IACX,IAAM,EAAU,IAAI,CAAC,SAAS,CAAC,EAAK,EAAmB,kBACnD,uBACA,aACA,oBACA,aACA,YACA,eACA,CACJ,EAAG,GAGH,OADI,GAAW,EAAU,GAClB,CACX,GACA,OAAO,GAAqB,EAChC,CASE,MAAM,UAAU,CAAG,CAAE,CAAiB,CAAE,CAAO,CAAE,CAAO,CAAE,CACxD,IAAI,EAAgC,KAChC,GAAW,EACf,GAAI,CAOA,GAAI,CALJ,EAAgC,AAAC,IAAI,CAAC,YAAY,CAI7C,KAJgD,MAAM,EAAQ,gBAAgB,CAAC,GAAG,CAAC,EAAK,CACzF,KdxHT,AcwHe,SdxHN,AAAgC,CAAS,EACrD,OAAO,GACH,KAAK,GAAU,KAAK,CAChB,OAAO,GAAqB,KAAK,AACrC,MAAK,GAAU,QAAQ,CACnB,OAAO,GAAqB,QAAQ,AACxC,MAAK,GAAU,KAAK,CAChB,OAAO,GAAqB,KAAK,AACrC,MAAK,GAAU,SAAS,CACpB,OAAO,GAAqB,SAChC,AADyC,MACpC,GAAU,SAAS,CAEpB,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,sBAAsB,EAAE,EAAA,CAAW,EAAG,oBAAqB,CAC9F,MAAO,MACP,YAAY,EACZ,cAAc,CAClB,EACJ,SACI,OAAO,CACf,CACJ,EAEA,AckGsD,EAAQ,SAAS,EACvD,kBAAmB,EdnGF,AcmGU,iBAAiB,CAC5C,WAAY,EAAQ,UAAU,AAClC,EAAK,GACgC,CAAC,EAAQ,oBAAoB,EAAE,CAChE,EAAQ,GACR,GAAW,EACP,CAAC,EAA8B,OAAO,EAAI,EAAQ,UAAU,EAAE,AAE9D,OAAO,EAIf,IAAM,EAAgC,MAAM,IAAI,CAAC,UAAU,CAAC,EAAK,EAAQ,gBAAgB,CAAE,EAAQ,iBAAiB,CAAE,EAAQ,UAAU,CAAE,EAAmB,EAAiE,OAAlC,GAA0C,CAAC,EAAQ,oBAAoB,MAAE,EAAW,EAAQ,YAAY,EAEpS,GAAI,CAAC,EAA+B,CAEhC,GAAI,IAAI,CAAC,YAAY,CAAE,CACnB,IAAM,EAAW,GAAe,EAAK,EAAQ,YAAY,EACzD,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,EACtB,CACA,OAAO,IACX,CAKA,OAHI,EAAQ,oBAAoB,CAGzB,CACX,CAAE,CAJsC,CAAC,IAIhC,EAAK,CAGV,GAP+C,AAO3C,EAEA,OADA,CADU,OACF,KAAK,CAAC,GACP,IAEX,OAAM,CACV,CACJ,CAcE,MAAM,WAAW,CAAG,CAAE,CAAgB,CAAE,CAAiB,CAAE,CAAU,CAAE,CAAiB,CAAE,CAA6B,CAAE,CAAW,CAAE,CAAS,CAAE,CAAY,CAAE,CAC7J,OAAO,IAAI,CAAC,iBAAiB,CAAC,KAAK,CAAC,EAAK,KACrC,IAAM,EAAU,IAAI,CAAC,gBAAgB,CAAC,EAAK,EAAkB,EAAmB,EAAY,EAAmB,EAA+B,EAAa,GAG3J,OADI,GAAW,EAAU,GAClB,CACX,EACJ,CACA,MAAM,iBAAiB,CAAG,CAAE,CAAgB,CAAE,CAAiB,CAAE,CAAU,CAAE,CAAiB,CAAE,CAA6B,CAAE,CAAW,CAAE,CAAY,CAAE,CACtJ,GAAI,CAEA,IAAM,EAAqB,MAAM,EAAkB,aAC/C,EACA,mBAAoB,EACpB,gBAAgB,CACpB,GACA,GAAI,CAAC,EACD,OAAO,KAGX,IAAM,EAAgC,AAJb,MAImB,GAAuB,CAC/D,GAAG,CAAkB,CACrB,OAAQ,CAAC,CACb,GAGA,GAAI,EAA8B,YAAY,CAC1C,CAD4C,EACxC,IAAI,CAAC,YAAY,CAAE,CAInB,IAAM,EAAW,GAAe,EAAK,GACrC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,EAAU,CACrB,MAAO,EACP,UAAW,KAAK,GAAG,GAAK,IAAI,CAAC,GAAG,AACpC,EACJ,MACI,CADG,KACG,EAAiB,GAAG,CAAC,EAAK,EAA8B,KAAK,CAAE,CACjE,aAAc,EAA8B,YAAY,mBACxD,EACA,YACJ,GAGR,OAAO,CACX,CAAE,MAAO,EAAK,CAGV,GAAqC,MAAjC,EAAwC,KAAK,EAAI,EAA8B,YAAY,CAAE,CAC7F,IAAM,EAAa,KAAK,GAAG,CAAC,KAAK,GAAG,CAAC,EAA8B,YAAY,CAAC,UAAU,EAAI,EAAG,GAAI,IAC/F,OAA+D,IAAtD,EAA8B,YAAY,CAAC,MAAM,CAAiB,OAAY,KAAK,GAAG,CAAC,EAAa,EAAG,EAA8B,YAAY,CAAC,MAAM,CACvK,OAAM,EAAiB,GAAG,CAAC,EAAK,EAA8B,KAAK,CAAE,CACjE,aAAc,CACV,WAAY,EACZ,OAAQ,CACZ,oBACA,aACA,CACJ,EACJ,CAEA,MAAM,CACV,CACJ,CACJ,EAEA,6B9C7RA,IAAA,A8C6RiC,G9C7RjC,EAAA,CAAA,CAAA,MkDIW,OAAM,GACb,YAEI,AAFQ,CAEN,CAAC,CACH,IAAI,CAAC,EAAE,CAAG,EACV,IAAI,CAAC,KAAK,CAAG,EAAE,AACnB,CAME,iBAAiB,CAAS,CAAE,CAE1B,IAAK,IAAM,KAAQ,IAAI,CAAC,KAAK,CACzB,AAD0B,GACtB,CAAI,CAAC,EAAE,GAAK,EACZ,OAAO,EADgB,AAI/B,IAAM,EAAU,IAAI,CAAC,EAAE,CAAC,KAAK,CAAC,GAG9B,EAAQ,KAAK,CAAC,KAAK,GAEnB,IAAM,EAAO,CACT,EACA,EACA,EAAE,CACL,CAED,OADA,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,GACT,CACX,CAUE,OAAO,CAAQ,CAAE,CAAI,CAAE,CAErB,IAAM,EAAO,IAAI,CAAC,gBAAgB,CAAC,GAAA,OAAI,CAAC,OAAO,CAAC,IAC1C,EAAU,CAAI,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC,EAAU,IAG7D,EAAQ,KAAK,CAAC,KAAK,GAEnB,CAAI,CAAC,EAAE,CAAC,IAAI,CAAC,EACjB,CAGE,MAAO,CACL,OAAO,QAAQ,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,AAAC,GAAO,CAAI,CAAC,EAAE,EACzD,CACJ,ClDvDe,CkDyDf,KlDzDqB,GACjB,QAAO,CAAA,AAAE,CAAG,IAAI,CAAC,KAAK,CAAG,CAAC,CAAC,QAAQ,GAAG,CAAC,EkDwDE,sBlDxDsB,AAAC,AAChE,aAAY,CAAG,CAAC,CACZ,IAAI,CAAC,EAAE,CAAG,EAAI,EAAE,CAChB,IAAI,CAAC,WAAW,CAAG,EAAI,WAAW,CAClC,IAAI,CAAC,aAAa,CAAG,EAAI,aAAa,CACtC,IAAI,CAAC,eAAe,CAAG,EAAI,eAAe,CACtC,EAAI,kBAAkB,CACjB,CADmB,EACH,WAAW,CAKrB,CALuB,EAKP,KAAK,EAAE,AAC9B,QAAQ,GAAG,CAAC,sDALR,GAAgB,KAAK,EAAE,AACvB,QAAQ,GAAG,CAAC,uDAEhB,GAAgB,WAAW,CUfpC,AVeuC,SUf9B,AAAe,CAAkB,EAuB7C,OAtBI,AAAC,IACD,EAAc,IAAI,GADJ,AACa,EAAoB,SAAS,AAAO,CAAE,MAAA,CAAK,CAAE,EACpE,IAAI,EACJ,GAAI,CAAC,EACD,MADQ,CACD,GACJ,GAAI,EAAM,IAAI,GAAK,GAAgB,QAAQ,CAC9C,CADgD,MACzC,KAAK,SAAS,CAAC,EAAM,KAAK,EAAE,MAAM,CACtC,GAAI,EAAM,IAAI,GAAK,GAAgB,KAAK,CAC3C,CAD6C,KACvC,OAAO,cAAc,CAAC,AAAI,MAAM,mDAAoD,oBAAqB,CAC3G,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GACG,GAAI,EAAM,IAAI,GAAK,GAAgB,KAAK,CAC3C,CAD6C,MACtC,KAAK,SAAS,CAAC,EAAM,IAAI,EAAI,IAAI,MAAM,CAC3C,GAAI,EAAM,IAAI,GAAK,GAAgB,SAAS,CAC/C,CADiD,MAC1C,EAAM,IAAI,CAAC,MAAM,CAG5B,OAAO,EAAM,IAAI,CAAC,MAAM,EAAI,CAAD,AAAE,AAAgH,OAA/G,EAAkB,KAAK,SAAS,CAAC,EAAM,IAAI,GAAK,GAAgB,QAAQ,CAAG,EAAM,OAAO,CAAG,EAAM,SAAQ,CAAC,CAAY,KAAK,EAAI,EAAgB,MAAA,AAAM,IAAK,CAAC,AAC7L,EAAA,EAEG,CACX,EVT6D,AUW7D,EVXiE,kBAAkB,GAIhE,GAAgB,KAAK,EAAE,AAC9B,QAAQ,GAAG,CAAC,IUMyB,sDVJ7C,CACA,mBAAoB,CAAC,CACrB,MAAM,cAAc,CAAI,CAAE,CAAS,CAAE,CAOjC,GANA,EAAO,AAAgB,iBAAT,EAAoB,CAC9B,EACH,CAAG,EACA,GAAgB,KAAK,EACrB,AADuB,QACf,GAAG,CAAC,iCAAkC,EAAM,GAEpC,AAAhB,GAAmB,GAAd,MAAM,CACX,OAEJ,IAAM,EAAM,KAAK,GAAG,GACpB,IAAK,IAAM,KAAO,EAAK,CACnB,IAAM,EAAgB,GAAa,GAAG,CAAC,IAAQ,CAAC,EAChD,GAAI,EAAW,CAEX,IAAM,EAAU,CACZ,GAAG,CAAa,AACpB,CAEA,GAAQ,KAAK,CAAG,OACS,IAArB,EAAU,KAAsB,CAAhB,GAChB,EAAQ,OAAO,CAAG,EAAyB,IAAnB,EAAU,MAAM,AAAG,EAAK,AAGpD,GAAa,GAAG,CAAC,EAAK,EAC1B,MAEI,CAFG,EAEU,GAAG,CAN4D,AAM3D,EAAK,CAClB,GAAG,CAAa,CAChB,QAAS,CACb,EAER,CACJ,CACA,MAAM,IAAI,GAAG,CAAI,CAAE,KACX,EAA8B,EAAa,EAAc,EAAc,EAyInE,EAxIR,GAAM,CAAC,EAAK,EAAI,CAAG,EACb,MAAE,CAAI,CAAE,CAAG,EACb,EAAuE,AAAhE,OAAC,EAA+B,GAAgB,WAAA,AAAW,EAAY,KAAK,EAAI,EAA6B,GAAG,CAAC,GAqI5H,GApII,GAAgB,KAAK,EAAE,CACnB,IAAS,GAAqB,KAAK,CACnC,CADqC,OAC7B,GAAG,CAAC,uBAAwB,EAAK,EAAI,IAAI,CAAE,EAAM,CAAC,CAAC,GAE3D,QAAQ,GAAG,CAAC,uBAAwB,EAAK,EAAM,CAAC,CAAC,IAgIrD,CAAS,MAAR,CAAe,EAAuC,AAA9B,GAAJ,IAAK,EAAc,EAAK,KAAA,AAAK,EAAY,KAAK,EAAI,EAAY,IAAI,IAAM,GAAgB,QAAQ,EAAI,CAAS,MAAR,CAAe,EAAS,AAA+B,GAAnC,IAAK,EAAe,EAAK,KAAK,AAAL,EAAiB,KAAK,EAAI,EAAa,IAAI,IAAM,GAAgB,SAAS,EAAI,CAAS,MAAR,CAAe,EAAwC,AAA/B,GAAJ,IAAK,EAAe,EAAK,KAAA,AAAK,EAAY,KAAK,EAAI,EAAa,IAAI,IAAM,GAAgB,KAAK,CAAE,CAE3W,IAAM,EAAa,AAA8C,OAA7C,EAAsB,EAAK,KAAK,CAAC,OAAA,AAAO,EAAY,KAAK,EAAI,CAAmB,CAAC,EAAuB,CAC5H,GAAI,AAAsB,iBAAf,EAAyB,CAChC,IAAM,EAAY,EAAW,KAAK,CAAC,KAInC,GAAI,EAAU,MAAM,CAAG,GAAK,GAAe,EAAW,EAAK,YAAY,EAInE,CAJsE,MAClE,GAAgB,KAAK,EACrB,AADuB,QACf,GAAG,CAAC,gCAAiC,GAE1C,IAEf,CACJ,MAAO,GAAI,CAAS,MAAR,CAAe,EAAS,AAA+B,GAAnC,IAAK,EAAe,EAAK,KAAA,AAAK,EAAY,KAAK,EAAI,EAAa,IAAI,IAAM,GAAgB,KAAK,CAAE,CAC7H,IAAM,EAAe,EAAI,IAAI,GAAK,GAAqB,KAAK,CAAG,IACxD,EAAI,IAAI,EAAI,EAAE,IACd,EAAI,QAAQ,EAAI,EAAE,CACxB,CAAG,EAAE,CAGN,GAAI,EAAa,IAAI,CAAC,AAAC,GAAM,IAAI,CAAC,eAAe,CAAC,QAAQ,CAAC,IAIvD,GAJ8D,IAC1D,GAAgB,KAAK,EAAE,AACvB,QAAQ,GAAG,CAAC,mCAAoC,GAE7C,KAEX,GAAI,GAAe,EAAc,EAAK,YAAY,EAI9C,CAJiD,MAC7C,GAAgB,KAAK,EAAE,AACvB,QAAQ,GAAG,CAAC,gCAAiC,GAE1C,IAEf,CACA,OAAO,GAAQ,IACnB,CACA,MAAM,IAAI,CAAG,CAAE,CAAI,CAAE,CAAG,CAAE,CACtB,IAAI,EAQJ,GAPgE,AAAhE,OAAuE,AAAtE,EAA+B,GAAgB,AAA4B,WAA5B,AAAW,GAAqB,EAA6B,GAAG,CAAC,EAAK,CAClH,MAAO,EACP,aAAc,KAAK,GAAG,EAC1B,GACI,GAAgB,KAAK,EAAE,AACvB,QAAQ,GAAG,CAAC,uBAAwB,GAEpC,CAAC,IAAI,CAAC,WAAW,EAAI,CAAC,EAAM,OAGhC,IAAM,EAAS,IAAI,GAAgB,IAAI,CAAC,EAAE,EAC1C,GAAI,EAAK,IAAI,GAAK,GAAgB,SAAS,CAAE,CACzC,IAAM,EAAW,IAAI,CAAC,WAAW,CAAC,CAAA,EAAG,EAAI,KAAK,CAAC,CAAE,GAAqB,SAAS,EAC/E,EAAO,MAAM,CAAC,EAAU,EAAK,IAAI,EACjC,IAAM,EAAO,CACT,QAAS,EAAK,OAAO,CACrB,OAAQ,EAAK,MAAM,CACnB,eAAW,EACX,kBAAc,CAClB,EACA,EAAO,MAAM,CAAC,EAAS,OAAO,CAAC,UAAW,GAAmB,KAAK,SAAS,CAAC,EAAM,KAAM,GAC5F,MAAO,GAAI,EAAK,IAAI,GAAK,GAAgB,KAAK,EAAI,EAAK,IAAI,GAAK,GAAgB,QAAQ,CAAE,CACtF,IAAM,EAAY,EAAK,IAAI,GAAK,GAAgB,QAAQ,CAClD,EAAW,IAAI,CAAC,WAAW,CAAC,CAAA,EAAG,EAAI,KAAK,CAAC,CAAE,EAAY,GAAqB,QAAQ,CAAG,GAAqB,KAAK,EAMvH,GALA,EAAO,MAAM,CAAC,EAAU,EAAK,IAAI,EAE7B,AAAC,EAAI,UAAU,EAAK,EAAI,AAAL,UAAe,EAAK,EAAD,AAAK,iBAAiB,EAAE,AAC9D,EAAO,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,CAAA,EAAG,EAAA,EAAM,EAAY,EAAa,EAAA,CAAkB,CAAE,EAAY,GAAqB,QAAQ,CAAG,GAAqB,KAAK,EAAG,EAAY,EAAK,OAAO,CAAG,KAAK,SAAS,CAAC,EAAK,QAAQ,GAErN,CAAS,MAAR,EAAe,KAAK,EAAI,EAAK,IAAA,AAAI,IAAM,GAAgB,QAAQ,CAAE,KAC9D,EACJ,GAAI,EAAK,WAAW,CAAE,CAClB,EAAe,EAAE,CACjB,IAAM,EAAc,EAAS,OAAO,CAAC,UAAW,GAChD,IAAK,GAAM,CAAC,EAAa,EAAO,GAAI,EAAK,WAAW,CAAC,CACjD,EAAa,IAAI,CAAC,GAClB,IAAM,EAAsB,EAAc,EAAc,EACxD,EAAO,MAAM,CAAC,EAAqB,EACvC,CACJ,CACA,IAAM,EAAO,CACT,QAAS,EAAK,OAAO,CACrB,OAAQ,EAAK,MAAM,CACnB,UAAW,EAAK,SAAS,CACzB,cACJ,EACA,EAAO,MAAM,CAAC,EAAS,OAAO,CAAC,UAAW,GAAmB,KAAK,SAAS,CAAC,GAChF,CACJ,MAAO,GAAI,EAAK,IAAI,GAAK,GAAgB,KAAK,CAAE,CAC5C,IAAM,EAAW,IAAI,CAAC,WAAW,CAAC,EAAK,GAAqB,KAAK,EACjE,EAAO,MAAM,CAAC,EAAU,KAAK,SAAS,CAAC,CACnC,GAAG,CAAI,CACP,KAAM,EAAI,UAAU,CAAG,EAAI,IAAI,CAAG,EAAE,AACxC,GACJ,CAEA,MAAM,EAAO,IAAI,EACrB,CACA,YAAY,CAAQ,CAAE,CAAI,CAAE,CACxB,OAAO,GACH,KAAK,GAAqB,KAAK,CAG3B,OAAO,GAAA,OAAI,CAAC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAE,KAAM,QAAS,cAAe,EACvE,MAAK,GAAqB,KAAK,CAC3B,OAAO,GAAA,OAAI,CAAC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAE,QAAS,EAClD,MAAK,GAAqB,KAAK,CAC/B,KAAK,GAAqB,QAAQ,CAClC,KAAK,GAAqB,SAAS,CAC/B,OAAO,GAAA,OAAI,CAAC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAE,MAAO,EAChD,SACI,MAAM,OAAO,cAAc,CAAK,AAAJ,MAAU,CAAC,2BAA2B,EAAE,EAAA,CAAM,EAAG,oBAAqB,CAC9F,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,EACR,CACJ,CACJ,CazTO,Cb2TP,Ga3Ta,GAA6B,CACtC,WACA,MACA,OACA,QACH,CACM,KbqTsC,IarT7B,GAA2B,CAAI,EAE3C,YAAwG,IAAjG,EAAK,KAAK,CAAC,KAAK,IAAI,CAAC,AAAC,GAAU,GAA2B,IAAI,CAAC,AAAC,GAAI,EAAQ,UAAU,CAAC,IACnG,CACO,SAAS,GAAoC,CAAI,EACpD,IAAI,EACA,EACA,EACJ,IAAK,IAAM,KAAW,EAAK,KAAK,CAAC,KAAK,AAElC,GADA,CACI,CADK,GAA2B,IAAI,CAAC,AAAC,GAAI,EAAQ,UAAU,CAAC,IACrD,CAER,CAAC,EAAmB,EAAiB,CAAG,EAAK,KAAK,CAAC,EAAQ,GAC3D,KACJ,CAEJ,GAAI,CAAC,GAAqB,CAAC,GAAU,CAAC,EAClC,MAAM,OAAO,GADuC,WACzB,CAAC,AAAI,MAAM,CAAC,4BAA4B,EAAE,EAAK,iFAAiF,CAAC,EAAG,oBAAqB,CAChL,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,GAIJ,OAFA,EAAoB,EAAiB,GAE9B,GACH,IAAK,MAGG,EADA,AAAsB,CALsB,IAKjB,GACR,CAAC,CAAC,EAAE,EAAA,CAAkB,CAEtB,EAAoB,IAAM,EAEjD,KACJ,KAAK,OAED,GAA0B,KAAK,CAbkE,AAa7F,EACA,MAAM,OAAO,cAAc,CAAK,AAAJ,MAAU,CAAC,4BAA4B,EAAE,EAAK,4DAA4D,CAAC,EAAG,oBAAqB,CAC3J,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,EAAmB,EAAkB,KAAK,CAAC,KAAK,KAAK,CAAC,EAAG,CAAC,GAAG,MAAM,CAAC,GAAkB,IAAI,CAAC,KAC3F,KACJ,KAAK,QAED,EAAmB,IAAM,EACzB,KACJ,KAAK,WAED,IAAM,EAAyB,EAAkB,KAAK,CAAC,KACvD,GAAI,EAAuB,MAAM,EAAI,EACjC,CADoC,KAC9B,OAAO,cAAc,CAAK,AAAJ,MAAU,CAAC,4BAA4B,EAAE,EAAK,+DAA+D,CAAC,EAAG,oBAAqB,CAC9J,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,EAAmB,EAAuB,KAAK,CAAC,EAAG,CAAC,GAAG,MAAM,CAAC,GAAkB,IAAI,CAAC,KACrF,KACJ,SACI,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,gCAAiC,oBAAqB,CACxF,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACR,CACA,MAAO,mBACH,EACA,kBACJ,CACJ,EAEA,+CAA+C,gFZhF/C,IAAM,GAAa,gCAEb,GAAoB,sBAOf,SAAS,GAAe,CAAK,CAAE,GAAS,CAAI,QAInD,CAHI,GAA2B,KAC3B,EAAQ,CAD2B,EACS,GAAO,gBAAA,AAAgB,EAEnE,GACO,GAAkB,EADjB,EACqB,CAAC,GAE3B,GAAW,IAAI,CAAC,EAC3B,EAEA,sCAAsC,YyBsEG,AACvB,IADA,OAAO,aACD,CACpB,OACA,UACA,mBACH,CAAC,KAAK,CAAC,AAAC,GAAwC,YAA/B,OAAO,WAAW,CAAC,EAAO,CACrC,OAAM,WAAoB,MACjC,C6CvFW,SAAS,GAAkB,CAAI,EAStC,MARmB,CAQZ,gBAR6B,IAAI,CAAC,IAAS,CAAC,GAAe,GAAQ,CAAC,MAAM,EAAE,EAAA,CAAM,CAAY,MAAT,EAAe,SAAW,EAAmB,EAS7I,CKCW,CLCX,QKDoB,GAAQ,CAAQ,EAChC,OAAO,EAAS,OAAO,CAAC,gBLAmB,GKAC,KAAO,GACvD,EAEA,oCAAoC,oCvCtBzB,OAAM,GACb,QAAO,CAAA,AAAE,CAGP,EAHU,EAGN,CAAC,aAAa,CAAG,IAAI,GAAM,AACjC,YAAY,CAGR,CAAiB,CAAC,CAClB,IAAI,CAAC,iBAAiB,CAAG,CAC7B,CASE,IAAI,CAAK,CAAE,CAIT,IAAI,EAAe,GAAoB,aAAa,CAAC,GAAG,CAAC,GACzD,GAAI,EAAc,OAAO,EACzB,IAAI,EAAgB,IAAI,CAAC,iBAAiB,CAAC,MAAM,CAAC,EAAM,CACxD,GAAI,EAAe,CACf,GAAM,0BAAE,CAAwB,sBAAE,CAAoB,CAAE,CAAG,EAC3D,GAAI,KAAoC,IAA7B,EACP,MAAO,CAD0C,AAE7C,WAAY,EACZ,OAAQ,CACZ,CAER,CACA,IAAM,EAAuB,IAAI,CAAC,iBAAiB,CAAC,aAAa,CAAC,EAAM,CACxE,GAAI,EAAsB,CACtB,GAAM,oBAAE,CAAkB,gBAAE,CAAc,CAAE,CAAG,EAC/C,GAAI,AAA8B,SAAvB,EACP,EAD2C,IACpC,CACH,WAAY,EACZ,OAAQ,CACZ,CAER,CAEJ,CAME,IAAI,CAAK,CAAE,CAAY,CAAE,CACvB,GAAoB,aAAa,CAAC,GAAG,CAAC,EAAO,EACjD,CAGE,OAAQ,CACN,GAAoB,aAAa,CAAC,KAAK,EAC3C,CACJ,C/DhEA,C+DkEA,G/DlEA,GAAA,EAAA,CAAA,CAAA,OCCA,IAAM,GAAc,sBACd,GAAkB,S8DgEkC,c9D/DnD,SAAS,GAAmB,CAAG,SAElC,AAAI,GAAY,IAAI,CAAC,GACV,EAAI,CADY,MACL,CAAC,GAAiB,QAEjC,CACX,CuDqHW,CvDnHX,GuDmHiB,GAAoB,mCvDnHI,QuDgJ9B,SAAS,GAAsB,CAAK,EAC3C,IAAM,EAAW,EAAM,UAAU,CAAC,MAAQ,EAAM,QAAQ,CAAC,KACrD,IACA,EAAQ,EAAM,EADJ,GACS,CAAC,EAAG,CAAC,EAAA,EAE5B,IAAM,EAAS,EAAM,UAAU,CAAC,OAIhC,OAHI,IACA,EAAQ,EADA,AACM,KAAK,CAAC,EAAA,EAEjB,CACH,IAAK,SACL,WACA,CACJ,CACJ,CYnHW,CZqHX,QYrHoB,GAAc,CAAe,CAAE,eAAE,GAAgB,CAAK,aZqH7B,EYrH+B,GAAgB,CAAK,8BAAE,EAA+B,EAAK,CAAE,CAAG,CAAC,CAAC,EAC1I,GAAM,oBAAE,CAAkB,QAAE,CAAM,CAAE,CAAG,AAlD3C,SAAS,AAAqB,CAAK,CAAE,CAAa,CAAE,CAAa,EAC7D,IAAM,EAAS,CAAC,EACZ,EAAa,EACX,EAAW,EAAE,CACnB,IAAK,IAAM,KAAW,GAAoB,GAAO,KAAK,CAAC,GAAG,KAAK,CAAC,KAAK,CACjE,IAAM,EAAc,GAA2B,IAAI,CAAC,AAAC,GAAI,EAAQ,UAAU,CAAC,IACtE,EAAe,EAAQ,KAAK,CAAC,IAEnC,GAAI,GAAe,GAAgB,CAAY,CAAC,EAAE,CAAE,CAChD,AAHkD,GAG5C,KAAE,CAAG,UAAE,CAAQ,GAHoD,KAGlD,CAAM,CAAE,CAAG,GAAsB,CAAY,CAAC,EAAE,EACvE,CAAM,CAAC,EAAI,CAAG,CACV,IAAK,WACL,WACA,CACJ,EACA,EAAS,IAAI,CAAC,CAAC,CAAC,EAAE,GAAmB,GAAa,QAAQ,CAAC,CAC/D,MAAO,GAAI,GAAgB,CAAY,CAAC,EAAE,CAAE,CACxC,GAAM,KAAE,CAAG,QAAE,CAAM,UAAE,CAAQ,CAAE,CAAG,GAAsB,CAAY,CAAC,EAAE,EACvE,CAAM,CAAC,EAAI,CAAG,CACV,IAAK,WACL,WACA,CACJ,EACI,GAAiB,CAAY,CAAC,EAAE,EAAE,AAClC,EAAS,IAAI,CAAC,CAAC,CAAC,EAAE,GAAmB,CAAY,CAAC,EAAE,EAAA,CAAG,EAE3D,IAAI,EAAI,EAAS,EAAW,cAAgB,SAAW,YAEnD,GAAiB,CAAY,CAAC,EAAE,EAAE,CAClC,EAAI,EAAE,SAAS,CAAC,EAAA,EAEpB,EAAS,IAAI,CAAC,EAClB,MACI,CADG,CACM,IAAI,CAAC,CAAC,CAAC,EAAE,GAAmB,GAAA,CAAU,EAG/C,GAAiB,GAAgB,CAAY,CAAC,EAAE,EAChD,AADkD,EACzC,IAAI,CAAC,GAAmB,CAAY,CAAC,EAAE,EAExD,CACA,MAAO,CACH,mBAAoB,EAAS,IAAI,CAAC,WAClC,CACJ,CACJ,EAMgE,EAAiB,EAAe,GACxF,EAAK,EAIT,OAHI,AAAC,GACD,IAAM,QAAA,EAEH,CACH,GAAI,AAAI,OAAO,CAAC,CAJe,AAId,EAAE,EAAG,CAAC,CAAC,EACxB,OAAQ,CACZ,CACJ,CAgBA,SAAS,GAAsB,oBAAE,CAAkB,CAAE,iBAAe,SAAE,CAAO,CAAE,WAAS,WAAE,CAAS,4BAAE,CAA0B,CAAE,EAC7H,IA6BI,EA7BE,KAAE,CAAG,UAAE,CAAQ,QAAE,CAAM,CAAE,CAAG,GAAsB,GAGpD,EAAa,EAAI,OAAO,CAAC,MAAO,IAChC,IACA,EAAa,CAAA,EAAG,EADL,AACK,EAAY,EAAA,CAAA,AAAY,EAE5C,IAAI,GAAa,GAGS,IAAtB,EAAW,MAAM,EAAU,EAAW,MAAM,CAAG,EAAA,GAAI,CACnD,GAAa,CAAA,EAEb,AAAC,MAAM,SAAS,EAAW,KAAK,CAAC,EAAG,MAAM,CAC1C,GAAa,CAAA,EAEb,IACA,EAAa,GAAA,EAEjB,CAHgB,GAGV,EAAe,KAAc,EAC/B,EACA,CAAS,CAAC,EAAW,CAAG,CAAA,EAAG,CADhB,CACgB,EAAY,EAAA,CAAK,CAE5C,CAAS,CAAC,EAAW,CAAG,EAK5B,IAAM,EAAqB,EAAqB,GAAmB,GAAsB,GAWzF,OANI,EAHA,GAAgB,EAGN,CAAC,IAAI,EAAE,EAAW,CAAC,CAAC,CACvB,EACG,CAAC,GAAG,EADC,AACC,EAAW,IALiB,CAKZ,CAAC,CAEvB,CAAC,GAAG,EAAE,EAAW,QAAQ,CAAC,CAEjC,KACH,EACA,QAAS,EAAW,CAAC,IAAI,EAAE,EAAA,EAAqB,EAAQ,EAAE,CAAC,CAAG,CAAC,CAAC,EAAE,EAAA,EAAqB,EAAA,CAAS,CAChG,WAAY,WACZ,EACA,QACJ,CACJ,CAmFW,SAAS,GAAmB,CAAe,CAAE,CAAO,EAC3D,IAAM,EAAS,AAnFnB,SAAS,AAA0B,CAAK,CAAE,CAAe,CAAE,CAAa,CAAE,CAAa,CAAE,CAA0B,CAAE,EAAY,CAC7H,MAAO,CAAC,EACR,YAAa,CAAC,CAClB,CAAC,EACG,MAAM,GA/DF,EAAI,EACD,KACH,IAAI,EA6DgB,AA7DL,GACX,EAAI,EAAE,EACV,KAAM,EAAI,EAAE,CACR,GAAY,OAAO,YAAY,CAAC,GAAK,CAAC,GAAI,CAAC,CAAI,IAC/C,EAAI,KAAK,KAAK,CAAC,CAAC,GAAI,CAAC,CAAI,IAE7B,OAAO,CACX,GAuDM,EAAY,CAAC,EACb,EAAW,EAAE,CACb,EAAe,EAAE,CAGvB,IAAK,IAAM,KADX,EAAY,gBAAgB,GACN,GAAoB,GAAO,KAAK,CAAC,GAAG,KAAK,CAAC,MAAK,CACjE,IAII,EAJE,EAAwB,GAA2B,IAAI,CAAC,AAAC,GAAI,EAAQ,UAAU,CAAC,IAChF,EAAe,EAAQ,KAAK,CAAC,IAE7B,EAAqB,EAAwB,GAAc,CAAC,EAAE,CAAG,IAFjB,GAYtD,GARI,GAAsB,GAAc,CAAC,EAAE,EAAE,AACzC,EAAY,EAAkB,EAL2C,KAKT,EAChE,EAAU,WAAW,CAAC,CAAY,CAAC,EAAE,CAAC,CAAG,GAEzC,EADO,GAAc,CAAC,EAAE,EAAI,EAAU,WAAW,CAAC,CAAY,CAAC,EAAE,CAAC,CACtD,CADwD,CACtC,OAAkC,EAEpD,EAAkB,OAA0B,EAExD,GAAsB,GAAgB,CAAY,CAAC,EAAE,CAAE,CAEvD,GAAM,KAAE,CAAG,SAAE,CAAO,YAAE,CAAU,QAAE,CAAM,UAAE,CAAQ,CAAE,CAAG,GAAsB,iBACzE,qBACA,EACA,QAAS,CAAY,CAAC,EAAE,WACxB,YACA,6BACA,CACJ,GACA,EAAS,IAAI,CAAC,GACd,EAAa,IAAI,CAAC,CAAC,CAAC,EAAE,CAAY,CAAC,EAAE,CAAC,CAAC,EAAE,EAAU,KAAK,CAAC,EAAI,EAAI,EAAA,EAAa,EAAS,EAAW,IAAM,IAAM,GAAA,CAAI,EAClH,EAAU,KAAK,CAAC,EAAI,GAAK,CAC7B,MAAO,GAAI,GAAgB,CAAY,CAAC,EAAE,CAAE,CAEpC,GAAiB,CAAY,CAAC,EAAE,EAAE,CAClC,EAAS,IAAI,CAAC,CAAC,CAAC,EAAE,GAAmB,CAAY,CAAC,EAAE,EAAA,CAAG,EACvD,EAAa,IAAI,CAAC,CAAC,CAAC,EAAE,CAAY,CAAC,EAAE,CAAA,CAAE,GAE3C,GAAM,KAAE,CAAG,SAAE,CAAO,YAAE,CAAU,QAAE,CAAM,UAAE,CAAQ,CAAE,CAAG,GAAsB,iBACzE,EACA,QAAS,CAAY,CAAC,EAAE,CACxB,sBACA,6BACA,CACJ,GAEI,EAAI,EACJ,GAAiB,CAAY,CAAC,EAAE,EAAE,AAClC,GAAI,EAAE,SAAS,CAAC,EAAA,EAEpB,EAAS,IAAI,CAAC,GACd,EAAa,IAAI,CAAC,CAAC,EAAE,EAAE,EAAU,KAAK,CAAC,EAAI,EAAI,EAAA,EAAa,EAAS,EAAW,IAAM,IAAM,GAAA,CAAI,EAChG,EAAU,KAAK,CAAC,EAAI,GAAK,CAC7B,MACI,CADG,CACM,IAAI,CAAC,CAAC,CAAC,EAAE,GAAmB,GAAA,CAAU,EAC/C,EAAa,IAAI,CAAC,CAAC,CAAC,EAAE,EAAA,CAAS,EAG/B,GAAiB,GAAgB,CAAY,CAAC,EAAE,EAAE,CAClD,EAAS,IAAI,CAAC,GAAmB,CAAY,CAAC,EAAE,GAChD,EAAa,IAAI,CAAC,CAAY,CAAC,EAAE,EAEzC,CACA,MAAO,CACH,wBAAyB,EAAS,IAAI,CAAC,cACvC,EACA,oBAAqB,EAAa,IAAI,CAAC,cACvC,CACJ,CACJ,EAS6C,EAAiB,EAAQ,eAAe,CAAE,EAAQ,aAAa,GAAI,EAAO,EAAQ,aAAa,GAAI,EAAO,EAAQ,0BAA0B,GAAI,EAAO,EAAQ,SAAS,EAC7M,EAAa,EAAO,uBAAuB,CAI/C,OAHI,AAAC,EAAQ,4BAA4B,EAAE,CACvC,GAAc,QAAA,EAEX,CACH,GAAG,GAAc,EAAiB,EAAQ,CAC1C,WAAY,CAAC,CAAC,EAAE,EAAW,CAAC,CAAC,CAC7B,UAAW,EAAO,SAAS,CAC3B,oBAAqB,EAAO,mBAAmB,CAC/C,UAAW,EAAO,SAAS,AAC/B,CACJ,iE4BpNW,IAAM,GAAkB,YAGxB,SAAS,GAA2B,CAAK,QAChD,AAAqB,UAAjB,AAA2B,OAAO,AAA3B,MAIP,wBAAwB,IAAI,CAAC,IAK7B,IALqC,6CAKY,IAAI,CAAC,GAI9D,CAIW,IAR2D,KAQlD,GAA4B,CAAK,EACjD,IAAI,EAAa,EAKjB,MADa,CAFb,AAGO,EAHM,EAAW,OAAO,CAAC,yBAA0B,CAAC,EAAE,EAAE,GAAgB,GAAG,EAAC,EAE3D,OAAO,CAAC,qBAAsB,CAAC,GAAG,EAAE,GAAA,CAAiB,CAEjF,CAwCW,SAAS,GAA0B,CAAQ,EAIlD,OAAO,EAAS,OAAO,CAAC,AAAI,OAAO,CAAC,GAAG,EAAE,GAAA,CAAiB,CAAE,KAAM,IACtE,CN5EW,SAAS,GAAiB,CAAK,CAAE,CAAI,CAAE,CAAO,EACrD,GAAI,AAAiB,UAAU,OAApB,EACP,MAAO,CAAA,EAAA,GAAA,YAAA,AAAY,EAAC,EAAO,EAAM,GAGrC,IAAM,EAAqB,GAA2B,GAChD,EAAa,EAAqB,GAA4B,GAAS,EAC7E,GAAI,CACA,MAAO,CAAA,EAAA,GAAA,YAAA,AAAY,EAAC,EAAY,EAAM,EAC1C,CAAE,MAAO,EAAO,CAEZ,GAAI,CAAC,EACD,GAAI,CACA,IAAM,EAAkB,GAA4B,GACpD,EAHiB,IAGV,CAAA,EAAA,GAAA,YAAA,AAAY,EAAC,EAAiB,EAAM,EAC/C,CAAE,MAAO,EAAY,CAGrB,CAEJ,MAAM,CACV,CACJ,CAMW,SAAS,GAAY,CAAK,CAAE,CAAO,EAE1C,IAAM,EAAqB,GAA2B,GAChD,EAAa,EAAqB,GAA4B,GAAS,EAC7E,GAAI,CACA,IAAM,EAAW,CAAA,EAAA,GAAA,OAAA,AAAO,EAAC,EAAY,GAIrC,GAAI,EACA,OAAO,AAAC,GACG,GAA0B,EAAS,GAF1B,CAKxB,OAAO,CACX,CAAE,MAAO,EAAO,CAEZ,GAAI,CAAC,EACD,GAAI,CACA,IAAM,EAAkB,GAA4B,GAC9C,EAHW,AAGA,CAAA,EAAA,GAAA,OAAA,AAAO,EAAC,EAAiB,GAE1C,OAAO,AAAC,GACG,GAA0B,EAAS,GAElD,CAAE,MAAO,EAAY,CAGrB,CAEJ,MAAM,CACV,CACJ,ChDlEO,SAAS,GAAgB,IAAE,CAAE,QAAE,CAAM,CAAE,MgDoFT,EhDvDjC,OgDuD0C,AhDvDnC,EA5BY,AAAC,IAChB,IAAM,EAAa,EAAG,GA2BF,CA3BM,CAAC,GAC3B,GAAI,CAAC,EAAY,OAAO,EACxB,IAAM,EAAS,AAAC,IACZ,GAAI,CACA,OAAO,mBAAmB,EAC9B,CAAE,KAAO,CACL,MAAM,OAAO,cAAc,CAAC,IAAI,GAAY,0BAA2B,oBAAqB,CACxF,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACJ,EACM,EAAS,CAAC,EAChB,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,GAAQ,CAC9C,IAAM,EAAQ,CAAU,CAAC,EAAM,GAAG,CAAC,MACrB,IAAV,IACI,EAAM,CADW,KACL,CACZ,CAAM,AADQ,CACP,EAAI,CAAG,EAAM,KAAK,CAAC,KAAK,GAAG,CAAC,AAAC,GAAQ,EAAO,IAEnD,CAAM,CAAC,EAAI,CAAG,EAAO,GAGjC,CACA,OAAO,CACX,EgD0DQ,AAAD,IACH,IAAM,EAAS,EAAU,GACzB,GAAI,CAAC,EAAQ,OAAO,EMAxB,IAAM,EAAU,CAAC,EACjB,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,ANCN,GMAX,KADyB,KACf,AAA3B,OAAO,EAEP,CAAO,CAAC,EAAI,CAAG,EAAM,OAAO,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,GAAA,CAAiB,EAAG,IACzD,MAAM,OAAO,CAAC,GAErB,CAAO,CAAC,EAAI,CAAG,CAFc,CAER,GAAG,CAAC,AAAC,GAAuB,UAAhB,OAAO,EAAoB,EAAK,OAAO,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,GAAA,CAAiB,EAAG,IAAM,GAElH,CAAO,CAAC,EAAI,CAAG,EAGvB,OAAO,CNTP,ChD5DJ,CxBhCO,CwBkCP,QxBlCgB,GAAuB,CAAY,EAC/C,IAAM,EAAQ,CAAC,EACf,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,EAAa,CwBgCH,MxBhCU,GAAG,CAC9C,IAAM,EAAW,CAAK,CAAC,EAAI,AACvB,AAAoB,UAAb,EACP,CADiC,AAC5B,CAAC,EAAI,CAAG,EACN,MAAM,OAAO,CAAC,GACrB,EAAS,IAAI,CAAC,CADkB,EAGhC,CAAK,CAAC,EAAI,CAAG,CACT,EACA,EACH,AAET,CACA,OAAO,CACX,CACA,SAAS,GAAuB,CAAK,QACjC,AAAqB,UAAjB,AAA2B,OAApB,EACA,GAEU,UAAjB,EAA6B,KAAtB,GAAuB,MAAM,EAAA,GAAU,AAAiB,WAAW,OAArB,EAG9C,GAFA,OAAO,EAItB,CACO,SAAS,GAAuB,CAAK,EACxC,IAAM,EAAe,IAAI,gBACzB,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,GACtC,GAAI,CADyC,KACnC,OAAO,CAAC,GACd,IAAK,EADiB,EACX,KAAQ,EACf,EAAa,GADQ,GACF,CAAC,EAAK,GAAuB,SAGpD,EAAa,GAAG,CAAC,EAAK,GAAuB,IAGrD,OAAO,CACX,CiCpCW,SAAS,GAAgB,CAAO,EACvC,OAAO,SAAS,EACZ,GAAM,QAAE,CAAM,CAAE,CAAG,EACnB,GAAI,CAAC,EACD,MADS,AACF,CAAC,EAEZ,GAAM,CAAE,MAAO,CAAa,CAAE,CAAA,EAAA,CAAA,CAAA,OAC9B,OAAO,EAAc,MAAM,OAAO,CAAC,GAAU,EAAO,IAAI,CAAC,MAAQ,EACrE,CACJ,CkBWA,ClBTA,QkBSS,GAAiB,CAAG,EACzB,OAAO,EAAI,OAAO,CAAC,clBVsB,GkBUJ,IACzC,CAoEO,SAAS,GAAe,CAAK,CAAE,CAAM,EACxC,GAAI,CAAC,EAAM,QAAQ,CAAC,KAChB,CADsB,MACf,EAEX,IAAK,IAAM,KAAO,OAAO,IAAI,CAAC,GACtB,EAAM,GADwB,KAChB,CAAC,CAAC,CAAC,EAAE,EAAA,CAAK,GAAG,CAC3B,EAAQ,EAAM,OAAO,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,EAAI,GAAG,CAAC,CAAE,KAAM,CAAC,CAAC,EAAE,EAAI,yBAAyB,CAAC,EAAE,OAAO,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,EAAI,GAAG,CAAC,CAAE,KAAM,CAAC,CAAC,EAAE,EAAI,wBAAwB,CAAC,EAAE,OAAO,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,EAAI,GAAG,CAAC,CAAE,KAAM,CAAC,CAAC,EAAE,EAAI,oBAAoB,CAAC,EAAE,OAAO,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,EAAI,OAAO,CAAC,CAAE,KAAM,CAAC,qBAAqB,EAAE,EAAA,EAAK,EAMzT,OAHA,EAAQ,EAAM,OAAO,CAAC,4BAA6B,QAAQ,OAAO,CAAC,wBAAyB,KAAK,OAAO,CAAC,yBAA0B,KAAK,OAAO,CAAC,4BAA6B,KAAK,OAAO,CAAC,6BAA8B,KAGjN,GAAY,CAAC,CAAC,EAAE,EAAA,CAAO,CAAE,CAC5B,SAAU,EACd,GAAG,GAAQ,KAAK,CAAC,EACrB,CQvGW,SAAS,GAAyB,CAAK,EAG9C,GAAI,CACA,OAAO,mBAAmB,EAC9B,CAAE,KAAO,CACL,OAAO,CACX,CACJ,CpDDO,CoDGP,QpDHgB,GAAY,CAAG,EAC3B,IAAM,EARH,AAQe,SARN,AAAS,CAAG,EACxB,IAAI,EACJ,GAAI,CACA,EAAS,CAFA,GAEI,IAAI,EAPJ,CoDckC,EpDPzB,QAC1B,CAAE,KAAO,CAAC,CACV,OAAO,CACX,EAE+B,GAC3B,GAAI,CAAC,EACD,OAEJ,EAHgB,EAGV,EAAQ,CAAC,EACf,IAAK,IAAM,KAAO,EAAU,YAAY,CAAC,IAAI,GAAG,CAC5C,IAAM,EAAS,EAAU,YAAY,CAAC,MAAM,CAAC,GAC7C,CAAK,CAAC,EAAI,CAAG,EAAO,MAAM,CAAG,EAAI,EAAS,CAAM,CAAC,EAAE,AACvD,CAeA,MAdkB,CACd,AAaG,QAZH,KAAM,EAAU,IAAI,CACpB,OAAQ,EAAU,MAAM,CACxB,KAAM,EAAU,QAAQ,CACxB,SAAU,EAAU,QAAQ,CAC5B,KAAM,CAAA,EAAG,EAAU,QAAQ,CAAA,EAAG,EAAU,MAAM,CAAA,EAAG,EAAU,IAAI,CAAA,CAAE,CACjE,KAAM,GACN,SAAU,GACV,KAAM,GACN,SAAU,GACV,QAAS,KACT,KAAM,EACV,CAEJ,4L4EfA,IAAM,GAAmB,yBHVzB,SAAS,GAAoB,CAAK,CAAE,CAAS,EAIzC,IAAI,IAAM,KADV,OAAO,EAAM,GAAD,eAAsB,CACjB,EAAM,CACnB,IAAM,EAAoB,IAAQ,GAA2B,EAAI,UAAU,CAAC,GACtE,EAAiC,IAAQ,GAAmC,EAAI,UAAU,CAAC,IAC7F,GAAqB,GAAkC,EAAU,QAAQ,CAAC,EAAA,GAAM,AAChF,OAAO,CAAK,CAAC,EAAI,AAEzB,CACJ,CAkFO,SAAS,GAAe,MAAE,CAAI,MAAE,CAAI,UAAE,CAAQ,UAAE,CAAQ,eAAE,CAAa,CAAE,eAAa,CAAE,eAAa,CAAE,EAC1G,IAAI,EACA,EACA,SACA,IAKA,EAAsB,CADtB,EAAsB,GAHtB,EAAoB,CADL,EACwB,EAAM,CACzC,KAEkC,YAFjB,CACrB,GACsC,EACI,EAAA,EA+IvC,CACH,eA9IJ,SAAS,AAAe,CAAG,CAAE,CAAS,EAGlC,IAAM,EAAqB,gBAAgB,GACrC,EAAgB,CAAC,EACnB,EAAa,EAAmB,QAAQ,CAKtC,EAAe,AAAC,QlGxHG,EAAM,EAAF,KAAS,CAEpC,EAKA,EkGkHQ,KAAuB,EAAQ,GAArB,GAA2B,CAAI,EAAD,CAAiB,OAAS,EAAA,CAAE,GAAG,CACzE,qBAAqB,EACrB,QAAQ,EACR,UAAW,CAAC,CAAC,CACjB,ElG5HF,EAAO,EAAE,GACA,CAAA,EAAA,GAAA,YAAA,AAAY,EAAC,EAAM,EAAM,CACpC,UAAW,IACX,UAAyC,WAA9B,OAAO,GAAS,WAA0B,EAAQ,SAAS,CACtE,EADyE,KACjE,GAAS,MACrB,KACgB,CAAA,EAAA,GAAA,gBAAgB,AAAhB,EAAiB,GAAS,cAAgB,IAAI,OAAO,EAAQ,aAAa,CAAC,EAAO,MAAM,EAAG,EAAO,KAAK,EAAI,EAAQ,GAM1H,CAAC,EAAU,KAEhB,GAAI,AAAoB,iBAAb,EAAuB,OAAO,EACzC,IAAM,EAAQ,EAAQ,GAEtB,GAAI,CAAC,EAAO,OAAO,EAKnB,GAAI,GAAS,oBACT,CAD8B,GACzB,IAAM,KAAO,EACU,GADL,OACf,AAA8B,OAAvB,EAAI,IAAI,EACf,OAAO,EAAM,MAAM,CAAC,EAAI,IAAI,CAAC,CAIzC,MAAO,CACH,GAAG,CAAM,CACT,GAAG,EAAM,MACb,AADmB,CAEvB,GkG4FQ,GAAI,CAAC,EAAmB,QAAQ,CAAE,OAAO,EACzC,IAAI,EAAS,EAAQ,EAAmB,QAAQ,EAChD,GAAI,CAAC,EAAQ,GAAG,EAAI,EAAQ,OAAA,AAAO,GAAK,EAAQ,CAC5C,IAAM,EAAY,A7B7G3B,SAAS,AAAS,CAAG,CAAE,CAAK,CAAE,EAAM,EAAE,CAAE,EAAU,EAAE,EACvD,IAAM,EAAS,CAAC,EACV,EAAW,AAAC,IAEd,IADI,EACA,EAAM,EAAQ,GAAG,CACrB,OAAO,EAAQ,IAAI,EACf,IAAK,SAEG,EAAM,EAAI,WAAW,GACrB,EAAQ,EAAI,OAAO,CAAC,EAAI,CACxB,KAER,KAAK,SAGO,EADA,YAAa,EACL,EAAI,CADM,MACC,CAAC,EAAQ,GAAG,CAAC,CAEhB,AACR,GADwB,EAAI,OAAO,GAC5B,CAAC,EAAQ,GAAG,CAAC,CAEhC,KAER,KAAK,QAEG,EAAQ,CAAK,CAAC,EAAI,CAClB,KAER,KAAK,OACD,CACI,GAAM,MAAE,CAAI,CAAE,CAAG,GAAK,SAAW,CAAC,EAGlC,EADiB,GAAM,IACf,EADqB,IAAK,EAAE,CAAC,EAAE,CAAC,aAG5C,CAKR,CACA,GAAI,CAAC,EAAQ,KAAK,EAAI,EAElB,MAFyB,CACzB,CAAM,CA3Dd,AA2De,SA3DN,AAAiB,CAAS,EACnC,IAAI,EAAe,GACnB,IAAI,IAAI,EAAI,EAAG,EAAI,EAAU,MAAM,CAAE,IAAI,CACrC,IAAM,EAAW,EAAU,UAAU,CAAC,GAClC,GAAW,IAAM,EAAW,IAChC,EADsC,AAC3B,IAAM,EAD2B,AAChB,GAAA,EAAI,EAE5B,GAAgB,CAFkB,AAET,CAAC,EAAA,AAAE,CAEpC,CACA,OAAO,CACX,EAgDoC,GAAK,CAAG,EACzB,GACJ,GAAI,EAAO,CACd,IAAM,EAAU,AAAI,OAAO,CAAC,CAAC,EAAE,EAAQ,KAAK,CAAC,CAAC,CAAC,EACzC,EAAU,MAAM,OAAO,CAAC,GAAS,EAAM,KAAK,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,KAAK,CAAC,GAAW,EAAM,KAAK,CAAC,GACvF,GAAI,EAUA,OAVS,AACL,MAAM,OAAO,CAAC,KACV,EAAQ,GADY,GACN,CACd,CADgB,MACT,IAAI,CAAC,EAAQ,MAAM,EAAE,OAAO,CAAC,AAAC,IACjC,CAAM,CAAC,EAAS,CAAG,EAAQ,MAAM,CAAC,EAAS,AAC/C,GACwB,SAAjB,EAAQ,IAAI,EAAe,CAAO,CAAC,EAAE,EAAE,CAC9C,EAAO,IAAI,CAAG,CAAO,CAAC,EAAA,AAAE,IAGzB,CAEf,CACA,OAAO,CACX,QAEA,GADiB,CACb,CADiB,KAAK,CAAC,AAAC,GAAO,AACrB,EAD8B,KAAW,EAAQ,GAAT,CAAa,CAAC,AAAC,GAAO,EAAS,GAAA,GAE1E,CAGf,E6B2C2C,EAAK,EAAmB,KAAK,CAAE,EAAQ,GAAG,CAAE,EAAQ,OAAO,EAClF,EACA,OAAO,EADI,IACE,CAAC,EAAQ,GAEtB,GAAS,CAEjB,CACA,GAAI,EAAQ,CACR,GAAM,mBAAE,CAAiB,WAAE,CAAS,CAAE,C7BU/C,A6BVkD,S7BUtB,AAAnB,CAAuB,EACnC,IA8BI,EA0BA,EAxDE,EA7CH,AA6CuB,SA7Cd,AAAiB,CAAI,EACjC,IAAI,EAAU,EAAK,WAAW,CAC9B,IAAK,IAAM,KAAS,OAAO,IAAI,CAAC,CAC5B,GAAG,EAAK,MAAM,CACd,GAAG,EAAK,KAAK,AACjB,GAAG,AACM,IACL,EA/FG,AA+FqB,CADZ,CA9FL,MA+FG,CA/FI,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,MAAmB,CAAc,CAAE,KAAM,CAAC,KAAvB,OAAmC,EAAE,AA+FrD,EA/FqD,CAAa,CA+FlE,EAErC,IAAM,E5BpHH,A4BoHY,S5BpHH,AAAS,CAAG,EACxB,GAAI,EAAI,UAAU,CAAC,KACf,CADqB,MDDtB,ACEQ,SDFC,AAAiB,CAAG,CAAE,CAAI,CAAE,GAAa,CAAI,EACzD,IAAM,EAAa,IAAI,IAAI,AAAgC,YACrD,CADkE,CAChB,EAAI,UAAU,CAAjD,AAAkD,KAAO,EAAlD,EAAsD,EAAlD,EAAsD,AAAgC,EAAlF,MAAM,IAAiH,CAAxB,CAC7H,UAAE,CAAQ,cAAE,CAAY,QAAE,CAAM,CAAE,MAAI,MAAE,CAAI,QAAE,CAAM,CAAE,CAAG,IAAI,IAAI,EAAK,GAC5E,GAAI,IAAW,EAAW,MAAM,CAC5B,CAD8B,KACxB,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,iDAAiD,EAAE,EAAA,CAAK,EAAG,oBAAqB,CACnH,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,MAAO,UACH,EACA,MAAO,EAAa,GAAuB,QAAgB,SAC3D,OACA,EACA,KAAM,EAAK,KAAK,CAAC,EAAO,MAAM,EAG9B,aAAS,CACb,CACJ,EAEA,ACrBgC,GAE5B,IAAM,EAAY,IAAI,IAAI,GAC1B,MAAO,CACH,KAAM,EAAU,IAAI,CACpB,ODgBsC,EChB5B,EAAU,QAAQ,CAC5B,KAAM,EAAU,IAAI,CACpB,SAAU,EAAU,QAAQ,CAC5B,KAAM,EAAU,IAAI,CACpB,SAAU,EAAU,QAAQ,CAC5B,MAAO,GAAuB,EAAU,YAAY,EACpD,OAAQ,EAAU,MAAM,CACxB,OAAQ,EAAU,MAAM,CACxB,QAA4F,OAAnF,EAAU,IAAI,CAAC,KAAK,CAAC,EAAU,QAAQ,CAAC,MAAM,CAAE,EAAU,QAAQ,CAAC,MAAM,CAAG,EACzF,CACJ,EAEA,A4BiG4B,GACpB,EAAW,EAAO,QAAQ,CAC1B,IACA,EAAW,GAAiB,CADlB,CACkB,EAEhC,IAAI,EAAO,E5BtGsB,A4BsGf,IAAI,CAClB,IACA,EADM,AACC,GAAiB,EAAA,EAE5B,IAAI,EAAW,EAAO,QAAQ,CAC1B,IACA,EAAW,GAAiB,CADlB,CACkB,EAEhC,IAAI,EAAO,EAAO,IAAI,CAClB,IACA,EADM,AACC,GAAiB,EAAA,EAE5B,IAAI,EAAS,EAAO,MAAM,CACtB,IACA,EAAS,EADD,CACkB,EAAA,EAE9B,IAAI,EAAS,EAAO,MAAM,CAI1B,OAHI,IACA,EAAS,EADD,CACkB,EAAA,EAEvB,CACH,GAAG,CAAM,UACT,WACA,OACA,OACA,SACA,SACA,CACJ,CACJ,EAE+C,GACrC,CAAE,SAAU,CAAY,CAAE,MAAO,CAAS,CAAE,OAAQ,CAAU,CAAE,CAAG,EAGrE,EAAW,EAAkB,QAAQ,CACrC,EAAkB,IAAI,EAAE,CACxB,EAAW,CAAA,EAAG,EAAA,EAAW,EAAkB,IAAI,CAAA,CAAA,AAAE,EAErD,IAAM,EAAa,EAAE,CACf,EAAoB,EAAE,CAE5B,IAAK,IAAM,KADX,GAAiB,EAAU,GACT,GACd,EAAW,IAAI,CAAC,EAAI,IAAI,EADQ,AAGpC,GAAI,EAAc,CACd,IAAM,EAAwB,EAAE,CAEhC,IAAK,IAAM,KADX,GAAiB,EAAc,GACb,GACd,EAAW,IAAI,CAAC,EAAI,IAAI,CAEhC,CACA,IAJ4C,AAItC,EAAmB,GAAY,EAMrC,CACI,OANJ,EAMc,EACd,GAQA,IAAK,GAAM,CAAC,EAAK,EAAW,GANxB,IACA,EAAuB,GAAY,EAAc,CAC7C,EAFU,QAEA,CACd,EAAA,EAG4B,OAAO,OAAO,CAAC,IAfqB,AAkB5D,MAAM,CAH4C,MAGrC,CAAC,GACd,CAAS,CAAC,EAAI,CAAG,EAAW,GADD,AACI,CAAE,AAAD,GAAS,GAAe,GAAiB,GAAQ,EAAK,MAAM,GAC/D,UAAtB,AAAgC,OAAzB,IACd,CAAS,CAAC,EAAI,CAAG,GAAe,GAAiB,GAAa,EAAK,OAAM,EAKjF,IAAI,EAAY,OAAO,IAAI,CAAC,EAAK,MAAM,EAAE,MAAM,CAAC,AAAC,GAAgB,uBAAT,GACxD,GAAI,EAAK,mBAAmB,EAAI,CAAC,EAAU,IAAI,CAAE,AAAD,GAAO,EAAW,QAAQ,CAAC,IACvE,GAD8E,CACzE,IAAM,KAAO,EACV,AAAE,CAAD,IAAQ,GADW,CAEpB,CAAS,CAAC,EAAI,CADI,AACD,EAAK,CADD,KACO,CAAC,EAAA,AAAI,EAO7C,GAAI,GAA2B,GAC3B,IAAK,IADiC,AAC3B,KAAW,EAAS,KAAK,CAAC,KAAK,CACtC,IAAM,EAAS,GAA2B,IAAI,CAAC,AAAC,GAAI,EAAQ,UAAU,CAAC,IACvE,GAAI,EAAQ,CACO,YAAY,CAAvB,GACA,EAAK,MAAM,CAAC,IAAI,CAAG,OACnB,EAAK,MAAM,CAAC,IAAI,CAAG,QAEnB,EAAK,MAAM,CAAC,IAAI,CAAG,EAEvB,KACJ,CACJ,CAEJ,GAAI,CAEA,GAAM,CAAC,EAAU,EAAK,CAAG,CADzB,EAAS,EAAiB,EAAK,OAAM,EACL,KAAK,CAAC,IAAK,GACvC,IACA,EAAkB,QAAQ,CAAG,EAAqB,EAAK,GADjC,IACuC,EAEjE,EAAkB,QAAQ,CAAG,EAC7B,EAAkB,IAAI,CAAG,CAAA,EAAG,EAAO,IAAM,GAAA,EAAK,GAAQ,GAAA,CAAI,CAC1D,EAAkB,MAAM,CAAG,EAAa,GAAe,EAAY,EAAK,MAAM,EAAI,EACtF,CAAE,MAAO,EAAK,CACV,GAAI,EAAI,OAAO,CAAC,KAAK,CAAC,gDAClB,CADmE,KAC7D,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,yKAAyK,CAAC,AAAG,oBAAqB,CACrO,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAEJ,OAAM,CACV,CASA,OAJA,EAAkB,KAAK,CAAG,CACtB,GAAG,EAAK,KAAK,CACb,GAAG,EAAkB,KAAK,AAC9B,EACO,QACH,YACA,oBACA,CACJ,CACJ,EAEA,A6BtH4E,CACxD,qBAAqB,EACrB,YAAa,EAAQ,S7BoHM,E6BpHK,CAChC,OAAQ,EACR,MAAO,EAAmB,KAC9B,AADmC,GAGnC,GAAI,EAAkB,QAAQ,CAC1B,CAD4B,MACrB,EAOX,GALA,OAAO,MAAM,CAAC,EAAe,EAAW,GACxC,OAAO,MAAM,CAAC,EAAmB,KAAK,CAAE,EAAkB,KAAK,EAC/D,OAAO,EAAkB,KAAK,CAC9B,OAAO,MAAM,CAAC,EAAoB,GAE9B,CAAC,CADL,EAAa,EAAmB,QAAA,AAAQ,EACvB,OAAO,EAIxB,GAHI,IACA,EAAa,EAAW,EADd,KACqB,CAAC,AAAI,OAAO,CAAC,CAAC,EAAE,EAAA,CAAU,EAAG,KAAO,GAAA,EAEnE,EAAM,CACN,IAAM,EAAS,GAAoB,EAAY,EAAK,OAAO,EAC3D,EAAa,EAAO,QAAQ,CAC5B,EAAmB,KAAK,CAAC,kBAAkB,CAAG,EAAO,cAAc,EAAI,EAAO,kBAAkB,AACpG,CACA,GAAI,IAAe,EACf,IADqB,GACd,EAEX,GAAI,GAAiB,EAAqB,CACtC,IAAM,EAAgB,EAAoB,GAC1C,GAAI,EAKA,OAJA,EAAmB,IADJ,CACS,CAAG,CACvB,GAAG,EAAmB,KAAK,CAC3B,GAAG,CAAa,AACpB,GACO,CAEf,CACJ,CACA,MAAO,EACX,EACA,IAAK,IAAM,KAAW,EAAS,WAAW,EAAI,EAAE,CAC5C,AAD6C,EAChC,GAEjB,GAAI,IAAe,EAAM,CACrB,MAAI,GAAW,EACf,IAAK,IAAM,KAAW,EAAS,UAAU,EAAI,EAAE,CAAC,AAE5C,GADA,CACI,CADO,EAAa,GACV,MAElB,GAAI,CAAC,KApEE,CADD,EAAoB,GAAoB,CAqE7B,CAAC,CArE0C,OAC/B,GAAoB,IAoEhB,CApE0B,AAAuB,IAAxB,IAA+B,KAAK,EAAI,EAAoB,EAAA,CAAkB,GAqEpI,IAAK,IAAM,KAAW,EAAS,QAAQ,EAAI,EAAE,CAAC,AAE1C,GADA,CACI,CADO,EAAa,GACV,KAClB,CAER,CACA,MAAO,eACH,qBACA,CACJ,CACJ,oBAwDI,EACA,0CACA,EACA,qBApBJ,SAA8B,AAArB,CAA0B,CAAE,CAAc,EAI/C,IAAK,GAAM,CAAC,EAAK,EAAM,GADvB,OAAO,EAAM,GAAD,eAAsB,CACP,OAAO,OAAO,CAAC,IAAO,CAC7C,IAAM,EAAgB,GAAwB,GACzC,IAGL,OAAO,CAAK,CAAC,EAHO,AAGH,CACjB,EAAe,GAAG,CAAC,QACE,IAAV,IACX,CAAK,CAAC,EAAc,CADc,AACX,MAAM,OAAO,CAAC,GAAS,EAAM,GAAG,CAAC,AAAC,GAAI,GAAyB,IAAM,GAAyB,EAAA,EACzH,CACJ,EAOI,0BA3DJ,SAAS,AAA0B,CAAkB,EAGjD,GAAI,CAAC,EAAmB,OAAO,KAC/B,GAAM,CAAE,QAAM,WAAE,CAAS,CAAE,CAAG,EA8BxB,EAAe,AA7BL,GAAgB,CAC5B,GAAI,CAEA,KAAM,AAAC,IAEH,IAAM,EAAM,OAAO,WAAW,CAAC,IAAI,gBAAgB,IACnD,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,GAAK,CAC3C,IAAM,EAAgB,GAAwB,GACzC,IACL,CAAG,CAAC,EAAc,CAAG,EACrB,IAFoB,GAEb,CAAG,CAAC,EAAI,CACnB,CAEA,IAAM,EAAS,CAAC,EAChB,IAAK,IAAM,KAAW,OAAO,IAAI,CAAC,GAAW,CACzC,IAAM,EAAY,CAAS,CAAC,EAAQ,CAEpC,GAAI,CAAC,EAAW,SAChB,IAAM,EAAQ,CAAM,CAAC,EAAU,CACzB,EAAQ,CAAG,CAAC,EAAQ,CAE1B,GAAI,CAAC,EAAM,QAAQ,EAAI,CAAC,EAAO,OAAO,KACtC,CAAM,CAAC,EAAM,GAAG,CAAC,CAAG,CACxB,CACA,OAAO,CACX,CACJ,SACA,CACJ,GAC6B,UAC7B,AAAK,GAAqB,CAAtB,GAER,EA6BI,KA/BmB,uBA+BU,CAAC,EAAO,KACjC,GAAI,CAAC,GAAqB,CAAC,EACvB,MAAO,CACH,OAAQ,CAAC,EACT,EAHwC,cAGxB,CACpB,MAxNmC,EA0NG,EA1NgB,EA0NG,EAxNrE,IAAI,EAAS,CAAC,EAFkD,AAGhE,IAAK,EAHgF,EAAE,AAG5E,KAAO,OAAO,IAAI,CAAC,EAAkB,EAH4D,IAGtD,EAAE,CACpD,IAAI,EAsNmC,AAtN3B,CAAK,CAAC,EAAI,CACD,UAAjB,AAA2B,OAApB,EACP,EAAQ,EAAgB,GACjB,MAAM,OAAO,CAAC,KACrB,EAAQ,EADqB,AACf,GAAG,CAAC,EAAA,EAKtB,IAAM,EAAe,CAAmB,CAAC,EAAI,CACvC,EAAa,EAAkB,MAAM,CAAC,EAAI,CAAC,QAAQ,CAIzD,GAAI,CAHmB,MAAM,OAAO,CAAC,GAAgB,EAAa,IAAI,CAAC,AAAC,GAC7D,MAAM,OAAO,CAAC,GAAS,EAAM,IAAI,CAAC,AAAC,GAAM,EAAI,QAAQ,CAAC,IAAwB,MAAT,EAAgB,KAAK,EAAI,EAAM,QAAQ,CAAC,IAC1G,MAAT,EAAgB,KAAK,EAAI,EAAM,QAAQ,CAAC,EAAA,GACvB,KAAiB,IAAV,GAAyB,CAAC,CAAC,GAwM8B,CAxMhB,CAAqB,CACvF,EAD0F,IACnF,CACH,CAF8D,MAEtD,CAAC,EACT,gBAAgB,CACpB,EAIA,IAAe,CAAC,GAAS,MAAX,AAAiB,OAAO,CAAC,IAA2B,IAAjB,CAAsB,CAAhB,MAAM,GAEnD,UAAb,CAAK,CAAC,EAAE,EAAgB,CAAK,CAAC,EAAE,GAAK,CAAC,KAAK,EAAE,EAAI,EAFsE,CAEpE,AAAC,GAAe,UAAV,GAAqB,IAAU,CAAC,KAAK,EAAE,EAAI,GAAE,AAAC,GAAG,CACvG,OAAQ,EACR,OAAO,CAAK,CAAC,EAAI,EAIjB,GAA0B,UAAjB,OAAO,GAAsB,EAAkB,MAAM,CAAC,EAAI,CAAC,MAAM,EAAE,CAC5E,EAAQ,EAAM,KAAK,CAAC,IAAA,EAEpB,IACA,CAAM,CAAC,EAAI,AADJ,CACO,CAAA,CAEtB,CACA,MAAO,QACH,EACA,gBA1CiB,CA2CrB,CA+KI,EACA,gBAAiB,CAAC,EAAK,IAAY,AA/PpC,SAAS,CAAgB,CAAG,CAAE,CAAS,EAG1C,IAAM,EAAa,GAAY,EAAI,GAAG,EAEtC,GAAI,CAAC,EACD,OAAO,EAAI,CADE,EAGjB,AAFkB,QAEX,EAAW,MAAM,CACxB,GAAoB,EAAW,KAAK,CAAE,GACtC,EAAI,GAAG,CGXJ,AHWO,SGXE,AAAU,CAAM,EAC5B,GAAI,MAAE,CAAI,UAAE,CAAQ,CAAE,CAAG,EACrB,EAAW,EAAO,QAAQ,EAAI,GAC9B,EAAW,EAAO,QAAQ,EAAI,GAC9B,EAAO,EAAO,IAAI,EAAI,GACtB,EAAQ,EAAO,KAAK,EAAI,GACxB,EAAO,GACX,EAAO,EAAO,mBAAmB,GAAM,OAAO,CAAC,OAAQ,KAAO,IAAM,GAChE,EAAO,IAAI,CACX,CADa,CACN,EAAO,EAAO,IAAI,CAClB,IACP,EAAO,GAAQ,CADE,AACD,EAAS,CAAX,MAAkB,CAAC,KAAO,CAAC,CAAC,EAAE,EAAS,CAAC,CAAC,CAAG,CAAA,CAAQ,CAC9D,EAAO,IAAI,EAAE,CACb,GAAQ,IAAM,EAAO,IAAA,AAAI,GAG7B,GAA0B,UAAjB,AAA2B,OAApB,IAChB,EAAQ,OAAO,GAAmC,GAAA,EAEtD,IAAI,EAAS,EAAO,MAAM,EAAI,GAAS,CAAC,CAAC,EAAE,EAAA,CAAO,EAAI,GAYtD,OAXI,GAAY,CAAC,EAAS,QAAQ,CAAC,OAAM,GAAY,GAAA,EACjD,EAAO,OAAO,EAAI,AAAC,EAAC,GAAY,GAAiB,IAAI,CAAC,EAAA,CAAS,GAAc,IAAT,GAAgB,AACpF,EAAO,MAAQ,CAAD,EAAS,EAAA,CAAE,CACrB,GAA4B,MAAhB,CAAQ,CAAC,EAAE,GAAU,EAAW,IAAM,CAAA,GAC9C,AAAD,IACP,EAAO,AADO,EACP,EAEP,GAAoB,MAAZ,CAAI,CAAC,EAAE,GAAU,EAAO,IAAM,CAAA,EACtC,GAAwB,MAAd,CAAM,CAAC,EAAE,GAAU,EAAS,IAAM,CAAA,EAChD,EAAW,EAAS,OAAO,CAAC,QAAS,oBACrC,EAAS,EAAO,OAAO,CAAC,IAAK,OACtB,CAAA,EAAG,EAAA,EAAW,EAAA,EAAO,EAAA,EAAW,EAAA,EAAS,EAAA,CACpD,AAD0D,EHpBlC,GACxB,EAoP2D,EAAK,GACxD,uBAAwB,CAAC,EAAU,IAAS,CApP7C,SAAS,AAAuB,CAAQ,CAAE,CAAM,CAAE,CAAiB,EACtE,GAAI,CAAC,EAAmB,OAAO,EAC/B,IAAK,IAAM,KAAS,OAAO,IAAI,CAAC,EAAkB,MAAM,EAAE,CACtD,IAKI,EALE,UAAE,CAAQ,QAAE,CAAM,CAAE,CAAG,EAAkB,MAAM,CAAC,EAAM,CACxD,EAAa,CAAC,CAAC,EAAE,EAAS,MAAQ,GAAA,EAAK,EAAM,CAAC,CAAC,CAC/C,IACA,EAAa,CAAC,CAAC,EADL,AACO,EAAW,CAAC,CAAC,EAGlC,IAAM,EAAQ,CAAM,CAAC,EAAM,EAQvB,CANA,EADA,MAAM,OAAO,CAAC,GACD,EAAM,GAAG,CADA,AACC,AAAC,GAAI,GAAK,mBAAmB,IAAI,IAAI,CAAC,KACtD,EACM,MADC,aACkB,GAEnB,KAEC,CAAA,GAAU,CACxB,EAAW,EAAS,UAAU,CAAC,EAAY,EAAA,CAEnD,CACA,OAAO,CACX,GA8N2E,EAAU,EAAQ,GACrF,oBAAqB,CAAC,EAAO,IAAY,GAAoB,EAAO,EACxE,CACJ,CACO,SAAS,GAA6B,CAAO,CAAE,CAAa,EAC/D,MAA8D,UAAvD,OAAO,CAAO,CAAC,EAAmC,EAAiB,CAAO,CAAC,EAAuC,GAAK,EAAgB,CAAO,CAAC,EAAmC,CAAC,KAAK,CAAC,KAAO,EAAE,AAC7M,EAEA,wCAAwC,iCC1QjC,OAAM,GACT,QAAO,CAAA,AAAE,CAAG,IAAI,CAAC,KAAK,CAAG,CAAC,CAAC,QAAQ,GAAG,CAAC,wBAAwB,AAAC,AAChE,aAAY,IAAE,CAAE,KAAE,CAAG,aAAE,CAAW,CAAE,aAAW,CAAE,eAAa,gBAAE,CAAc,oBAAE,CAAkB,CAAE,sBAAoB,qBAAE,CAAmB,iBAAE,CAAe,6BAAE,CAA2B,CAAE,CAAC,KACtL,EAAiC,EA4C7B,EAAkC,EA3C1C,IAAI,CAAC,KAAK,CAAG,IAAI,IACjB,IAAI,CAAC,qBAAqB,EAAG,CAAQ,EACrC,MAAM,EAAsB,OAAO,GAAG,CAAC,wBACjC,EAAc,WACpB,GAAK,CAAD,CAgBO,GAAiB,KAAK,EAAE,AAC/B,QAAQ,GAAG,CAAC,+CAAgD,EAAgB,IAAI,MAjB9D,CAElB,MAAM,EAAqB,CAAW,CAAC,EAAoB,EACjC,MAAtB,EAA6B,KAAK,EAAI,EAAmB,UAAA,AAAU,EAAE,CACrE,EAAkB,EAAmB,UAAU,CAC3C,GAAiB,KAAK,EAAE,AACxB,QAAQ,GAAG,CAAC,4DAGZ,GAAM,IACF,GAAiB,KAAK,EAAE,AACxB,CAFiB,OAET,GAAG,CAAC,oDAEhB,EAAkB,GAG9B,CAGI,MAHG,EAGK,GAAG,CAAC,yBAAyB,EAAE,CAEvC,EAAqB,SAAS,QAAQ,GAAG,CAAC,yBAAyB,CAAE,GAAA,EAEzE,IAAI,CAAC,GAAG,CAAG,EACX,IAAI,CAAC,kBAAkB,CAA2C,SAAxC,QAAQ,GAAG,CAAC,uBAAuB,CAI7D,IAAI,CADmB,AAClB,WAAe,CAAG,EACvB,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,2BAA2B,CAAG,EACnC,IAAI,CAAC,iBAAiB,CAAG,IACzB,IAAI,CAAC,aAAa,CAAG,IAAI,GAAoB,IAAI,CAAC,iBAAiB,EACnE,IAAI,CAAC,mBAAmB,CAAG,EAC3B,IAAI,EAAkB,EAAE,CACpB,CAAc,CAAC,EAA4B,IAA4D,CAAvD,CAAC,KAAC,AAA4D,EAAlC,GAAuC,CAAnC,CAAC,iBAAA,AAAiB,GAA4F,AAAvE,OAAC,EAAkC,EAAwB,OAAA,AAAO,EAAY,KAAK,EAAI,EAAgC,aAAa,GAAG,CAC9P,IAAI,CAAC,oBAAoB,EAAG,CAAA,EAE5B,IAEA,EAAkB,IAAI,CAAC,EAFV,aAEyB,CAAG,GAA6B,EAAuE,OAAtD,AAA6D,EAAlC,GAAuC,CAAnC,CAAC,AAAjC,iBAAkD,AAAjB,GAA+G,AAAzE,MAAC,GAAmC,EAAyB,OAAA,AAAO,EAAY,KAAK,EAAI,EAAiC,cAAa,EAEpS,IACA,IAAI,CAAC,QADY,IACA,CAAG,IAAI,EAAgB,KACpC,EACA,KACA,4BACA,kBACA,qBACA,EACA,gBAAiB,sBACjB,CACJ,EAAA,CAER,CACA,oBAAoB,CAAQ,CAAE,CAAQ,CAAE,CAAG,CAAE,CAAU,CAAE,CAGrD,GAAI,EAAK,OAAO,KAAK,KAAK,CAAC,YAAY,UAAU,CAAG,YAAY,GAAG,GAAK,KACxE,IAAM,EAAe,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,GAAQ,IAG9C,EAA2B,EAAe,EAAa,UAAU,EAAG,GAAqB,EAE/F,MAD4D,AAApC,CACjB,CAFgF,eACxD,EAAmE,IAA3B,EAAkC,EAAW,CAExH,CACA,aAAa,CAAQ,CAAE,CAAU,CAAE,CAC/B,OAAO,EAAa,EAAW,GAAkB,EACrD,CACA,mBAAoB,CAChB,IAAI,EAAsC,CAC1C,AAA4C,OAAO,CAAlD,EAAqB,EAAkC,EAA9B,CAAC,YAAA,AAAY,GAAqB,AAAiF,OAAO,AAAvF,EAAuC,EAAmB,CAAkC,gBAAjB,AAAjB,GAAsC,EAAqC,IAAI,CAAC,EAC3M,CACA,MAAM,KAAK,CAAQ,CAAE,CAGjB,MAAM,CAAK,CACP,IAAM,EAAO,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,GAK5B,GAJI,GAAiB,KAAK,EAAE,AACxB,QAAQ,GAAG,CAAC,6BAA8B,EAAU,CAAC,CAAC,GAGtD,CAAC,EAAM,KAEX,OAAM,CACV,CAGA,GAAM,SAAE,CAAO,SAAE,CAAO,CAAE,CAAG,IAAI,GAMjC,OALI,GAAiB,KAAK,EACtB,AADwB,QAChB,GAAG,CAAC,wCAAyC,GAGzD,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,EAAU,GAClB,KAEH,IAGA,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,EACtB,CACJ,CACA,MAAM,cAAc,CAAI,CAAE,CAAS,CAAE,CACjC,IAAI,EACJ,OAAmD,AAA5C,OAAC,EAAqB,IAAI,CAAC,YAAA,AAAY,EAAY,KAAK,EAAI,EAAmB,aAAa,CAAC,EAAM,EAC9G,CAEA,MAAM,iBAAiB,CAAG,CAAE,EAAO,CAAC,CAAC,CAAE,CAInC,IAAM,EAAa,EAAE,CACf,EAAU,IAAI,YACd,EAAU,IAAI,YACpB,GAAI,EAAK,IAAI,CAET,CAFW,EAEP,EAAK,IAAI,YAAY,WACrB,CADiC,CACtB,IAAI,CAAC,EAAQ,MAAM,CAAC,EAAK,IAAI,GACxC,EAAK,OAAO,CAAG,EAAK,IAAI,MACrB,GAAmC,YAA/B,OAAO,EAAK,IAAI,CAAC,SAAS,CAAiB,CAClD,IAAM,EAAe,EAAK,IAAI,CACxB,EAAS,EAAE,CACjB,GAAI,CACA,MAAM,EAAa,MAAM,CAAC,IAAI,eAAe,CACzC,MAAO,CAAK,EACJ,AAAiB,UAAU,OAApB,GACP,EAAO,IAAI,CAAC,EAAQ,MAAM,CAAC,IAC3B,EAAW,IAAI,CAAC,KAEhB,EAAO,IAAI,CAAC,GACZ,EAAW,IAAI,CAAC,EAAQ,MAAM,CAAC,EAAO,CAClC,QAAQ,CACZ,IAER,CACJ,IAEA,EAAW,IAAI,CAAC,EAAQ,MAAM,IAE9B,IAAM,EAAS,EAAO,MAAM,CAAC,CAAC,EAAO,IAAM,EAAQ,EAAI,MAAM,CAAE,GACzD,EAAc,IAAI,WAAW,GAE/B,EAAS,EACb,IAAK,IAAM,KAAS,EAChB,EAAY,GAAG,AADQ,CACP,EAAO,GACvB,GAAU,EAAM,MAAM,CAG1B,EAAK,OAAO,CAAG,CACnB,CAAE,MAAO,EAAK,CACV,QAAQ,KAAK,CAAC,uBAAwB,EAC1C,CACJ,MAAO,GAA8B,YAA1B,OAAO,EAAK,IAAI,CAAC,IAAI,CAAiB,CAC7C,IAAM,EAAW,EAAK,IAAI,CAE1B,IAAK,IAAM,KADX,EAAK,OAAO,CAAG,EAAK,IAAI,CACN,IAAI,IAAI,IACnB,EAAS,IAAI,GACnB,GAAE,CACC,IAAM,EAAS,EAAS,MAAM,CAAC,GAC/B,EAAW,IAAI,CAAC,CAAA,EAAG,EAAI,CAAC,EAAE,CAAC,MAAM,QAAQ,GAAG,CAAC,EAAO,GAAG,CAAC,MAAO,GAC3D,AAAI,AAAe,UAAU,OAAlB,EACA,EAEA,MAAM,EAAI,IAAI,IAE7B,CAAG,CAAE,IAAI,CAAC,KAAA,CAAM,CACpB,CAEJ,MAAO,GAAqC,YAAjC,OAAO,EAAK,IAAI,CAAC,WAAW,CAAiB,CACpD,IAAM,EAAO,EAAK,IAAI,CAChB,EAAc,MAAM,EAAK,WAAW,GAC1C,EAAW,IAAI,CAAC,MAAM,EAAK,IAAI,IAC/B,EAAK,OAAO,CAAG,IAAI,KAAK,CACpB,EACH,CAAE,CACC,KAAM,EAAK,IAAI,AACnB,EACJ,KAAgC,EAAzB,QAAI,AAA+B,OAAxB,EAAK,IAAI,GACvB,EAAW,IAAI,CAAC,EAAK,IAAI,EACzB,EAAK,OAAO,CAAG,EAAK,IAAI,EAGhC,IAAM,EAA+C,YAArC,MAAO,CAAC,EAAK,OAAO,EAAI,CAAC,CAAC,EAAE,IAAI,CAAkB,OAAO,WAAW,CAAC,EAAK,OAAO,EAAI,OAAO,MAAM,CAAC,CAAC,EAAG,EAAK,OAAO,CAG/H,iBAAiB,GAAS,OAAO,EAAQ,KAAD,MAAe,CACvD,eAAgB,GAAS,OAAO,EAAQ,KAAD,KAAc,CACzD,IAAM,EAAc,KAAK,SAAS,CAAC,CA7EX,KA+EpB,IAAI,CAAC,mBAAmB,EAAI,GAC5B,EACA,EAAK,MAAM,CACX,EACA,EAAK,IAAI,CACT,EAAK,QAAQ,CACb,EAAK,WAAW,CAChB,EAAK,QAAQ,CACb,EAAK,cAAc,CACnB,EAAK,SAAS,CACd,EAAK,KAAK,CACV,EACH,CACwC,QAIrC,IAAM,EAAS,EAAQ,MAAM,CAAC,GAC9B,OAAO,AAJc,EAIF,IAJQ,EAIF,OAAO,MAAM,CAAC,MAAM,CAAC,UAAW,GAH9C,MAAM,SAAS,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,WAAW,GAAS,AAAC,GAAI,EAAE,QAAQ,CAAC,IAAI,QAAQ,CAAC,EAAG,MAAM,IAAI,CAAC,GAI3G,CAIJ,CACA,MAAM,IAAI,CAAQ,CAAE,CAAG,CAAE,KACjB,EAAoB,EAiChB,EAKI,EAwEJ,EAAmB,EAQf,MAdR,EACA,EAtGJ,GAAI,EAAI,IAAI,GAAK,GAAqB,KAAK,CAAE,CACzC,IAAM,EAAgB,GAAqB,QAAQ,GAC7C,EAAkB,EAAgB,GAAyB,GAAiB,KAClF,GAAI,EAAiB,CACjB,IAAM,EAAkB,EAAgB,KAAK,CAAC,GAAG,CAAC,GAClD,GAAI,CAAoB,MAAnB,EAA0B,KAAK,EAAI,EAAgB,IAAI,AAAJ,IAAU,GAAgB,KAAK,CAInF,CAJqF,MACjF,GAAiB,KAAK,EAAE,AACxB,QAAQ,GAAG,CAAC,4BAA6B,GAEtC,CACH,QAAS,GACT,MAAO,CACX,EACO,GAAiB,KAAK,EAC7B,AAD+B,QACvB,GAAG,CAAC,6BAA8B,EAElD,MACQ,CADD,EACkB,KAAK,EACtB,AADwB,QAChB,GAAG,CAAC,uCAGxB,CAGA,GAAI,IAAI,CAAC,kBAAkB,EAAI,IAAI,CAAC,GAAG,GAAK,CAAD,CAAK,IAAI,GAAK,GAAqB,KAAK,EAA6C,aAAzC,IAAI,CAAC,cAAc,CAAC,gBAAgB,AAAK,CAAU,CACtI,EADyI,KAClI,KAEX,EAAW,IAAI,CAAC,YAAY,CAAC,EAAU,EAAI,IAAI,GAAK,GAAqB,KAAK,EAC9E,IAAM,EAAY,MAAM,CAAC,AAA4C,OAA3C,EAAqB,IAAI,CAAC,YAAA,AAAY,EAAY,KAAK,EAAI,EAAmB,GAAG,CAAC,EAAU,EAAA,CAAI,CAC1H,GAAI,EAAI,IAAI,GAAK,GAAqB,KAAK,CAAE,CAEzC,GAAI,CAAC,EACD,OAAO,EADK,GAGhB,GAAI,CAAC,AAAyC,OAAxC,EAAoB,EAAU,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,AAAJ,IAAU,GAAgB,KAAK,CAE3G,CAF6G,KAEvG,OAAO,cAAc,CAAC,IAAI,EAAe,CAAC,oCAAoC,EAAE,KAAK,SAAS,CAAC,GAAU,2BAA2B,EAAE,KAAK,SAAS,CAA0C,AAAzC,OAAC,EAAoB,EAAU,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,EAAE,SAAS,CAAC,EAAG,oBAAqB,CAC1Q,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAM,EAAY,EAAiB,QAAQ,GACrC,EAAe,IACd,EAAI,IAAI,EAAI,EAAE,IACd,EAAI,QAAQ,EAAI,EAAE,CACxB,CAED,GAAI,EAAa,IAAI,CAAC,AAAC,IACnB,IAAI,EAAuB,EAC3B,MAAO,CAAC,AAAkD,OAAjD,EAAwB,IAAI,CAAC,eAAA,AAAe,EAAY,KAAK,EAAI,EAAsB,QAAQ,CAAC,EAAA,CAAI,GAAmB,EAAd,IAAC,CAAoB,EAAmF,AAA1E,GAAJ,GAAK,GAAoC,EAAU,sBAAA,AAAsB,EAAY,KAAK,EAAI,EAAkC,IAAI,CAAE,AAAD,GAAQ,EAAK,GAAG,GAAK,GAC1S,CAD8S,EAK1S,CAJA,MACI,GAAiB,KAAK,EACtB,AADwB,QAChB,GAAG,CAAC,gCAAiC,GAE1C,KAUX,IAAM,EAAgB,GAAqB,QAAQ,GACnD,GAAI,EAAe,CACf,IAAM,EAA2B,GAA4B,GACzD,IACI,GAAiB,KAAK,EAAE,AACxB,QAAQ,GAAG,CAFW,AAEV,4BAA6B,GAE7C,EAAyB,KAAK,CAAC,GAAG,CAAC,EAAU,EAAU,KAAK,EAEpE,CACA,IAAM,EAAa,EAAI,UAAU,EAAI,EAAU,KAAK,CAAC,UAAU,CAE3D,EADS,AACC,aADW,UAAU,CAAG,YAAY,GAAG,IAAM,CAAD,CAAW,YAAY,GAAI,CAAC,CAAC,CAAI,IACvE,EACd,EAAO,EAAU,KAAK,CAAC,IAAI,QACjC,AAAI,GAAe,EAAc,EAAU,YAAY,EAC5C,CAD+C,KAE/C,GAAa,EAAc,EAAU,YAAY,GAAG,CAC3D,GAAU,CAAA,EAEP,SACH,EACA,MAAO,CACH,KAAM,GAAgB,KAAK,CAC3B,OACA,YACJ,CACJ,EACJ,CAAO,GAAI,CAAc,MAAb,CAAoB,EAAS,AAAwC,GAA5C,IAAK,EAAmB,EAAU,KAAA,AAAK,EAAY,KAAK,EAAI,EAAiB,IAAI,IAAM,GAAgB,KAAK,CAC7I,CAD+I,KACzI,OAAO,cAAc,CAAC,IAAI,EAAe,CAAC,oCAAoC,EAAE,KAAK,SAAS,CAAC,GAAU,aAAa,EAAE,KAAK,SAAS,CAAC,EAAI,IAAI,EAAE,2BAA2B,CAAC,EAAG,oBAAqB,CACvM,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAI,EAAQ,KACN,EAAe,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,GAAQ,IAGpD,GAAI,CAAc,MAAb,EAAoB,KAAK,EAAI,EAAU,YAAA,AAAY,IAAM,CAAC,EAC3D,CAD8D,CACpD,CAAC,EACX,EAAkB,CAAC,IAAI,QACpB,CAEH,IAAM,EAAM,YAAY,UAAU,CAAG,YAAY,GAAG,GAC9C,EAAe,CAAc,MAAb,EAAoB,KAAK,EAAI,EAAU,YAAA,AAAY,GAAK,EAK9E,GAAI,KAAY,IAHhB,GAAU,CAAoB,IAD9B,CAI6B,EAJX,IAAI,CAAC,mBAAmB,CAAC,EAAU,EAAc,IAAI,CAAC,GAAG,GAAI,EAAO,EAAI,WAAU,GAC7D,EAAkB,MAAM,EAAO,CAAA,IAGxC,CAAc,MAAb,CAAoB,EAAS,AAAyC,GAA7C,IAAK,EAAoB,EAAU,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,IAAM,GAAgB,QAAQ,EAAI,CAAc,MAAb,CAAoB,EAAkD,AAAzC,GAAJ,IAAK,EAAoB,EAAU,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,IAAM,GAAgB,SAAA,AAAS,EAAG,CAExT,IAAM,EAAa,AAAwD,OAAvD,EAA2B,EAAU,KAAK,CAAC,OAAA,AAAO,EAAY,KAAK,EAAI,CAAwB,CAAC,EAAuB,CAC3I,GAA0B,UAAtB,OAAO,EAAyB,CAChC,IAAM,EAAY,EAAW,KAAK,CAAC,KAC/B,EAAU,MAAM,CAAG,GAAG,CAClB,GAAe,EAAW,GAC1B,EAAU,CAAC,EACJ,GAAa,EAAW,EAFU,GAGzC,GAAU,CAAA,EAGtB,CACJ,CACJ,CA0BA,CAhCkE,MAO9D,IACA,EAAQ,KADG,IAEP,eACA,kBACA,EACA,MAAO,EAAU,KAAK,CAC1B,EAEA,CAAC,GAAa,IAAI,CAAC,iBAAiB,CAAC,cAAc,CAAC,QAAQ,CAAC,KAM7D,EAAQ,IANgE,KAOpE,EACA,MAAO,kBACP,EACA,iBACJ,EACA,IAAI,CAAC,GAAG,CAAC,EAAU,EAAM,KAAK,CAAE,CAC5B,GAAG,CAAG,cACN,CACJ,IAEG,CACX,CACA,MAAM,IAAI,CAAQ,CAAE,CAAI,CAAE,CAAG,CAAE,CAM3B,GAAI,CAAS,MAAR,EAAe,KAAK,EAAI,EAAK,IAAA,AAAI,IAAM,GAAgB,KAAK,CAAE,CAC/D,IAAM,EAAgB,GAAqB,QAAQ,GAC7C,EAA2B,EAAgB,GAA4B,GAAiB,KAC1F,IACI,GAAiB,KAAK,EAAE,AACxB,QAAQ,GAAG,CAFW,AAEV,4BAA6B,GAE7C,EAAyB,KAAK,CAAC,GAAG,CAAC,EAAU,GAErD,CACA,GAAI,IAAI,CAAC,kBAAkB,EAAI,IAAI,CAAC,GAAG,EAAI,CAAC,EAAI,UAAU,CAAE,OAC5D,EAAW,IAAI,CAAC,YAAY,CAAC,EAAU,EAAI,UAAU,EAErD,IAAM,EAAW,KAAK,SAAS,CAAC,GAAM,MAAM,CAC5C,GAAI,EAAI,UAAU,EAAI,EAAW,IAAI,KAErC,CAAC,CAF2C,GAEvC,CAAC,IAF8C,iBAEzB,EAE3B,CAAC,CAF8B,CAE1B,wBAAwB,CAAE,CAC3B,IAAM,EAAc,CAAC,mBALqG,iBAEzB,CAGvC,EAAE,EAAI,QAAQ,EAAI,EAAS,oCAAoC,EAAE,EAAS,OAAO,CAAC,CAC5I,GAAI,IAAI,CAAC,GAAG,CACR,CADU,KACJ,OAAO,cAAc,CAAC,AAAI,MAAM,GAAc,oBAAqB,CACrE,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,GAEJ,QAAQ,IAAI,CAAC,GACb,MACJ,CACA,GAAI,CACA,IAAI,CACA,EAAC,EAAI,UAAU,EAAI,EAAI,YAAY,EAAE,AACrC,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,GAAQ,GAAW,EAAI,YAAY,EAE9D,MAAM,AAAC,CAA4C,MAA3C,GAAqB,IAAI,CAAC,YAAA,AAAY,EAAY,KAAK,EAAI,EAAmB,GAAG,CAAC,EAAU,EAAM,EAAA,CAAI,AAClH,CAAE,MAAO,EAAO,CACZ,QAAQ,IAAI,CAAC,uCAAwC,EAAU,EACnE,CACJ,CACJ,EAEA,iCAAiC,IhFnc1B,IAAI,IACP,CADmD,EAKrD,CAAC,EAJmB,CAAC,CAMvB,CAN0C,QAAW,AADrB,CACwB,CADiB,GACb,CAAG,EAAtB,GADE,GAAG,GAE1C,CAAkB,CAAC,EAAmB,gBAAD,CAAqB,CAKd,AALiB,IAAI,CAAG,oBACpE,CAAkB,CAAC,EAAmB,gBAAD,CAAqB,CAAG,IAAI,CAAG,oBAC7D,4CjBiBX,IAAA,GAAA,EAAA,CAAA,CAAA,OCrBA,IAAM,GAAqB,sBACpB,OAAM,WAA2B,MACpC,YAAY,CAAW,CAAC,CACpB,KAAK,CAAC,CAAC,sBAAsB,EAAE,EAAA,CAAa,EAAG,IAAI,CAAC,WAAW,CAAG,EAAa,IAAI,CAAC,MAAM,CAAG,EACjG,CACJ,CACO,SAAS,GAAqB,CAAG,QACpC,AAAmB,UAAf,OAAO,GAA4B,OAAR,CAAgB,CAAC,CAAC,WAAY,GAAG,AAA2B,UAAU,AAAhC,OAAO,EAAI,MAAM,EAG/E,EAAI,MAAM,GAAK,EAC1B,EAEA,gDAAgD,qBCZzC,OAAM,WAA8B,MACvC,YAAY,GAAG,CAAI,CAAC,CAChB,KAAK,IAAI,GAAO,IAAI,CAAC,IAAI,CAHD,EAGI,uBAChC,CACJ,4CiBEA,OAAM,WAAqC,MACvC,YAAY,CAAK,CAAE,CAAU,CAAC,CAC1B,KAAK,CAAC,CAAC,qBAAqB,EAAE,EAAW,qGAAqG,EAAE,EAAW,8KAA8K,EAAE,EAAM,EAAE,CAAC,EAAG,IAAI,CAAC,KAAK,CAAG,EAAO,IAAI,CAAC,UAAU,CAAG,EAAY,IAAI,CAAC,MAAM,CAH1X,EAG6X,yBAC3Z,CACJ,CACA,IAAM,GAAyB,IAAI,QAOxB,SAAS,GAAmB,CAAM,CAAE,CAAK,CAAE,CAAU,EAC5D,GAAI,EAAO,OAAO,CACd,CADgB,MACT,QAAQ,MAAM,CAAC,IAAI,GAA6B,EAAO,GAC3D,EACH,IAAM,EAAiB,IAAI,QAAQ,CAAC,EAAG,KACnC,IAAM,EAAiB,EAAO,IAAI,CAAC,KAAM,IAAI,GAA6B,EAAO,IAC7E,EAAmB,GAAuB,GAAG,CAAC,GAClD,GAAI,EACA,EAAiB,IAAI,CAAC,OACnB,CACH,CAHkB,GAGZ,EAAY,CACd,EACH,CACD,GAAuB,GAAG,CAAC,EAAQ,GACnC,EAAO,gBAAgB,CAAC,QAAS,KAC7B,IAAI,IAAI,EAAI,EAAG,EAAI,EAAU,MAAM,CAAE,IAAI,AACrC,CAAS,CAAC,EAAE,EAEpB,EAAG,CACC,MAAM,CACV,EACJ,CACJ,GAKA,OADA,EAAe,KAAK,CAAC,IACd,CACX,CACJ,CACA,SAAS,KAAgB,CAClB,SAAS,GAA2B,CAAU,CAAE,CAAY,CAAE,CAAK,SACtE,AAAI,EAAa,eAAe,CAErB,CAFuB,CAEV,eAAe,CAAC,eAAe,CAAC,OAAO,EAAW,GAInE,IAAI,QAAS,AAAD,IAEf,WAAW,KACP,EAAQ,EACZ,EAAG,EACP,EACJ,ChBxDsH,CgB0DtH,QhB1D+H,GAAoB,CAAG,QAClJ,AAAmB,UAAf,OAAO,GAAoB,AAAQ,QAAQ,CAAC,CAAC,CgByDF,UhBzDc,GAP1C,AAO6C,GAAG,kCAG5D,EAAI,MAAM,AACrB,EAEA,GAH0B,uCAGgB,4EHiB1C,IAAM,GAAiD,YAAnC,OAAO,GAAA,OAAK,CAAC,iBAAiB,CAC3C,SAAS,GAA2B,CAAsB,EAC7D,MAAO,CACH,yBACA,gBAAiB,EAAE,CACnB,0BAA2B,IAC/B,CACJ,CAWO,SAAS,GAAsB,CAAa,EAC/C,IAAI,EACJ,OAA+E,AAAxE,OAAC,EAAkC,EAAc,eAAe,CAAC,EAAA,AAAE,EAAY,KAAK,EAAI,EAAgC,UAAU,AAC7I,CAOW,SAAS,GAA0B,CAAK,CAAE,CAAa,CAAE,CAAU,EAC1E,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,QACL,IAAK,iBAML,IAAK,gBADD,MAUR,CAKJ,GAAI,GAAM,YAAY,GAAI,EAAM,WAAW,EAAE,AAC7C,GAAI,EAAM,kBAAkB,CACxB,CAD0B,KACpB,OAAO,cAAc,CAAC,IAAI,GAAsB,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,8EAA8E,EAAE,EAAW,4HAA4H,CAAC,EAAG,oBAAqB,CACvT,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,gBACD,OAAO,GAAqB,EAAM,KAAK,CAAE,EAAY,EAAc,eAAe,CACtF,KAAK,mBACD,EAAc,UAAU,CAAG,EAG3B,IAAM,EAAM,OAAO,cAAc,CAAC,IAAI,GAAmB,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,iDAAiD,EAAE,EAAW,2EAA2E,CAAC,EAAG,oBAAqB,CAC5O,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,EAGA,OAFA,EAAM,uBAAuB,CAAG,EAChC,EAAM,iBAAiB,CAAG,EAAI,KAAK,CAC7B,CAQd,EAER,CAMW,SAAS,GAAiC,CAAU,CAAE,CAAK,CAAE,CAAc,EAElF,IAAM,EAAM,OAAO,cAAc,CAAC,IAAI,GAAmB,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,mDAAmD,EAAE,EAAW,6EAA6E,CAAC,EAAG,oBAAqB,CAChP,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAIA,OAHA,EAAe,UAAU,CAAG,EAC5B,EAAM,uBAAuB,CAAG,EAChC,EAAM,iBAAiB,CAAG,EAAI,KAAK,CAC7B,CACV,CAsEW,SAAS,GAA4C,CAAK,CAAE,CAAU,CAAE,CAAc,CAAE,CAAc,EAE7G,IAAgC,IADR,AACpB,EADmC,UAAU,CAAC,MAAM,CACpC,OAAO,CAAY,OAlCjC,EAFA,EAAQ,GADC,CAAC,MAAM,EA2CkB,AA3ChB,EAAM,kBACgB,+CADiD,EAAE,EAAW,CAAC,CAAC,EAE9G,EAAe,UAAU,CAAC,KAAK,CAAC,GAE5B,GADoB,AAwCmC,EAxCpB,YAClB,GADiC,GAElD,EAAgB,eAAe,CAAC,IAAI,CAAC,CAGjC,MAAO,EAAgB,sBAAsB,CAAG,AAAI,QAAQ,KAAK,MAAG,EACpE,WAkCuC,CAjC3C,GAsCA,IAAM,EAAkB,EAAe,eAAe,CAClD,GACkD,MAAM,CAApD,EAAgB,KADH,oBAC4B,GACzC,EAAgB,yBAAyB,CAAG,CAAA,CAGxD,CACA,MAAM,GAAgC,CAAC,MAAM,EAAE,EAAM,iEAAiE,EAAE,EAAW,CAAC,CAAC,CACzI,CAMO,SAAS,GAAqB,CAAK,CAAE,CAAU,CAAE,CAAe,EACnE,AA4EJ,SAAS,GACL,GAAI,CAAC,GACD,MAAM,IADQ,GACD,cAAc,CAAC,AAAI,MAAM,CAAC,gIAAgI,CAAC,EAAG,oBAAqB,CAC5L,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAER,IAnFQ,GACA,EAAgB,YADC,GACc,CAAC,IAAI,CAAC,CAGjC,MAAO,EAAgB,sBAAsB,CAAG,AAAI,QAAQ,KAAK,MAAG,aACpE,CACJ,GAEJ,GAAA,OAAK,CAAC,iBAAiB,CAAC,GAAqB,EAAO,GACxD,CACA,SAAS,GAAqB,CAAK,CAAE,CAAU,EAC3C,MAAO,CAAC,MAAM,EAAE,EAAM,iEAAiE,EAAE,EAAW,kKAAE,CAAC,AAC3G,CAUA,EAX8G,CAW1G,AAX2G,CAW3C,KAFzD,EAEgE,CAA/C,GAAqB,MAAO,QAFtC,QAAQ,CAAC,4CATmK,CAAC,GAAG,CAAC,mBASlG,EAAO,QAAQ,CAAC,mDATmK,CAAC,YASpK,EAG7G,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,0FAA2F,oBAAqB,CAClJ,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAM,GAA6B,6BACnC,SAAS,GAAgC,CAAO,EAC5C,IAAM,EAAQ,OAAO,cAAc,CAAC,AAAI,MAAM,GAAU,oBAAqB,CACzE,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEA,OADA,EAAM,MAAM,CAAG,GACR,CACX,CACO,SAAS,GAA4B,CAAK,EAC7C,MAAwB,UAAjB,OAAO,GAAgC,OAAV,GAAkB,EAAM,MAAM,GAAK,IAA8B,SAAU,GAAS,YAAa,GAAS,aAAiB,KACnK,CAkcO,SAAS,GAAuB,CAAc,CAAE,CAAM,SACzD,AAAI,EAAe,mBAAmB,CAC3B,CAD6B,CACd,mBAAmB,CAAC,IAAI,CAAC,IAAI,GAEhD,CACX,CAvOkE,AAAI,CAyOtE,MAzO6E,CAAC,sCAyOjC,iBAzOwF,EAAE,oBAAoB,yCAAyC,EAAE,0BAA0B,cAAc,+DAAC,EACtN,AAAI,OAAO,CAAC,UAAU,EAAE,uBAAuB,QAAQ,EAAC,EACpD,AAAJ,OAAW,CAAC,UAAU,EAAE,uBAAuB,QAAQ,EAAC,EACtD,AAAJ,OAAW,CAAC,UAAU,EAAE,qBAAqB,QAAQ,EAAC,uTIpf7E,IAAM,GAAO,KAAK,EAqBP,SAAS,GAAc,CAAQ,EAGtC,GAAI,CAAC,EAAS,IAAI,CACd,CADgB,KACT,CACH,EACA,EACH,CAEL,GAAM,CAAC,EAAO,EAAM,CAAG,EAAS,IAAI,CAAC,GAAG,GAClC,EAAU,IAAI,SAAS,EAAO,CAChC,OAAQ,EAAS,MAAM,CACvB,WAAY,EAAS,UAAU,CAC/B,QAAS,EAAS,OAAO,AAC7B,GACA,OAAO,cAAc,CAAC,EAAS,MAAO,CAClC,MAAO,EAAS,GAAG,CAEnB,cAAc,EACd,YAAY,EACZ,UAAU,CACd,GAcI,GAAY,EAAQ,IAAI,EAAE,AAC1B,EAAS,QAAQ,CAAC,EAAS,IAAI,QAAQ,EAAQ,IAAI,GAEvD,IAAM,EAAU,IAAI,SAAS,EAAO,CAChC,OAAQ,EAAS,MAAM,CACvB,WAAY,EAAS,UAAU,CAC/B,QAAS,EAAS,OAAO,AAC7B,GAQA,OAPA,OAAO,cAAc,CAAC,EAAS,MAAO,CAClC,MAAO,EAAS,GAAG,CAEnB,cAAc,EACd,YAAY,EACZ,UAAU,CACd,GACO,CACH,EACA,EACH,AACL,CAzEI,CA2EJ,UA3Ee,oBAAoB,EAAE,CACjC,EAAW,IAAI,GA0EuB,kBA1EF,AAAC,IACjC,IAAM,EAAS,EAAQ,KAAK,GACxB,GAAU,CAAC,EAAO,MAAM,EACxB,AAD0B,EACnB,MAAM,CAAC,8CAA8C,IAAI,CAAC,GAEzE,EAAA,EgECJ,IAAM,GAA6B,IAAI,IAAI,CACvC,cACA,aACH,EzBVM,IAAI,IACP,CAD4C,EAO9C,CAAC,EANY,CAAC,EAAY,CADH,EAAkC,GACtB,CAAG,EAAE,AAAf,CAAkB,EADT,GAAG,IAEnC,CAAW,CAAC,EAAY,MAAS,CAAG,EAAb,AAAe,CAAG,SACzC,CAAW,CAAC,EAAY,OAAU,CAAG,CAAd,CAAgB,CAAG,UAC1C,CAAW,CAAC,EAAY,OAAU,CAAG,CAAd,CAAgB,CAAG,UAC1C,CAAW,CAAC,EAAY,SAAD,AAAa,CAAG,EAAE,CAAG,YACrC,qCiDGJ,IAAM,GAAoB,OAAO,GAAG,CAAC,cA0D5C,SAAS,GAAiB,CAAS,CAAE,CAAG,EAC/B,EAAU,uBAAuB,EAAE,CAGxC,EAAU,YAAY,GAAK,EAAE,CAC7B,EAAU,YAAY,CAAC,IAAI,CAAC,CACxB,GAAG,CAAG,CACN,IAAK,YAAY,UAAU,CAAG,YAAY,GAAG,GAC7C,IAAK,EAAU,WAAW,EAAI,CAClC,GACJ,CACA,eAAe,GAA8B,CAAG,CAAE,CAAQ,CAAE,CAAuB,CAAE,CAAgB,CAAE,CAAU,CAAE,CAAY,EAI3H,IAAM,EAAa,MAAM,EAAI,WAAW,GAClC,EAAc,CAChB,QAAS,OAAO,WAAW,CAAC,EAAI,OAAO,CAAC,OAAO,IAC/C,KAAM,GAAA,MAAM,CAAC,IAAI,CAAC,GAAY,QAAQ,CAAC,UACvC,OAAQ,EAAI,MAAM,CAClB,IAAK,EAAI,GAAG,AAChB,EAYA,OATI,GACA,MAAM,EAAiB,GAAG,CAAC,EAAU,CACjC,KAAM,EAFe,CAEC,KAAK,CAC3B,KAAM,aACN,CACJ,EAAG,GAEP,MAAM,IAEC,IAAI,SAAS,EAAY,CAC5B,QAAS,EAAI,OAAO,CACpB,OAAQ,EAAI,MAAM,CAClB,WAAY,EAAI,UAAU,AAC9B,EACJ,CACA,eAAe,GAA4B,CAAS,CAAE,CAAG,CAAE,CAAQ,CAAE,CAAuB,CAAE,CAAgB,CAAE,CAAwB,CAAE,CAAU,CAAE,CAAK,CAAE,CAAY,EAIrK,GAAM,CAAC,EAAS,EAAQ,CAAG,GAAc,GAInC,EAAkB,EAAQ,WAAW,GAAG,IAAI,CAAC,MAAO,IACtD,IAAM,EAAa,GAAA,MAAM,CAAC,IAAI,CAAC,GACzB,EAAc,CAChB,QAAS,OAAO,WAAW,CAAC,EAAQ,OAAO,CAAC,OAAO,IACnD,KAAM,EAAW,QAAQ,CAAC,UAC1B,OAAQ,EAAQ,MAAM,CACtB,IAAK,EAAQ,GAAG,AACpB,CAC4B,OAA5B,AAAmC,GAAS,EAAJ,AAA6B,GAAG,CAAC,EAAU,GAC/E,GACA,MAAM,EAAiB,GAAG,CAAC,EAAU,CACjC,KAAM,EAFe,CAEC,KAAK,CAC3B,KAAM,aACN,CACJ,EAAG,EAEX,GAAG,KAAK,CAAC,AAAC,GAAQ,QAAQ,IAAI,CAAC,CAAC,yBAAyB,CAAC,CAAE,EAAO,IAAQ,OAAO,CAAC,GAC7E,EAAuB,CAAC,UAAU,EAAE,EAAA,CAAU,CAC9C,EAAqB,EAAU,kBAAkB,GAAK,CAAC,EACzD,EAA2B,QAAQ,OAAO,GAc9C,OAbI,KAAwB,IAGxB,EAA2B,CAAkB,CAAC,EAAA,AAAqB,EAEvE,CAAkB,CAAC,EAAqB,CAAG,EAAyB,CALpB,GAKwB,CAAC,IAAI,GAAiB,OAAO,CAAC,KAG5F,CAAsB,QAAO,KAAK,EAAI,CAAkB,CAAC,EAAA,AAAqB,GAAG,AAGvF,OAAO,CAAkB,CAAC,EAAqB,AACnD,GACO,CACX,CAouBO,SAAS,GAAW,CAAO,MxB11BA,QwB41B9B,IA/2ByC,AA+2BrC,CxB51BuC,GwBnBpC,UAAU,CAAC,GAAkB,CA+2Bd,OAGtB,IAAM,KAA6B,MAAlB,KAA6B,KAAK,CxB91B7C,EAAkB,GAAA,KAAW,CACnC,AAAC,GAAM,EAAE,EACF,SAAS,AAAY,CAAQ,CAAE,CAAO,MAYrC,EACA,EAZJ,GAAI,GAAW,EAAQ,MAAM,CAQzB,CAR2B,MAQpB,EAAc,EAAU,GAKnC,GAAwB,UAApB,EAAgC,KAAzB,GAA0B,EAI9B,CAKH,MAT0C,AASpC,EAA8B,UAApB,OAAO,GAAyB,aAAoB,IAAM,IAAI,QAAQ,EAAU,GAAW,EAC3G,GAAuB,QAAnB,EAAQ,MAAM,EAAiC,SAAnB,EAAQ,MAAM,EAAe,EAAQ,SAAS,CAK1E,CAL4E,MAKrE,EAAc,EAAU,GA5CrC,EAAkB,MAAM,IAAI,CAAC,EAAQ,OAAO,CAAC,OAAO,IAAI,MAAM,CAAC,CAAC,CAAC,EAAI,GAAG,CAAC,GAA2B,GAAG,CAAC,EAAI,WAAW,KA8CrH,EA7CD,KAAK,IA6CO,KA7CE,CAAC,CAClB,EAAQ,MAAM,CACd,EACA,EAAQ,IAAI,CACZ,EAAQ,QAAQ,CAChB,EAAQ,WAAW,CACnB,EAAQ,QAAQ,CAChB,AAsCgC,EAtCxB,cAAc,CACtB,EAAQ,SAAS,CACpB,EAqCO,EAAM,EAAQ,GAClB,AADqB,MAhBjB,EA9CW,SA8CA,sCACX,AA/C0D,EA+CpD,EAiBV,IAAM,EAAe,EAAgB,GACrC,IAAI,IAAI,EAAI,EAAG,EAAI,EAAa,MAAM,CAAE,EAAI,EAAG,GAAK,EAAE,CAClD,EAlE4G,CAkEtG,CAAC,EAAK,EAAQ,CAAG,CAAY,CAAC,EAAE,CACtC,GAAI,IAAQ,EACR,OAAO,CADW,CACH,IAAI,CAAC,KAChB,IAAM,EAAW,CAAY,CAAC,EAAE,CAAC,EAAE,CACnC,GAAI,CAAC,EAAU,MAAM,OAAO,cAAc,CAAC,IAAI,EAAe,sBAAuB,oBAAqB,CACtG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAKA,GAAM,CAAC,EAAS,EAAQ,CAAG,GAAc,GAEzC,OADA,CAAY,CAAC,EAAE,CAAC,EAAE,CAAG,EACd,CACX,EAER,CAGA,IAAM,EAAU,EAAc,EAAU,GAClC,EAAQ,CACV,EACA,EACA,KACH,CAED,OADA,EAAa,IAAI,CAAC,GACX,EAAQ,IAAI,CAAC,AAAC,IAKjB,GAAM,CAAC,EAAS,EAAQ,CAAG,GAAc,GAEzC,OADA,CAAK,CAAC,EAAE,CAAG,EACJ,CACX,EACJ,GwBqxBA,WAAW,KAAK,CA1uBb,AA0uBgB,SA1uBP,AAAqB,CAAW,CAAE,kBAAE,CAAgB,sBAAE,CAAoB,CAAE,EAExF,IAAM,EAAU,eAAqB,AAAN,CAAW,CAAE,CAAI,MACxC,EAAc,MACd,EACJ,GAAI,CAEA,CADA,EAAM,IAAI,IAAI,aAAiB,QAAU,EAAM,GAAG,CAAG,EAAA,EACjD,QAAQ,CAAG,GACf,EAAI,QAAQ,CAAG,EACnB,CAAE,KAAO,CAEL,EAAM,MACV,CACA,IAAM,EAAW,CAAQ,MAAP,EAAc,KAAK,EAAI,EAAI,IAAA,AAAI,GAAK,GAChD,EAAS,CAAS,MAAR,CAAe,EAAS,AAAgC,GAApC,IAAK,EAAe,EAAK,MAAA,AAAM,EAAY,KAAK,EAAI,EAAa,WAAW,EAAE,GAAK,MAGjH,EAAa,CAAS,MAAR,CAAe,EAAS,AAA4B,GAAhC,IAAK,EAAa,EAAK,IAAA,AAAI,EAAY,KAAK,EAAI,EAAW,QAAQ,KAAM,EAC3G,EAAoD,MAAzC,QAAQ,GAAG,CAAC,wBAAwB,CAK/C,EAAa,OAAa,EAAY,YAAY,UAAU,CAAG,YAAY,GAAG,GAC9E,EAAY,EAAiB,QAAQ,GACrC,EAAgB,EAAqB,QAAQ,GAC/C,EAAc,EAAgB,GAAe,GAAiB,KAC9D,GACA,EAAY,QADC,CACQ,GAEzB,IAAM,EAAS,KAAY,KAAK,CAAC,EAAa,GAAmB,aAAa,CAAG,GAAc,KAAK,CAAE,UAClG,EACA,KAAM,GAAS,MAAM,CACrB,SAAU,CACN,QACA,EACA,EACH,CAAC,MAAM,CAAC,SAAS,IAAI,CAAC,KACvB,WAAY,CACR,WAAY,EACZ,cAAe,EACf,gBAAwB,MAAP,EAAc,KAAK,EAAI,EAAI,QAAQ,CACpD,gBAAiB,CAAQ,MAAP,EAAc,KAAK,EAAI,EAAI,IAAA,AAAI,GAAK,MAC1D,CACJ,EAAG,cACK,MAgCA,EAwDA,EAwNA,EAGA,EAiIA,EA9ZA,EApBJ,GAAI,GAMA,CAAC,GAKD,EAAU,GAXE,CAoBM,EAdN,KAKS,CAVrB,CAUuB,MAVhB,EAAY,EAAO,GAa9B,IAAM,EAAiB,GAAS,AAAiB,iBAAV,GAA8C,UAAxB,OAAO,EAAM,MAAM,CAC1E,EAAiB,AAAC,GAGb,CADe,MAAR,EAAe,CACb,IADkB,EAAI,CAAI,CAAC,EAAA,AAAM,IAChC,EAAiB,CAAK,CAAC,EAAM,CAAG,IAAA,CAAI,CAGnD,EAAe,AAAC,IAClB,IAAI,EAAY,EAAa,EAC7B,OAAO,KAAmG,EAA5F,GAAS,MAAR,CAAe,EAAS,AAA4B,GAAhC,IAAK,EAAa,EAAK,IAAA,AAAI,EAAY,KAAK,EAAI,CAAU,CAAC,EAAM,EAA4B,MAAR,CAAe,EAAS,AAA6B,GAAjC,IAAK,EAAc,EAAK,IAAA,AAAI,EAAY,KAAK,EAAI,CAAW,CAAC,EAAM,CAAG,EAAiB,AAA8B,MAA7B,GAAc,EAAM,IAAA,AAAI,EAAY,KAAK,EAAI,CAAW,CAAC,EAAM,CAAG,MAC1S,EAGM,EAA0B,EAAa,cACzC,EAAyB,EACvB,EA7LX,AA6LkB,SA7LT,AAAa,CAAI,CAAE,CAAW,EAC1C,IAAM,EAAY,EAAE,CACd,EAAc,EAAE,CACtB,IAAI,IAAI,EAAI,EAAG,EAAI,EAAK,MAAM,CAAE,IAAI,CAChC,IAAM,EAAM,CAAI,CAAC,EAAE,CAcnB,GAbmB,UAAf,AAAyB,OAAlB,EACP,EAAY,IAAI,CAAC,KACb,EACA,OAAQ,gCACZ,GACO,EAAI,MAAM,CvE1BY,EuE0BT,EACpB,EAAY,IAAI,CAAC,KACb,EACA,OAAQ,CAAC,GAHkC,oBAGX,EAAE,EACtC,GAEA,EAAU,IAAI,CAAC,GAEf,EAAU,MAAM,GAAG,CAL8C,CAKpB,CAC7C,QAAQ,IAAI,CAAC,CAAC,oCAAoC,EAAE,EAAY,eAAe,CAAC,CAAE,EAAK,KAAK,CAAC,GAAG,IAAI,CAAC,OACrG,KACJ,CACJ,CACA,GAAI,EAAY,MAAM,CAAG,EAErB,CAFwB,GAEnB,GAAM,CAAE,KAAG,QAAE,CAAM,CAAE,GAD1B,QAAQ,IAAI,CAAC,CAAC,gCAAgC,EAAE,EAAY,EAAE,CAAC,EACjC,GAC1B,QAAQ,CAD8B,EAC3B,CAAC,CAAC,MAAM,EAAE,EAAI,EAAE,EAAE,EAAA,CAAQ,EAG7C,OAAO,CACX,EA+JsC,EAAa,SAAW,EAAE,CAAE,CAAC,MAAM,EAAE,EAAM,QAAQ,GAAA,CAAI,EAEjF,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,YACL,IAAK,oBAEL,IAAK,mBACL,IAAK,gBACL,IAAK,mBACL,IAAK,QACL,IAAK,gBACD,EAAkB,CAO1B,CAEJ,GAAI,GACI,MAAM,OAAO,CADA,AACC,GAAO,CAErB,IAAM,EAAgB,EAAgB,IAAI,GAAK,CAAD,CAAiB,IAAI,CAAG,EAAA,AAAE,EACxE,IAAK,IAAM,KAAO,EACV,AAAC,EAAc,CADA,OACQ,CAAC,IACxB,EAD8B,AAChB,IAAI,CAAC,EAG/B,CAEJ,IAAM,EAAe,AAAiB,QAAO,KAAK,EAAI,EAAc,YAAY,CAC5E,EAAqB,EAAU,UAAU,CACzC,GAES,YAFM,OACR,EAAc,IAAI,GAIjB,EAAqB,gBAAA,EAejC,IAAM,EAAiB,CAAC,CAAC,EAAU,iBAAiB,CAChD,EAA0B,EAAe,SACzC,EAAc,GAEqB,UAAnC,OAAO,GAAwC,KAAkC,IAA3B,IAGtD,AAA4B,KAHkE,cAGtB,IAA3B,CAAgC,EAC7E,AAA4B,cAAc,EAAC,GAAyB,IAAgC,IAA3B,CAA2B,CAAK,IAErG,EAAe,CAAC,kBAAkB,EAHiG,AAG/F,EAAwB,mBAAmB,EAAE,EAAuB,gCAAgC,CAAC,CACzI,OAA0B,EAC1B,OAAyB,GAGjC,IAAM,EACsB,aAA5B,GAA0C,AAA4B,cAAc,EAEpF,AAAuB,sBAA2C,kBAAvB,EAMrC,EAA+B,CAAC,GAAsB,CAAC,GAA2B,CAAC,GAA0B,EAAU,YAAY,CAG7G,gBAA5B,GAA6C,CAXoI,IAWlG,IAA3B,EAChD,GAAyB,GAClB,CAFiF,EAElD,CAAA,GAA8B,CACpE,GAAyB,GAEG,aAA5B,GAAsE,aAA5B,CAA4B,GAAY,AAClF,GAAc,CAAC,OAAO,EAAE,EAAA,CAAA,AAAyB,EAErD,EAAkB,AA7SvB,SAAS,AAAmB,CAAa,CAAE,CAAK,EACnD,GAAI,CACA,IAAI,EACJ,IAAsB,IAAlB,EACA,CADyB,UADF,OAGpB,GAAI,AAAyB,EADT,eACT,GAA8B,CAAC,MAAM,IAAkB,EAAgB,CAAC,EACtF,CADyF,CAClE,OACpB,GAAI,KAAyB,IAAlB,EACd,MAAM,CADuC,MAChC,cAAc,CAAC,AAAI,MAAM,CAAC,0BAA0B,EAAE,EAAc,MAAM,EAAE,EAAM,yCAAyC,CAAC,EAAG,oBAAqB,CAC7J,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,OAAO,CACX,CAAE,MAAO,EAAK,CAEV,GAAI,aAAe,OAAS,EAAI,OAAO,CAAC,QAAQ,CAAC,sBAC7C,CADoE,KAC9D,EAEV,MACJ,CACJ,AAFe,EAyRkC,EAAwB,EAAU,KAAK,EAC5E,IAAM,EAAW,EAAe,WAC1B,EAAoE,AAAtD,OAAO,YAAa,MAAZ,EAAmB,KAAK,EAAI,EAAS,GAAG,AAAH,EAAsB,EAAW,IAAI,QAAQ,GAAY,CAAC,GACrH,EAAuB,EAAY,GAAG,CAAC,kBAAoB,EAAY,GAAG,CAAC,UAC3E,EAAsB,CAAC,CACzB,MACA,OACH,CAAC,QAAQ,CAAC,AAAC,CAAgD,OAA/C,EAAkB,EAAe,SAAA,CAAS,CAAY,KAAK,EAAI,EAAgB,WAAW,EAAA,CAAE,EAAK,OAUxG,EACN,KAAsB,YACM,CADO,EAClC,GAED,AAA4B,OAFa,MAEb,CAAS,KAAK,EAChB,GAA1B,EACI,EAAc,CALmD,EAK3C,CAAC,GAAwB,CAAA,CAAmB,EAAK,CAAC,AAAmB,QAAO,KAF1B,AAE+B,EAAI,EAAgB,UAAA,AAAU,IAAM,GAC3I,GAA2B,EAa/B,GAZI,CAAC,GANmH,AAMpG,IAIZ,EAAU,oBAJ4B,GAIL,CACjC,CADmC,EACR,EAE3B,GAAc,GAKlB,QAA8C,IAAlB,EAC5B,KADyD,EAClD,EAAc,IAAI,EACrB,IAAK,YACL,IAAK,oBAIL,IAAK,mBAKD,OAJI,IACA,EAAY,OADC,AACM,GACnB,EAAc,MAEX,GAAmB,EAAc,YAAY,CAAE,EAAU,KAAK,CAAE,UAkB/E,CAEJ,OAAO,GACH,IAAK,iBAEG,EAAc,8BACd,KAER,KAAK,gBAEG,GAAgC,gBAA5B,GAAwE,AAA3B,SAAO,GAAmC,EAAkB,EACzG,CAD4G,KACtG,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,uCAAuC,EAAE,EAAS,gDAAgD,CAAC,EAAG,oBAAqB,CAC9J,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,GAEJ,EAAc,6BACd,KAER,KAAK,aAEG,GAAgC,YAAY,CAAxC,EACA,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,oCAAoC,EAAE,EAAS,6CAA6C,CAAC,EAAG,oBAAqB,CACxJ,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,KAER,KAAK,eAEO,KAAkC,IAA3B,GAA0C,AAA2B,GAAG,MAC/E,EAAc,2BACd,aAWhB,CAsBA,GArBI,CAZ8B,AAkClC,IAtB+B,IAApB,EACoB,OADa,QAsBnB,GArBjB,CAA0C,EAAC,EAGb,cAH6B,MAGT,CAA3C,GACP,EAAkB,EAClB,EAAc,iCACP,GACP,EAAkB,EAClB,EAAc,OAFS,SAGhB,GACP,EAAkB,EAClB,EAAc,IAFM,cAKpB,EAAc,aACd,EAAkB,EAAkB,EAAgB,UAAU,GAAG,WAdjE,aACA,EAAc,GADI,2BAgBf,AAAC,IACR,EAAc,CAAC,MADM,MACM,EAAE,EAAA,CAAA,AAAiB,EAIlD,CAAC,CAAC,EAAU,WAAW,MAAI,CAAoB,CAAC,EAChD,CAAC,EADoD,CAIrD,GAAmB,EAAkB,EAAgB,KAHrC,KAG+C,CAAE,CAG7D,GAAwB,IAApB,EAAuB,CACvB,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,OAV6F,KAWlG,IAAK,UAV8D,SAWnE,IAAK,oBAKD,OAJI,IACA,EAAY,OADC,AACM,GACnB,EAAc,MAEX,GAAmB,EAAc,YAAY,CAAE,EAAU,KAAK,CAAE,UAkB/E,CAEJ,GAA0B,EAAW,EAAe,CAAC,oBAAoB,EAAE,EAAM,CAAC,EAAE,EAAU,KAAK,CAAA,CAAE,CACzG,CAII,GAAmB,IAA4B,IAC/C,EAAgB,UAAU,CADsC,AACnC,CAAA,CAErC,CACA,IAAM,EAAmD,UAA3B,OAAO,GAAgC,EAAkB,EAEjF,CAAE,kBAAgB,CAAE,CAAG,EACzB,EAAe,GAEnB,GAAI,EACA,OAAO,EAAc,IAAI,AADV,EAEX,IAAK,UACL,IAAK,QACL,IAAK,gBACD,EAAe,EAAc,YAAY,GAAI,EAC7C,EAA2B,EAAc,wBAAwB,AAWzE,CAEJ,GAAI,IAAqB,GAAyB,CAAA,CAAwB,CACtE,EADyE,CACrE,CACA,EAAW,IAFK,EAEC,EAAiB,gBAAgB,CAAC,EAAU,EAAiB,EAAQ,EAC1F,CAAE,MAAO,EAAK,CACV,QAAQ,KAAK,CAAC,CAAC,gCAAgC,CAAC,CAAE,EACtD,CAEJ,IAAM,EAAW,EAAU,WAAW,EAAI,EAC1C,EAAU,WAAW,CAAG,EAAW,EACnC,IAAI,EAAe,KAAK,EAClB,EAAkB,MAAO,EAAS,KACpC,IAAM,EAAqB,CACvB,QACA,cACA,UACA,YACA,YACA,SACA,OACA,WACA,WACA,iBACA,SACA,YAEG,EAAU,EAAE,CAAG,CACd,SACH,CACJ,CACD,GAAI,EAAgB,CAChB,IAAM,EAAW,EACX,EAAa,CACf,KAAM,EAAS,OAAO,EAAI,EAAS,IAAI,AAC3C,EACA,IAAK,IAAM,KAAS,EAEhB,CAAU,CAAC,EAAM,CAAG,CAAQ,CAAC,EAAM,CAEvC,EAAQ,IAAI,CAJ2B,OAInB,EAAS,GAAG,CAAE,EACtC,MAAO,GAAI,EAAM,CACb,GAAM,SAAE,CAAO,MAAE,CAAI,QAAE,CAAM,CAAE,GAAG,EAAY,CAAG,EACjD,EAAO,CACH,GAAG,CAAU,CACb,KAAM,GAAW,EACjB,OAAQ,OAAU,EAAY,CAClC,CACJ,CAEA,IAAM,EAAa,CACf,GAAG,CAAI,CACP,KAAM,CACF,GAAW,MAAR,EAAe,KAAK,EAAI,EAAK,IAAI,CACpC,UAAW,kBACX,CACJ,CACJ,EACA,OAAO,EAAY,EAAO,GAAY,IAAI,CAAC,MAAO,IAY9C,GAXI,CAAC,GAAW,GACZ,GAAiB,EAAW,CACxB,GAFoB,GAEb,EACP,IAAK,EACL,YAAa,GAAuB,EACpC,YAAiC,IAApB,GAAyB,EAAsB,OAAS,oBACrE,EACA,OAAQ,EAAI,MAAM,CAClB,OAAQ,EAAW,MAAM,EAAI,KACjC,GAEA,AAAe,QAAX,MAAM,EAAY,GAAoB,IAAa,GAAyB,CAAA,CAAwB,CAAG,CAC3G,CADsD,GAChD,EAAuB,GvEljBvB,WAJA,KuEsjB0C,GAAkC,EAC5E,EAAyB,EAAwB,CACnD,OAF6D,KAEjD,WACZ,WACA,OACA,2BACA,CACJ,OAAI,EACJ,OAAwB,MAAjB,EAAwB,KAAK,EAAI,EAAc,IAAI,EACtD,IAAK,YACL,IAAK,mBACL,IAAK,oBACD,OAAO,GAA8B,EAAK,EAAU,EAAwB,EAAkB,EAAsB,EACxH,KAAK,UAOL,IAAK,gBACL,IAAK,mBACL,IAAK,QACL,IAAK,gBACL,IAAK,iBACL,UAAK,EACD,OAAO,GAA4B,EAAW,EAAK,EAAU,EAAwB,EAAkB,EAA0B,EAAsB,EAAO,EAGtK,CACJ,CAIA,OADA,MAAM,IACC,CACX,GAAG,KAAK,CAAC,AAAC,IAEN,MADA,IACM,CACV,EACJ,EAEI,GAAyB,EACzB,GAAoB,EACxB,GAAI,GAAY,EAAkB,CAC9B,IAAI,EAKJ,GAJI,GAAgB,IAChB,EAAkB,EAAyB,GAAG,CAAC,GAC/C,GAAoB,GAEpB,GAAyB,CAAC,CAJgB,CAIC,CAC3C,EAAe,MAAM,EAAiB,IAAI,CAAC,GAC3C,IAAM,EAAQ,EAAU,oBAAoB,CAAG,KAAO,MAAM,EAAiB,GAAG,CAAC,EAAU,CACvF,KAAM,GAAqB,KAAK,CAChC,WAAY,WACZ,WACA,EACA,OACA,SAA0B,MAAhB,EAAuB,KAAK,EAAI,EAAa,IAAI,AAC/D,GACA,GAAI,GAA4B,EAC5B,OAAO,EAAc,IADsB,AAClB,EACrB,IAAK,YACL,IAAK,mBACL,IAAK,oBAMD,MAAM,CAgP9B,AAAC,IACD,IAAyB,IAAI,QAAQ,AAAC,IADb,AAErB,WAAW,KACP,GAAyB,KACzB,GACJ,EAAG,EACP,EAAA,EAEG,GAzOa,CASJ,GAPI,EACA,KADO,CACD,IAIN,EAAsB,yCAEtB,CAAU,MAAT,EAAgB,KAAK,EAAI,EAAM,KAAA,AAAK,GAAK,EAAM,KAAK,CAAC,IAAI,GAAK,GAAgB,KAAK,CAGpF,CAHsF,EAGlF,EAAU,kBAAkB,EAAI,EAAM,OAAO,CAC7C,CAD+C,EACtB,MACtB,CACH,GAAI,EAAM,OAAO,EAAE,CACf,EAAU,kBAAkB,GAAK,CAAC,EAC9B,CAAC,EAAU,kBAAkB,CAAC,EAAS,EAAE,CACzC,IAAM,EAAoB,GAAgB,GAAM,IAAI,CAAC,MAAO,IAAY,CAChE,KAAM,CADyD,KACnD,EAAS,WAAW,GAChC,QAAS,EAAS,OAAO,CACzB,OAAQ,EAAS,MAAM,CACvB,WAAY,EAAS,UAAU,CACnC,CAAC,EAAG,OAAO,CAAC,KACZ,EAAU,kBAAkB,GAAK,CAAC,EAClC,OAAO,EAAU,kBAAkB,CAAC,GAAY,GAAG,AACvD,GAGA,EAAkB,KAAK,CAAC,QAAQ,KAAK,EACrC,EAAU,kBAAkB,CAAC,EAAS,CAAG,CAC7C,CAEJ,EAAkB,EAAM,KAAK,CAAC,IAAI,AACtC,CAER,CACA,GAAI,EAAiB,CACb,GACA,GAAiB,EAAW,CACxB,GAFQ,GAED,EACP,IAAK,cACL,EACA,YAAa,EAAoB,MAAQ,mBACzC,EACA,OAAQ,EAAgB,MAAM,EAAI,IAClC,OAAQ,CAAS,MAAR,EAAe,KAAK,EAAI,EAAK,MAAA,AAAM,GAAK,KACrD,GAEJ,IAAM,EAAW,IAAI,SAAS,GAAA,MAAM,CAAC,IAAI,CAAC,EAAgB,IAAI,CAAE,UAAW,CACvE,QAAS,EAAgB,OAAO,CAChC,OAAQ,EAAgB,MAAM,AAClC,GAIA,OAHA,OAAO,cAAc,CAAC,EAAU,MAAO,CACnC,MAAO,EAAgB,GAAG,AAC9B,GACO,CACX,CACJ,CACA,GAAK,AAAD,EAAW,kBAAkB,EACqC,EADjC,CACyD,UAAhB,OAAO,EAAmB,CACpG,GAAM,OAAE,CAAK,CAAE,CAAG,EAGlB,GADmB,OAAO,EAAK,GAJ2B,EAItB,CAChC,AAAU,eAAY,CAEtB,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,YACL,IAAK,CAViG,iBAAiB,CAWvH,IAAK,oBAKD,OAJI,IACA,EAAY,OADC,AACM,GAb4I,AAc/J,EAAc,MAEX,GAAmB,EAAc,YAAY,CAAE,EAAU,KAAK,CAAE,UAkB/E,CAEJ,GAA0B,EAAW,EAAe,CAAC,eAAe,EAAE,EAAM,CAAC,EAAE,EAAU,KAAK,CAAA,CAAE,CACpG,CACA,IAAM,EAAgB,SAAU,EAC1B,MAAE,EAAO,CAAC,CAAC,CAAE,CAAG,EACtB,GAA+B,UAA3B,OAAO,EAAK,UAAU,EAAiB,GAAmB,EAAK,UAAU,CAAG,EAAgB,UAAU,CAAE,CACxG,GAAwB,IAApB,EAAK,UAAU,CAAQ,CAEvB,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,YACL,IAAK,mBACL,IAAK,oBACD,OAAO,GAAmB,EAAc,YAAY,CAAE,EAAU,KAAK,CAAE,UAc/E,CAEJ,GAA0B,EAAW,EAAe,CAAC,oBAAoB,EAAE,EAAM,CAAC,EAAE,EAAU,KAAK,CAAA,CAAE,CACzG,CACI,AAAC,EAAU,WAAW,EAAwB,GAAG,CAAvB,EAAK,UAAU,GACzC,EAAgB,UAAU,CAAG,EAAK,UAAA,AAAU,CAEpD,CACI,GAAe,OAAO,EAAK,IAAI,AACvC,CAIA,IAAI,IAAY,EAgDZ,OAAO,GAAgB,EAAO,EAhDM,EACpC,IAAM,EAAuB,EAC7B,EAAU,kBAAkB,GAAK,CAAC,EAClC,IAAI,EAAoB,EAAU,kBAAkB,CAAC,EAAqB,CAC1E,GAAI,EAAmB,CACnB,IAAM,EAAoB,MAAM,EAChC,OAAO,IAAI,SAAS,EAAkB,IAAI,CAAE,CACxC,QAAS,EAAkB,OAAO,CAClC,OAAQ,EAAkB,MAAM,CAChC,WAAY,EAAkB,UAClC,AAD4C,EAEhD,CASA,IAAM,EAAkB,GAAgB,EAAM,GAI7C,IAAI,CAAC,IAsBN,MAFA,CAnBA,EAAoB,AAL8C,EAK9B,IAAI,CAAC,MAAO,IAC5C,IAAM,EAAW,CAAS,CAAC,EAAE,CAC7B,MAAO,CACH,KAAM,MAAM,EAAS,WAAW,GAChC,AATwH,QAS/G,EAAS,OAAO,CACzB,OAAQ,EAAS,MAAM,CACvB,WAAY,EAAS,UAAU,AACnC,CACJ,GAAG,OAAO,CAAC,KACP,IAAI,GAGE,AAAkE,OAAjE,EAAgC,EAAU,kBAAA,AAAkB,EAAY,KAAK,EAAI,CAA6B,CAAC,EAAqB,AAArB,GAGtH,AAH8I,OAGvI,EAAU,kBAAkB,CAAC,EAAqB,AAC7D,EAAA,EAGkB,KAAK,CAAC,KAAK,GAC7B,EAAU,kBAAkB,CAAC,EAAqB,CAAG,EAC9C,EAAgB,IAAI,CAAC,AAAC,GAAY,CAAS,CAAC,EAAE,CACzD,CAGJ,GACA,GAJW,AAIP,EACA,GAAI,CACA,OAFS,AAEF,MAAM,CACjB,QAAS,CACD,GACA,EAAY,OAAO,CADN,CAGrB,CAEJ,OAAO,CACX,EAeA,OAVA,EAAQ,aAAa,EAAG,EACxB,EAAQ,oBAAoB,CAAG,IAAI,EACnC,EAAQ,kBAAkB,CAAG,EAC7B,UAAU,CAAC,GAAkB,CAAG,GAGhC,OAAO,cAAc,CAAC,EAAS,OAAQ,CACnC,MAAO,QACP,UAAU,CACd,GACO,CACX,EAU4C,EAAU,EACtD,CACA,IAAI,GAAyB,uDSn4B7B,AAAC,MAAK,aAAa,IAAI,EAAE,CAAC,IAAI,IAA0F,EAAE,OAAO,CAA/F,EAAgG,OAAvF,AAAK,CAAC,EAAwB,IAAtB,IAAI,EAAE,KAAK,EAAE,EAAE,MAAM,CAAO,EAAE,CAAC,EAAI,GAAF,EAAK,EAAE,UAAU,CAAC,EAAE,GAAG,OAAO,IAAI,CAAC,CAAe,CAAC,EAAM,EAAE,CAAC,EAAE,SAAS,EAAoB,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,QAAO,IAAJ,EAAe,KAAD,EAAQ,EAAE,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,QAAQ,CAAC,CAAC,EAAM,GAAE,EAAK,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,OAAO,CAAC,GAAqB,GAAE,CAAK,QAAQ,CAAI,GAAE,OAAO,CAAC,CAAC,EAAE,CAAC,OAAO,EAAE,OAAO,CAA6C,EAAoB,EAAE,CAAC,sFAA6C,EAAO,OAAO,CAAvC,EAAoB,AAAoB,KAAC,CAAC,iBAApD,eCCra,IAAM,EAA6B,CAAA,EAD1C,AAC0C,EAD1C,CAAA,CAAA,OAC0C,uBAAuB,AAAvB,KAE1C,yDAAyD,+BCQzD,IAAI,EAAA,EAAA,CAAA,CAAA,OACJ,SAAS,IAAQ,CACjB,IAAI,EAAY,CACd,EAAG,CACD,EAAG,EACH,EAAG,WACD,MAAM,MACJ,2FAEJ,EACA,EAAG,EACH,EAAG,EACH,EAAG,EACH,EAAG,EACH,EAAG,EACH,EAAG,EACH,EAAG,CACL,EACA,EAAG,EACH,YAAa,IACf,EACA,GAAI,CAAC,EAAM,+DAA+D,CACxE,MAAM,MACJ,2KAEJ,SAAS,EAAuB,CAAE,CAAE,CAAK,QACvC,AAAI,SAAW,EAAW,EAAP,CACf,UAAa,OAAO,EACf,KAAP,eAA6B,EAAQ,EAAQ,SACjD,CACA,EAAQ,4DAA4D,CAClE,EACF,EAAQ,UAAU,CAAG,SAAU,CAAI,CAAE,CAAO,EAC1C,UAAa,OAAO,IAGb,EAFJ,EAGK,AAHN,QACI,EAEe,OAAO,AAFpB,EAAU,EAAQ,WAAW,AAAX,EAGd,oBAAsB,EACpB,EACA,GACF,KAAK,CAAE,CACF,GAAV,EACL,EAAU,CAAC,CAAC,CAAC,CAAC,EAAM,EAAA,CAAQ,AAChC,EACA,EAAQ,WAAW,CAAG,SAAU,CAAI,EAClC,UAAa,OAAO,GAAQ,EAAU,CAAC,CAAC,CAAC,CAAC,EAC5C,EACA,EAAQ,OAAO,CAAG,SAAU,CAAI,CAAE,CAAO,EACvC,GAAI,UAAa,OAAO,GAAQ,GAAW,UAAa,OAAO,EAAQ,EAAE,CAAE,CACzE,IAAI,EAAK,EAAQ,EAAE,CACjB,EAAc,EAAuB,EAAI,EAAQ,WAAW,EAC5D,EACE,UAAa,OAAO,EAAQ,SAAS,CAAG,EAAQ,SAAS,CAAG,KAAK,EACnE,EACE,UAAa,OAAO,EAAQ,aAAa,CACrC,EAAQ,aAAa,CACrB,KAAK,EACb,UAAY,EACR,EAAU,CAAC,CAAC,CAAC,CACX,EACA,UAAa,OAAO,EAAQ,UAAU,CAAG,EAAQ,UAAU,CAAG,KAAK,EACnE,CACE,YAAa,EACb,UAAW,EACX,cAAe,CACjB,GAEF,WAAa,GACb,EAAU,CAAC,CAAC,CAAC,CAAC,EAAM,CAClB,YAAa,EACb,UAAW,EACX,cAAe,EACf,MAAO,UAAa,OAAO,EAAQ,KAAK,CAAG,EAAQ,KAAK,CAAG,KAAK,CAClE,EACN,CACF,EACA,EAAQ,aAAa,CAAG,SAAU,CAAI,CAAE,CAAO,EAC7C,GAAI,UAAa,OAAO,EACtB,GAAI,UAAa,OAAO,GAAW,OAAS,GAC1C,GAAI,GAD+C,GACvC,EAAQ,EAAE,EAAI,WAAa,EAAQ,EAAE,CAAE,CACjD,IAAI,EAAc,EAChB,EAAQ,EAAE,CACV,EAAQ,WAAW,EAErB,EAAU,CAAC,CAAC,CAAC,CAAC,EAAM,CAClB,YAAa,EACb,UACE,UAAa,OAAO,EAAQ,SAAS,CAAG,EAAQ,SAAS,CAAG,KAAK,EACnE,MAAO,UAAa,OAAO,EAAQ,KAAK,CAAG,EAAQ,KAAK,CAAG,KAAK,CAClE,GACF,MACK,MAAQ,GAAW,EAAU,CAAC,CAAC,CAAC,CAAC,EAC5C,EACA,EAAQ,OAAO,CAAG,SAAU,CAAI,CAAE,CAAO,EACvC,GACE,UAAa,OAAO,GACpB,UAAa,OAAO,GACpB,OAAS,GACT,UAAa,OAAO,EAAQ,EAAE,CAC9B,CACA,IAAI,EAAK,EAAQ,EAAE,CACjB,EAAc,EAAuB,EAAI,EAAQ,WAAW,EAC9D,EAAU,CAAC,CAAC,CAAC,CAAC,EAAM,EAAI,CACtB,YAAa,EACb,UACE,UAAa,OAAO,EAAQ,SAAS,CAAG,EAAQ,SAAS,CAAG,KAAK,EACnE,MAAO,UAAa,OAAO,EAAQ,KAAK,CAAG,EAAQ,KAAK,CAAG,KAAK,EAChE,KAAM,UAAa,OAAO,EAAQ,IAAI,CAAG,EAAQ,IAAI,CAAG,KAAK,EAC7D,cACE,UAAa,OAAO,EAAQ,aAAa,CACrC,EAAQ,aAAa,CACrB,KAAK,EACX,eACE,UAAa,OAAO,EAAQ,cAAc,CACtC,EAAQ,cAAc,CACtB,KAAK,EACX,YACE,UAAa,OAAO,EAAQ,WAAW,CAAG,EAAQ,WAAW,CAAG,KAAK,EACvE,WACE,UAAa,OAAO,EAAQ,UAAU,CAAG,EAAQ,UAAU,CAAG,KAAK,EACrE,MAAO,UAAa,OAAO,EAAQ,KAAK,CAAG,EAAQ,KAAK,CAAG,KAAK,CAClE,EACF,CACF,EACA,EAAQ,aAAa,CAAG,SAAU,CAAI,CAAE,CAAO,EAC7C,GAAI,UAAa,OAAO,EACtB,GAAI,EAAS,CACX,IAAI,EAAc,EAAuB,EAAQ,EAAE,CAAE,EAAQ,WAAW,EACxE,EAAU,CAAC,CAAC,CAAC,CAAC,EAAM,CAClB,GACE,UAAa,OAAO,EAAQ,EAAE,EAAI,WAAa,EAAQ,EAAE,CACrD,EAAQ,EAAE,CACV,KAAK,EACX,YAAa,EACb,UACE,UAAa,OAAO,EAAQ,SAAS,CAAG,EAAQ,SAAS,CAAG,KAAK,CACrE,EACF,MAAO,EAAU,CAAC,CAAC,CAAC,CAAC,EACzB,EACA,EAAQ,OAAO,CAAG,gECpJhB,EAAO,OAAO,CAAA,EAAA,CAAA,CAAA,qCCQhB,IAAI,EAAA,EAAA,CAAA,CAAA,OACF,EAAA,EAAA,CAAA,CAAA,OACA,EAA4B,OAAO,GAAG,CAAC,iBACvC,EAAqB,OAAO,GAAG,CAAC,8BAChC,EAAsB,OAAO,GAAG,CAAC,kBACjC,EAAqB,OAAO,GAAG,CAAC,iBAChC,EAAyB,OAAO,GAAG,CAAC,qBACpC,EAAsB,OAAO,GAAG,CAAC,kBACjC,EAA2B,OAAO,GAAG,CAAC,uBACtC,EAAkB,OAAO,GAAG,CAAC,cAC7B,EAAkB,OAAO,GAAG,CAAC,cAC7B,EAA4B,OAAO,GAAG,CAAC,6BACvC,EAA6B,OAAO,GAAG,CAAC,yBACxC,EAAwB,OAAO,QAAQ,CACzC,SAAS,EAAc,CAAa,SAClC,AAAI,OAAS,GAAiB,UAAa,OAAO,EAAsB,KAIjE,QAJ0D,IAI3C,OAAO,AAH7B,EACG,GAAyB,CAAa,CAAC,EAAsB,EAC9D,CAAa,CAAC,aAAA,AAAa,EACgB,EAAgB,IAC/D,CACA,IAAI,EAAiB,OAAO,aAAa,CACvC,EAAuB,OAAO,GAAG,CAAC,wBACpC,SAAS,EAAsB,CAAK,EAClC,WAAW,WACT,MAAM,CACR,EACF,CACA,IAAI,EAAe,QACjB,EACE,YAAe,OAAO,eAClB,eACA,SAAU,CAAQ,EAChB,EAAa,OAAO,CAAC,MAClB,IAAI,CAAC,GACL,KAAK,CAAC,EACX,EACN,EAAc,KACd,EAAe,EACjB,SAAS,EAAoB,CAAW,CAAE,CAAK,EAC7C,GAAI,IAAM,EAAM,UAAU,CACxB,GAAI,KAAO,EAAM,UAAU,CACzB,EAAI,GACD,GAAY,OAAO,CAClB,EADF,EACM,WAAW,EAAY,MAAM,CAAE,EAAG,IAEvC,EAAc,IAAI,WAAW,MAC7B,GAAe,CAAE,CAClB,EAAY,OAAO,CAAC,OACnB,CACH,IAAI,EAAiB,EAAY,MAAM,CAAG,EAC1C,EAAiB,EAAM,UAAU,EAC9B,EAAD,GAAO,EACH,EAAY,OAAO,CAAC,GACnB,GAAY,GAAG,CAAC,EAAM,GAAvB,KAA+B,CAAC,EAAG,GAAiB,GACpD,EAAY,OAAO,CAAC,GACnB,EAAQ,EAAM,QAAQ,CAAC,EAAA,CAAgB,CAC3C,EAAc,IAAI,WAAW,MAC7B,GAAe,CAAE,CACpB,EAAY,GAAG,CAAC,EAAO,GACvB,GAAgB,EAAM,UAAU,AAClC,CACF,MAAO,CAAC,CACV,CACA,IAAI,EAAc,IAAI,YACtB,SAAS,EAAc,CAAO,EAC5B,OAAO,EAAY,MAAM,CAAC,EAC5B,CACA,SAAS,EAAkB,CAAK,EAC9B,OAAO,EAAM,UAAU,AACzB,CACA,SAAS,EAAe,CAAW,CAAE,CAAK,EACxC,YAAe,OAAO,EAAY,KAAK,CACnC,EAAY,KAAK,CAAC,GAClB,EAAY,KAAK,EACvB,CACA,IAAI,EAAyB,OAAO,GAAG,CAAC,0BACtC,EAAuB,OAAO,GAAG,CAAC,0BACpC,SAAS,EAA4B,CAAmB,CAAE,CAAE,CAAE,CAAK,EACjE,OAAO,OAAO,gBAAgB,CAAC,EAAqB,CAClD,SAAU,CAAE,MAAO,CAAuB,EAC1C,KAAM,CAAE,MAAO,CAAG,EAClB,QAAS,CAAE,MAAO,CAAM,CAC1B,EACF,CACA,IAAI,EAAe,SAAS,SAAS,CAAC,IAAI,CACxC,EAAa,MAAM,SAAS,CAAC,KAAK,CACpC,SAAS,IACP,IAAI,EAAQ,EAAa,KAAK,CAAC,IAAI,CAAE,WACrC,GAAI,IAAI,CAAC,QAAQ,GAAK,EAAsB,CAC1C,IAAI,EAAO,EAAW,IAAI,CAAC,UAAW,GAItC,CAHE,MAGK,OAAO,gBAAgB,CAAC,EAAO,CACpC,SAJW,CAAE,AAIH,MAJU,CAAqB,EAKzC,CAJA,IAAO,CAAE,AAIH,MAJU,IAAI,CAAC,IAAI,AAAC,EAK1B,QAJF,CAIW,CAJJ,CAAE,MAAO,IAAI,CAAC,OAAO,CAAG,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,GAAQ,CAAK,EAK9D,KAAM,CAAE,MAAO,EAAM,aAAc,CAAC,CAAE,CACxC,EACF,CACA,OAAO,CACT,CACA,IAAI,EAA0B,CAC1B,MAAO,WACL,MAAO,gCACT,EACA,aAAc,CAAC,EACf,SAAU,CAAC,CACb,EACA,EAAoB,QAAQ,SAAS,CACrC,EAAoB,CAClB,IAAK,SAAU,CAAM,CAAE,CAAI,EACzB,OAAQ,GACN,IAAK,WACH,OAAO,EAAO,QAAQ,AACxB,KAAK,OACH,OAAO,EAAO,IAAI,AACpB,KAAK,UACH,OAAO,EAAO,OAAO,AACvB,KAAK,OACH,OAAO,EAAO,IAAI,AACpB,KAAK,cAEL,IAAK,eAEL,IAAK,aAEL,IAAK,SALH,MAOF,MAAK,OAAO,WAAW,CACrB,OAAO,OAAO,SAAS,CAAC,OAAO,WAAW,CAAC,AAC7C,MAAK,OAAO,WAAW,CACrB,OAAO,OAAO,SAAS,CAAC,OAAO,WAAW,CAAC,AAC7C,KAAK,WACH,MAAM,MACJ,2JAEJ,KAAK,OACH,MAAM,MACJ,oGAEN,CACA,MAAM,MACJ,iBACG,EAAD,KAAQ,EAAO,IAAI,EAAI,IAAM,OAAO,GACpC,EADyC,0HAG/C,EACA,IAAK,WACH,MAAM,MAAM,yDACd,CACF,EACF,SAAS,EAAa,CAAM,CAAE,CAAI,EAChC,OAAQ,GACN,IAAK,WACH,OAAO,EAAO,QAAQ,AACxB,KAAK,OACH,OAAO,EAAO,IAAI,AACpB,KAAK,UACH,OAAO,EAAO,OAAO,AACvB,KAAK,OACH,OAAO,EAAO,IAAI,AACpB,KAAK,eAEL,IAAK,aAEL,IAAK,SAHH,MAKF,MAAK,OAAO,WAAW,CACrB,OAAO,OAAO,SAAS,CAAC,OAAO,WAAW,CAAC,AAC7C,MAAK,OAAO,WAAW,CACrB,OAAO,OAAO,SAAS,CAAC,OAAO,WAAW,CAC5C,AAD6C,KACxC,aACH,IAAI,EAAW,EAAO,IAAI,CAY1B,OAXA,EAAO,OAAO,CAAG,EACf,WACE,MAAM,MACJ,2CACE,EACA,2LAEN,EACA,EAAO,IAAI,CAAG,IACd,EAAO,OAAO,EAET,CAAC,CACV,KAAK,OACH,GAAI,EAAO,IAAI,CAAE,OAAO,EAAO,IAAI,CACnC,GAAI,EAAO,OAAO,CAAE,OACpB,IAAI,EAAkB,EAA4B,CAAC,EAAG,EAAO,IAAI,CAAE,CAAC,GAClE,EAAQ,IAAI,MAAM,EAAiB,GAGrC,OAFA,EAAO,MAAM,CAAG,YAChB,EAAO,KAAK,CAAG,EACP,EAAO,IAAI,CAAG,EACpB,SAAU,CAAO,EACf,OAAO,QAAQ,OAAO,CAAC,EAAQ,GACjC,EACA,EAAO,IAAI,CAAG,QACd,CAAC,EAEP,CACA,GAAI,UAAa,OAAO,EACtB,MAAM,MACJ,2GAoBJ,MAjBA,CADA,EAAkB,CAAM,CAAC,EAAA,AAAK,IAe5B,OAAO,CAbP,aAaqB,CAAC,AAbpB,EAAkB,EAClB,WACE,MAAM,MACJ,qBACE,OAAO,GACP,0BACA,OAAO,GACP,qKAEN,EACA,EAAO,IAAI,CAAG,IAAM,EACpB,EAAO,OAAO,EAEuB,OAAQ,CAAE,MAAO,CAAK,GAC5D,EAAkB,CAAM,CAAC,EAAK,CAC7B,IAAI,MAAM,EAAiB,EAAA,CAAmB,CAC3C,CACT,CACA,IAAI,EAAkB,CAClB,IAAK,SAAU,CAAM,CAAE,CAAI,EACzB,OAAO,EAAa,EAAQ,EAC9B,EACA,yBAA0B,SAAU,CAAM,CAAE,CAAI,EAC9C,IAAI,EAAa,OAAO,wBAAwB,CAAC,EAAQ,GASzD,OARA,IACI,EAAa,CACb,MAAO,CADT,CACsB,EAAQ,GAC5B,SAAU,CAAC,EACX,aAAc,CAAC,EACf,WAAY,CAAC,CACf,EACA,OAAO,cAAc,CAAC,EAAQ,EAAM,EAAA,CAAW,CAC1C,CACT,EACA,eAAgB,WACd,OAAO,CACT,EACA,IAAK,WACH,MAAM,MAAM,yDACd,CACF,EACA,EACE,EAAS,4DAA4D,CACvE,EAAqB,EAAwB,CAAC,CAoChD,SAAS,EAAQ,CAAI,CAAE,CAAE,CAAE,CAAO,EAChC,GAAI,UAAa,OAAO,EAAM,CAC5B,IAAI,EAAU,KACd,GAAI,EAAS,CACX,IAAI,EAAQ,EAAQ,KAAK,CACvB,EAAM,IACR,GAAI,UAAY,GAAM,EAAS,CAC7B,IAAI,EAAc,EAAQ,WAAW,CACnC,EAAa,EAAQ,UAAU,CAC/B,EAAa,GACf,UAAa,OAAO,GAAe,KAAO,GACpC,GAAc,IAAM,EAAc,EAApC,EACA,UAAa,OAAO,IACjB,GAAc,IAAM,EAAa,CAAlC,EAAkC,CAAG,CAAC,CACvC,GAAc,OAAS,EAC5B,GAAO,UAAY,CACrB,MAAO,GAAO,IAAM,EAAK,IAAM,EAC/B,EAAM,GAAG,CAAC,KACP,EAAM,CAAP,EAAU,CAAC,GACX,CAAC,EAAU,EAAY,EAAA,CAAQ,CAC3B,GAAS,EAAS,IAAK,CAAC,EAAM,EAAI,EAAQ,EAC1C,GAAS,EAAS,IAAK,CAAC,EAAM,GAAG,CAAC,AAC1C,MAAO,EAAmB,CAAC,CAAC,EAAM,EAAI,EACxC,CACF,CACA,SAAS,EAAgB,CAAI,CAAE,CAAO,EACpC,GAAI,UAAa,OAAO,EAAM,CAC5B,IAAI,EAAU,KACd,GAAI,EAAS,CACX,IAAI,EAAQ,EAAQ,KAAK,CACvB,EAAM,KAAO,EACf,GAAI,EAAM,GAAG,CAAC,GAAM,OAEpB,OADA,EAAM,GAAG,CAAC,GACF,AAAD,GAAW,EAAY,EAAA,CAAQ,CAClC,GAAS,EAAS,IAAK,CAAC,EAAM,EAAQ,EACtC,GAAS,EAAS,IAAK,EAC7B,CACA,EAAmB,CAAC,CAAC,EAAM,EAC7B,CACF,CAoDA,SAAS,EAAY,CAAO,EAC1B,GAAI,MAAQ,EAAS,OAAO,KAC5B,IAEE,EAFE,EAAgB,CAAC,EACnB,EAAU,CAAC,EAEb,IAAK,KAAO,EACV,MAAQ,CAAO,CAAC,EAAI,GAChB,CAAF,CAAkB,CAAC,EAAK,CAAO,CAAC,EAAI,CAAG,CAAO,CAAC,EAAA,AAAK,EACxD,OAAO,EAAgB,EAAU,IACnC,CAvIA,EAAwB,CAAC,CAAG,CAC1B,EAAG,EAAmB,CAAC,CACvB,EAAG,EAAmB,CAAC,CACvB,EAQF,CARK,QAQI,AAAY,CAAI,EACvB,GAAI,UAAa,OAAO,GAAQ,EAAM,CACpC,IAAI,EAAU,KACd,GAAI,EAAS,CACX,IAAI,EAAQ,EAAQ,KAAK,CACvB,EAAM,KAAO,EACf,EAAM,GAAG,CAAC,IAAS,GAAM,CAAP,EAAU,CAAC,GAAM,GAAS,EAAS,IAAK,EAAA,CAAK,AACjE,MAAO,EAAmB,CAAC,CAAC,EAC9B,CACF,EAhBE,EAiBF,CAjBK,QAiBI,AAAW,CAAI,CAAE,CAAW,EACnC,GAAI,UAAa,OAAO,EAAM,CAC5B,IAAI,EAAU,KACd,GAAI,EAAS,CACX,IAAI,EAAQ,EAAQ,KAAK,CACvB,EAAM,MAAQ,CAAD,KAAS,EAAc,OAAS,CAAA,CAAW,CAAI,IAAM,EACpE,EAAM,GAAG,CAAC,IACP,GAAM,CAAP,EAAU,CAAC,GACX,UAAa,OAAO,EAChB,GAAS,EAAS,IAAK,CAAC,EAAM,EAAY,EAC1C,GAAS,EAAS,IAAK,EAAA,CAC/B,AADoC,MAC7B,EAAmB,CAAC,CAAC,EAAM,EACpC,CACF,EA7BE,EAAG,EACH,EAAG,EACH,EAyFF,CAzFK,QAyFI,AAAc,CAAG,CAAE,CAAO,EACjC,GAAI,UAAa,OAAO,EAAK,CAC3B,IAAI,EAAU,KACd,GAAI,EAAS,CACX,IAAI,EAAQ,EAAQ,KAAK,CACvB,EAAM,KAAO,EACf,GAAI,EAAM,GAAG,CAAC,GAAM,OAEpB,OADA,EAAM,GAAG,CAAC,GACH,CAAC,EAAU,EAAY,EAAA,CAAQ,CAClC,GAAS,EAAS,IAAK,CAAC,EAAK,EAAQ,EACrC,GAAS,EAAS,IAAK,EAC7B,CACA,EAAmB,CAAC,CAAC,EAAK,EAC5B,CACF,EAtGE,EAmEF,CAnEK,QAmEI,AAAa,CAAI,CAAE,CAAU,CAAE,CAAO,EAC7C,GAAI,UAAa,OAAO,EAAM,CAC5B,IAAI,EAAU,KACd,GAAI,EAAS,CACX,IAAI,EAAQ,EAAQ,KAAK,CACvB,EAAM,KAAO,EACf,GAAI,EAAM,GAAG,CAAC,GAAM,OAEpB,OADA,EAAM,GAAG,CAAC,GACH,CAAC,EAAU,EAAY,EAAA,CAAQ,CAClC,GAAS,EAAS,IAAK,CACrB,EACA,UAAa,OAAO,EAAa,EAAa,EAC9C,EACD,EACD,UAAa,OAAO,EAClB,GAAS,EAAS,IAAK,CAAC,EAAM,EAAW,EACzC,GAAS,EAAS,IAAK,EAC/B,CACA,EAAmB,CAAC,CAAC,EAAM,EAAY,EACzC,CACF,EAtFE,EAsGF,CAtGK,QAsGI,AAAoB,CAAG,CAAE,CAAO,EACvC,GAAI,UAAa,OAAO,EAAK,CAC3B,IAAI,EAAU,KACd,GAAI,EAAS,CACX,IAAI,EAAQ,EAAQ,KAAK,CACvB,EAAM,KAAO,EACf,GAAI,EAAM,GAAG,CAAC,GAAM,OAEpB,OADA,EAAM,GAAG,CAAC,GACH,CAAC,EAAU,EAAY,EAAA,CAAQ,CAClC,GAAS,EAAS,IAAK,CAAC,EAAK,EAAQ,EACrC,GAAS,EAAS,IAAK,EAC7B,CACA,EAAmB,CAAC,CAAC,EAAK,EAC5B,CACF,CAnHA,EAiOA,IAAI,EAAyB,YAAe,OAAO,kBACjD,EAAiB,EAAyB,IAAI,kBAAsB,KACpE,EAA0B,OAAO,GAAG,CAAC,6BACrC,EAAgB,CACd,IAAK,SAAU,CAAM,CAAE,CAAI,EACzB,OAAQ,GACN,IAAK,WACH,OAAO,EAAO,QAAQ,AACxB,KAAK,OAEL,IAAK,cAEL,IAAK,eAEL,IAAK,aAEL,IAAK,SAPH,MASF,MAAK,OAAO,WAAW,CACrB,OAAO,OAAO,SAAS,CAAC,OAAO,WAAW,CAAC,AAC7C,MAAK,OAAO,WAAW,CACrB,OAAO,OAAO,SAAS,CAAC,OAAO,WAAW,CAAC,AAC7C,KAAK,WACH,MAAM,MACJ,2JAEJ,KAAK,OACH,MACJ,CACA,MAAM,MACJ,iBACE,OAAO,GACP,+IAEN,EACA,IAAK,WACH,MAAM,MACJ,sEAEJ,CACF,EAcF,SAAS,IAAQ,CACjB,IAAI,EAAoB,MACtB,kaA2CE,EAAoB,KACxB,SAAS,IACP,GAAI,OAAS,EACX,MAAM,MACJ,gFAEJ,IAAI,EAAW,EAEf,OADA,EAAoB,KACb,CACT,CACA,IAAI,GAAmB,KACrB,GAAuB,EACvB,GAAgB,KAClB,SAAS,KACP,IAAI,EAAQ,IAAiB,EAAE,CAE/B,OADA,GAAgB,KACT,CACT,CACA,IAAI,GAAkB,CACpB,YAAa,GACb,IAiDF,CAjDO,QAiDE,AAAI,CAAM,EACjB,GACG,OAAS,GAAU,UAAa,OAAO,GACxC,YAAe,OAAO,EACtB,CACA,GAAI,YAAe,OAAO,EAAO,IAAI,CAAE,CACrC,IAAI,EAAQ,GACZ,IAAwB,EACxB,OAAS,KAAkB,GAAgB,EAAA,AAAE,MAtHxB,CAsHK,CACD,GAvHW,EAuHI,EAvHM,EAuHE,EAvHd,AAAU,AAKhD,CALuD,MAEvD,KAAK,IADL,EACW,CADH,CAAa,CAAC,EAAA,AAAM,EAExB,EAAc,IAAI,CAAC,GACnB,IAAU,IAAa,EAAS,IAAI,CAAC,CAAf,CAAqB,GAAQ,EAAW,CAAA,CAAM,CAChE,EAAS,MAAM,EACrB,IAAK,YACH,OAAO,EAAS,KAAK,AACvB,KAAK,WACH,MAAM,EAAS,MAAM,AACvB,SAqBE,OApBA,UAAa,OAAO,EAAS,MAAM,CAC/B,EAAS,IAAI,CAAC,EAAM,IAEnB,CADC,EAAgB,CAAlB,AAAkB,EACH,MAAM,CAAG,UACxB,EAAc,IAAI,CAChB,SAAU,CAAc,EACtB,GAAI,YAAc,EAAS,MAAM,CAAE,CACjC,IAAI,EAAoB,EACxB,EAAkB,MAAM,CAAG,YAC3B,EAAkB,KAAK,CAAG,CAC5B,CACF,EACA,SAAU,CAAK,EACb,GAAI,YAAc,EAAS,MAAM,CAAE,CACjC,IAAI,EAAmB,CACvB,GAAiB,MAAM,CAAG,WAC1B,EAAiB,MAAM,CAAG,CAC5B,CACF,EAAA,CACD,CACG,EAAS,MAAM,EACrB,IAAK,YACH,OAAO,EAAS,KAAK,AACvB,KAAK,WACH,MAAM,EAAS,MACnB,AADyB,CAGzB,MADA,EAAoB,EACd,CACV,CAiFE,CACA,EAAO,QAAQ,GAAK,GAAsB,IAC5C,CACA,GAAI,EAAO,QAAQ,GAAK,EAAwB,CAC9C,GAAI,MAAQ,EAAO,KAAK,EAAI,EAAO,KAAK,CAAC,QAAQ,GAAK,EACpD,MAAM,MAAM,wDACd,OAAM,MAAM,qDACd,CACA,MAAM,MAAM,4CAA8C,OAAO,GACnE,EAnEE,YAAa,SAAU,CAAQ,EAC7B,OAAO,CACT,EACA,WAAY,GACZ,UAAW,GACX,oBAAqB,GACrB,gBAAiB,GACjB,mBAAoB,GACpB,QAAS,SAAU,CAAU,EAC3B,OAAO,GACT,EACA,WAAY,GACZ,OAAQ,GACR,SAAU,GACV,cAAe,WAAa,EAC5B,iBAAkB,GAClB,cAAe,GACf,qBAAsB,GACtB,MAwBF,CAxBS,QAwBA,EACP,GAAI,OAAS,GACX,MAAM,MAAM,mDACd,IAAI,EAAK,GAAiB,eAAe,GACzC,MAAO,IAAM,GAAiB,gBAAgB,CAAG,KAAO,EAAG,QAAQ,CAAC,IAAM,GAC5E,EA5BE,wBAAyB,GACzB,aAAc,GACd,eAAgB,GAChB,cAAe,GACf,aAAc,SAAU,CAAI,EAC1B,IAAK,IAAI,EAAO,MAAM,GAAO,EAAI,EAAG,EAAI,EAAM,IAC5C,CAAI,CAAC,EAAE,CAAG,EACZ,OAAO,CACT,EACA,gBAAiB,WACf,OAAO,EACT,CACF,EAEA,SAAS,KACP,MAAM,MAAM,mDACd,CACA,SAAS,KACP,MAAM,MAAM,8DACd,CACA,SAAS,KACP,MAAM,MAAM,wDACd,CATA,GAAgB,cAAc,CAAG,GAoCjC,IAAI,GAAyB,CACzB,gBAAiB,SAAU,CAAY,EACrC,IAAI,EAA2B,CAAC,EAC9B,IAAA,CAAgB,CACd,EAAyB,KAAK,CAC9B,IAAI,IACJ,EAAQ,EAAyB,GAAG,CAAC,GAIzC,OAHA,KAAK,IAAM,IACP,EAAQ,GAAV,CACA,EAAyB,GAAG,CAAC,EAAc,EAAA,CAAM,CAC5C,CACT,EACA,YAAa,WACX,IAAI,EAAU,KACd,OAAO,EAAU,EAAQ,eAAe,CAAC,MAAM,CAAG,IACpD,CACF,EACA,GACE,EAAM,+DAA+D,CACzE,GAAI,CAAC,GACH,MAAM,MACJ,2KAEJ,IAAI,GAAc,MAAM,OAAO,CAC7B,GAAiB,OAAO,cAAc,CACxC,SAAS,GAAW,CAAM,EAExB,MAAO,CADP,EAAS,OAAO,SAAS,CAAC,QAAQ,CAAC,IAAI,CAAC,EAAA,EAC1B,KAAK,CAAC,EAAG,EAAO,MAAM,CAAG,EACzC,CACA,SAAS,GAA6B,CAAK,EACzC,OAAQ,OAAO,GACb,IAAK,SACH,OAAO,KAAK,SAAS,CACnB,IAAM,EAAM,MAAM,CAAG,EAAQ,EAAM,KAAK,CAAC,EAAG,IAAM,MAEtD,KAAK,SACH,GAAI,GAAY,GAAQ,MAAO,QAC/B,GAAI,OAAS,GAAS,EAAM,QAAQ,GAAK,GACvC,MAAO,SAET,MAAO,YADP,CACoB,CADZ,GAAW,EAAA,EACS,QAAU,CACxC,KAAK,WACH,OAAO,EAAM,QAAQ,GAAK,GACtB,SACA,CAAC,EAAQ,EAAM,WAAW,EAAI,EAAM,IAAA,AAAI,EACtC,YAAc,EACd,UACR,SACE,OAAO,OAAO,EAClB,CACF,CA0BA,IAAI,GAAuB,OAAO,GAAG,CAAC,0BACtC,SAAS,GAA8B,CAAa,CAAE,CAAY,EAChE,IAAI,EAAU,GAAW,GACzB,GAAI,WAAa,GAAW,UAAY,EAAS,OAAO,EACxD,EAAU,CAAC,EACX,IAAI,EAAS,EACb,GAAI,GAAY,GAAgB,CAE9B,IAAK,IADD,EAAM,IACD,EAAI,EAAG,EAAI,EAAc,MAAM,CAAE,IAAK,CAC7C,EAAI,IAAM,CAAD,EAAQ,IAAA,CAAI,CACrB,IAAI,EAAQ,CAAa,CAAC,EAAE,CAC5B,EACE,UAAa,OAAO,GAAS,OAAS,EAClC,GAA8B,GAC9B,GAA6B,GACnC,GAAK,IAAM,GACL,EAAU,EAAI,MAAM,CAAI,CAA1B,CAAmC,EAAM,MAAM,CAAI,GAAO,CAAA,CAAM,CAC/D,EACC,GAAK,EAAM,MAAM,EAAI,GAAK,EAAI,MAAM,CAAG,EAAM,MAAM,CAC/C,EAAM,EACN,EAAM,KAClB,CACA,GAAO,GACT,MAAO,GAAI,EAAc,QAAQ,GAAK,EACpC,EAAM,IAAM,AAjDhB,SAAS,EAAoB,CAAI,EAC/B,GAAI,UAAa,OAAO,EAAM,OAAO,EACrC,OAAQ,GACN,KAAK,EACH,MAAO,UACT,MAAK,EACH,MAAO,cACT,MAAK,EACH,MAAO,gBACX,CACA,GAAI,UAAa,OAAO,EACtB,OAAQ,EAAK,QAAQ,EACnB,KAAK,EACH,OAAO,EAAoB,EAAK,MAAM,CACxC,MAAK,EACH,OAAO,EAAoB,EAAK,IAAI,CACtC,MAAK,EACH,IAAI,EAAU,EAAK,QAAQ,CAC3B,EAAO,EAAK,KAAK,CACjB,GAAI,CACF,OAAO,EAAoB,EAAK,GAClC,CAAE,MAAO,EAAG,CAAC,CACjB,CACF,MAAO,EACT,EAyBoC,EAAc,IAAI,EAAI,SACnD,CACH,GAAI,EAAc,QAAQ,GAAK,GAAsB,MAAO,SAG5D,IAAK,EAAQ,EAFb,EAAM,IACN,EAAI,OAAO,IAAI,CAAC,GACA,EAAQ,EAAE,MAAM,CAAE,IAAS,CACzC,EAAI,IAAU,GAAO,EAAR,EAAQ,CAAI,CACzB,IAAI,EAAO,CAAC,CAAC,EAAM,CACjB,EAAa,KAAK,SAAS,CAAC,GAC9B,GAAO,CAAC,IAAM,EAAO,MAAQ,EAAa,EAAO,CAAA,CAAU,CAAI,KAE/D,EACE,UAAa,OAAO,AAFtB,EAAa,CAAa,CAAC,EAAK,AAAL,GAES,OAAS,EACvC,GAA8B,GAC9B,GAA6B,GACnC,IAAS,GACH,EAAU,EAAI,MAAM,CACrB,CADD,CACU,EAAW,MAAM,CAC1B,GAAO,CAAA,CAAW,CAClB,EACC,GAAK,EAAW,MAAM,EAAI,GAAK,EAAI,MAAM,CAAG,EAAW,MAAM,CACzD,EAAM,EACN,EAAM,KAClB,CACA,GAAO,GACT,CACA,OAAO,KAAK,IAAM,EACd,EACA,CAAC,EAAI,GAAW,EAAI,EAElB,OADA,AACS,EAAM,QADb,CACsB,CADN,IAAI,MAAM,CAAC,CACQ,EADG,IAAI,MAAM,CAAC,EAAA,EAEnD,OAAS,CACjB,CACA,IAAI,GAAiB,OAAO,SAAS,CAAC,cAAc,CAClD,GAAoB,OAAO,SAAS,CACpC,GAAY,KAAK,SAAS,CAC5B,SAAS,GAAoB,CAAK,EAChC,QAAQ,KAAK,CAAC,EAChB,CACA,SAAS,GACP,CAAI,CACJ,CAAK,CACL,CAAa,CACb,CAAO,CACP,CAAU,CACV,CAAY,CACZ,CAAgB,CAChB,CAAmB,EAEnB,GACE,OAAS,GAA2B,CAAC,EACrC,GAA2B,CAAC,GAAK,GAEjC,MAAM,MAAM,6DACd,GAA2B,CAAC,CAAG,GAC/B,IAAI,EAAW,IAAI,IACjB,EAAc,EAAE,CAChB,EAAQ,IAAI,IACd,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,MAAM,CAAG,GACd,IAAI,CAAC,cAAc,CAAG,CAAC,EACvB,IAAI,CAAC,WAAW,CAAG,IAAI,CAAC,UAAU,CAAG,KACrC,IAAI,CAAC,aAAa,CAAG,EACrB,IAAI,CAAC,KAAK,CAAG,IAAI,IACjB,IAAI,CAAC,eAAe,CAAG,IAAI,gBAC3B,IAAI,CAAC,aAAa,CAAG,IAAI,CAAC,WAAW,CAAG,EACxC,IAAI,CAAC,KAAK,CAAG,EACb,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,qBAAqB,CAAG,EAAE,CAC/B,IAAI,CAAC,mBAAmB,CAAG,EAAE,CAC7B,IAAI,CAAC,sBAAsB,CAAG,EAAE,CAChC,IAAI,CAAC,oBAAoB,CAAG,EAAE,CAC9B,IAAI,CAAC,cAAc,CAAG,IAAI,IAC1B,IAAI,CAAC,uBAAuB,CAAG,IAAI,IACnC,IAAI,CAAC,uBAAuB,CAAG,IAAI,IACnC,IAAI,CAAC,cAAc,CAAG,IAAI,QAC1B,IAAI,CAAC,mBAAmB,CAAG,EAC3B,IAAI,CAAC,gBAAgB,CAAG,GAAoB,GAC5C,IAAI,CAAC,eAAe,CAAG,EACvB,IAAI,CAAC,iBAAiB,CAAG,EAAE,CAC3B,IAAI,CAAC,OAAO,CAAG,KAAK,IAAM,EAAU,GAAsB,EAC1D,IAAI,CAAC,UAAU,CAAG,EAClB,IAAI,CAAC,YAAY,CAAG,EAEpB,EAAY,IAAI,CADhB,AACiB,EADV,GAAW,IAAI,CAAE,EAAO,KAAM,CAAC,EAAG,EAAG,GAE9C,CACA,IAAI,GAAiB,KACrB,SAAS,KACP,GAAI,GAAgB,OAAO,GAC3B,GAAI,EAAwB,CAC1B,IAAI,EAAQ,EAAe,QAAQ,GACnC,GAAI,EAAO,OAAO,CACpB,CACA,OAAO,IACT,CACA,SAAS,GAAkB,CAAO,CAAE,CAAI,CAAE,CAAQ,EAChD,IAAI,EAAU,GACZ,EACA,EACA,EAAK,OAAO,CACZ,EAAK,YAAY,CACjB,EAAK,aAAa,CAClB,EAAQ,cAAc,EAExB,OAAQ,EAAS,MAAM,EACrB,IAAK,YACH,OACG,EAAQ,KAAK,CAAG,EAAS,KAAK,CAAG,GAAS,EAAS,GAAU,EAAQ,EAAE,AAE5E,KAAK,WACH,OAAO,GAAY,EAAS,EAAS,EAAS,MAAM,EAAG,EAAQ,EAAE,AACnE,SACE,GAAI,KAAO,EAAQ,MAAM,CACvB,OACE,EAAQ,cAAc,CAAC,MAAM,CAAC,GAC9B,KAAO,EAAQ,IAAI,CACd,EAAD,EAAU,GAAU,GAAiB,EAAS,EAAA,CAAQ,EACpD,EAAO,AAAT,EAAiB,UAAU,CAC3B,GAAU,GACV,GAAkB,EAAS,EAAS,EAAA,CAAK,CAC7C,EAAQ,EAAE,CAEd,UAAa,OAAO,EAAS,MAAM,GAC/B,CAAF,CAAW,MAAM,CAAG,UACpB,EAAS,IAAI,CACX,SAAU,CAAc,EACtB,YAAc,EAAS,MAAM,GACzB,CAAF,CAAW,MAAM,CAAG,YACnB,EAAS,KAAK,CAAG,CAAA,CAAe,AACrC,EACA,SAAU,CAAK,EACb,YAAc,EAAS,MAAM,GACzB,CAAF,CAAW,MAAM,CAAG,WAAc,EAAS,MAAM,CAAG,CAAA,CACxD,AAD8D,EAC9D,CACD,AACP,CAWA,OAVA,EAAS,IAAI,CACX,SAAU,CAAK,EACb,EAAQ,KAAK,CAAG,EAChB,GAAS,EAAS,EACpB,EACA,SAAU,CAAM,EACd,IAAM,EAAQ,MAAM,GACjB,CAAD,EAAa,EAAS,EAAS,GAAS,GAAa,EAAA,CACzD,AADiE,GAG5D,EAAQ,EAAE,AACnB,CAkKA,SAAS,GAAS,CAAO,CAAE,CAAI,CAAE,CAAK,EAEpC,EAAO,EAAc,KAAO,GAD5B,EAAQ,EAC2B,CADjB,EAAA,EACyB,MAC3C,EAAQ,mBAAmB,CAAC,IAAI,CAAC,GACjC,GAAa,EACf,CACA,SAAS,GAAa,CAAQ,EAC5B,GAAI,cAAgB,EAAS,MAAM,CAAE,OAAO,EAAS,KAAK,CAC1D,GAAI,aAAe,EAAS,MAAM,CAAE,MAAM,EAAS,MAAM,AACzD,OAAM,CACR,CAwBA,SAAS,KAAe,CA2BxB,SAAS,GAAwB,CAAO,CAAE,CAAI,CAAE,CAAG,CAAE,CAAS,CAAE,CAAK,EACnE,IAAI,EAAoB,EAAK,aAAa,CAK1C,GAJA,EAAK,aAAa,CAAG,KACrB,GAAuB,EACvB,GAAgB,EAChB,EAAQ,EAAU,EAAO,KAAK,GAC1B,KAAO,EAAQ,MAAM,CACvB,KACG,UAAa,OAAO,GACnB,OAAS,GACT,YAAe,OAAO,EAAM,IAAI,EAChC,EAAM,QAAQ,GAAK,GACnB,EAAM,IAAI,CAAC,GAAa,IAC1B,KAgBJ,OAdA,EAzCF,AAyCU,SAzCD,AAAkC,CAAO,CAAE,CAAI,CAAE,CAAS,CAAE,CAAM,EACzE,GACE,UAAa,OAAO,GACpB,OAAS,GACT,EAAO,QAAQ,GAAK,EAEpB,OAAO,EACT,GAAI,YAAe,OAAO,EAAO,IAAI,CAC5B,CA/BT,AA+BE,OA/BM,EAAS,MAAM,EACrB,IAAK,UA8BkC,EA7BrC,OA6B8C,AA7BvC,EAAS,KAAK,AACvB,KAAK,WACH,KACF,SACE,UAAa,OAAO,EAAS,MAAM,EAC/B,EAAF,CAAW,MAAM,CAAG,UACpB,EAAS,IAAI,CACX,SAAU,CAAc,EACtB,YAAc,EAAS,MAAM,GACzB,CAAF,CAAW,MAAM,CAAG,YACnB,EAAS,KAAK,CAAG,CAAA,CAAe,AACrC,EACA,SAAU,CAAK,EACb,YAAc,EAAS,MAAM,GACzB,CAAF,CAAW,MAAM,CAAG,WAAc,EAAS,MAAM,CAAG,CAAA,CAAM,AAC9D,EAAA,CACD,AACP,CACA,MAAO,CAAE,SAAU,EAAiB,SAWoB,CAXV,CAAU,MAAO,EAAa,CAWpB,CACxD,IAAI,EAAa,EAAc,GAC/B,OAAO,GAEF,CADC,EAAU,EAAC,CACL,CAAC,GADT,IACgB,QAAQ,CAAC,CAAG,WAC1B,OAAO,EAAW,IAAI,CAAC,EACzB,EACA,CAAA,CAAO,CACP,YAAe,OAAO,CAAM,CAAC,EAAe,EACzC,YAAe,OAAO,gBACrB,aAAkB,eACpB,GAEC,CADC,EAAU,EAAC,CAAb,AACQ,CAAC,EAAe,CAAG,WACzB,OAAO,CAAM,CAAC,EAAe,EAC/B,EACA,CAAA,CAAO,AACf,EAgB4C,EAAS,EAAM,EAAW,GACpE,EAAY,EAAK,OAAO,CACxB,EAAoB,EAAK,YAAY,CACrC,OAAS,EACJ,EAAK,OAAO,CACX,IAAQ,GAAwB,IAAc,EAC1C,EACA,OAAS,EACP,EACA,EAAY,IAAM,EAC1B,OAAS,IAAc,EAAK,OAAN,KAAkB,CAAG,CAAC,CAAC,EACjD,EAAU,GAAuB,EAAS,EAAM,GAAW,GAAI,GAC/D,EAAK,OAAO,CAAG,EACf,EAAK,YAAY,CAAG,EACb,CACT,CACA,SAAS,GAAe,CAAO,CAAE,CAAI,CAAE,CAAQ,EAC7C,OAAO,OAAS,EAAK,OAAO,EACtB,CAAF,CAAY,CACV,EACA,EACA,EAAK,OAAO,CACZ,CAAE,SAAU,CAAS,EACtB,CACD,EAAK,YAAY,CAAG,CAAC,EAAQ,CAAG,CAAA,CAAO,CACvC,CACN,CACA,IAAI,GAAiB,EACrB,SAAS,GAAU,CAAO,CAAE,CAAI,EAU9B,OATA,EAAO,GACL,EACA,EAAK,KAAK,CACV,EAAK,OAAO,CACZ,EAAK,YAAY,CACjB,EAAK,aAAa,CAClB,EAAQ,cAAc,EAExB,GAAS,EAAS,GACX,GAAgB,EAAK,EAAE,CAChC,CA8DA,SAAS,GAAS,CAAO,CAAE,CAAI,EAC7B,IAAI,EAAc,EAAQ,WAAW,CACrC,EAAY,IAAI,CAAC,GACjB,IAAM,EAAY,MAAM,GACpB,CAAF,CAAU,cAAc,CAAG,OAAS,EAAQ,WAAW,CACvD,KAAO,EAAQ,IAAI,EAAI,KAAO,EAAQ,MAAM,CACxC,EAAkB,WAChB,OAAO,GAAY,EACrB,GACA,WAAW,WACT,OAAO,GAAY,EACrB,EAAG,EAAA,CAAE,AACb,CACA,SAAS,GACP,CAAO,CACP,CAAK,CACL,CAAO,CACP,CAAY,CACZ,CAAa,CACb,CAAQ,EAER,EAAQ,aAAa,GACrB,IAAI,EAAK,EAAQ,WAAW,GAC5B,UAAa,OAAO,GAClB,OAAS,GACT,OAAS,GACT,GACA,EAAQ,cAAc,CAAC,GAAG,CAAC,EAAO,GAAmB,IACvD,IAAI,EAAO,CACT,GAAI,EACJ,OAAQ,EACR,MAAO,EACP,QAAS,EACT,aAAc,EACd,cAAe,EACf,KAAM,WACJ,OAAO,GAAS,EAAS,EAC3B,EACA,OAAQ,SAAU,CAAkB,CAAE,CAAK,EACzC,IAAkB,EAAmB,MAAM,CAC3C,IAAI,EAAc,EAAK,OAAO,CAC5B,EAAmB,EAAK,YAAY,CACtC,GAAI,CACF,IAAI,EAA2B,GAC7B,EACA,EACA,IAAI,CACJ,EACA,EAEJ,CAAE,MAAO,EAAa,CACpB,GAEG,EACC,UAAa,OAAO,AAFpB,EAAqB,EAAK,KAAA,AAAK,GAG/B,OAAS,IACR,EAAmB,QAAQ,GAAK,GAC/B,EADF,AACqB,QAAQ,GAAK,CAAA,CAAe,CACnD,KAAO,EAAQ,MAAM,CAEpB,EAAK,MAAM,CAAG,EACb,KAAO,EAAQ,IAAI,EACb,CAAF,CAAgB,EAAQ,WAAW,GAIlC,EAHA,EAAc,EACX,GAAgB,GAChB,GAAmB,EACK,CAAY,EACtC,EAAF,AAAgB,EAAQ,GADI,OACM,CACjC,EAA2B,EACxB,GAAgB,GAChB,GAAmB,EAAA,CAAa,MACvC,GAKH,UAAa,OAJX,AAIkB,EAHlB,IAAgB,EACZ,IACA,CAAA,GAEJ,OAAS,GACT,YAAe,OAAO,EAAM,IAAI,CAClC,CASA,IAAI,EAAO,CARX,EAA2B,GACzB,EACA,EAAK,KAAK,CACV,EAAK,OAAO,CACZ,EAAK,YAAY,CACjB,EAAK,aAAa,CAClB,EAAQ,eAAc,EAEY,IAAI,CACxC,EAAM,IAAI,CAAC,EAAM,GACjB,EAAyB,aAAa,CACpC,KACF,EAAK,OAAO,CAAG,EACf,EAAK,YAAY,CAAG,EACpB,EAA2B,EACvB,GAAgB,EAAyB,EAAE,EAC3C,GAAmB,EAAyB,EAAE,CACpD,MACG,EAAK,OAAO,CAAG,EACb,EAAK,YAAY,CAAG,EACrB,EAAQ,aAAa,GACpB,EAAc,EAAQ,WAAW,GACjC,EAAmB,GAAoB,EAAS,EAAO,GACxD,GAAe,EAAS,EAAa,GACpC,EAA2B,EACxB,GAAgB,GAChB,GAAmB,EAC7B,CACA,OAAO,CACT,EACA,cAAe,IACjB,EAEA,OADA,EAAS,GAAG,CAAC,GACN,CACT,CACA,SAAS,GAAmB,CAAE,EAC5B,MAAO,IAAM,EAAG,QAAQ,CAAC,GAC3B,CACA,SAAS,GAAgB,CAAE,EACzB,MAAO,KAAO,EAAG,QAAQ,CAAC,GAC5B,CACA,SAAS,GAAqB,CAAO,CAAE,CAAE,CAAE,CAAS,EAGlD,OAFA,EAAU,GAAU,GAEb,EADP,EAAK,EAAG,QAAQ,AACK,CADJ,IAAM,IAAM,EAAU,KAEzC,CACA,SAAS,GACP,CAAO,CACP,CAAM,CACN,CAAkB,CAClB,CAAe,EAEf,IAAI,EAAqB,EAAgB,OAAO,CAC1C,EAAgB,IAAI,CAAG,SACvB,EAAgB,IAAI,CACxB,EAA0B,EAAQ,uBAAuB,CACzD,EAAa,EAAwB,GAAG,CAAC,GAC3C,GAAI,KAAK,IAAM,EACb,OAAO,CAAM,CAAC,EAAE,GAAK,GAAsB,MAAQ,EAC/C,GAAgB,GAChB,GAAmB,GACzB,GAAI,CACF,IAAI,EAAS,EAAQ,aAAa,CAChC,EAAa,EAAgB,IAAI,CACnC,EAAa,GACb,IAAI,EAAqB,CAAM,CAAC,EAAW,CAC3C,GAAI,EAAoB,EAAa,EAAmB,IAAI,KACvD,CACH,IAAI,EAAM,EAAW,WAAW,CAAC,KAIjC,GAHA,CAAC,IAAM,IACH,EAAa,CAAf,CAA0B,KAAK,CAAC,EAAM,GACrC,EAAqB,CAAM,CAAC,EAAW,KAAK,CAAC,EAAG,GAAA,AAAM,EACrD,CAAC,EACH,MAAM,MACJ,8BACE,EACA,iGAER,CACA,GAAI,CAAC,IAAM,EAAmB,KAAK,EAAI,CAAC,IAAM,EAAgB,OAAO,CACnE,MAAM,MACJ,eACE,EACA,oIAEN,IAAI,EACF,CAAC,IAAM,EAAmB,KAAK,EAAI,CAAC,IAAM,EAAgB,OAAO,CAC7D,CAAC,EAAmB,EAAE,CAAE,EAAmB,MAAM,CAAE,EAAY,EAAE,CACjE,CAAC,EAAmB,EAAE,CAAE,EAAmB,MAAM,CAAE,EAAW,CACpE,EAAQ,aAAa,GACrB,IAAI,EAAW,EAAQ,WAAW,GAChC,EAAO,GAAU,GACjB,EAAM,EAAS,QAAQ,CAAC,IAAM,KAAO,EAAO,KAC5C,EAAiB,EAAc,GAGjC,OAFA,EAAQ,qBAAqB,CAAC,IAAI,CAAC,GACnC,EAAwB,GAAG,CAAC,EAAoB,GACzC,CAAM,CAAC,EAAE,GAAK,GAAsB,MAAQ,EAC/C,GAAgB,GAChB,GAAmB,EACzB,CAAE,MAAO,EAAG,CACV,OACE,EAAQ,aAAa,GACpB,EAAS,EAAQ,WAAW,GAC5B,EAAqB,GAAoB,EAAS,EAAG,MACtD,GAAe,EAAS,EAAQ,GAChC,GAAmB,EAEvB,CACF,CACA,SAAS,GAA8B,CAAO,CAAE,CAAK,CAAE,CAAa,EAUlE,OATA,EAAQ,GACN,EACA,EACA,KACA,CAAC,EACD,EACA,EAAQ,cAAc,EAExB,GAAU,EAAS,GACZ,EAAM,EACf,AADiB,CAEjB,SAAS,GAAoB,CAAO,CAAE,CAAG,CAAE,CAAU,EACnD,EAAQ,aAAa,GACrB,IAAI,EAAW,EAAQ,WAAW,GAElC,OADA,GAAoB,EAAS,EAAU,EAAK,EAAY,CAAC,GAClD,GAAmB,EAC5B,CAuCA,IAAI,GAAY,CAAC,EACjB,SAAS,GACP,CAAO,CACP,CAAI,CACJ,CAAM,CACN,CAAkB,CAClB,CAAK,EAGL,GADA,EAAK,KAAK,CAAG,EACT,IAAU,EAAoB,MAAO,IACzC,GAAI,OAAS,EAAO,OAAO,KAC3B,GAAI,UAAa,OAAO,EAAO,CAC7B,OAAQ,EAAM,QAAQ,EACpB,KAAK,EACH,IAAI,EAAmB,KACrB,EAAiB,EAAQ,cAAc,CACzC,GAAI,OAAS,EAAK,OAAO,EAAI,CAAC,EAAK,YAAY,CAAE,CAC/C,IAAI,EAAoB,EAAe,GAAG,CAAC,GAC3C,GAAI,KAAK,IAAM,EACb,GAAI,KAAc,EACb,OAAO,OADa,GAAY,UAGrC,CAAC,IAAM,EAAmB,OAAO,CAAC,MAEhC,EADA,GACK,KADH,CACS,CADA,EAAe,GAAG,CAAC,EAAA,CAE5B,GAAE,EAAmB,EAAS,IAAM,EACpC,EAAe,GAAG,CAAC,EAAO,EAAA,CAAiB,AACnD,CADoD,AAEpD,GAAI,KAAO,GAAgB,OAAO,GAAU,EAAS,GAgBrD,OAdA,EAAS,AADT,GAAqB,EAAM,KAAA,AAAK,EACJ,GAAG,CAS/B,UAAa,OAAO,AARpB,EAjVR,AAiVkB,SAjVT,EAAc,CAAO,CAAE,CAAI,CAAE,CAAI,CAAE,CAAG,CAAE,CAAG,CAAE,CAAK,EACzD,GAAI,MAAS,EACX,KADkB,CACZ,IADiB,EAErB,IAF2B,0EAI/B,GACE,YAAe,OAAO,GACtB,EAAK,QAAQ,GAAK,GAClB,EAAK,QAAQ,GAAK,EAElB,OAAO,GAAwB,EAAS,EAAM,EAAK,EAAM,GAC3D,GAAI,IAAS,GAAuB,OAAS,EAC3C,OACG,EAAO,EAAK,YAAY,CACzB,OAAS,EAAK,OAAO,GAAK,CAAD,CAAM,YAAY,CAAG,EAAC,CAAC,CAC/C,EAAQ,GACP,EACA,EACA,GACA,GACA,EAAM,QAAQ,EAEf,EAAK,YAAY,CAAG,EACrB,EAEJ,GACE,MAAQ,GACR,UAAa,OAAO,GACpB,EAAK,QAAQ,GAAK,EAElB,OAAQ,EAAK,QAAQ,EACnB,KAAK,EACH,IAAI,EAAO,EAAK,KAAK,CAErB,GADA,EAAO,EAAK,EAAK,QAAQ,EACrB,KAAO,EAAQ,MAAM,CAAE,MAAM,KACjC,OAAO,EAAc,EAAS,EAAM,EAAM,EAAK,EAAK,EACtD,MAAK,EACH,OAAO,GAAwB,EAAS,EAAM,EAAK,EAAK,MAAM,CAAE,EAClE,MAAK,EACH,OAAO,EAAc,EAAS,EAAM,EAAK,IAAI,CAAE,EAAK,EAAK,EAC7D,KAEA,UAAa,OAAO,GAChB,CACD,EAAO,AAz1Bd,EAw1BM,OAx1BG,AAAsB,CAAa,CAAE,CAAI,CAAE,CAAK,EACvD,MAw1BkC,CAx1B1B,GACN,IAAK,MACH,EAAO,EAAM,GAAG,CAChB,IAAI,EAAS,EAAM,MAAM,CACzB,GACE,CAAC,CACC,SAAW,EAAM,OAAO,EACvB,CAAC,GAAQ,CAAC,GACV,UAAa,OAAO,GAAQ,MAAQ,GACpC,UAAa,OAAO,GAAU,MAAQ,GACvC,QAAU,EAAM,aAAa,IAC7B,CAAgB,CAClB,EACC,GAAD,QAAc,OAAO,GACnB,MAAQ,CAAI,CAAC,EAAE,EACd,MAAQ,CAAI,CAAC,EAAE,EAAI,MAAQ,CAAI,CAAC,EAAE,EAClC,MAAQ,CAAI,CAAC,EAAE,EAAI,MAAQ,CAAI,CAAC,EAAE,EAClC,MAAQ,CAAI,CAAC,EAAE,EAAI,MAAQ,CAAI,CAAC,EAAE,EAClC,MAAQ,CAAI,CAAC,EAAE,EAAI,MAAQ,CAAI,CAAC,EAAA,AAAG,GACrC,EAAD,SAAc,OAAO,GACnB,MAAQ,CAAM,CAAC,EAAE,EAChB,MAAQ,CAAM,CAAC,EAAE,EAAI,MAAQ,CAAM,CAAC,EAAE,EACtC,MAAQ,CAAM,CAAC,EAAE,EAAI,MAAQ,CAAM,CAAC,EAAE,EACtC,MAAQ,CAAM,CAAC,EAAE,EAAI,MAAQ,CAAM,CAAC,EAAE,EACtC,MAAQ,CAAM,CAAC,EAAE,EAAI,MAAQ,CAAM,CAAC,EAAA,AAAG,EAC1C,CACA,IAAI,EAAQ,UAAa,OAAO,EAAM,KAAK,CAAG,EAAM,KAAK,CAAG,KAAK,EAC7D,EAAQ,EAAM,WAAW,CAC7B,EAAQ,GAAQ,GAAI,QAAS,CAC3B,YAAa,EACb,WAAY,EACZ,YACE,UAAa,OAAO,EAChB,oBAAsB,EACpB,EACA,GACF,KAAK,EACX,UAAW,EAAM,SAAS,CAC1B,KAAM,EAAM,IAAI,CAChB,cAAe,EAAM,aAAa,CAClC,eAAgB,EAAM,cAAc,AACtC,EACF,CACA,OAAO,CACT,KAAK,OAGH,GAFA,EAAO,EAAM,GAAG,CAChB,EAAS,EAAM,IAAI,CAEjB,CAAC,CACC,AAAgB,KAChB,MAAQ,EAAM,QAAQ,EACtB,UAAa,OAAO,GACpB,UAAa,OAAO,GACpB,KAAO,CAAA,CACT,CAEA,OAAQ,GACN,IAAK,UACH,EAAQ,EAAQ,EAAM,EAAE,CAAE,CACxB,YAAa,EAAM,WAAW,CAC9B,UAAW,EAAM,SAAS,CAC1B,MAAO,EAAM,KAAK,CAClB,KAAM,EAAM,IAAI,CAChB,cAAe,EAAM,aAAa,CAClC,eAAgB,EAAM,cAAc,CACpC,YAAa,EAAM,WAAW,CAC9B,WAAY,EAAM,UAAU,CAC5B,MAAO,EAAM,KAAK,AACpB,GACA,KACF,KAAK,gBACH,EAAgB,EAAQ,CACtB,GAAI,EAAM,EAAE,CACZ,YAAa,EAAM,WAAW,CAC9B,UAAW,EAAM,SAAS,CAC1B,MAAO,EAAM,KACf,AADoB,GAEpB,KACF,KAAK,aACH,EAAQ,EAAQ,QAAS,CACvB,YAAa,EAAM,WAAW,CAC9B,UAAW,EAAM,SAAS,CAC1B,MAAO,EAAM,KAAK,CAClB,KAAM,EAAM,IAAI,CAChB,cAAe,EAAM,aAAa,CAClC,eAAgB,EAAM,cAAc,CACpC,MAAO,EAAM,KAAK,AACpB,EACJ,CACF,OAAO,CACT,KAAK,UACH,OAAuB,EAAhB,CACT,KAAK,WACH,OAAuB,EAAhB,CACT,SACE,OAAO,CACX,CACF,IAsvBc,EAAK,aAAa,CACS,EAAM,GACzC,IAAQ,GACN,MAAQ,EAAM,QAAQ,EACtB,GAA8B,EAAS,EAAM,QAAQ,CAAE,EAAA,CAAK,CAYlE,OAXA,AAWO,EAXG,EACV,EAAM,EAAK,OAAO,CAClB,OAAS,EACJ,EAAU,EACX,OAAS,IACR,EACC,CADF,GACU,GAAwB,IAAY,EACxC,EACA,EAAM,IAAM,CAAA,CAAO,CAC7B,EAAQ,CAAC,EAAoB,EAAM,EAAS,EAAM,CAClD,EAAO,EAAK,YAAY,EAAI,OAAS,EAAU,CAAC,EAAM,CAAG,CAE3D,EAsRU,EACA,EACA,EAAM,IAAI,CACV,EAAM,GAAG,CACT,KAAK,IAAM,EAAS,EAAS,KAC7B,EAAA,GAGA,OAAS,GACT,OAAS,IACR,EAAe,GAAG,CAAC,IAClB,EAAe,GAAG,CAAC,AADrB,EAC8B,EAAA,CAAiB,CAC1C,CACT,MAAK,EACH,GAAI,KAAO,GAAgB,OAAO,GAAU,EAAS,GAIrD,GAHA,EAAK,aAAa,CAAG,KAErB,EAAQ,CADR,EAAqB,EAAM,KAAA,AAAK,EACL,EAAM,QAAQ,EACrC,KAAO,EAAQ,MAAM,CAAE,MAAM,KACjC,OAAO,GAAuB,EAAS,EAAM,GAAW,GAAI,EAC9D,MAAK,EACH,MAAM,MACJ,qSAEN,CACA,GAAI,EAAM,QAAQ,GAAK,EACrB,OAAO,GACL,EACA,EACA,EACA,GAEJ,GACE,KAAK,IAAM,EAAQ,mBAAmB,EAEtC,EADA,GACK,KADH,CACS,CADU,EAAQ,aACF,MADqB,CAAC,GAAG,CAAC,EAAA,EAGrD,MAAO,KAAO,EAGhB,GADA,EAAiB,CADjB,EAAmB,EAAQ,cAAA,AAAc,EACP,GAAG,CAAC,GAClC,YAAe,OAAO,EAAM,IAAI,CAAE,CACpC,GAAI,KAAK,IAAM,EAAgB,CAC7B,GAAI,OAAS,EAAK,OAAO,EAAI,EAAK,YAAY,CAC5C,MAAO,KAAO,GAAkB,EAAS,EAAM,GAAO,QAAQ,CAAC,IACjE,GAAI,KAAc,EACb,OAAO,EADa,GAAY,IAEvC,CAGA,OAFA,EAAU,KAAO,GAAkB,EAAS,EAAM,GAAO,QAAQ,CAAC,IAClE,EAAiB,GAAG,CAAC,EAAO,GACrB,CACT,CACA,GAAI,KAAK,IAAM,EACb,GAAI,KAAc,EAIX,OAAO,MAJW,CACvB,GAAI,IAAmB,GAAmB,EAAK,EAAE,EAC/C,OAAO,EACT,GAAY,IACd,MACG,GACH,CAAC,IAAM,EAAmB,OAAO,CAAC,MAElC,EADA,GACK,KADH,CACS,CADQ,EAAiB,GAAG,CAAC,EAAA,EAExC,CAEA,EAHyB,CAEzB,EAAoB,EAChB,GAAY,IAAW,CAAM,CAAC,EAAE,GAAK,EACvC,OAAQ,GACN,IAAK,IACH,EAAoB,OACpB,KACF,KAAK,IACH,EAAoB,MACpB,KACF,KAAK,IACH,EAAoB,QACpB,KACF,KAAK,IACH,EAAoB,QACxB,CACF,EAAiB,GAAG,CAAC,EAAO,EAAiB,IAAM,EACrD,CACA,GAAI,GAAY,GAAQ,OAAO,GAAe,EAAS,EAAM,GAC7D,GAAI,aAAiB,IACnB,MAEE,KAAO,GAA8B,EADpC,EAAQ,KACqC,CAD/B,IAAI,CAAC,GACiC,GAAG,QAAQ,CAAC,IAErE,GAAI,aAAiB,IACnB,MACG,AACD,KAAO,GAA8B,IAD5B,KACqC,CAD/B,IAAI,CAAC,GACiC,GAAG,QAAQ,CAAC,IAErE,GAAI,YAAe,OAAO,UAAY,aAAiB,SACrD,MAEE,KAAO,GAA8B,EADpC,EAAQ,KACqC,CAD/B,IAAI,CAAC,EAAM,OAAO,IACoB,GAAG,QAAQ,CAAC,IAErE,GAAI,aAAiB,MAAO,MAAO,KACnC,GAAI,aAAiB,YACnB,OAAO,GAAoB,EAAS,IAAK,IAAI,WAAW,IAC1D,GAAI,aAAiB,UACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,WACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,kBACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,WACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,YACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,WACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,YACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,aACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,aACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,cACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,eACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,aAAiB,SACnB,OAAO,GAAoB,EAAS,IAAK,GAC3C,GAAI,YAAe,OAAO,MAAQ,aAAiB,KACjD,OAjMN,AAiMa,SAjMJ,AAAc,CAAO,CAAE,CAAI,EAWlC,SAAS,EAAM,CAAM,EACnB,IAAM,EAAQ,MAAM,GACjB,CAAD,CAAS,eAAe,CAAC,MAAM,CAAC,mBAAmB,CAAC,QAAS,GAC7D,GAAY,EAAS,EAAS,GAC9B,GAAa,GACb,EAAO,MAAM,CAAC,GAAQ,IAAI,CAAC,EAAO,EAAA,CACtC,AAD4C,CAE5C,SAAS,IACP,GAAI,IAAM,EAAQ,MAAM,CAAE,CACxB,IAAI,EAAS,EAAQ,eAAe,CAAC,MAAM,CAC3C,EAAO,mBAAmB,CAAC,QAAS,GACpC,EAAS,EAAO,MAAM,CACtB,KAAO,EAAQ,IAAI,EACd,CAAD,CAAS,cAAc,CAAC,MAAM,CAAC,GAC/B,GAAS,GACT,GAAiB,EAAS,EAAA,CAAQ,EACjC,EAAD,CAAa,EAAS,EAAS,GAAS,GAAa,EAAA,CAAQ,CACjE,EAAO,MAAM,CAAC,GAAQ,IAAI,CAAC,EAAO,EACpC,CACF,CACA,IAAI,EAAQ,CAAC,EAAK,IAAI,CAAC,CACrB,EAAU,GAAW,EAAS,EAAO,KAAM,CAAC,EAAG,EAAG,EAAQ,cAAc,EACxE,EAAS,EAAK,MAAM,GAAG,SAAS,GAGlC,OAFA,EAAQ,eAAe,CAAC,MAAM,CAAC,gBAAgB,CAAC,QAAS,GACzD,EAAO,IAAI,GAAG,IAAI,CAAC,AAlCnB,SAAS,EAAS,CAAK,EACrB,GAAI,IAAM,EAAQ,MAAM,CACtB,IAAI,EAAM,IAAI,CAIZ,OACE,EAAM,IAAI,CAAC,EAAM,KAAK,EAAG,EAAO,IAAI,GAAG,IAAI,CAAC,GAAU,KAAK,CAAC,QAJ9D,EAAQ,eAAe,CAAC,MAAM,CAAC,mBAAmB,CAAC,QAAS,GAC1D,GAAS,EAAS,EAK1B,GAyB6B,KAAK,CAAC,GAC5B,KAAO,EAAQ,EAAE,CAAC,QAAQ,CAAC,GACpC,EA4J2B,EAAS,GAChC,GAAK,EAAmB,EAAc,GACpC,MAEE,CADC,EAAqB,EAAiB,IAAI,CAAC,EAAA,IACrB,EAEnB,KACE,CAFF,EAEgC,EAF9B,EAAQ,KAE+B,CAFzB,IAAI,CAAC,GAE2B,GAAG,QAAQ,CAAC,GAAG,CAC/D,GAAe,EAAS,EAAM,MAAM,IAAI,CAAC,IAEjD,GAAI,YAAe,OAAO,gBAAkB,aAAiB,eAC3D,OAAO,AA7uBb,SAAS,AAAwB,CAAO,CAAE,CAAI,CAAE,CAAM,EAiCpD,SAAS,EAAM,CAAM,EACnB,IAAM,EAAW,MAAM,GACpB,CAAD,CAAS,eAAe,CAAC,MAAM,CAAC,mBAAmB,CAAC,QAAS,GAC7D,GAAY,EAAS,EAAY,GACjC,GAAa,GACb,EAAO,MAAM,CAAC,GAAQ,IAAI,CAAC,EAAO,EAAA,CAAM,AAC5C,CACA,SAAS,IACP,GAAI,IAAM,EAAW,MAAM,CAAE,CAC3B,IAAI,EAAS,EAAQ,eAAe,CAAC,MAAM,CAC3C,EAAO,mBAAmB,CAAC,QAAS,GACpC,EAAS,EAAO,MAAM,CACtB,KAAO,EAAQ,IAAI,EACd,CAAD,CAAS,cAAc,CAAC,MAAM,CAAC,GAC/B,GAAS,GACT,GAAiB,EAAY,EAAA,CAAQ,EACpC,EAAD,CAAa,EAAS,EAAY,GAAS,GAAa,EAAA,CAAQ,CACpE,EAAO,MAAM,CAAC,GAAQ,IAAI,CAAC,EAAO,EACpC,CACF,CACA,IAAI,EAAe,EAAO,YAAY,CACtC,GAAI,KAAK,IAAM,EACb,GAAI,CACF,EAAO,SAAS,CAAC,CAAE,KAAM,MAAO,GAAG,WAAW,GAAK,EAAe,CAAC,CACrE,CAAE,MAAO,EAAG,CACV,EAAe,CAAC,CAClB,CACF,IAAI,EAAe,EACjB,EAAS,EAAO,SAAS,GACzB,EAAa,GACX,EACA,EAAK,KAAK,CACV,EAAK,OAAO,CACZ,EAAK,YAAY,CACjB,EAAK,aAAa,CAClB,EAAQ,cAAc,EAO1B,OALA,EAAQ,aAAa,GACrB,EAAO,EAAW,EAAE,CAAC,QAAQ,CAAC,IAAM,IAAO,EAAD,CAAgB,IAAM,GAAA,CAAG,CAAI,KACvE,EAAQ,sBAAsB,CAAC,IAAI,CAAC,EAAc,IAClD,EAAQ,eAAe,CAAC,MAAM,CAAC,gBAAgB,CAAC,QAAS,GACzD,EAAO,IAAI,GAAG,IAAI,CAAC,AAzEnB,SAAS,EAAS,CAAK,EACrB,GAAI,IAAM,EAAW,MAAM,CACzB,GAAI,EAAM,IAAI,CACX,EAAW,MAAM,CAAG,EAClB,EAAQ,EAAW,EAAE,CAAC,QAAQ,CAAC,IAAM,OACtC,EAAQ,sBAAsB,CAAC,IAAI,CAAC,EAAc,IAClD,EAAQ,cAAc,CAAC,MAAM,CAAC,GAC9B,EAAQ,eAAe,CAAC,MAAM,CAAC,mBAAmB,CAChD,QACA,GAEF,GAAa,GACb,GAAsB,QAExB,GAAI,CACF,EAAQ,aAAa,GAClB,EAAW,KAAK,CAAG,EAAM,KAAK,CAC/B,EACI,GACE,EACA,EAAW,EAAE,CACb,IACA,EAAW,KAAK,CAChB,CAAC,GAEH,GAAc,EAAS,GAC3B,GAAa,GACb,EAAO,IAAI,GAAG,IAAI,CAAC,EAAU,EACjC,CAAE,MAAO,EAAM,CACb,EAAM,EACR,CACN,EA0C6B,GACtB,GAAmB,EAAW,EAAE,CACzC,EAiqBqC,EAAS,EAAM,GAEhD,GAAI,YAAe,OADnB,AAC0B,EADP,CAAK,CAAC,EAAA,AAAe,EAEtC,OACE,OAAS,EAAK,OAAO,EACf,CAAF,CAAY,CACV,EACA,EACA,EAAK,OAAO,CACZ,CAAE,SAAU,CAAM,EACnB,CACA,EAAU,EAAK,YAAY,CAAG,CAAC,EAAQ,CAAG,CAAA,CAAQ,EACjD,EAAF,AAAuB,EAAiB,IAAI,CAAC,GAC5C,EAAU,AA7qBvB,SAAgC,AAAvB,CAA8B,CAAE,CAAI,CAAE,CAAQ,CAAE,CAAQ,EA0C/D,SAAS,EAAM,CAAM,EACnB,IAAM,EAAW,MAAM,GACpB,CAAD,CAAS,eAAe,CAAC,MAAM,CAAC,mBAAmB,CACjD,QACA,GAEF,GAAY,EAAS,EAAY,GACjC,GAAa,GACb,YAAe,OAAO,EAAS,KAAK,EAClC,EAAS,KAAK,CAAC,GAAQ,IAAI,CAAC,EAAO,EAAA,CAAM,AAC/C,CACA,SAAS,IACP,GAAI,IAAM,EAAW,MAAM,CAAE,CAC3B,IAAI,EAAS,EAAQ,eAAe,CAAC,MAAM,CAC3C,EAAO,mBAAmB,CAAC,QAAS,GACpC,IAAI,EAAS,EAAO,MAAM,CAC1B,KAAO,EAAQ,IAAI,EACd,CAAD,CAAS,cAAc,CAAC,MAAM,CAAC,GAC/B,GAAS,GACT,GAAiB,EAAY,EAAA,CAAQ,EACpC,EAAD,CAAa,EAAS,EAAY,EAAO,MAAM,EAC/C,GAAa,EAAA,CAAQ,CACzB,YAAe,OAAO,EAAS,KAAK,EAClC,EAAS,KAAK,CAAC,GAAQ,IAAI,CAAC,EAAO,EACvC,CACF,CACA,EAAW,IAAa,EACxB,IAAI,EAAa,GACf,EACA,EAAK,KAAK,CACV,EAAK,OAAO,CACZ,EAAK,YAAY,CACjB,EAAK,aAAa,CAClB,EAAQ,cAAc,EAOxB,OALA,EAAQ,aAAa,GACrB,EAAO,EAAW,EAAE,CAAC,QAAQ,CAAC,IAAM,KAAO,CAAD,CAAY,IAAM,GAAA,CAAG,CAAI,KACnE,EAAQ,sBAAsB,CAAC,IAAI,CAAC,EAAc,IAClD,EAAQ,eAAe,CAAC,MAAM,CAAC,gBAAgB,CAAC,QAAS,GACzD,EAAS,IAAI,GAAG,IAAI,CAAC,AAhFrB,SAAS,EAAS,CAAK,EACrB,GAAI,IAAM,EAAW,MAAM,CACzB,GAAI,EAAM,IAAI,CAAE,CAEd,GADA,EAAW,MAAM,CAAG,EAChB,KAAK,IAAM,EAAM,KAAK,CACxB,IAAI,EAAe,EAAW,EAAE,CAAC,QAAQ,CAAC,IAAM,YAEhD,GAAI,CACF,IAAI,EAAU,GACZ,EACA,EAAM,KAAK,CACX,GAEF,EACE,EAAW,EAAE,CAAC,QAAQ,CAAC,IACvB,KACA,GAAU,GAAmB,IAC7B,IACJ,CAAE,MAAO,EAAG,CACV,EAAM,GACN,MACF,CACF,EAAQ,sBAAsB,CAAC,IAAI,CAAC,EAAc,IAClD,EAAQ,cAAc,CAAC,MAAM,CAAC,GAC9B,EAAQ,eAAe,CAAC,MAAM,CAAC,mBAAmB,CAChD,QACA,GAEF,GAAa,GACb,GAAsB,EACxB,MACE,GAAI,CACD,EAAW,KAAK,CAAG,EAAM,KAAK,CAC7B,EAAQ,aAAa,GACrB,GAAc,EAAS,GACvB,GAAa,GACb,EAAS,IAAI,GAAG,IAAI,CAAC,EAAU,EACnC,CAAE,MAAO,EAAM,CACb,EAAM,EACR,CACN,EAwC+B,GACxB,GAAmB,EAAW,EAAE,CACzC,EA2lBc,EACA,EACA,EACA,EAAA,CACA,CACN,EAEJ,GAAI,aAAiB,KAAM,MAAO,KAAO,EAAM,MAAM,GAErD,GACE,CAFF,EAAU,GAAe,EAAA,IAEX,KACX,OAAS,GAAW,MAArB,CAA8B,GAAe,EAAA,CAAQ,CAErD,MAAM,MACJ,oJACE,GAA8B,EAAQ,IAE5C,OAAO,CACT,CACA,GAAI,UAAa,OAAO,OAAO,CAE7B,CADA,IAAkB,EAAM,MAAM,CAE5B,MAAQ,CAAK,CAAC,EAAM,MAAM,CAAG,EAAE,EAC/B,CAAM,CAAC,EAAmB,WAAY,MAEtC,AAAO,KAAO,EACZ,MAAQ,EAAM,MAAM,EAAI,OAAS,GAEjC,EAAQ,aAAa,CADvB,EAEG,EAAO,EAAQ,WAAW,GAC3B,GAAc,EAAS,EAAM,EAAO,CAAC,GACrC,GAAmB,EAAA,EAEvB,EAAU,MAAQ,CAAK,CAAC,EAAE,CAAG,IAAM,EAAQ,EAG7C,GAAI,WAAc,OAAO,EAAO,OAAO,EACvC,GAAI,UAAa,OAAO,EACtB,OAAO,OAAO,QAAQ,CAAC,GACnB,IAAM,GAAS,CAAC,KAAa,EAAI,EAC/B,MACA,EACF,MAAa,EACX,YACA,CAAC,MAAa,EACZ,aACA,OACV,QAAI,IAAuB,EAAO,MAAO,IAArB,SACpB,GAAI,YAAe,OAAO,EAAO,CAC/B,GAAI,EAAM,QAAQ,GAAK,EACrB,OAAO,GACL,EACA,EACA,EACA,GAEJ,GAAI,EAAM,QAAQ,GAAK,EACrB,OACG,AAED,KAAK,KADJ,CACU,CADW,GADd,EAAQ,uBAAA,AAAuB,EACZ,GAAG,CAAC,EAAA,EAE1B,EAAU,KAAO,EAAmB,QAAQ,CAAC,KAE7C,CADD,CAEE,QAFA,CAES,CAFY,EAAM,OAAA,AAAO,EAG9B,KACA,QAAQ,OAAO,CAAC,GACrB,EAAU,GACT,EACA,CAAE,GAAI,EAAM,IAAI,CAAE,MAAO,CAAmB,EAC5C,GAEF,EAAK,GAAG,CAAC,EAAO,GACf,EAAU,KAAO,EAAQ,QAAQ,CAAC,GAAA,CAAI,CAC3C,EAEJ,GACE,KAAK,IAAM,EAAQ,mBAAmB,EACe,EAArD,GAA0D,KAAxD,CAA8D,CAApD,EAAQ,IAAmD,eAAhC,CAAC,GAAG,CAAC,EAAA,EAE5C,MAAO,KAAO,EAChB,GAAI,EAAM,QAAQ,GAAK,EACrB,MAAM,MACJ,0IAEJ,GAAI,WAAW,IAAI,CAAC,GAClB,MAAM,MACJ,6DACE,GAA8B,EAAQ,GACtC,uFAEN,OAAM,MACJ,4LACE,GAA8B,EAAQ,GAE5C,CACA,GAAI,UAAa,OAAO,EAAO,CAG7B,GAAI,KAAK,KADT,CACe,CADI,CADnB,EAAO,EAAQ,cAAc,AAAd,EACS,GAAG,CAAC,EAAA,EAE1B,OAAO,GAAmB,GAE5B,GAAI,OAAO,GAAG,CAAC,AADf,EAAmB,EAAM,WAAW,IACC,EACnC,MAAM,MACJ,+GACG,EAAD,AAAO,WAAW,CAAG,yCAAyC,CAC9D,GAA8B,EAAQ,IAW5C,OATA,EAAQ,aAAa,GACrB,EAAqB,EAAQ,WAAW,GACxC,EAAS,GACP,EACA,EACA,KAAO,GAET,EAAQ,qBAAqB,CAAC,IAAI,CAAC,GACnC,EAAK,GAAG,CAAC,EAAO,GACT,GAAmB,EAC5B,CACA,GAAI,UAAa,OAAO,EAAO,MAAO,KAAO,EAAM,QAAQ,CAAC,GAC5D,OAAM,MACJ,QACE,OAAO,EACP,+CACA,GAA8B,EAAQ,GAE5C,CACA,SAAS,GAAoB,CAAO,CAAE,CAAK,EACzC,IAAI,EAAc,GAClB,GAAiB,KACjB,GAAI,CACF,IAAI,EAAU,EAAQ,OAAO,CACzB,EAAc,EACd,EAAe,GAAG,CAAC,KAAK,EAAG,EAAS,GACpC,EAAQ,EACd,QAAU,CACR,GAAiB,CACnB,CACA,GAAI,MAAQ,GAAe,UAAa,OAAO,EAC7C,MAAM,MACJ,iMACE,OAAO,EACP,aAEN,OAAO,GAAe,EACxB,CACA,SAAS,GAAW,CAAO,CAAE,CAAK,EAEhC,GADmB,EAAQ,YAAA,AAAY,EAC1B,GACb,OAAS,EAAQ,WAAW,EACtB,CAAF,CAAU,MAAM,CAAG,GAAK,EAAe,EAAQ,WAAW,CAAE,EAAA,CAAM,EAChE,EAAF,AAAU,MAAM,CAAG,GAAM,EAAQ,UAAU,CAAG,CAAA,CAAM,CACxD,EAAQ,eAAe,CAAC,KAAK,CAC3B,MAAM,+CAAgD,CAAE,MAAO,CAAM,GAEzE,CACA,SAAS,GAAe,CAAO,CAAE,CAAE,CAAE,CAAM,EACzC,EAAS,CAAE,OAAQ,CAAO,EAE1B,EAAK,EADL,EAAK,EAAG,QAAQ,AACG,CADF,IAAM,KAAO,GAAU,GAAU,MAElD,EAAQ,oBAAoB,CAAC,IAAI,CAAC,EACpC,CACA,SAAS,GAAe,CAAO,CAAE,CAAE,CAAE,CAAI,EAEvC,EAAK,EADL,EAAK,EAAG,QACW,AADH,CAAC,IAAM,IAAM,EAAO,MAEpC,EAAQ,sBAAsB,CAAC,IAAI,CAAC,EACtC,CACA,SAAS,GAAoB,CAAO,CAAE,CAAE,CAAE,CAAG,CAAE,CAAU,CAAE,CAAK,EAC9D,EAAQ,EAAQ,kBAAkB,GAAK,EAAQ,aAAa,GAM5D,EAAQ,CALR,EAAa,IAAI,WACf,EAAW,MAAM,CACjB,EAAW,UAAU,CACrB,EAAW,WAAU,EAEJ,UAAU,CAE7B,EAAK,EADL,EAAK,EAAG,QAAQ,AACG,CADF,IAAM,IAAM,EAAM,EAAM,QAAQ,CAAC,IAAM,KAExD,EAAQ,sBAAsB,CAAC,IAAI,CAAC,EAAI,EAC1C,CACA,SAAS,GAAc,CAAO,CAAE,CAAE,CAAE,CAAI,CAAE,CAAK,EAC7C,GAAI,OAAS,EACX,MAAM,MACJ,2FAEJ,GAAQ,EAAQ,kBAAkB,GAAK,EAAQ,aAAa,GAE5D,EAAQ,CADR,EAAO,EAAc,EAAA,EACR,UAAU,CAEvB,EAAK,EADL,EAAK,EAAG,QACW,AADH,CAAC,IAAM,KAAO,EAAM,QAAQ,CAAC,IAAM,KAEnD,EAAQ,sBAAsB,CAAC,IAAI,CAAC,EAAI,EAC1C,CACA,SAAS,GAAU,CAAO,CAAE,CAAI,CAAE,CAAK,EACrC,IAAI,EAAK,EAAK,EAAE,CAChB,UAAa,OAAO,GAAS,OAAS,EAClC,GAAc,EAAS,EAAI,EAAO,CAAC,GACnC,aAAiB,YACf,GAAoB,EAAS,EAAI,IAAK,IAAI,WAAW,GAAQ,CAAC,GAC9D,aAAiB,UACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,WACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,kBACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,WACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,YACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,WACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,YACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,aACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,aACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,cACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,eACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,GAC9C,aAAiB,SACf,GAAoB,EAAS,EAAI,IAAK,EAAO,CAAC,IAC5C,CAAF,CAAU,GAAU,EAAO,EAAK,MAAM,EACtC,GAAe,EAAS,EAAK,EAAE,CAAE,EAAA,CAAM,AACvE,CACA,SAAS,GAAY,CAAO,CAAE,CAAI,CAAE,CAAK,EACvC,EAAK,MAAM,CAAG,EACd,EAAQ,GAAoB,EAAS,EAAO,GAC5C,GAAe,EAAS,EAAK,EAAE,CAAE,GACjC,EAAQ,cAAc,CAAC,MAAM,CAAC,GAC9B,GAAsB,EACxB,CACA,IAAI,GAAY,CAAC,EACjB,SAAS,GAAU,CAAO,CAAE,CAAI,EAC9B,GAAI,IAAM,EAAK,MAAM,CAAE,CACrB,EAAK,MAAM,CAAG,EACd,IAAI,EAAuB,GAC3B,GAAI,CACF,GAAY,EAAK,KAAK,CACtB,IAAI,EAAgB,GAClB,EACA,EACA,GACA,GACA,EAAK,KAAK,EAKZ,GAHA,GAAY,EACZ,EAAK,OAAO,CAAG,KACf,EAAK,YAAY,CAAG,CAAC,EACjB,UAAa,OAAO,GAAiB,OAAS,EAChD,EAAQ,cAAc,CAAC,GAAG,CAAC,EAAe,GAAmB,EAAK,EAAE,GAClE,GAAU,EAAS,EAAM,OACxB,CACH,IAAI,EAAO,GAAU,GACrB,GAAe,EAAS,EAAK,EAAE,CAAE,EACnC,CACA,EAAK,MAAM,CAAG,EACd,EAAQ,cAAc,CAAC,MAAM,CAAC,GAC9B,GAAsB,EACxB,CAAE,MAAO,EAAa,CACpB,GAAI,KAAO,EAAQ,MAAM,CACvB,GACG,EAAQ,cAAc,CAAC,MAAM,CAAC,GAC9B,EAAK,MAAM,CAAG,EACf,KAAO,EAAQ,IAAI,CAEnB,GAAS,GAAO,GAAiB,EAAM,OACpC,CACH,IAAI,EAAU,EAAQ,UAAU,CAChC,GAAU,GACV,GAAkB,EAAM,EAAS,EACnC,KACG,CACH,IAAI,EACF,IAAgB,EACZ,IACA,EACN,GACE,UAAa,OAAO,GACpB,OAAS,GACT,YAAe,OAAO,EAAE,IAAI,CAC5B,CACA,EAAK,MAAM,CAAG,EACd,EAAK,aAAa,CAAG,KACrB,IAAI,EAAO,EAAK,IAAI,CACpB,EAAE,IAAI,CAAC,EAAM,EACf,MAAO,GAAY,EAAS,EAAM,EACpC,CACF,QAAU,CACR,GAAiB,CACnB,CACF,CACF,CACA,SAAS,GAAc,CAAO,CAAE,CAAI,EAClC,IAAI,EAAuB,GAC3B,GAAI,CACF,GAAU,EAAS,EAAM,EAAK,KAAK,CACrC,QAAU,CACR,GAAiB,CACnB,CACF,CACA,SAAS,GAAY,CAAO,EAC1B,IAAI,EAAiB,GAA2B,CAAC,CACjD,GAA2B,CAAC,CAAG,GAC/B,IAAI,EAAc,GAClB,GAAmB,GAAiB,EACpC,GAAI,CACF,IAAI,EAAc,EAAQ,WAAW,CACrC,EAAQ,WAAW,CAAG,EAAE,CACxB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAY,MAAM,CAAE,IACtC,GAAU,EAAS,CAAW,CAAC,EAAE,EACnC,GAAqB,EACvB,CAAE,MAAO,EAAO,CACd,GAAoB,EAAS,EAAO,MAAO,GAAW,EAAS,EACjE,QAAU,CACP,GAA2B,CAAC,CAAG,EAC7B,GAAmB,KACnB,GAAiB,CACtB,CACF,CACA,SAAS,GAAU,CAAI,EACrB,IAAM,EAAK,MAAM,GAAK,CAAD,CAAM,MAAM,CAAG,CAAC,CACvC,CACA,SAAS,GAAkB,CAAI,CAAE,CAAO,CAAE,CAAO,EAC/C,IAAM,EAAK,MAAM,GACb,CAAF,CAAY,GAAmB,GAC9B,EAAO,GAAqB,EAAS,EAAK,EAAE,CAAE,GAC/C,EAAQ,oBAAoB,CAAC,IAAI,CAAC,EAAA,CAAK,AAC3C,CACA,SAAS,GAAS,CAAI,EACpB,IAAM,EAAK,MAAM,GAAK,CAAD,CAAM,MAAM,EAAG,CAAC,AACvC,CACA,SAAS,GAAiB,CAAI,CAAE,CAAO,EACrC,IAAM,EAAK,MAAM,EAAI,EAAQ,aAAa,EAC5C,CACA,SAAS,GAAqB,CAAO,EACnC,IAAI,EAAc,EAAQ,WAAW,CACrC,GAAI,OAAS,EAAa,CACxB,EAAc,IAAI,WAAW,MAC7B,EAAe,EACf,GAAI,CACF,IACE,IAAI,EAAgB,EAAQ,qBAAqB,CAAE,EAAI,EACvD,EAAI,EAAc,MAAM,CACxB,IAEA,EAAQ,aAAa,GACnB,EAAoB,EAAa,CAAa,CAAC,EAAE,EACrD,EAAc,MAAM,CAAC,EAAG,GACxB,IAAI,EAAa,EAAQ,mBAAmB,CAC5C,IAAK,EAAI,EAAG,EAAI,EAAW,MAAM,CAAE,IACjC,EAAoB,EAAa,CAAU,CAAC,EAAE,EAChD,EAAW,MAAM,CAAC,EAAG,GACrB,IAAI,EAAgB,EAAQ,sBAAsB,CAClD,IAAK,EAAI,EAAG,EAAI,EAAc,MAAM,CAAE,IACpC,EAAQ,aAAa,GACnB,EAAoB,EAAa,CAAa,CAAC,EAAE,EACrD,EAAc,MAAM,CAAC,EAAG,GACxB,IAAI,EAAc,EAAQ,oBAAoB,CAC9C,IAAK,EAAI,EAAG,EAAI,EAAY,MAAM,CAAE,IAClC,EAAQ,aAAa,GACnB,EAAoB,EAAa,CAAW,CAAC,EAAE,EACnD,EAAY,MAAM,CAAC,EAAG,EACxB,QAAU,CACP,EAAQ,cAAc,CAAG,CAAC,EACzB,GACE,EAAI,IACH,EAAY,OAAO,CAClB,EADF,EACM,WAAW,EAAY,MAAM,CAAE,EAAG,IAEvC,EAAc,KACd,GAAe,CAAE,AACxB,CACF,CACA,IAAM,EAAQ,aAAa,GACxB,CAAD,EAAM,EAAQ,MAAM,EAClB,EAAQ,eAAe,CAAC,KAAK,CAC3B,MACE,oHAGN,OAAS,EAAQ,WAAW,GACxB,CAAF,CAAU,MAAM,CAAG,GACnB,EAAQ,WAAW,CAAC,KAAK,GACxB,EAAQ,WAAW,CAAG,IAAA,CAAK,CAAC,AACnC,CACA,SAAS,GAAU,CAAO,EACxB,EAAQ,cAAc,CAAG,OAAS,EAAQ,WAAW,CACrD,EACI,EAAkB,WAChB,EAAe,GAAG,CAAC,EAAS,GAAa,EAC3C,GACA,EAAkB,WAChB,OAAO,GAAY,EACrB,GACJ,WAAW,WACT,KAAO,EAAQ,MAAM,GAAK,CAAD,CAAS,MAAM,CAAG,EAAA,CAAE,AAC/C,EAAG,EACL,CACA,SAAS,GAAa,CAAO,EAC3B,CAAC,IAAM,EAAQ,cAAc,EAC3B,IAAM,EAAQ,WAAW,CAAC,MAAM,EAChC,OAAS,EAAQ,WAAW,GAC1B,CAAF,CAAU,cAAc,CAAG,CAAC,EAC5B,WAAW,WACT,EAAQ,cAAc,CAAG,CAAC,EAC1B,GAAqB,EACvB,EAAG,EAAA,CAAE,AACT,CACA,SAAS,GAAsB,CAAO,EACpC,IAAM,EAAQ,cAAc,CAAC,IAAI,EAC7B,EAAF,CAAY,EAAQ,UAAU,AAAV,EAAa,CACrC,CACA,OAF8C,EAErC,GAAa,CAAO,CAAE,CAAW,EACxC,GAAI,KAAO,EAAQ,MAAM,CACtB,EAAQ,MAAM,CAAG,GAAK,EAAe,EAAa,EAAQ,UAAU,OAClE,GAAI,KAAO,EAAQ,MAAM,EAAI,OAAS,EAAQ,WAAW,CAAE,CAC9D,EAAQ,WAAW,CAAG,EACtB,GAAI,CACF,GAAqB,EACvB,CAAE,MAAO,EAAO,CACd,GAAoB,EAAS,EAAO,MAAO,GAAW,EAAS,EACjE,CACF,CACF,CAyBA,SAAS,GAAM,CAAO,CAAE,CAAM,EAC5B,GAAI,CAAC,CAAC,GAAK,EAAQ,MAAA,AAAM,EACvB,GAAI,CACF,EAAQ,MAAM,CAAG,GACjB,EAAQ,eAAe,CAAC,KAAK,CAAC,GAC9B,IAAI,EAAiB,EAAQ,cAAc,CAC3C,GAAI,EAAI,EAAe,IAAI,CACzB,GAAI,KAAO,EAAQ,IAAI,CACrB,EAAe,OAAO,CAAC,SAAU,CAAI,EACnC,OAAO,GAAS,EAAM,EACxB,GACE,WAAW,WAlCrB,GAAI,CACF,AAkCqC,EAlCxB,OAAO,CAAC,SAAU,CAAI,EACjC,OAAO,GAAiB,IAC1B,EADgC,CAGhC,GADiB,EAAQ,UAAU,AAAV,IAEzB,GA6B4B,EA5B9B,CAAE,MAAO,EAAO,CACd,KAA6B,CAFR,CAEe,MAAO,KAAoB,EAA3C,AACtB,CA2BU,EAAG,CA5B2C,MA6B7C,CACH,IAAI,EACA,KAAK,IAAM,EACP,MACE,0DAEF,UAAa,OAAO,GAClB,OAAS,GACT,YAAe,OAAO,EAAO,IAAI,CACjC,MACE,wDAEF,EACR,EAAS,GAAoB,EAAS,EAAO,MAC7C,EAAU,EAAQ,WAAW,GAC/B,EAAQ,UAAU,CAAG,EACrB,EAAQ,aAAa,GACrB,GAAe,EAAS,EAAS,EAAQ,EAAO,CAAC,EAAG,MACpD,EAAe,OAAO,CAAC,SAAU,CAAI,EACnC,OAAO,GAAU,EAAM,EAAS,EAClC,GACA,WAAW,WA9CnB,GAAI,CA+CkC,AA9CpC,EAAa,OAAO,CAAC,SAAU,CAAI,EACjC,OAAO,GAAkB,IA6CyB,EA5CpD,AADiC,GAGjC,GADiB,EAAQ,CAFiB,SAEjB,AAAU,IAEnC,KACF,CAAE,MAAO,EAAO,CACd,GAuC2B,EAvCE,CAFR,CAEe,MAAO,KAAoB,EACjE,AADsB,CAwCd,EAAG,CAxC6C,CAyClD,KAGA,CADiB,IAAQ,UAAA,AAAU,IAEnC,GAAqB,EAEzB,CAAE,MAAO,EAAU,CACjB,GAAoB,EAAS,EAAU,MACrC,GAAW,EAAS,EACxB,CACJ,CACA,SAAS,GAAuB,CAAa,CAAE,CAAE,EAC/C,IAAI,EAAO,GACT,EAAqB,CAAa,CAAC,EAAG,CACxC,GAAI,EAAoB,EAAO,EAAmB,IAAI,KACjD,CACH,IAAI,EAAM,EAAG,WAAW,CAAC,KAIzB,GAHA,CAAC,IAAM,IACH,EAAO,CAAT,CAAY,KAAK,CAAC,EAAM,GACvB,EAAqB,CAAa,CAAC,EAAG,KAAK,CAAC,EAAG,GAAA,AAAM,EACpD,CAAC,EACH,MAAM,MACJ,8BACE,EACA,iGAER,CACA,OAAO,EAAmB,KAAK,CAC3B,CAAC,EAAmB,EAAE,CAAE,EAAmB,MAAM,CAAE,EAAM,EAAE,CAC3D,CAAC,EAAmB,EAAE,CAAE,EAAmB,MAAM,CAAE,EAAK,AAC9D,CACA,SAAS,GAAmB,CAAE,EAC5B,IAAI,EAAU,WAAW,gBAAgB,CAAC,SAC1C,AAAI,YAAe,OAAO,EAAQ,IAAI,EAAI,cAAgB,EAAQ,MAAM,CAC/D,CAAP,KACF,EAAQ,IAAI,CACV,SAAU,CAAK,EACb,EAAQ,MAAM,CAAG,YACjB,EAAQ,KAAK,CAAG,CAClB,EACA,SAAU,CAAM,EACd,EAAQ,MAAM,CAAG,WACjB,EAAQ,MAAM,CAAG,CACnB,GAEK,EACT,CACA,IAAI,GAAqB,IAAI,QAC3B,GAAe,IAAI,QACrB,SAAS,KAAgB,CACzB,SAAS,GAAc,CAAQ,EAC7B,IAAK,IAAI,EAAS,CAAQ,CAAC,EAAE,CAAE,EAAW,EAAE,CAAE,EAAI,EAAG,EAAI,EAAO,MAAM,CAAE,IAAK,CAC3E,IAAI,EAAW,WAAW,mBAAmB,CAAC,CAAM,CAAC,EAAE,EAEvD,GADA,GAAa,GAAG,CAAC,IAAa,EAAS,IAAI,CAAC,GACxC,CAAC,GAAmB,GAAG,CAAC,GAAW,CACrC,IAAI,EAAU,GAAa,GAAG,CAAC,IAAI,CAAC,GAAc,GAClD,EAAS,IAAI,CAAC,EAAS,IACvB,GAAmB,GAAG,CAAC,EACzB,CACF,CACA,OAAO,IAAM,EAAS,MAAM,CACxB,IAAM,EAAS,MAAM,CACnB,GAAmB,CAAQ,CAAC,EAAE,EAC9B,QAAQ,GAAG,CAAC,GAAU,IAAI,CAAC,WACzB,OAAO,GAAmB,CAAQ,CAAC,EAAE,CACvC,GACF,EAAI,EAAS,MAAM,CACjB,QAAQ,GAAG,CAAC,GACZ,IACR,CACA,SAAS,GAAc,CAAQ,EAC7B,IAAI,EAAgB,WAAW,gBAAgB,CAAC,CAAQ,CAAC,EAAE,EAC3D,GAAI,IAAM,EAAS,MAAM,EAAI,YAAe,OAAO,EAAc,IAAI,CACnE,GAAI,cAAgB,EAAc,MAAM,CACtC,EAAgB,EAAc,KAAK,MAChC,MAAM,EAAc,MAAM,OACjC,AAAI,MAAQ,CAAQ,CAAC,EAAE,CAAS,CAAP,CACrB,KAAO,CAAQ,CAAC,EAAE,CACb,CAAP,CAAqB,UAAU,CAAG,EAAc,OAAO,CAAG,EACxD,GAAe,IAAI,CAAC,EAAe,CAAQ,CAAC,EAAE,EACzC,CAAP,AAAoB,CAAC,CAAQ,CAAC,EAAE,CAAC,OACrC,CACA,IAAI,GAAkB,SACtB,SAAS,GAAa,CAAM,CAAE,CAAK,CAAE,CAAM,EACzC,IAAI,CAAC,MAAM,CAAG,EACd,IAAI,CAAC,KAAK,CAAG,EACb,IAAI,CAAC,MAAM,CAAG,CAChB,CACA,GAAa,SAAS,CAAG,OAAO,MAAM,CAAC,QAAQ,SAAS,EACxD,GAAa,SAAS,CAAC,IAAI,CAAG,SAAU,CAAO,CAAE,CAAM,EAKrD,OAHO,mBADC,IAAI,CAAC,MAAM,EAEf,GAAqB,IAAI,EAErB,IAAI,CAAC,MAAM,EACjB,IAAK,YACH,GAAI,YAAe,OAAO,EAAS,CACjC,IACE,IAAI,EAAiB,IAAI,CAAC,KAAK,CAC7B,EAAkB,EAClB,EAAU,IAAI,IAChB,aAA0B,IAE1B,CAEA,GADA,IAEE,IAAmB,IAAI,EACvB,EAAQ,GAAG,CAAC,IACZ,IAAM,EACN,CACA,YAAe,OAAO,GACpB,EAAO,MAAM,kCACf,MACF,CAEA,GADA,EAAQ,GAAG,CAAC,GACR,cAAgB,EAAe,MAAM,CACvC,EAAiB,EAAe,KAAK,MAClC,KACP,CACA,EAAQ,IAAI,CAAC,KAAK,CACpB,CACA,KACF,KAAK,UACL,IAAK,UACH,YAAe,OAAO,IACnB,OAAD,AAAU,IAAI,CAAC,KAAK,GAAK,CAAD,GAAK,CAAC,KAAK,CAAG,EAAA,AAAE,EAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,EAAA,CAAQ,CACrE,YAAe,OAAO,IACnB,MAAD,CAAU,IAAI,CAAC,MAAM,GAAK,CAAD,GAAK,CAAC,MAAM,CAAG,EAAA,AAAE,EAAG,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,EAAA,CAAO,CACvE,KACF,SACE,YAAe,OAAO,GAAU,EAAO,IAAI,CAAC,MAAM,CACtD,CACF,EACA,IAAI,GAAkB,OAAO,SAAS,CACpC,GAAiB,MAAM,SAAS,CAClC,SAAS,GAAU,CAAQ,CAAE,CAAS,CAAE,CAAK,CAAE,CAAK,EAClD,IAAK,IAAI,EAAI,EAAG,EAAI,EAAU,MAAM,CAAE,IAAK,CACzC,IAAI,EAAW,CAAS,CAAC,EAAE,CAC3B,YAAe,OAAO,EAClB,EAAS,GACT,GAAiB,EAAU,EAAU,EAAO,EAAM,MAAM,CAC9D,CACF,CACA,SAAS,GAAY,CAAQ,CAAE,CAAS,CAAE,CAAK,EAC7C,IAAK,IAAI,EAAI,EAAG,EAAI,EAAU,MAAM,CAAE,IAAK,CACzC,IAAI,EAAW,CAAS,CAAC,EAAE,CAC3B,YAAe,OAAO,EAClB,EAAS,GACT,GAAgB,EAAU,EAAS,OAAO,CAAE,EAClD,CACF,CACA,SAAS,GAAoB,CAAQ,CAAE,CAAK,CAAE,CAAK,EACjD,GAAI,YAAc,EAAM,MAAM,EAAI,YAAc,EAAM,MAAM,CAC1D,EAAM,MAAM,CAAC,KAAK,CAAC,OAChB,CACH,IAAI,EAAY,EAAM,MAAM,CAC5B,EAAM,MAAM,CAAG,WACf,EAAM,MAAM,CAAG,EACf,OAAS,GAAa,GAAY,EAAU,EAAW,EACzD,CACF,CACA,SAAS,GAAyB,CAAQ,CAAE,CAAK,CAAE,CAAE,EACnD,IAAI,EAAoB,CAAC,EACzB,OAAO,IAAI,GACT,iBACA,GACE,EAAkB,EAApB,AAAsB,CAAG,EACxB,CAAiB,CAAC,GAAgB,CAAG,EACtC,CAAA,CAAiB,CAErB,CACA,SAAS,GAAkB,CAAQ,CAAE,CAAK,CAAE,CAAK,CAAE,CAAE,EACnD,GAAI,YAAc,EAAM,MAAM,CAC3B,EAAQ,EAAM,MAAM,CACnB,MAAQ,CAAK,CAAC,EAAE,CACZ,EAAM,KAAK,CAAC,MAAQ,EAAQ,eAAiB,EAAM,KAAK,CAAC,IACzD,EAAM,YAAY,CAAC,OACtB,CACH,IAAI,EAAmB,EAAM,KAAK,CAChC,EAAkB,EAAM,MAAM,CAMhC,GALA,EAAM,MAAM,CAAG,iBACf,EAAM,KAAK,CAAG,EACd,EAAQ,CAAC,EACT,EAAM,MAAM,EACR,CAAF,CAAQ,EAAE,CAAG,EAAM,CAAK,CAAC,GAAgB,CAAG,EAAW,CAAA,CAAK,CAC1D,OAAS,EACX,OAAS,GAAqB,GAAQ,EAAM,MAAM,EAChD,IAAK,YACH,GAAU,EAAU,EAAkB,EAAM,KAAK,CAAE,GACnD,KACF,KAAK,UACL,IAAK,UACH,GAAI,EAAM,KAAK,CACb,IAAK,EAAW,EAAG,EAAW,EAAiB,MAAM,CAAE,IACrD,EAAM,KAAK,CAAC,IAAI,CAAC,CAAgB,CAAC,EAAS,OAC1C,EAAM,KAAK,CAAG,EACnB,GAAI,EAAM,MAAM,EAAE,AAChB,GAAI,EACF,IACE,EAAmB,EACnB,EAAmB,EAAgB,MAAM,CACzC,IAEA,EAAM,MAAM,CAAC,IAAI,CAAC,CAAe,CAAC,EAAiB,CAAA,MAClD,EAAM,MAAM,CAAG,EACtB,KACF,KAAK,WACH,GACE,GAAY,EAAU,EAAiB,EAAM,MAAM,CACzD,CACJ,CACF,CACA,SAAS,GAAkC,CAAQ,CAAE,CAAK,CAAE,CAAI,EAC9D,IAAI,EAAoB,CAAC,EACzB,OAAO,IAAI,GACT,iBACA,CAAC,EAAO,wBAA0B,wBAAA,CAAwB,CAAI,EAAQ,KACtE,AAAE,EAAkB,EAAE,CAAG,CAAC,EACzB,CAAiB,CAAC,GAAgB,CAAG,EACtC,CAAA,CAAiB,CAErB,CACA,SAAS,GAA2B,CAAQ,CAAE,CAAK,CAAE,CAAK,CAAE,CAAI,EAC9D,GACE,EACA,EACA,CAAC,EAAO,wBAA0B,wBAAA,CAAwB,CAAI,EAAQ,IACtE,CAAC,EAEL,CACA,SAAS,GAAsB,CAAQ,CAAE,CAAQ,CAAE,CAAY,CAAE,CAAG,EAClE,SAAS,EAAO,CAAK,EACnB,IAAI,EAAkB,EAAe,MAAM,AAE3C,EADE,CACa,MAAM,CAAG,WACxB,EAAe,KAAK,CAAG,KACvB,AAHmB,EAGJ,MAAM,CAAG,EACxB,OAAS,GAAmB,GAAY,EAAU,EAAiB,GACnE,GAAgB,EAAU,EAAS,EACrC,CACA,IAAI,EAAK,EAAS,EAAE,CACpB,GAAI,UAAa,OAAO,GAAM,SAAW,EAAK,OAAO,KACrD,IAAI,EAAgB,EAAS,SAAS,CACtC,GAAI,KAAK,IAAM,QACb,AAAI,OADwB,OACR,EAAc,MAAM,EACtC,AACG,EAAgB,EAAc,KAAK,CACpC,cAAgB,EAAM,KAAQ,CAAY,CAAC,EAAI,CAAG,CAAA,GAEtD,IACM,EAAK,GAAsB,EAAG,IAAI,EAAA,CAAE,CACrC,EAAK,CADN,EAEE,CAAE,MAAO,KAAM,MAAO,KAAM,OAAQ,KAAM,KAAM,EAAG,QAAS,CAAC,CAAE,EACrE,EAAc,IAAI,CAChB,GAAiB,IAAI,CAAC,KAAM,EAAU,EAAI,EAAc,GACxD,GAAgB,IAAI,CAAC,KAAM,EAAU,IAEhC,MAET,IAAI,EAAiB,IAAI,GAAa,UAAW,KAAM,MACvD,EAAS,SAAS,CAAG,EACrB,IAAI,EAAkB,GAAuB,EAAS,cAAc,CAAE,GAEtE,GADA,EAAgB,EAAS,KAAK,CACzB,EAAK,GAAc,GACtB,aAAyB,KACtB,EAAK,QAAQ,CAAd,EAAiB,CAAC,CAAC,EAAI,GAAc,CAAC,MACrC,KAAI,aAAyB,EAAA,EAGhC,OACG,EAAgB,GAAc,GAE9B,CADA,EAAK,CAAA,EACF,MAAM,CAAG,YACZ,EAAG,KAAK,CAAG,EANd,EAAK,QAAQ,OAAO,CAAC,GAQvB,GAAI,GAAqB,CACvB,IAAI,EAAU,GACd,EAAQ,IAAI,EACd,MACE,EAAU,GAAsB,CAC9B,MAAO,KACP,MAAO,KACP,OAAQ,KACR,KAAM,EACN,QAAS,CAAC,CACZ,EA4BF,OA3BA,EAAG,IAAI,CAAC,WACN,IAAI,EAAgB,GAAc,GAClC,GAAI,EAAS,KAAK,CAAE,CAClB,IAAI,EAAe,EAAS,KAAK,CAAC,KAAK,CAEvC,GAAI,IADJ,AACU,GADK,GAAY,GAAgB,EAAa,KAAK,CAAC,GAAK,EAAA,AAAE,EAC9C,MAAM,CAAE,YAC7B,EACE,MACE,0DACE,EAAa,MAAM,CACnB,4BAKR,EAAa,OAAO,CAAC,MACrB,EAAgB,EAAc,IAAI,CAAC,KAAK,CAAC,EAAe,EAC1D,CACA,EAAe,EAAe,KAAK,CACV,AACzB,EAAmB,MAAM,CAAG,YAC5B,EAAmB,KAAK,CAAG,EAC3B,EAAmB,MAAM,CAAG,KAC5B,OAAS,GACP,GAAU,EAAU,EAAc,KACpC,GAAiB,EAAU,EAAS,EAAc,CADC,CACI,EACzD,EAAG,GACI,IACT,CA8DA,SAAS,GAAe,CAAY,CAAE,CAAK,CAAE,CAAQ,EACnD,GACE,CAAC,EAAa,KAAK,EAAI,CAAA,CAAK,CAAI,EAAS,eAAe,EACxD,EAAa,IAAI,CAEjB,MAAM,MACJ,yGAEN,CACA,IAAI,GAAsB,KAC1B,SAAS,GAAqB,CAAK,EACjC,IAAI,EAAc,GAClB,GAAsB,KACtB,IAAI,EAAgB,EAAM,MAAM,CAC9B,EAAW,CAAa,CAAC,GAAgB,CAE3C,EAAgB,CAAC,KADjB,CACuB,CADP,EAAc,EAAA,AAAE,EACO,KAAK,EAAI,EAAc,QAAQ,CAAC,IACvE,IAAI,EAAgB,EAAM,KAAK,CAC/B,EAAM,MAAM,CAAG,UACf,EAAM,KAAK,CAAG,KACd,EAAM,MAAM,CAAG,KACf,GAAI,CACF,IAAI,EAAW,KAAK,KAAK,CAAC,GAC1B,EAAgB,CAAE,MAAO,EAAG,KAAM,CAAC,CAAE,EACrC,IAAI,EArFR,AAqFgB,SArFP,EACP,CAAQ,CACR,CAAS,CACT,CAAS,CACT,CAAK,CACL,CAAS,CACT,CAAS,EAET,GAAI,UAAa,OAAO,EACtB,OAAO,AAukBX,SAAS,AAAiB,CAAQ,CAAE,CAAG,CAAE,CAAG,CAAE,CAAK,CAAE,CAAS,CAAE,CAAS,EACvE,GAAI,MAAQ,CAAK,CAAC,EAAE,CAAE,CACpB,OAAQ,CAAK,CAAC,EAAE,EACd,IAAK,IACH,OACE,OAAS,GACP,GAAe,EAAW,EAAM,MAAM,CAAG,EAAG,GAC9C,EAAM,KAAK,CAAC,EAEhB,KAAK,IACH,OAA6C,GAAS,EAA9C,EAAM,MAAkD,GAAzC,EAAM,KAAK,CAAC,GAAI,IACzC,KAAK,IACH,OAEE,GACE,EAFD,EAAY,EAAM,IAGjB,CAHsB,CAAC,GAIvB,EACA,EACA,KACA,GAGN,KAAK,cACH,GAAI,KAAK,IAAM,GAAa,KAAK,IAAM,EAAS,oBAAoB,CAClE,MAAM,MACJ,0IAEJ,OAphF0B,AAohFnB,EACL,EAAS,eArhFkC,KAqhFd,CArhFgB,EAAE,AAshF/C,EA7gFR,EAAY,IAAI,MAAM,AARlB,EAAY,OAAO,gBAAgB,CACrC,WACE,MAAM,MACJ,0OAEJ,EACA,CAAE,SAAU,CAAE,MAAO,CAAwB,CAAE,GAEhB,GACjC,EAAoB,GAAG,CAAC,EAAW,GAC5B,CA6gFH,KAAK,IACH,OAEE,GAAiB,EADhB,EAAY,EAAM,IACQ,CADH,CAAC,GACa,EAAK,EAAK,KAAM,GAE1D,KAAK,IACH,OAEE,GAAiB,EADhB,EAAY,EAAM,IACQ,CADH,CAAC,GACa,EAAK,EAAK,KAAM,GAE1D,KAAK,IAMH,IALA,EAAM,EAAM,KAAK,CAAC,GAClB,EAAM,EAAS,OAAO,CAAG,EAAM,IAC/B,EAAM,IAAI,SAEV,EAAY,MAAM,IAAI,CAAC,CADvB,EAAW,EAAS,SAAA,AAAS,EACG,IAAI,IAC/B,EAAQ,EAAG,EAAQ,EAAU,MAAM,CAAE,IACxC,GAAqC,CAA/B,EAAY,CAAS,CAAC,EAAA,AAAM,EAAa,UAAU,CAAC,GAAO,CAC/D,IACE,IAAI,EAAU,EAAS,MAAM,CAAC,GAC5B,EAAS,EAAU,KAAK,CAAC,EAAI,MAAM,EACnC,EAAI,EACN,EAAI,EAAQ,MAAM,CAClB,IAEA,EAAI,MAAM,CAAC,EAAQ,CAAO,CAAC,EAAE,EAC/B,EAAS,MAAM,CAAC,EAClB,CACF,OAAO,CACT,KAAK,IACH,OAEE,GAAiB,EADhB,EAAY,EAAM,IACQ,CADH,CAAC,GACa,EAAK,EAAK,KAAM,GAE1D,KAAK,IACH,OAAO,GACT,KAAK,IACH,MAAO,QAAU,EAAQ,CAAC,EAAI,CAAC,GACjC,KAAK,IACH,OAAO,GACT,KAAK,IACH,MACF,KAAK,IACH,OAAO,IAAI,KAAK,KAAK,KAAK,CAAC,EAAM,KAAK,CAAC,IACzC,KAAK,IAEH,GAAI,IADJ,AACU,GADJ,EAAM,KAAK,CAAC,EAAA,EACJ,MAAM,CAClB,MAAM,MACJ,iCACE,EAAI,MAAM,CACV,iCAGN,OADA,OAAS,GAAa,GAAe,EAAW,EAAI,MAAM,CAAE,GACrD,OAAO,EAChB,KAAK,IACH,OAAO,GACL,EACA,EACA,YACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,UACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,WACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,kBACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,WACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,YACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,WACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,YACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,aACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,aACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,cACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,eACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OAAO,GACL,EACA,EACA,SACA,EACA,EACA,EACA,EAEJ,KAAK,IACH,OACG,EAAM,SAAS,EAAM,KAAK,CAAC,GAAI,IAChC,EAAS,SAAS,CAAC,GAAG,CAAC,EAAS,OAAO,CAAG,EAE9C,KAAK,IACH,OAAO,GAAoB,EAAU,EAAO,KAAK,EACnD,KAAK,IACH,OAAO,GAAoB,EAAU,EAAO,QAC9C,KAAK,IACH,OAAO,GAAmB,EAAU,EAAO,CAAC,EAC9C,KAAK,IACH,OAAO,GAAmB,EAAU,EAAO,CAAC,EAChD,CAEA,OAAO,GAAiB,EADxB,EAAQ,EAAM,IACoB,CADf,CAAC,GACqB,EAAK,EAAK,EAAW,GAChE,CAEA,OADA,OAAS,GAAa,GAAe,EAAW,EAAM,MAAM,CAAE,GACvD,CACT,EAjzBM,EACA,EACA,EACA,EACA,EACA,GAEJ,GAAI,UAAa,OAAO,GAAS,OAAS,EACxC,GACG,KAAK,IAAM,GACV,KAAK,IAAM,EAAS,oBAAoB,EACxC,EAAS,oBAAoB,CAAC,GAAG,CAAC,EAAO,GAC3C,GAAY,GACZ,CACA,GAAI,OAAS,EAAW,CACtB,IAAI,EAAe,CAAE,MAAO,EAAG,KAAM,CAAC,CAAE,EACxC,EAAS,kBAAkB,CAAC,GAAG,CAAC,EAAO,EACzC,MAAO,EAAe,EAGtB,IAFA,EAAI,EAAM,MAAM,GAAK,CAAD,CAAc,IAAI,CAAG,EAAC,CAAC,CAC3C,GAAe,EAAc,EAAM,MAAM,CAAG,EAAG,GAC1C,EAAY,EAAG,EAAY,EAAM,MAAM,CAAE,IAC5C,CAAK,CAAC,EAAU,CAAG,EACjB,EACA,EACA,GAAK,EACL,CAAK,CAAC,EAAU,CAChB,KAAK,IAAM,EAAY,EAAY,IAAM,EAAY,KAAK,EAC1D,EAEN,MACE,IAAK,KAAgB,EACnB,GAAe,IAAI,CAAC,EAAO,KACxB,YAAD,EAAiB,EACb,OAAO,CAAK,CAAC,EAAa,EACxB,CAAF,CACE,KAAK,IAAM,GAAa,CAAC,IAAM,EAAa,OAAO,CAAC,KAChD,EAAY,IAAM,EAClB,KAAK,EASX,KAAK,KARJ,CAQU,CARE,EACX,EACA,EACA,EACA,CAAK,CAAC,EAAa,CACnB,EACA,KAAA,EAGG,CAAK,CAAC,EAAa,CAAG,EACvB,OAAO,CAAK,CAAC,EAAA,CAAa,CAAC,CAC3C,OAAO,CACT,EA0BQ,EACA,CAAE,GAAI,CAAS,EACf,GACA,EACA,EACA,GAEF,EAAmB,EAAM,KAAK,CAChC,GAAI,OAAS,EACX,IACE,EAAM,KAAK,CAAG,KAAM,EAAM,MAAM,CAAG,KAAM,EAAW,EACpD,EAAW,EAAiB,MAAM,CAClC,IACA,CACA,IAAI,EAAW,CAAgB,CAAC,EAAS,CACzC,YAAe,OAAO,EAClB,EAAS,GACT,GAAiB,EAAU,EAAU,EAAO,EAClD,CACF,GAAI,OAAS,GAAqB,CAChC,GAAI,GAAoB,OAAO,CAAE,MAAM,GAAoB,MAAM,CACjE,GAAI,EAAI,GAAoB,IAAI,CAAE,CAChC,GAAoB,KAAK,CAAG,EAC5B,GAAoB,MAAM,CAAG,EAC7B,GAAoB,KAAK,CAAG,EAC5B,MACF,CACF,CACA,EAAM,MAAM,CAAG,YACf,EAAM,KAAK,CAAG,EACd,EAAM,MAAM,CAAG,CACjB,CAAE,MAAO,EAAO,CACb,EAAM,MAAM,CAAG,WAAc,EAAM,MAAM,CAAG,CAC/C,QAAU,CACR,GAAsB,CACxB,CACF,CACA,SAAS,GAAkB,CAAQ,CAAE,CAAK,EACxC,EAAS,OAAO,CAAG,CAAC,EACpB,EAAS,aAAa,CAAG,EACzB,EAAS,OAAO,CAAC,OAAO,CAAC,SAAU,CAAK,EACtC,YAAc,EAAM,MAAM,CACtB,GAAoB,EAAU,EAAO,GACrC,cAAgB,EAAM,MAAM,EAC5B,OAAS,EAAM,MAAM,EAErB,EADA,UACe,MAAO,CADpB,EAAQ,EAAM,MAAM,AAAN,EACY,KAAK,EAAI,EAAM,KAAK,CAAC,EACvD,EACF,CACA,CAH+D,QAGtD,GAAS,CAAQ,CAAE,CAAE,EAC5B,IAAI,EAAS,EAAS,OAAO,CAC3B,EAAQ,EAAO,GAAG,CAAC,GAUrB,OATA,IACI,AACD,EACC,GAFF,OAEe,OAAO,EAFZ,EAAS,SAAS,CAAC,GAAG,CAAC,EAAS,OAAO,CAAG,EAAA,EAG9C,GAAyB,EAAU,EAAO,GAC1C,EAAS,OAAO,CACd,IAAI,GAAa,WAAY,KAAM,EAAS,aAAa,EACzD,IAAI,GAAa,UAAW,KAAM,MAC1C,EAAO,GAAG,CAAC,EAAI,EAAA,CAAM,CAChB,CACT,CACA,SAAS,GAAiB,CAAQ,CAAE,CAAS,CAAE,CAAK,CAAE,CAAS,EAC7D,IAAI,EAAU,EAAU,OAAO,CAC7B,EAAe,EAAU,YAAY,CACrC,EAAM,EAAU,GAAG,CACnB,EAAM,EAAU,GAAG,CACnB,EAAO,EAAU,IAAI,CACvB,GAAI,CACF,IACE,IAAI,EAAc,EAChB,EAAoB,EAAS,kBAAkB,CAC/C,EAAI,EACN,EAAI,EAAK,MAAM,CACf,IACA,CACA,IAAI,EAAO,CAAI,CAAC,EAAE,CAClB,GACE,UAAa,OAAO,GACpB,OAAS,GACR,GAAe,KAAW,IACzB,GAAe,KAAW,IAC5B,CAAC,GAAe,IAAI,CAAC,EAAO,GAE5B,MAAM,MAAM,sBAEd,GADA,EAAQ,CAAK,CAAC,EAAK,CACf,GAAY,GACb,EAAc,EACZ,EAAY,EAAkB,GAAG,CAAC,IAAU,OAC5C,GAAM,EAAY,KAAO,UAAa,OAAO,EAChD,EAAc,EAAM,MAAM,MACvB,GAAI,UAAa,OAAO,EAAO,CAClC,IAAI,EAAI,KAAK,GAAG,CAAC,OAAO,IACxB,EAAc,IAAM,EAAI,EAAI,KAAK,KAAK,CAAC,KAAK,KAAK,CAAC,IAAM,CAC1D,MAAO,EAAc,YAAY,MAAM,CAAC,GAAS,EAAM,UAAU,CAAG,CACtE,CACA,IAAI,EAAgB,EAAI,EAAU,EAAO,EAAc,GACnD,EAAqB,EAAU,SACnC,AAD4C,QACnC,IACN,OAAS,GACL,EAAU,IAAI,EADnB,CACI,AAAoB,CAAD,CAAoB,IAAI,CAAG,EAAC,CAAC,CAChD,GAAe,EAAoB,EAAU,KAAK,CAAE,EAAA,CAAS,CAC7D,EAAI,GACJ,GAAe,EAAoB,EAAa,EAAA,CAAS,AACjE,CAAE,MAAO,EAAO,CACd,GAAgB,EAAU,EAAS,GACnC,MACF,CACA,GAAiB,EAAU,EAAS,EAAc,EAAK,EACzD,CACA,SAAS,GAAiB,CAAQ,CAAE,CAAO,CAAE,CAAY,CAAE,CAAG,CAAE,CAAa,EAC3E,cAAgB,IAAQ,CAAY,CAAC,CAAd,CAAkB,CAAG,CAAA,CAAa,CACzD,KAAO,GAAO,OAAS,EAAQ,KAAK,GAAK,CAAD,CAAS,KAAK,CAAG,CAAA,CAAa,CACtE,EAAQ,IAAI,GACZ,IAAM,EAAQ,IAAI,EAEhB,EADA,MAAE,CACO,CADQ,EAAQ,KAAA,AAAK,GAE5B,YAAc,EAAa,MAAM,GAC/B,CAAF,CAAQ,EAAa,KAAK,CACzB,EAAa,MAAM,CAAG,YACtB,EAAa,KAAK,CAAG,EAAQ,KAAK,CAClC,EAAa,MAAM,CAAG,EAAQ,MAAM,CACrC,OAAS,GAAO,GAAU,EAAU,EAAK,EAAQ,KAAK,CAAE,EAAA,CAAa,AAC3E,CAD4E,AAE5E,SAAS,GAAgB,CAAQ,CAAE,CAAO,CAAE,CAAK,EAC/C,EAAQ,OAAO,GACX,CAAF,CAAU,OAAO,CAAG,CAAC,EACpB,EAAQ,KAAK,CAAG,KAChB,EAAQ,MAAM,CAAG,EAElB,OADC,EACQ,CADE,EAAQ,KAAA,AAAK,GAEtB,YAAc,EAAQ,MAAM,EAC5B,GAAoB,EAAU,EAAS,EAAA,CAAM,AACnD,CACA,SAAS,GACP,CAAQ,CACR,CAAS,CACT,CAAY,CACZ,CAAG,CACH,CAAkB,CAClB,CAAG,EAGH,IAAI,EAAK,SAAS,CADlB,EAAY,EAAU,KAAK,CAAC,IAAA,CACD,CAAC,EAAE,CAAE,IAC9B,EAAQ,GAAS,EAAU,GAK7B,OAHO,mBADC,EAAM,MAAM,EAEhB,GAAqB,GAEjB,EAAM,MAAM,EAClB,IAAK,YACH,EAAK,EAAM,KAAK,CAChB,EAAQ,EAAM,MAAM,CACpB,IACE,IAAI,EAAc,EAChB,EAAoB,EAAS,kBAAkB,CAC/C,EAAI,EACN,EAAI,EAAU,MAAM,CACpB,IACA,CAEA,GADA,EAAc,CAAS,CAAC,EAAE,CAExB,UAAa,OAAO,GACpB,OAAS,GACR,GAAe,KAAQ,IACtB,GAAe,KAAQ,IACzB,CAAC,GAAe,IAAI,CAAC,EAAI,GAEzB,MAAM,MAAM,sBAEd,GADA,EAAK,CAAE,CAAC,EAAY,GACR,AACN,EAAc,EAAK,EAArB,AAA6B,EAAkB,GAAG,CAAC,IAAO,CAAA,CAAM,EAC9D,EAAF,AAAU,KAEL,EADL,UAAa,OAAO,EACD,EAAG,MAAM,CACxB,UAAa,OAAO,EAGhB,GAFF,CAAE,EAEM,CAFQ,KAAK,GAAG,CAAC,OAAO,GAAA,EAG1B,CAFL,CAGK,KAAK,KAAK,CAAC,KAAK,KAAK,CAAC,IAAgB,CAAE,CAC/B,GAAd,SAA0B,MAAM,CAAC,GAAM,EAAG,UAAU,EAAG,CAAE,AACtE,CAQA,OAPA,EAAe,EAAI,EAAU,EAAI,EAAc,GAC/C,OAAS,GACN,QAAS,GACL,EAAM,GAAP,CAAW,EADf,CACoB,CAAD,CAAoB,IAAI,CAAG,EAAC,CAAC,CAC5C,GAAe,EAAoB,EAAM,KAAK,CAAE,EAAA,CAAS,CACzD,EAAI,GACJ,GAAe,EAAoB,EAAa,EAAA,CAAS,CACxD,CACT,KAAK,UACH,OACE,IACM,EAAW,GAAsB,EAAS,IAAI,EAAA,CAAE,CACjD,EAAW,CADZ,EAEE,CAAE,MAAO,KAAM,MAAO,KAAM,OAAQ,KAAM,KAAM,EAAG,QAAS,CAAC,CAAE,EACpE,EAAqB,CACpB,QAAS,EACT,aAAc,EACd,IAAK,EACL,IAAK,EACL,KAAM,EACN,UAAW,CACb,EACA,OAAS,EAAM,KAAK,CACf,EAAM,KAAK,CAAG,CAAC,EAAmB,CACnC,EAAM,KAAK,CAAC,IAAI,CAAC,GACrB,OAAS,EAAM,MAAM,CAChB,EAAM,MAAM,CAAG,CAAC,EAAmB,CACpC,EAAM,MAAM,CAAC,IAAI,CAAC,GACtB,IAEJ,KAAK,UACH,MAAM,MAAM,6BACd,SACE,OACE,IACM,GAAoB,OAAO,CAAG,CAAC,EAChC,GAAoB,CADrB,IAC0B,CAAG,KAC5B,GAAoB,MAAM,CAAG,EAAM,MAAA,AAAO,EAC1C,GAAsB,CACrB,MAAO,KACP,MAAO,KACP,OAAQ,EAAM,MAAM,CACpB,KAAM,EACN,QAAS,CAAC,CACZ,EACJ,IAEN,CACF,CACA,SAAS,GAAU,CAAQ,CAAE,CAAK,EAChC,GAAI,CAAC,GAAY,GAAQ,MAAM,MAAM,4BACrC,GAAI,CAAC,IAAM,EAAM,UAAU,CAAE,MAAM,MAAM,4BAGzC,OAFA,EAAW,IAAI,IAAI,GACnB,EAAM,UAAU,CAAG,CAAC,EACb,CACT,CACA,SAAS,GAAU,CAAQ,CAAE,CAAK,EAChC,GAAI,CAAC,GAAY,GAAQ,MAAM,MAAM,4BACrC,GAAI,CAAC,IAAM,EAAM,UAAU,CAAE,MAAM,MAAM,4BAGzC,OAFA,EAAW,IAAI,IAAI,GACnB,EAAM,UAAU,CAAG,CAAC,EACb,CACT,CACA,SAAS,GAAgB,CAAQ,CAAE,CAAK,EACtC,GAAI,CAAC,GAAY,GAAQ,MAAM,MAAM,iCACrC,GAAI,CAAC,IAAM,EAAM,UAAU,CAAE,MAAM,MAAM,iCAGzC,OAFA,EAAW,CAAK,CAAC,OAAO,QAAQ,CAAC,GACjC,EAAM,UAAU,CAAG,CAAC,EACb,CACT,CACA,SAAS,GAAY,CAAQ,CAAE,CAAK,CAAE,CAAY,CAAE,CAAG,EACrD,MAAO,SAAW,GAAO,YAAe,OAAO,EAAQ,KAAO,CAChE,CACA,SAAS,GACP,CAAQ,CACR,CAAS,CACT,CAAW,CACX,CAAe,CACf,CAAY,CACZ,CAAS,CACT,CAAkB,EAElB,SAAS,EAAO,CAAK,EACnB,GAAI,CAAC,EAAQ,OAAO,CAAE,CACpB,EAAQ,OAAO,CAAG,CAAC,EACnB,EAAQ,KAAK,CAAG,KAChB,EAAQ,MAAM,CAAG,EACjB,IAAI,EAAQ,EAAQ,KAAK,AACzB,QAAS,GACP,YAAc,EAAM,MAAM,EAC1B,GAAoB,EAAU,EAAO,EACzC,CACF,CACA,EAAY,SAAS,EAAU,KAAK,CAAC,GAAI,IACzC,IAAI,EAAM,EAAS,OAAO,CAAG,EAE7B,GAAI,CADJ,EAAkB,EAAS,OAAA,AAAO,EACd,GAAG,CAAC,GACtB,MAAM,MAAM,oCAUd,GATA,EAAgB,GAAG,CACjB,EACA,IAAI,GACF,WACA,KACA,MAAM,sCAGV,EAAY,EAAS,SAAS,CAAC,GAAG,CAAC,GAAK,WAAW,GAC/C,GAAqB,CACvB,IAAI,EAAU,GACd,EAAQ,IAAI,EACd,MACE,EAAU,GAAsB,CAC9B,MAAO,KACP,MAAO,KACP,OAAQ,KACR,KAAM,EACN,QAAS,CAAC,CACZ,EA2BF,OA1BA,EAAU,IAAI,CAAC,SAAU,CAAM,EAC7B,GAAI,CACF,OAAS,GACP,GAAe,EAAoB,EAAO,UAAU,CAAE,GACxD,IAAI,EACF,IAAgB,YAAc,EAAS,IAAI,EAAY,GACzD,cAAgB,IAAQ,CAAY,CAAC,CAAd,CAAwB,CAAG,CAAA,CAAa,CAC/D,KAAO,GACL,OAAS,EAAQ,KAAK,GACrB,CAAD,CAAS,KAAK,CAAG,CAAA,CAAa,AAClC,CAAE,MAAO,EAAG,CACV,EAAO,GACP,MACF,CACA,EAAQ,IAAI,GACZ,IAAM,EAAQ,IAAI,EAEhB,EADA,MAAE,CACO,CADE,EAAQ,KAAA,AAAK,GAEtB,YAAc,EAAO,MAAM,GACzB,CAAF,CAAkB,EAAO,KAAK,CAC7B,EAAO,MAAM,CAAG,YAChB,EAAO,KAAK,CAAG,EAAQ,KAAK,CAC5B,EAAO,MAAM,CAAG,KACjB,OAAS,GACP,GAAU,EAAU,EAAe,EAAQ,KAAK,CAAE,EAAA,CAAO,AACjE,CADkE,CAC/D,GACI,IACT,CACA,SAAS,GAAc,CAAQ,CAAE,CAAE,CAAE,CAAM,CAAE,CAAU,EACrD,IAAI,EAAS,EAAS,OAAO,CAI7B,IAHA,EAAS,IAAI,GAAa,YAAa,EAAQ,GAC/C,EAAO,GAAG,CAAC,EAAI,GACf,EAAW,EAAS,SAAS,CAAC,MAAM,CAAC,EAAS,OAAO,CAAG,GACnD,EAAK,EAAG,EAAK,EAAS,MAAM,CAAE,IAE/B,UAAa,OADd,AACqB,EADZ,CAAQ,CAAC,EAAA,AAAG,IAElB,AAAC,MAAQ,CAAM,CAAC,EAAE,CACd,EAAW,KAAK,CAAC,MAAQ,EAAS,eAAiB,EAAO,KAAK,CAAC,IAChE,EAAW,YAAY,CAAC,EAAA,CACpC,AAD2C,CAE3C,SAAS,GAAoB,CAAQ,CAAE,CAAS,CAAE,CAAI,EACpD,SAAS,EAAQ,CAAK,EACpB,UAAY,GAAQ,YAAY,MAAM,CAAC,GACnC,EAAW,OAAO,CAAC,GACnB,EAAiB,KAAK,CAAC,MAAM,kCACnC,CAEA,GADA,EAAY,SAAS,EAAU,KAAK,CAAC,GAAI,IACrC,EAAS,OAAO,CAAC,GAAG,CAAC,GACvB,MAAM,MAAM,+BACd,IAAI,EAAa,KACf,EAAS,CAAC,EACV,EAAS,IAAI,eAAe,CAC1B,KAAM,EACN,MAAO,SAAU,CAAC,EAChB,EAAa,CACf,CACF,GACA,EAAuB,KACvB,EAAmB,CACjB,aAAc,SAAU,CAAI,EAC1B,GAAI,OAAS,EAAsB,CACjC,IAAI,EAAQ,GAAyB,EAAU,EAAM,CAAC,GACtD,GAAqB,GACrB,cAAgB,EAAM,MAAM,CACxB,EAAQ,EAAM,KAAK,GAClB,CAAD,CAAO,IAAI,CAAC,EAAS,EAAiB,KAAK,EAC1C,EAAuB,CAAA,CAAM,AACpC,KAAO,CACL,EAAQ,EACR,IAAI,EAAW,IAAI,GAAa,UAAW,KAAM,MACjD,EAAS,IAAI,CAAC,EAAS,EAAiB,KAAK,EAC7C,EAAuB,EACvB,EAAM,IAAI,CAAC,WACT,IAAyB,IAAa,EAAuB,IAAA,CAAI,CAA5B,AACrC,GAAkB,EAAU,EAAU,EAAM,CAAC,EAC/C,EACF,CACF,EACA,MAAO,WACL,GAAI,CAAC,EACH,GAAM,EAAS,CAAC,EAAI,OAAS,EAC3B,EAAW,KAAK,OACb,CACH,IAAI,EAAe,EACnB,EAAuB,KACvB,EAAa,IAAI,CAAC,WAChB,OAAO,EAAW,KAAK,EACzB,EACF,CACJ,EACA,MAAO,SAAU,CAAK,EACpB,GAAI,CAAC,EACH,GAAM,EAAS,CAAC,EAAI,OAAS,EAC3B,EAAW,KAAK,CAAC,OACd,CACH,IAAI,EAAe,EACnB,EAAuB,KACvB,EAAa,IAAI,CAAC,WAChB,OAAO,EAAW,KAAK,CAAC,EAC1B,EACF,CACJ,CACF,EAEF,OADA,GAAc,EAAU,EAAW,EAAQ,GACpC,CACT,CACA,SAAS,GAAe,CAAI,EAC1B,IAAI,CAAC,IAAI,CAAG,CACd,CAKA,SAAS,GAAmB,CAAQ,CAAE,CAAS,CAAE,CAAQ,EAEvD,GADA,EAAY,SAAS,EAAU,KAAK,CAAC,GAAI,IACrC,EAAS,OAAO,CAAC,GAAG,CAAC,GACvB,MAAM,MAAM,+BACd,IAAI,EAAS,EAAE,CACb,EAAS,CAAC,EACV,EAAiB,EACjB,EAAoB,CAAC,EAkFvB,OAhFI,CAAiB,CAAC,EAAe,CAAG,WACpC,IAAI,EAAgB,EACpB,OAAO,IAAI,GAAe,SAAU,CAAG,EACrC,GAAI,KAAK,IAAM,EACb,MAAM,MACJ,oFAEJ,GAAI,IAAkB,EAAO,MAAM,CAAE,CACnC,GAAI,EACF,OAAO,IAAI,GACT,YACA,CAAE,KAAM,CAAC,EAAG,MAAO,KAAK,CAAE,EAC1B,MAEJ,CAAM,CAAC,EAAc,CAAG,IAAI,GAAa,UAAW,KAAM,KAC5D,CACA,OAAO,CAAM,CAAC,IAAgB,AAChC,EACF,EAGF,CAFE,EAEY,EAAU,EADxB,EAAW,EAAW,CAAiB,CAAC,EAAe,CACpB,EADyB,AADzC,EAE0B,CAC3C,aAAc,SAAU,CAAK,EAC3B,IAAmB,EAAO,MAAM,CAC3B,CAAM,CAAC,EAAe,CAAG,GACxB,EACA,EACA,CAAC,GAEH,GACE,EACA,CAAM,CAAC,EAAe,CACtB,EACA,CAAC,GAEP,GACF,EACA,MAAO,SAAU,CAAK,EACpB,GAAI,CAAC,EACH,IACE,EAAS,CAAC,EACR,IAAmB,EAAO,MAAM,CAC3B,CAAM,CAAC,EAAe,CAAG,GACxB,EACA,EACA,CAAC,GAEH,GACE,EACA,CAAM,CAAC,EAAe,CACtB,EACA,CAAC,GAEP,IACF,EAAiB,EAAO,MAAM,EAG9B,GACE,EACA,CAAM,CAAC,IAAiB,CACxB,eACA,CAAC,EAET,EACA,MAAO,SAAU,CAAK,EACpB,GAAI,CAAC,EACH,IACE,EAAS,CAAC,EACR,IAAmB,EAAO,MAAM,GAC7B,CAAD,AAAO,CAAC,EAAe,CAAG,IAAI,GAC5B,UACA,KACA,KAAA,CACD,CACL,EAAiB,EAAO,MAAM,EAG9B,GAAoB,EAAU,CAAM,CAAC,IAAiB,CAAE,EAC9D,CACF,GACO,CACT,CA6OA,SAAS,GAAe,CAAa,CAAE,CAAe,CAAE,CAAmB,EACzE,IAAI,EACA,EAAI,UAAU,MAAM,EAAI,KAAK,IAAM,SAAS,CAAC,EAAE,CAC3C,SAAS,CAAC,EAAE,CACZ,IAAI,SACV,EACE,EAAI,UAAU,MAAM,EAAI,KAAK,IAAM,SAAS,CAAC,EAAE,CAAG,SAAS,CAAC,EAAE,CAAG,IAErE,CADE,KACK,CACL,eAAgB,EAChB,QAAS,EACT,UAAW,EACX,QALS,CAKA,GALI,IAMb,QAAS,CAAC,EACV,cAAe,KACf,qBAAsB,EACtB,mBAAoB,IAAI,QACxB,gBAAiB,CACnB,CACF,CACA,SAAS,GAAM,CAAQ,EACrB,GAAkB,EAAU,MAAM,sBACpC,CACA,SAAS,GAAoB,CAAa,CAAE,CAAQ,EAClD,IAAI,EAAK,EAAS,EAAE,CACpB,GAAI,UAAa,OAAO,EAAI,OAAO,KACnC,IAAI,EAAkB,GAAuB,EAAe,GAG5D,OAFA,EAAgB,GAAc,GAEvB,CADP,EAAW,EAAS,KAAA,AAAK,YACE,QACvB,QAAQ,GAAG,CAAC,CAAC,EAAU,EAAc,EAAE,IAAI,CAAC,SAAU,CAAI,EACxD,EAAO,CAAI,CAAC,EAAE,CACd,IAAI,EAAK,GAAc,GACvB,GAAI,IAAM,EAAK,MAAM,CACnB,MAAM,MACJ,0DACE,EAAK,MAAM,CACX,2BAEN,OAAO,EAAG,IAAI,CAAC,KAAK,CAAC,EAAI,CAAC,KAAK,CAAC,MAAM,CAAC,GACzC,GACA,EACE,QAAQ,OAAO,CAAC,GAAe,IAAI,CAAC,WAClC,OAAO,GAAc,EACvB,GACA,QAAQ,OAAO,CAAC,GAAc,GACtC,CACA,SAAS,GACP,CAAI,CACJ,CAAc,CACd,CAAe,CACf,CAAc,EAYd,GAHA,GAPA,EAAO,CAOD,EANJ,EACA,EACA,KAAK,EACL,EACA,IAIF,CADA,EAAO,GAAS,EAAM,EAAA,EACjB,IAAI,CAAC,WAAa,GACnB,cAAgB,EAAK,MAAM,CAAE,MAAM,EAAK,MAAM,CAClD,OAAO,EAAK,KACd,AADmB,CA3YnB,GAAe,SAAS,CAAG,CAAC,EAC5B,GAAe,SAAS,CAAC,EAAe,CAAG,WACzC,OAAO,IAAI,AACb,EA0YA,EAAQ,uBAAuB,CAAG,SAAU,CAAQ,EAElD,OAAO,IAAI,MADX,AACiB,EADN,EAA4B,CAAC,EAAG,EAAU,CAAC,GAC3B,EAC7B,EACA,EAAQ,2BAA2B,CAAG,WACpC,OAAO,IAAI,OACb,EACA,EAAQ,YAAY,CAAG,SAAU,CAAI,CAAE,CAAc,EACnD,IAAI,EAAW,IAAI,SACjB,EAAS,KACT,EAAc,IAAI,IAmBpB,OAlBA,EAAK,OAAO,CAAC,SAAU,CAAK,CAAE,CAAG,EAC/B,EAAI,UAAU,CAAC,YACX,EAAI,UAAU,CAAC,gBACb,EAAY,GAAG,CAAC,IACf,GAAY,CAAb,EAAgB,CAAC,GAEhB,EAAQ,GAA0B,EAAM,EADxC,EAAQ,WAAa,CACmC,CAD/B,KAAK,CAAC,IAAM,KAErC,EAAS,GAAoB,EAAgB,EAAA,CAAO,CACrD,EAAI,UAAU,CAAC,gBACf,CAAC,EAAY,GAAG,CAAC,KAChB,EAAY,CAAb,EAAgB,CAAC,GAEhB,EAAS,GAAoB,EAAgB,CAC5C,GAFD,CAEK,CAFG,EAAI,KAAK,CAAC,IAGjB,MAAO,IACT,EAAA,CAAG,CACL,EAAS,MAAM,CAAC,EAAK,EAC3B,GACO,OAAS,EACZ,KACA,EAAO,IAAI,CAAC,SAAU,CAAE,EACtB,OAAO,EAAG,IAAI,CAAC,KAAM,EACvB,EACN,EACA,EAAQ,eAAe,CAAG,SAAU,CAAY,CAAE,CAAI,CAAE,CAAc,EACpE,IAAI,EAAU,EAAK,GAAG,CAAC,eACvB,GAAI,UAAa,OAAO,EAAS,OAAO,QAAQ,OAAO,CAAC,MACxD,IAAI,EAAW,KAMf,GALA,EAAK,OAAO,CAAC,SAAU,CAAK,CAAE,CAAG,EAC/B,EAAI,UAAU,CAAC,iBACX,CACD,CADD,CACY,GAA0B,EAAM,EADlC,WAAa,EAAI,CACiC,IAD5B,CAAC,IAAM,IACqB,CAAO,AACvE,GACI,OAAS,EAAU,OAAO,QAAQ,OAAO,CAAC,MAC9C,IAAI,EAAc,EAAS,EAAE,CAC7B,OAAO,QAAQ,OAAO,CAAC,EAAS,KAAK,EAAE,IAAI,CAAC,SAAU,CAAK,EACzD,OAAO,OAAS,EACZ,KACA,CAAC,EAAc,EAAS,EAAa,EAAM,MAAM,CAAG,EAAE,AAC5D,EACF,EACA,EAAQ,WAAW,CAAG,SAAU,CAAI,CAAE,CAAY,CAAE,CAAO,EACzD,GAAI,UAAa,OAAO,EAAM,CAC5B,IAAI,EAAO,IAAI,SACf,EAAK,MAAM,CAAC,IAAK,GACjB,EAAO,CACT,CAUA,OAFA,EAAe,GAPf,EAAO,GACL,CAMsB,CALtB,GACA,EAAU,EAAQ,mBAAmB,CAAG,KAAK,EAC7C,EACA,EAAU,EAAQ,cAAc,CAAG,KAAK,GAEZ,GAC9B,GAAM,GACC,CACT,EACA,EAAQ,4BAA4B,CAAG,SACrC,CAAQ,CACR,CAAY,CACZ,CAAO,EAqBP,SAAS,EAAM,CAAM,EACnB,GAAkB,EAAU,GAC5B,YAAe,OAAO,EAAS,KAAK,EAClC,EAAS,KAAK,CAAC,GAAQ,IAAI,CAAC,EAAO,EACvC,CACA,IAAI,EAAW,CAAQ,CAAC,EAAe,GACrC,EAAW,GACT,EACA,GACA,EAAU,EAAQ,mBAAmB,CAAG,KAAK,EAC7C,KAAK,EACL,EAAU,EAAQ,cAAc,CAAG,KAAK,GAG5C,OADA,EAAS,IAAI,GAAG,IAAI,CAhCpB,AAgCqB,SAhCZ,EAAS,CAAK,EACrB,GAAI,EAAM,IAAI,CAAE,GAAM,OACjB,CAEH,IAAI,EAAO,AADX,GAAQ,EAAM,KAAA,AAAK,CACH,CAAC,EAAE,CAEnB,GAAI,UAAa,OADjB,AACwB,EADhB,CAAK,CAAC,EAAA,AAAE,EACe,CAC7B,EAAS,SAAS,CAAC,MAAM,CAAC,EAAM,GAChC,IAAI,EAAS,EAAS,OAAO,CAC7B,GAAI,EAAK,UAAU,CAAC,GAAS,CAC3B,IAAI,EAAS,EAAS,OAAO,CAC7B,EAAO,CAAC,EAAK,KAAK,CAAC,EAAO,MAAM,EAChC,AAAC,GAAS,EAAO,GAAG,CAAC,EAAA,CAAK,EACxB,GAAkB,EAAU,EAAQ,EAAO,EAC/C,CACF,MAAO,EAAS,SAAS,CAAC,MAAM,CAAC,EAAM,GACvC,EAAS,IAAI,GAAG,IAAI,CAAC,EAAU,EACjC,CACF,EAc+B,GACxB,GAAS,EAAU,EAC5B,EACA,EAAQ,SAAS,CAAG,SAAU,CAAK,CAAE,CAAY,CAAE,CAAO,EACxD,OAAO,IAAI,QAAQ,SAAU,CAAO,CAAE,CAAM,EAC1C,IAAI,EAAU,IAAI,GAChB,GACA,EACA,EACA,EAAU,EAAQ,OAAO,CAAG,KAAK,EACjC,WAcE,EAAQ,CAAE,QAbG,CAaM,GAbF,eACf,CACE,KAAM,QACN,KAAM,SAAU,CAAU,EACxB,GAAa,EAAS,EACxB,EACA,OAAQ,SAAU,CAAM,EACtB,EAAQ,WAAW,CAAG,KACtB,GAAM,EAAS,EACjB,CACF,EACA,CAAE,cAAe,CAAE,EAEK,EAC5B,EACA,EACA,EAAU,EAAQ,gBAAgB,CAAG,KAAK,EAC1C,EAAU,EAAQ,mBAAmB,CAAG,KAAK,GAE/C,GAAI,GAAW,EAAQ,MAAM,CAAE,CAC7B,IAAI,EAAS,EAAQ,MAAM,CAC3B,GAAI,EAAO,OAAO,CAAE,GAAM,EAAS,EAAO,MAAM,MAC3C,CACH,IAAI,EAAW,WACb,GAAM,EAAS,EAAO,MAAM,EAC5B,EAAO,mBAAmB,CAAC,QAAS,EACtC,EACA,EAAO,gBAAgB,CAAC,QAAS,EACnC,CACF,CACA,GAAU,EACZ,EACF,EACA,EAAQ,uBAAuB,CAAG,SAChC,CAAmB,CACnB,CAAE,CACF,CAAU,EAEV,OAAO,EACL,EACA,EAAK,IAAM,EACX,CAAC,EAEL,EACA,EAAQ,uBAAuB,CAAG,SAAU,CAAS,CAAE,CAAE,CAAE,CAAU,EACnE,OAAO,OAAO,gBAAgB,CAAC,EAAW,CACxC,SAAU,CAAE,MAAO,CAAqB,EACxC,KAAM,CACJ,MAAO,OAAS,EAAa,EAAK,EAAK,IAAM,EAC7C,aAAc,CAAC,CACjB,EACA,QAAS,CAAE,MAAO,KAAM,aAAc,CAAC,CAAE,EACzC,KAAM,CAAE,MAAO,EAAM,aAAc,CAAC,CAAE,EACtC,SAAU,CACZ,EACF,EACA,EAAQ,sBAAsB,CAAG,SAAU,CAAK,CAAE,CAAY,CAAE,CAAO,EACrE,IAAI,EAAU,IAAI,GAChB,GACA,EACA,EACA,EAAU,EAAQ,OAAO,CAAG,KAAK,EACjC,EACA,EACA,EAAU,EAAQ,gBAAgB,CAAG,KAAK,EAC1C,EAAU,EAAQ,mBAAmB,CAAG,KAAK,GAE/C,GAAI,GAAW,EAAQ,MAAM,CAAE,CAC7B,IAAI,EAAS,EAAQ,MAAM,CAC3B,GAAI,EAAO,OAAO,CAAE,GAAM,EAAS,EAAO,MAAM,MAC3C,CACH,IAAI,EAAW,WACb,GAAM,EAAS,EAAO,MAAM,EAC5B,EAAO,mBAAmB,CAAC,QAAS,EACtC,EACA,EAAO,gBAAgB,CAAC,QAAS,EACnC,CACF,CACA,OAAO,IAAI,eACT,CACE,KAAM,QACN,MAAO,WACL,GAAU,EACZ,EACA,KAAM,SAAU,CAAU,EACxB,GAAa,EAAS,EACxB,EACA,OAAQ,SAAU,CAAM,EACtB,EAAQ,WAAW,CAAG,KACtB,GAAM,EAAS,EACjB,CACF,EACA,CAAE,cAAe,CAAE,EAEvB,+BClhHA,IAAI,EAOJ,EAAQ,sBAAsB,CAAG,CAL/B,EAAA,EAAA,CAAA,CAAA,MAAA,EAKiC,sBAAsB,CACzD,EAAQ,WAAW,CAAG,EAAE,WAAW,CACnC,EAAQ,4BAA4B,CAAG,EAAE,4BAA4B,CACrE,EAAQ,YAAY,CAAG,EAAE,YAAY,CACrC,EAAQ,eAAe,CAAG,EAAE,eAAe,CAC3C,EAAQ,uBAAuB,CAAG,EAAE,uBAAuB,CAC3D,EAAQ,uBAAuB,CAAG,EAAE,uBAAuB,CAC3D,EAAQ,uBAAuB,CAAG,EAAE,uBAAuB,CAC3D,EAAQ,2BAA2B,CAAG,EAAE,2BAA2B,kBChBnE,GAAM,yBAAE,CAAuB,CAAE,CAAA,EAAA,CAAA,CAAA,MAEjC,EAAsB,CAAC,CAAC,EAAwB,2JAFhD,GAAM,CAAE,yBAAuB,CAAE,CAAA,EAAA,CAAA,CAAA,MAEjC,EAAsB,CAAC,CAAC,EAAwB,6T8BExC,EjBLR,EAAA,CAAA,CAAA,MAqE4B,KAMrB,SAAS,UAAU,WAAa,CAC/B,kBACH,CAAG,EAAE,CACT,CAmC2D,OAAO,AADd,aS/GrD,IUC0C,EVD1C,EAAA,CUC+C,CVD/C,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OAAA,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,MACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,MpBRA,EAAA,EAAA,CAAA,CAAA,MAGW,SAAS,EAAkB,CAAQ,QACrC,CAAA,EAAA,EAAA,aAAA,AAAa,EAAC,GAAY,IAAK,gBAAgB,AAIhD,AAAa,UAAU,EAD3B,EAAW,EAAS,OAAO,CAAC,0BAA2B,IAAI,OAAO,CAAC,UAAW,GAAA,EAEnE,IAEJ,CACX,CoBDA,CpBGA,GoBHA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OEXA,IAAA,EAAA,EAAA,CAAA,CAAA,OFaA,EAAA,CpBA+C,AoBA/C,CAAA,MACA,EAAA,CAAA,CAAA,OAEA,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,ONlBO,IAAM,EAA4B,OAAO,GAAG,CAAC,+BACvC,EAAqB,WSAlC,CTEA,GSFA,EAAA,EAAA,CAAA,CAAA,OHqBA,EAAA,EAAA,CAAA,CAAA,OnBtBA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,GaEiD,IbDjD,EAAA,CAAA,CAAA,MmB0BW,OAAM,EACb,YAAY,UAAE,CAAQ,CAAE,YAAU,SAAE,CAAO,CAAE,oBAAkB,CAAE,CAAC,CAC9D,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,UAAU,CAAG,EAClB,IAAI,CAAC,KAAK,EAAG,EACb,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,kBAAkB,CAAG,CAC9B,CACA,MAAM,EAJoC,4BAIN,CAAG,CAAE,GAAG,CAAI,CAAE,CACL,CACrC,GAAM,8BAAE,CAA4B,CAAE,CAAG,MAAA,QAAA,OAAA,GAAA,IAAA,CAAA,IAAA,EAAA,CAAA,CAAA,QACnC,EAAkB,MAAM,GAC1B,IACA,MAAM,CAAmC,MADxB,AACV,EAAgB,cAAc,CAAW,KAAK,EAAI,EAAgB,cAAc,CAAC,IAAI,CAAC,KAAoB,EAAA,CAAK,AAE9H,CAMJ,CACA,cAAc,CAAO,CAAE,CAAU,CAAE,CAC/B,IAAI,CACqC,EACrC,IAAI,EACJ,GAAM,qBAAE,CAAmB,CAAE,CAAA,EAAA,CAAA,CAAA,OACvB,EAAiB,AAAC,GAAM,EAAM,KAAK,KAAK,CAAC,QAAO,EACtD,EAAS,CACL,QAAS,QAAQ,GAAG,CAAC,eAAe,EAAI,GACxC,cAAe,KAAK,gBAAgB,CACpC,sBAAuB,CAAC,EACxB,sBAAuB,EAAe,KAAK,yBAAyB,EACpE,iBAAkB,EAAe,KAAK,oBAAoB,EAC1D,kBAAmB,CACf,OAAQ,CAAC,EACT,cAAe,CAAC,EAChB,eAAgB,EAAE,CAClB,QAAS,EACT,QAAS,GACb,EACA,eAAgB,CACZ,QAAS,EACT,cAAe,CAAA,EACf,SAA0C,CAAhC,EACV,SAAU,CAAA,0CAKV,IALyC,MAK9B,EAAE,CACb,QAAS,EAAE,CACX,MAAM,IAAkC,EACxC,uBAAuB,CAC3B,EACA,oBAAqB,KAAK,uBAAuB,CACjD,wBAAyE,AAAhD,OAAC,EAAuB,KAAK,cAAA,AAAc,EAAY,KAAK,EAAI,CAAoB,CAAC,EAAQ,CACtH,sBAAuB,EAAe,KAAK,qBAAqB,EAChE,6BAA8B,EAAe,KAAK,gCAAgC,EAClF,mBAAoB,EAAe,KAAK,sBAAsB,EAC9D,0BAA2B,CAAC,EAAe,KAAK,qCAAqC,GAAK,EAAA,AAAE,EAAE,GAAG,CAAC,AAAC,GAAU,IAAI,OAAO,EAAQ,KAAK,EACzI,CACJ,CA2GA,OAAO,CACX,CACA,MAAM,wBAAwB,CAAG,CAAE,CAAU,CAAE,CAe/C,CACA,MAAM,oBAAoB,CAAG,CAAE,CAAU,CAAE,CAAiB,CAAE,CAAa,CAAE,CAErE,OAAO,WAAW,kBAAkB,AA8B5C,CACA,MAAM,eAAe,CAAG,CAAE,CAAG,CAAE,CAAY,CAAE,CAAU,CAAE,CAAmB,CAAE,CACrE,KAC0B,MAAvB,CADS,CACqB,KAAK,EAAI,EAAoB,yBAAyB,AAAzB,EAA2B,AACtF,EAAoB,yBAAyB,CAAC,EAAK,WAEnD,QAAQ,KAAK,CAAC,IAGtB,MAAM,IAAI,CAAC,6BAA6B,CAAC,EAAK,EAAK,CAC/C,KAAM,EAAI,GAAG,EAAI,IACjB,QAAS,EAAI,OAAO,CACpB,OAAQ,EAAI,MAAM,EAAI,KAC1B,EAAG,EACP,CACwF,kBAAkB,CAAG,CAAE,KACvG,EAA+C,MAmB/C,EAXA,EAAsB,KAAK,uBAAuB,CAChD,EAAqB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,uBAAyB,IAAI,CAAC,kBAAkB,CACzF,EAAsB,AAAmG,OAAlG,EAAgD,CAAkB,CAAC,EAAA,AAA0B,EAAY,KAAK,EAAI,CAA6C,CAAC,EAAmB,CAC1M,EAAa,CAAC,AAAuB,QAAO,KAAK,EAAI,EAAoB,UAAA,AAAU,IAAM,AAAuB,CAAxB,OAA+B,KAAK,EAAI,EAAoB,MAAA,AAAM,EAChK,GAAI,CAAC,EACD,MAAM,IADO,GACA,cAAc,CAAC,AAAI,MAAM,4CAA6C,oBAAqB,CACpG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAGJ,GAA4D,AAAxD,OAAC,EAA2B,EAAW,YAAA,AAAY,EAAY,KAAK,EAAI,EAAyB,yBAAyB,CAEtH,CAFwH,KAElH,OAAO,cAAc,CAAC,AAAI,MAAM,sFAAuF,oBAAqB,CAC9I,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,UAIJ,EAAe,EAAW,YAAY,EAAI,GAEvC,YACH,eACA,CACJ,CACJ,CACA,MAAM,QAAQ,CAAG,CAAE,CAAG,CAAE,SAAE,CAAO,oBAAE,CAAkB,CAAE,CAAE,KACjD,EAA+C,MAC/C,EAmCA,EACA,EAyIA,EA+BA,EA9LE,EAAY,MAAM,IAAI,CAAC,aAAa,CAAC,EAAS,GAC9C,gBAAE,CAAc,mBAAE,CAAiB,qBAAE,CAAmB,CAAE,CAAG,EAC7D,CAAE,UAAQ,CAAE,MAAI,CAAE,UAAQ,CAAE,CAAG,CACjC,IACA,GAAI,GADM,AACH,CAAG,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,EAAI,GAAG,EAAI,IAAK,EAAA,EAE/C,IAAM,EAAY,CAAA,EAAA,EAAA,WAAA,AAAW,EAAC,EAAI,GAAG,EAAI,KAEzC,GAAI,CAAC,EACD,OAEJ,EAHgB,EAGZ,GAAoB,EACpB,CAAA,EAAA,EAAA,aAAA,AAAa,EAAC,EAAU,QAAQ,EAAI,IAAK,gBAAgB,CACzD,EAAoB,GACpB,EAAU,QAAQ,CAAG,EAAkB,EAAU,QAAQ,EAAI,MAEjE,IAAI,EAAmB,EAAU,QAAQ,EAAI,IACvC,EAAgB,CAClB,GAAG,EAAU,KACjB,AADsB,EAEhB,EAAgB,CAAA,EAAA,EAAA,cAAc,AAAd,EAAe,GAGjC,GACA,AACI,GADW,AADT,CACS,EAAA,EAAA,mBAAA,AAAmB,EAAC,EAAU,QAAQ,EAAI,IAAK,EAAK,QAAO,EACzD,cAAc,EAAE,CAC7B,EAAI,GAAG,CAAG,CAAA,EAAG,EAAa,QAAQ,CAAA,EAAG,EAAU,MAAM,CAAA,CAAE,CACvD,EAAmB,EAAa,QAAQ,CACpC,AAAC,IACD,EAAiB,EAAa,QADb,MACa,AAAc,GAOxD,IAAM,EAAoB,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,GACrC,EAAc,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,CAC/B,KAAM,EACN,gBACA,WACA,gBACA,EACA,aAAa,CAAA,CAAA,EACb,eAAe,CAAQ,EAAe,aAAa,AACvD,GACM,EAAe,CAAA,EAAA,EAAA,kBAAkB,AAAlB,EAA2B,MAAR,EAAe,KAAK,EAAI,EAAK,OAAO,CAAE,CAAA,EAAA,EAAA,WAAA,AAAW,EAAC,EAAW,EAAI,OAAO,EAAG,GACnH,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,kBAAkB,CAAQ,GAC9C,IAAM,EAAgB,CAAiB,MAAhB,EAAuB,KAAK,EAAI,EAAa,aAAA,AAAa,IAAc,CAAT,KAAC,EAAe,KAAK,EAAI,EAAK,aAAA,AAAa,EAG7H,GAAiB,CAAC,IAClB,EAAU,QAAQ,CAAG,CADa,AACZ,CAAC,EAAE,EAAA,EAAuC,MAAvB,EAAU,QAAQ,CAAW,GAAK,EAAU,QAAQ,CAAA,CAAA,AAAE,EAEnG,IAAM,EAAS,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,WAAa,GAAkB,EAG5D,eAAE,CAAa,CAAE,oBAAkB,CAAE,CAAG,EAAY,cAAc,CAAC,EAAK,GACxE,EAAmB,OAAO,IAAI,CAAC,GACrC,OAAO,MAAM,CAAC,EAAU,KAAK,CAAE,EAAmB,KAAK,EAGnD,IACA,EADM,AACI,QAAQ,CAAG,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,EAAU,QAAQ,EAAI,IAAK,EAAK,OAAO,EAAE,QAAQ,CAC1F,EAAmB,QAAQ,CAAG,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,EAAmB,QAAQ,EAAI,IAAK,EAAK,OAAO,EAAE,QAAQ,EAEhH,IAAI,EAAS,CAAA,EAAA,EAAA,cAAc,AAAd,EAAe,EAAK,UAEjC,GAAI,CAAC,GAAU,EAAY,mBAAmB,CAAE,CAC5C,IAAM,EAAc,EAAY,mBAAmB,CAAC,EAAkB,CAAC,AAAsB,QAAO,KAAK,EAAI,EAAmB,QAAA,AAAQ,GAAK,EAAU,QAAQ,EAAI,MAC7J,EAAe,EAAY,2BAA2B,CAAC,GAAe,CAAC,GAAG,GAC5E,EAAa,cAAc,EAAE,CAC7B,EAAS,EAAa,MAAA,AAAM,CAEpC,CASA,IAAM,EAAQ,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,UAAY,CAC1C,GAAG,EAAU,KAAK,AACtB,EACM,EAAiB,IAAI,IACrB,EAAoB,EAAE,CAK5B,GAAI,IAAI,CAAC,UAAU,CAAC,IAAI,GAAK,EAAA,SAAS,CAAC,KAAK,EAAI,IAAI,CAAC,UAAU,CAAC,IAAI,GAAK,EAAA,SAAS,CAAC,SAAS,CACxF,CAD0F,GACrF,IAAM,IAAO,IACX,KACA,OAAO,IAAI,CAAC,EAAY,mBAAmB,EAAI,CAAC,GACtD,CAAC,CAOE,IAAM,EAAgB,MAAM,OAAO,CAAC,CAAa,CAAC,EAAI,EAAI,CAAa,CAAC,EAAI,CAAC,IAAI,CAAC,IAAM,CAAa,CAAC,EAAI,CACpG,EAAa,MAAM,OAAO,CAAC,CAAK,CAAC,EAAI,EAAI,CAAK,CAAC,EAAI,CAAC,IAAI,CAAC,IAAM,CAAK,CAAC,EAAI,AAC3E,CAAC,AAAC,KAAO,GAAkB,IAAkB,GAC7C,EAAkB,CADI,GACA,CAAC,EAE/B,AAHiE,CAQrE,GAHA,EAAY,eAAe,CAAC,EAAK,GACjC,EAAY,oBAAoB,CAAC,EAAO,GACxC,EAAY,mBAAmB,CAAC,EAAe,GAC3C,EAAe,CACf,IAEI,EAFE,EAAc,EAAY,2BAA2B,CAAC,GAAO,GAC7D,EAAe,EAAY,2BAA2B,CAAC,GAAU,CAAC,GAAG,GAc3E,GAVA,GAAS,GAAU,EAAa,cAAc,EAAI,EAAY,cAAc,EAAI,OAAO,IAAI,CAAC,EAAa,MAAM,EAAE,MAAM,CAAG,OAAO,IAAI,CAAC,EAAY,MAAM,EAAE,MAAM,EAAE,AAC9J,EAAsB,EAAY,MAAM,CACxC,EAAS,OAAO,MAAM,CAAC,EAAY,MAAM,GAEzC,EAAsB,EAAa,cAAc,EAAI,EAAS,EAAS,EAAY,cAAc,CAAG,EAAQ,CAAC,EAEjH,EAAI,GAAG,CAAG,EAAY,sBAAsB,CAAC,EAAI,GAAG,EAAI,IAAK,GAC7D,EAAU,QAAQ,CAAG,EAAY,sBAAsB,CAAC,EAAU,QAAQ,EAAI,IAAK,GACnF,EAAmB,EAAY,sBAAsB,CAAC,EAAkB,GAEpE,CAAC,EACD,GAAI,EAAY,CADP,aACqB,CAI1B,CAJ4B,GAIxB,IAAM,KAHV,EAAS,OAAO,MAAM,CAAC,CAAC,EAAG,EAAY,MAAM,EAG5B,EAAY,mBAAmB,CAAC,AAC7C,OAAO,CAAK,CAAC,EAAI,KAElB,CAEH,IAAM,EAAiD,MAAnC,EAAY,mBAAmB,CAAW,KAAK,EAAI,EAAY,mBAAmB,CAAC,IAAI,CAAC,EAAa,EAAkB,AAAC,CAAgB,QAAO,KAAK,EAAI,EAAa,QAAA,AAAQ,GAAK,EAAU,QAAQ,EAAI,MAIxN,IACA,EAAS,OADI,AACG,MAAM,CAAC,CAAC,EAAG,EAAA,CAEnC,CAER,CAIA,IAAK,IAAM,KAAO,EACV,AAAE,CAAD,IAAQ,GACT,KAFyB,EAElB,CAAK,CAAC,CADS,CACL,CAGzB,CAJiC,EAI3B,sBAAE,CAAoB,yBAAE,CAAuB,CAAE,CAAG,CAAA,EAAA,EAAA,yBAAA,AAAyB,EAAC,EAAK,EAAkB,OAAO,EAS5G,GAAqB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,uBAAyB,IAAI,CAAC,kBAAkB,CACzF,GAAsB,AAAmG,OAAlG,EAAgD,CAAkB,CAAC,EAAA,AAA0B,EAAY,KAAK,EAAI,CAA6C,CAAC,GAAmB,CAC1M,GAAa,CAAwB,MAAvB,GAA8B,KAAK,EAAI,GAAoB,UAAA,AAAU,IAA6B,CAAxB,KAAC,EAA8B,KAAK,EAAI,EAAoB,MAAA,AAAM,EAChK,GAAI,CAAC,GACD,MAAM,GADO,IACA,cAAc,CAAC,AAAI,MAAM,4CAA6C,oBAAqB,CACpG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAI,GAAmB,EACnB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,KAAqB,IACpC,GAAmB,CADyB,CACb,sBAAsB,CAAC,GAAkB,EAAA,EAExE,AAAqB,UAAU,MAC/B,GAAmB,GAAA,EAEvB,IAAM,GAA0B,GAGhC,GAAI,CACA,GAAoC,AG5erC,GAAS,KAAK,CAAC,KAAK,EH4eA,CG5eG,CAAC,AAAC,IAC5B,GAAI,OGXiC,EHYN,KGZa,EAAE,YHYI,CGZS,EHYvD,EGXD,CHWqD,CGX7C,EHWD,KGXQ,CAAC,AAAI,OAAO,CAAC,MAAM,EAAE,gBAAgB,AAA2B,MAAQ,AAAD,GAAQ,WAAtB,GAAG,CAAC,CAAC,GAAoC,GHYpH,CAAE,MAAO,EAAG,CAER,MAAM,OAAO,cAAc,CAAC,IAAI,EAAA,WAAW,CAAC,mCAAoC,oBAAqB,CACjG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACA,OAAO,CACX,GAAG,IAAI,CAAC,IHieJ,CAAE,MAAO,EAAG,CAAC,CAGb,GAFA,GAAmB,CAAA,EAAA,EAAA,mBAAmB,AAAnB,EAAoB,IAEqB,AAAxD,OAAC,EAA2B,GAAW,YAAA,AAAY,EAAY,KAAK,EAAI,EAAyB,yBAAyB,CAEtH,CAFwH,KAElH,OAAO,cAAc,CAAC,AAAI,MAAM,sFAAuF,oBAAqB,CAC9I,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,UAIJ,EAAe,GAAW,YAAY,EAAI,GAEvC,OACH,gBACA,mBACA,SACA,YACA,SACA,oBACA,EACA,QAAS,AAAQ,QAAO,KAAK,EAAI,EAAK,OAAO,eAC7C,EACA,YAvDc,eAwDd,gBACA,mBACA,2BACA,wBACA,0BACA,EACA,GAAG,CAAS,CAGZ,WAAY,uBACZ,gBACA,CACJ,CACJ,CACA,iBAAiB,CAAG,CAAE,CAClB,GAAI,CAAC,IAAI,CAAC,aAAa,CAAE,CACrB,IAAM,EAAoD,AAAtC,AAAsC,CAArC,AAAqC,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,cAAc,GAAK,EACjG,IAAI,CAAC,aAAa,CAAG,IAAI,EAAA,OAAa,CAAC,EAC3C,CACA,OAAO,IAAI,CAAC,aAAa,AAC7B,CACA,MAAM,eAAe,CAAE,KAAG,YAAE,CAAU,UAAE,CAAQ,WAAE,CAAS,YAAE,CAAU,mBAAE,CAAiB,mBAAE,CAAiB,sBAAE,CAAoB,yBAAE,CAAuB,mBAAE,CAAiB,WAAE,CAAS,eAAE,CAAa,CAAE,CAAE,CACzM,IAAM,EAAgB,IAAI,CAAC,gBAAgB,CAAC,GACtC,EAAa,MAAM,EAAc,GAAG,CAAC,EAAU,EAAmB,WACpE,aACA,oBACA,uBACA,EACA,WAAoC,aAAxB,EAAI,OAAO,CAAC,OAAO,CAG/B,aAAc,EAAI,OAAO,CAAC,kBAAkB,CAC5C,iBAAkB,MAAM,IAAI,CAAC,mBAAmB,CAAC,EAAK,EAAY,EAAmB,aACrF,CACJ,GACA,GAAI,CAAC,GACG,GACJ,CAAC,CAAC,GAAwB,CAFb,AAEa,CAAuB,CAM7C,CAPY,CACoC,IAM1C,OAAO,cAAc,CAAC,AAAI,MAAM,iCAPwC,oBAOc,oBAAqB,CAC7G,MAAO,MACP,YAAY,EACZ,cAAc,CAClB,GAGR,OAAO,CACX,CACJ,CDrkBA,CCukBA,GDvkBA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OaCW,IAAM,EAAe,CAC5B,IZokBoC,EYnkBpC,OACA,UACA,OACA,MACA,SACA,QACH,CbPD,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OKPA,IAAM,EAA0B,CAC5B,OACA,UACH,CACD,SAAS,IACL,OAAO,IAAI,SAAS,KAAM,CACtB,OAAQ,GACZ,EACJ,CLCA,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OjBXA,EAAA,CAAA,CAAA,OAGA,EAAA,CAAA,CAAA,KACA,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OaAA,IAAM,EAAgB,IAAI,IAAI,OAAO,MAAM,CAAC,AALP,CACjC,UAAW,IACX,UAAW,IACX,aAAc,GAClB,IASW,SAAS,EAA0B,CAAK,EAC/C,GAAI,AAAiB,iBAAV,GAAgC,OAAV,GAAkB,CAAC,CAAC,WAAY,CAAA,CAAK,EAA6B,UAAxB,AAAkC,OAA3B,EAAM,MAAM,CAC1F,OAAO,EAEX,GAAM,CAAC,EAAQ,EAAW,CAAG,EAAM,MAAM,CAAC,KAAK,CAAC,KAChD,MAZ0C,6BAYnC,GAA6C,EAAc,GAAG,CAAC,EAApD,KAA2D,GACjF,CXnBA,IAAA,EAAA,EAAA,CAAA,CAAA,OAaW,SAAS,EAAgB,CAAK,EACrC,GAAqB,UAAjB,OAAO,GAAsB,AAAU,UAAQ,CAAC,CAAC,WAAY,CAAA,CAAK,EAA6B,UAAxB,AAAkC,OAA3B,EAAM,MAAM,CAC1F,MAAO,GAEX,IAAM,EAAS,EAAM,MAAM,CAAC,KAAK,CAAC,KAC5B,CAAC,EAAW,EAAK,CAAG,EACpB,EAAc,EAAO,KAAK,CAAC,EAAG,CAAC,GAAG,IAAI,CAAC,KAEvC,EAAa,OADJ,AACW,EADJ,EAAE,CAAC,CAAC,IAE1B,MArB+B,AAqBxB,cAAc,OAAwB,CAAS,eAAsB,AAAhC,SAAuB,CAAS,CAAM,EAA4B,UAAvB,OAAO,GAA4B,CAAC,MAAM,IAAe,KAAc,EAAA,kBAAkB,AACpL,CFhBA,CEkBA,GFlBA,EAAA,EAAA,CAAA,CAAA,O4BLW,GACP,GAGF,CAAC,CAJgB,AACV,EAAC,SADoB,GAAG,I1BuBS,C0BtBZ,CAAG,yBAC7B,EAAM,GAAD,cAAqB,CAAG,qBACtB,GAEJ,SAAS,EAA0C,CAAW,CAAE,CAAK,CAAE,CAAK,MAU3E,EARJ,I5BMO,A4BNH,S5BMY,AAA2B,CAAK,EAEhD,GAAI,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,ImCVjB,MAA0B,EnCYX,IAKlB,CAAA,EAAA,CAL0B,AmCZP,CnCiBnB,MALiC,MAAM,GmCZgB,GnCYV,EAK7C,AAAoB,EAAC,IAErB,CAAA,EAAA,CAF6B,CAE7B,MAFoC,MAAM,MAAM,SAEhD,AAA2B,EAAC,GATA,KASQ,EATD,EAAM,GASE,GATI,AAWvD,E4BnBmC,C5BiBsB,G4BdrD,G5Bc2D,A2BvBnC,CCSpB,MAHyC,GDNtC,OAAO,GAAsB,AAAU,UAAQ,aAAa,EAAkC,UAAzB,OAAO,ACSxD,EDT8D,OAAO,EAAiB,EAAM,OAAO,CAAC,UAAU,CAAC,qCCSjG,YAErC,QAAQ,KAAK,CAAC,GAIlB,GAA2B,UAAvB,OAAO,GAA4C,OAAhB,GAAwB,AAA+B,UAAU,OAAlC,EAAY,OAAO,EAErF,GADA,EAAU,EAAY,OAAO,CACI,UAA7B,OAAO,EAAY,KAAK,CAAe,CACvC,IAAM,EAAqB,EAAY,KAAK,CACtC,EAAa,EAAmB,OAAO,CAAC,MAC9C,GAAI,EAAa,CAAC,EAAG,CACjB,IAAM,EAAQ,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,MAAM,EAAE,EAAM,gBAAgB,EAAE,EAAM;;gBAErF,EAAE,EAAA,CAAS,EAAG,oBAAqB,CAC/B,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GACA,EAAM,KAAK,CAAG,UAAY,EAAM,OAAO,CAAG,EAAmB,KAAK,CAAC,GACnE,QAAQ,KAAK,CAAC,GACd,MACJ,EACJ,KAC8B,UAAvB,AAAiC,OAA1B,IACd,EAAU,CAAA,EAEd,GAAI,EAAS,YACT,QAAQ,KAAK,CAAC,CAAC,MAAM,EAAE,EAAM,gBAAgB,EAAE,EAAM;;kBAE3C,EAAE,EAAA,CAAS,EAGzB,QAAQ,KAAK,CAAC,CAAC,MAAM,EAAE,EAAM,gBAAgB,EAAE,EAAM,kMAAkM,CAAC,EACxP,QAAQ,KAAK,CAAC,GAElB,CX/BA,CWiCA,CXjCA,CAAA,CAAA,MAAA,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OAAA,EAAA,EAAA,CAAA,CAAA,OACA,AW+BoD,EX/BpD,CAAA,CAAA,2BbjBA,EAAA,EAAA,CAAA,CAAA,QAEA,0CAA0C,iBagB1C,IAAA,EAAA,EAAA,CAAA,CAAA,MAEA,EAAA,EAAA,CAAA,CAAA,OAEA,EAAA,EAAA,CAAA,CAAA,OAGA,EAAA,EAAA,CAAA,CAAA,OZtBI,EAAA,EAAA,CAAA,CAAA,MACG,OAAM,EACT,aAAa,CAkBL,MAjBJ,IAAI,CAAC,KAAK,CAAG,EACb,IAAI,CAAC,cAAc,CAAG,EAAE,CACxB,IAAI,CAAC,SAAS,CAAG,EAAE,CACnB,IAAI,CAAC,WAAW,EAAG,EACnB,IAAI,CAAC,qBAAqB,CAAG,KAC7B,IAAI,CAAC,iBAAiB,CAAG,KACzB,IAAI,CAAC,+BAA+B,CAAG,KAEnC,GADA,IAAI,CAAC,qBAAqB,CAAG,KACV,IAAf,IAAI,CAAC,KAAK,CAAQ,CAClB,IAAI,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,SAAS,CAAC,MAAM,CAAE,IAAI,AAC1C,IAAI,CAAC,SAAS,CAAC,EAAE,GAErB,IAAI,CAAC,SAAS,CAAC,MAAM,CAAG,CAC5B,CACJ,EAGU,OAAO,cAAc,CAAC,IAAI,EAAA,cAAc,CAAC,kGAAmG,oBAAqB,CACnK,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAER,CACA,qBAAsB,WAiIlB,EACE,EAjIG,IAAI,CAAC,WAAW,EAAE,CACnB,IAAI,CAAC,WAAW,EAAG,EACnB,eAAe,IAAI,QAAQ,QAAQ,CAAC,KAE5B,GADA,IAAI,CAAC,WAAW,EAAG,EACA,IAAf,IAAI,CAAC,KAAK,CAAQ,CAClB,IAAI,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,cAAc,CAAC,MAAM,CAAE,IAAI,AAC/C,IAAI,CAAC,cAAc,CAAC,EAAE,GAE1B,IAAI,CAAC,cAAc,CAAC,MAAM,CAAG,CACjC,CACJ,KAQJ,IAAI,CAAC,qBAAqB,EAAE,AAG5B,IAAI,CAAC,qBAAqB,GAE9B,IAAI,CAAC,qBAAqB,EAsGc,CAtGX,CAsGa,AAtG0B,IAAI,CAAC,+BAA+B,GA0G1F,aAAa,KAE3B,EAAe,aAAa,IAAI,CAAC,KADjB,CACuB,UADZ,EAAI,GAEnC,GACA,EAAe,eAAe,IAAI,CAAC,KAAM,GAClC,IAAI,IA9GX,CAIE,YAAa,CACX,OAAO,IAAI,QAAQ,AAAC,IAChB,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,GACN,GAAG,CAAlB,IAAI,CAAC,KAAK,EACV,IAAI,CAAC,mBAAmB,EAEhC,EACJ,CAKE,YAAa,CACX,OAAO,IAAI,QAAS,AAAD,IACf,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,GACD,GAAG,CAAlB,IAAI,CAAC,KAAK,EACV,IAAI,CAAC,mBAAmB,EAEhC,EACJ,CACA,WAAY,CAQR,GAPA,IAAI,CAAC,KAAK,GAGN,IAAI,CAAC,qBAAqB,EAAE,CAC5B,IAAI,CAAC,qBAAqB,GAC1B,IAAI,CAAC,qBAAqB,CAAG,MAEF,MAAM,CAAjC,IAAI,CAAC,iBAAiB,CACtB,IAAK,IAAM,KAAc,IAAI,CAAC,iBAAiB,CAC3C,AAD4C,EACjC,SAAS,EAGhC,CACA,SAAU,CACN,GAAmB,GAAG,CAAlB,IAAI,CAAC,KAAK,CACV,MAAM,OAAO,cAAc,CAAC,IAAI,EAAA,cAAc,CAAC,+DAAgE,oBAAqB,CAChI,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,GAYJ,GAJA,IAAI,CAAC,KAAK,GACS,GAAG,CAAlB,IAAI,CAAC,KAAK,EACV,IAAI,CAAC,mBAAmB,GAEG,MAAM,CAAjC,IAAI,CAAC,iBAAiB,CACtB,IAAK,IAAM,KAAc,IAAI,CAAC,iBAAiB,CAAC,AAC5C,EAAW,OAAO,EAG9B,CACA,iBAAkB,CACd,OAAO,IAAI,CAAC,KAAK,CAAG,CACxB,CACA,UAAU,CAAO,CAAE,CACf,IAAI,CAAC,SAAS,GAEd,IAAM,EAAY,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,EAExC,OADA,EAAQ,IAAI,CAAC,EAAW,GACjB,CACX,CACA,iBAAiB,CAAU,CAAE,CACzB,GAAI,IAAe,IAAI,CACnB,CADqB,KACf,OAAO,cAAc,CAAC,IAAI,EAAA,cAAc,CAAC,4CAA6C,oBAAqB,CAC7G,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,EAE2B,MAAM,EAAjC,IAAI,CAAC,iBAAiB,EACtB,KAAI,CAAC,iBAAiB,CAAG,IAAI,GAAA,EAEjC,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,GAG3B,IAAI,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,KAAK,CAAE,IAC3B,AAD+B,EACpB,SAAS,GAExB,OAAO,IAAI,CAAC,oBAAoB,CAAC,IAAI,CAAC,IAAI,CAAE,EAChD,CACA,qBAAqB,CAAU,CAAE,CACxB,IAAI,CAAC,iBAAiB,EAAE,AAG7B,IAAI,CAAC,iBAAiB,CAAC,MAAM,CAAC,EAIlC,CACJ,CYhIA,IAAA,GAAA,EAAA,CAAA,CAAA,OXxBA,IAAM,GAA+B,6BAWxB,GAAsB,IAAI,IAAI,CACvC,iBACA,gBACA,uBACA,WACA,UACA,iBAEA,OACA,QACA,UAEA,SAIA,cACA,aAEA,SACA,WACA,aACH,E4BhCD,C5BkCA,G4BlCA,GAAA,EAAA,CAAA,CAAA,O3BNA,GAAA,EAAA,CAAA,CAAA,OACA,IAAM,GAAW,CACb,EDsCqC,MCtC5B,IACb,EAEM,GAA+B,YAAvB,OAAO,GAAA,KAAW,CAAkB,GAAA,KAAW,CAAG,AAAC,GAAK,EAIhE,GAAuE,QAAQ,IAAI,CAG1D,CAHR,EAItB,AAAD,IACI,GAAI,CACA,GAAe,GAAS,OAAO,CACnC,QAAS,CACL,GAAS,EAR4C,KAQrC,CAAG,IACvB,CACJ,GClBO,IAAM,GAAoC,CAAA,EADjD,AACiD,EADjD,CAAA,CAAA,OACiD,uBAAA,AAAuB,I0BQxE,C1BNA,C0BMA,CAAA,CAAA,OAyNA,IAAM,GAAe,IAAI,QACnB,GAA6B,CAC/B,IAAK,SAAS,AAAI,CAAM,CAAE,CAAI,CAAE,CAAQ,EACpC,GAAa,SAAT,A1BlOqD,G0BkOzB,UAAT,GAA6B,YAAT,EAAoB,CAC3D,IAAM,EAAiB,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,GACxD,MAAO,CAAC,CACJ,CAAC,EAAK,CAAE,CAAC,GAAG,KACR,IAAM,EAAQ,GAA0B,QAAQ,GAQhD,OAPI,GACA,EAAM,EADC,aACc,CAAC,KAAK,CAAC,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,iDAAiD,CAAC,AAAG,oBAAqB,CACnI,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,IAEG,IAAI,MAAM,EAAe,KAAK,CAAC,EAAQ,GAAO,GACzD,EACJ,CAAC,AAAC,CAAC,EAAK,AACZ,CACA,OAAO,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAC5C,CACJ,EAqDA,SAAS,GAAoB,CAAgB,EACzC,IAAM,EAAe,GAAa,GAAG,CAAC,GACtC,GAAI,EACA,OAAO,EAEX,GAHkB,CAGZ,EAAU,QAAQ,OAAO,CAAC,GAEhC,OADA,GAAa,GAAG,CAAC,EAAkB,GAC5B,CACX,CTlT2D,EAAA,CAAA,CAAA,OAAiE,kBAAkB,CRiC9I,EQjCiJ,ERiCjJ,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,MnHpCO,OAAM,WAAuB,MAChC,YAAY,CAAO,CAAE,CAAO,CAAC,CACzB,KAAK,CAAC,CAAC,WAAW,EAAE,EAAQ,QAAQ,CAAC,KAAO,EAAU,EAAU,IAAI,0BAA0B,CAAC,CAAE,GACjG,IAAI,CAAC,IAAI,CAAG,gBAChB,CACJ,CuGCO,CvGCP,KuGDa,GACT,aAAa,CAkBL,MAjBJ,IAAI,CAAC,KAAK,CAAG,EACb,EvGFmC,EuGE/B,CAAC,cAAc,CAAG,EAAE,CACxB,IAAI,CAAC,SAAS,CAAG,EAAE,CACnB,IAAI,CAAC,WAAW,EAAG,EACnB,IAAI,CAAC,qBAAqB,CAAG,KAC7B,IAAI,CAAC,iBAAiB,CAAG,KACzB,IAAI,CAAC,+BAA+B,CAAG,KAEnC,GADA,IAAI,CAAC,qBAAqB,CAAG,KACV,IAAf,IAAI,CAAC,KAAK,CAAQ,CAClB,IAAI,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,SAAS,CAAC,MAAM,CAAE,IAAI,AAC1C,IAAI,CAAC,SAAS,CAAC,EAAE,GAErB,IAAI,CAAC,SAAS,CAAC,MAAM,CAAG,CAC5B,CACJ,EAGU,OAAO,cAAc,CAAC,IAAI,GAAe,kGAAmG,oBAAqB,CACnK,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAER,CACA,qBAAsB,WAiIlB,IAhIK,IAAI,CAAC,WAAW,EAAE,CACnB,IAAI,CAAC,WAAW,EAAG,EACnB,eAAe,IAAI,QAAQ,QAAQ,CAAC,KAE5B,GADA,IAAI,CAAC,WAAW,EAAG,EACA,IAAf,IAAI,CAAC,KAAK,CAAQ,CAClB,IAAI,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,cAAc,CAAC,MAAM,CAAE,IAAI,AAC/C,IAAI,CAAC,cAAc,CAAC,EAAE,GAE1B,IAAI,CAAC,cAAc,CAAC,MAAM,CAAG,CACjC,CACJ,KAQJ,IAAI,CAAC,qBAAqB,EAAE,AAG5B,IAAI,CAAC,qBAAqB,GAE9B,IAAI,CAAC,qBAAqB,EAsGc,CAtGX,CAAuC,AAsG1B,IAtG8B,CAAC,+BAA+B,CA0GtG,EAAY,aAAa,KAE3B,EAAe,aAAa,IAAI,CAAC,KADjB,CACuB,UADZ,EAAI,GAEnC,GACA,EAAe,eAAe,IAAI,CAAC,KAAM,GAClC,IAAI,IA9GX,CAIE,YAAa,CACX,OAAO,IAAI,QAAQ,AAAC,IAChB,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,GACN,GAAG,CAAlB,IAAI,CAAC,KAAK,EACV,IAAI,CAAC,mBAAmB,EAEhC,EACJ,CAKE,YAAa,CACX,OAAO,IAAI,QAAS,AAAD,IACf,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,GACD,GAAG,CAAlB,IAAI,CAAC,KAAK,EACV,IAAI,CAAC,mBAAmB,EAEhC,EACJ,CACA,WAAY,CAQR,GAPA,IAAI,CAAC,KAAK,GAGN,IAAI,CAAC,qBAAqB,EAAE,CAC5B,IAAI,CAAC,qBAAqB,GAC1B,IAAI,CAAC,qBAAqB,CAAG,MAEF,MAAM,CAAjC,IAAI,CAAC,iBAAiB,CACtB,IAAK,IAAM,KAAc,IAAI,CAAC,iBAAiB,CAAC,AAC5C,EAAW,SAAS,EAGhC,CACA,SAAU,CACN,GAAmB,GAAG,CAAlB,IAAI,CAAC,KAAK,CACV,MAAM,OAAO,cAAc,CAAC,IAAI,GAAe,+DAAgE,oBAAqB,CAChI,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAYJ,GAJA,IAAI,CAAC,KAAK,GACS,GAAG,CAAlB,IAAI,CAAC,KAAK,EACV,IAAI,CAAC,mBAAmB,GAEG,MAAM,CAAjC,IAAI,CAAC,iBAAiB,CACtB,IAAK,IAAM,KAAc,IAAI,CAAC,iBAAiB,CAAC,AAC5C,EAAW,OAAO,EAG9B,CACA,iBAAkB,CACd,OAAO,IAAI,CAAC,KAAK,CAAG,CACxB,CACA,UAAU,CAAO,CAAE,CACf,IAAI,CAAC,SAAS,GAEd,IAAM,EAAY,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,EAExC,OADA,EAAQ,IAAI,CAAC,EAAW,GACjB,CACX,CACA,iBAAiB,CAAU,CAAE,CACzB,GAAI,IAAe,IAAI,CACnB,CADqB,KACf,OAAO,cAAc,CAAC,IAAI,GAAe,4CAA6C,oBAAqB,CAC7G,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAE2B,MAAM,EAAjC,IAAI,CAAC,iBAAiB,GACtB,IAAI,CAAC,iBAAiB,CAAG,IAAI,GAAA,EAEjC,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,GAG3B,IAAI,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,KAAK,CAAE,IAAI,AAC/B,EAAW,SAAS,GAExB,OAAO,IAAI,CAAC,oBAAoB,CAAC,IAAI,CAAC,IAAI,CAAE,EAChD,CACA,qBAAqB,CAAU,CAAE,CACxB,IAAI,CAAC,iBAAiB,EAAE,AAG7B,IAAI,CAAC,iBAAiB,CAAC,MAAM,CAAC,EAIlC,CACJ,CW5JA,EAAA,CAAA,CAAA,MCuCO,OAAM,GACT,YAAY,CAAK,CAAE,CAAO,CAAC,CACvB,IAAI,CAAC,KAAK,CAAG,EACb,IAAI,CAAC,OAAO,CAAG,CACnB,CACJ,CAGW,MAAM,WAA4B,EACzC,QAAO,CAAA,AAAE,CAAG,IAAI,CAAC,aAAa,CAAG,CAAc,AAC/C,aAAY,UAAE,CAAQ,YAAE,CAAU,SAAE,CAAO,CAAE,oBAAkB,kBAAE,CAAgB,kBAAE,CAAgB,CAAE,CAAC,CA0BlG,GAzBA,KAAK,CAAC,CACF,sBACA,UACA,qBACA,CACJ,GAEF,CAFM,GAEF,CAAC,oBAAoB,CAAG,EAAA,oBAAoB,CAEhD,CAFkD,GAE9C,CAAC,gBAAgB,CAAG,EAAA,gBAAgB,CAGxC,CAH0C,GAGtC,CAAC,WAAW,GAAG,AAGnB,IAAI,CAAC,kBAAkB,CAAG,EAAA,eAHM,WAGY,CAC1C,IAAI,CAAC,gBAAgB,CAAG,EACxB,IAAI,CAAC,gBAAgB,CAAG,EAGxB,IAAI,CAAC,OAAO,CAAG,AK7DhB,SAAS,AAAqB,CAAQ,EAGzC,IAAM,EAAU,EAAa,MAAM,CAAC,CAAC,EAAK,KAAU,CAC5C,GAD2C,AACxC,CAAG,CAGN,CAAC,EAAO,CAAE,CAAQ,CAAC,EAAO,EAAI,EAClC,CAAC,CAAG,CAAC,GAGH,EAAc,IAAI,IAAI,EAAa,MAAM,CAAC,AAAC,GAAS,CAAQ,CAAC,EAAO,GAG1E,IAAK,IAAM,KAFK,EAAwB,GAEnB,GAFyB,CAAC,AAAC,GAAS,CAAC,EAAY,GAAG,CAAC,IAE7C,CAIzB,GAAe,SAAX,EAAmB,CACf,EAAS,GAAG,EAAE,CAEd,EAAQ,IAAI,CAAG,EAAS,GAAG,CAE3B,EAAY,GAAG,CAAC,SAEpB,QACJ,CAEA,GAAe,YAAX,EAAsB,CAGtB,IAAM,EAAQ,CACV,aACG,EACN,AAGG,EAAC,EAAY,GAAG,CAAC,SAAW,EAAY,GAAG,CAAC,QAAQ,AACpD,EAAM,IAAI,CAAC,QAIf,IAAM,EAAU,CACZ,MAAO,EAAM,IAAI,GAAG,IAAI,CAAC,KAC7B,EAGA,EAAQ,OAAO,CAAG,IAAI,IAAI,SAAS,KAAM,CACjC,OAAQ,YACR,CACJ,GAEJ,EAAY,GAAG,CAAC,WAChB,QACJ,CACA,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,0EAA0E,EAAE,EAAA,CAAQ,EAAG,oBAAqB,CAC/I,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACA,OAAO,CACX,EAEA,ALH4C,GAEpC,IAAI,CAAC,mBAAmB,CAAG,GAAoB,GAE/C,IAAI,CAAC,OAAO,CAAG,GKD2B,CLCvB,CAAC,QAAQ,CAAC,OAAO,CACN,UAAU,CAApC,IAAI,CAAC,gBAAgB,CACrB,GAAqB,iBAAiB,CAAlC,IAAI,CAAC,OAAO,CACZ,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,gDAAgD,EAAE,EAAW,QAAQ,CAAC,wHAAwH,CAAC,EAAG,oBAAqB,CAC1P,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,QACG,GAAI,CAAC,AoB5EjB,SAAS,AAAmB,CAAG,EAClC,MAAuB,iBAAhB,EAAI,OAAO,EAAuC,UAAhB,EAAI,OAAO,GAAmC,IAAnB,EAAI,UAAU,EAAiC,SAAnB,EAAI,UAAU,EAAkB,EAAI,UAAU,CAAG,GAAwC,YAAnC,OAAO,EAAI,oBAAoB,AACzL,EpB0E2C,AoBxE3C,IpBwE+C,CAAC,QAAQ,GAAK,IAAI,CAAC,QAAQ,CAAC,GAAM,CACjE,CADmE,KAC7D,OAAO,EoBzEoB,YpByEN,CAAC,AAAI,MAAM,CAAC,uFAAuF,EAAE,EAAW,QAAQ,CAAC,yGAAyG,CAAC,EAAG,oBAAqB,CAClR,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,QAEA,IAAI,CAAC,OAAO,CAAG,OAyB3B,CAME,QAAQ,CAAM,CAAE,QAEd,AaxGG,EAAa,EbwGZ,CAAC,KaxGmB,CbwGN,AaxGO,Gb4GlB,IAAI,CAAC,CAJe,MAIR,CAAC,EAAO,CAJO,IAAI,IAAI,SAAS,KAAM,CACjD,OAAQ,GACZ,EAGR,CACA,MAAM,GAAG,CAAO,CAAE,CAAW,CAAE,CAAS,CAGxC,CAFA,AAEY,CAAE,CAAY,CAAE,CAAO,CAAE,CAAO,CAAE,KAqRlC,EApRR,IAkBI,EAlBE,EAAqB,EAAU,kBAAkB,CACjD,EAAyB,CAAC,CAAC,EAAQ,UAAU,CAAC,aAJiB,EAIF,CAEnE,CAAA,EAAA,EAAA,UAAA,AAAU,EAAC,CACP,iBAAkB,IAAI,CAAC,gBAAgB,CACvC,qBAAsB,IAAI,CAAC,oBAAoB,AACnD,GACA,IAAM,EAAiB,CACnB,OAAQ,EAAQ,MAAM,CiB1F3B,AjB0F8B,SiB1FrB,AAA2B,CAAgB,CAAE,CAAS,EAClE,IAAM,EAAgB,EAAA,oBAAoB,CAAC,QAAQ,GACnD,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,YACL,IAAK,mBACL,IAAK,gBACL,IAAK,uBAsJqB,IAtCD,EA/Gc,EA+GI,EA/Gc,EA+GH,EA/Gc,EAqJ1B,AArClD,CAD4D,GAAX,GAC1C,EAAe,CADsD,GAClD,EACtB,IAAK,YACL,IAAK,mBACD,CACI,IAAM,EAAiB,EAAe,mBAAmB,CACzD,GAAI,GACA,IAAI,IAAM,KADM,AACC,EACb,GAAI,EAAe,GAAG,CAAC,GAKnB,GAN0B,AACD,IAKlB,AAiEnC,SAAS,AAAkB,CAAgB,CAAE,CAAS,CAAE,CAAc,EAClE,IAAM,EAAe,GAAa,GAAG,CAAC,GACtC,GAAI,EACA,OAAO,EAEX,GAHkB,CAGZ,EAAU,IAAI,MAAM,CAAA,EAAA,GAAA,kBAAA,AAAkB,EAAC,EAAe,YAAY,CAAE,EAAU,KAAK,CAAE,YAAa,IAExG,OADA,GAAa,GAAG,CAAC,EAAkB,GAC5B,CACX,EAzEqD,EAAkB,EAAW,EAE9D,CAEJ,KACJ,CACJ,IAAK,gBACD,CACI,IAAM,EAAiB,EAAe,mBAAmB,CACzD,GAAI,GACA,IAAI,IAAM,KADM,AACC,EACb,GAAI,EAAe,GAAG,CAAC,GACnB,GAF0B,AACD,IA+DrD,AA9DmC,SA8D1B,AAAmB,CAAgB,CAAE,CAAc,CAAE,CAAS,CAAE,CAAc,EACnF,IAAM,EAAe,GAAa,GAAG,CAAC,GACtC,GAAI,EACA,OAAO,EAEX,GAHkB,CAGZ,EAAsB,CACxB,GAAG,CAAgB,AACvB,EAIM,EAAU,QAAQ,OAAO,CAAC,GA8BhC,OA7BA,GAAa,GAAG,CAAC,EAAkB,GACnC,OAAO,IAAI,CAAC,GAAkB,OAAO,CAAE,AAAD,IAC9B,GAAoB,GAAG,CAAC,IAIpB,EAAe,CAJY,EAIT,CAAC,IACnB,GAD0B,IACnB,cAAc,CAAC,EAAqB,EAAM,CAC7C,YACI,IAAM,G5BhRe,E4BgR2B,I5BhRrB,EAAE,E4BgRV,C5B/QvC,AAAI,CADiD,EACpB,IAAI,CAAC,GAC3B,CAAC,EAAE,CAD+B,CAC7B,EAAO,CAAC,EAAE,EAAK,EAAE,CAAC,CAE3B,CAAC,EAAE,EAAE,EAAO,CAAC,EAAE,KAAK,SAAS,C4B4Q0C,A5B5QzC,GAAM,GAAG,CAAC,E4BmRC,iBAAiB,CAAzC,EAAe,IAAI,CAEnB,CAAA,EAAA,EAAA,oBAAA,AAAoB,EAAC,EAAU,KAAK,CAAE,EAAY,EAAe,eAAe,EAGhF,CAAA,EAAA,EAAA,gCAAA,AAAgC,EAAC,EAAY,EAAW,EAEhE,EACA,YAAY,CAChB,EAGZ,GACO,CACX,EAxGsD,EAAkB,EAAgB,EAAW,EAE/E,CAGR,CAKR,CACA,OAAO,GAAoB,EAlJnB,KAAK,QACL,IAAK,gBACL,IAAK,iBACD,MAAM,OAAO,cAAc,CAAC,IAAI,EAAA,cAAc,CAAC,sEAAuE,oBAAqB,CACvI,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,KAAK,oBACD,OAAO,EAA6B,EA2II,EA3Ic,EA4I3D,CAAA,EAAA,EAAA,IAD0D,kBAC1D,AAAsB,EAAC,EAAe,GAAoB,GA3IzD,KAAK,UAQG,OAsIT,AAtIgB,GAAyB,EAI5C,CAEJ,CAAA,EAAA,EAAA,SAgI2B,oBAhI3B,AAA6B,GACjC,EFhFW,AfwIqD,SexI5C,AAAuB,CAAK,EAC5C,IAAM,EAAS,CAAC,EAChB,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,OAAO,CACxB,IAAV,IACX,CAAM,CAAC,EAAI,CADuB,AACpB,CAAA,EAElB,OAAO,CACX,EAEA,Af+HuF,EAAQ,MAAM,EAAG,QAAa,CAC7G,EACM,EAA8B,KAChC,EAAQ,UAAU,CAAC,aelIuB,GfkIP,CAAG,CAAA,EAAA,GAAA,kBAAA,AAAkB,EAAC,GAAW,OAAO,CAAC,KACpE,QAAQ,GAAG,CAAC,wBAAwB,EAAE,AACtC,QAAQ,GAAG,CAAC,4CAA6C,EAAa,GAAG,CAEjF,EACJ,EACI,EAAiB,KAErB,GAAI,CACA,GAAI,EAAoB,CACpB,IAAM,EAAqB,IAAI,CAAC,QAAQ,CAAC,UAAU,CAC7C,GAGiB,IAAvB,QAAuD,IAAvB,CAFhC,CAEmE,GAAA,cAAc,CAAG,EACpF,GAAI,EAAwB,CAkB9B,IAwCU,ESjLd,ETyIU,EAAwB,IAAI,gBACxB,GAA6B,EAC3B,EAAc,IAvB4C,AAuBxC,EACpB,EAAkB,CAAA,EAAA,EAAA,0BAAA,AAA0B,OAAC,GAW3C,EqBtJf,CACH,MAAO,IAAI,IACX,MAAO,IAAI,ArBoJkC,IqBnJ7C,mBAAoB,IAAI,IACxB,mBAAoB,IAAI,GAC5B,ErBkJsB,EAAiC,EAAiB,CACpD,KAAM,YACN,MAAO,SAGP,WAAY,CAAC,EACb,oBAAqB,kBACrB,EACA,aAAc,EAAsB,MAAM,CAC1C,WAAY,cACZ,kBAGA,EACA,uBAAuB,EACvB,WAAY,EACZ,OAAQ,GAAA,cAAc,CACtB,MAAO,GAAA,cAAc,CACrB,KAAM,IACC,EAAa,IAAI,CACvB,0BACD,EACA,sBAAuB,KACvB,oBAAgB,CACpB,EAEA,GAAI,CACA,EAAoB,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,EAAgC,EAAS,EAAS,EACxG,CAAE,MAAO,EAAK,CACN,EAAsB,MAAM,CAAC,OAAO,CAGpC,CAHsC,EAGT,GACtB,QAAQ,GAAG,CAAC,gBAAgB,EAAI,QAAQ,GAAG,CAAC,sBAAA,AAAsB,EAAE,CAC3E,EAA0C,EAAK,EAAU,KAAK,CAAE,EAAM,iBAAiB,CAE/F,CAiBA,GAhBiC,UAA7B,OAAO,GAAwD,OAAtB,GAAgE,YAAlC,AAA8C,OAAvC,EAAkB,IAAI,EAIpG,EAAkB,IAAI,CAAC,KAAK,EAAG,AAAC,IACxB,EAAsB,MAAM,CAAC,OAAO,CAGpC,CAHsC,EAGT,EACtB,QAAQ,GAAG,CAAC,gBAAgB,EAAE,AACrC,EAA0C,EAAK,EAAU,KAAK,CAAE,EAAM,iBAAiB,CAE/F,KSzMA,CAjChB,CAAC,IACD,EAAuB,IAAI,EAAA,EAExB,GA8BiC,KAjCb,WAiC6B,CAAC,GT2MrB,ASxMpC,EAAY,UAAU,GAAG,IAAI,CAAC,GTyMd,MAAM,EAAY,UAAU,GACxB,EAA4B,CAG5B,IAAM,EAAgB,CAAA,EAAA,EAAA,qBAAA,AAAqB,EAAC,GAC5C,GAAI,EACA,MAAM,OAAO,AADE,cACY,CAAC,IAAI,EAAA,kBAAkB,CAAC,CAAC,MAAM,EAAE,EAAU,KAAK,CAAC,mDAAmD,EAAE,EAAc,6EAA6E,CAAC,EAAG,oBAAqB,CACjP,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAGA,OADA,QAAQ,KAAK,CAAC,+HACR,OAAO,cAAc,CAAC,IAAI,EAAA,kBAAkB,CAAC,CAAC,MAAM,EAAE,EAAU,KAAK,CAAC,yIAAyI,CAAC,EAAG,oBAAqB,CAC1O,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,EAER,CAIA,IAAM,EAAkB,IAAI,gBAC5B,EAAkB,CAAA,EAAA,EAAA,0BAAA,AAA0B,OAAC,GAC7C,IAAM,EAA2B,EAAiB,CAC9C,KAAM,YACN,MAAO,SACP,WAAY,CAAC,EACb,oBAAqB,kBACrB,EACA,aAAc,EAAgB,MAAM,CACpC,WAAY,EACZ,YAAa,qBACb,EACA,uBAAuB,EACvB,WAAY,EACZ,OAAQ,GAAA,cAAc,CACtB,MAAO,GAAA,cAAc,CACrB,KAAM,IACC,EAAa,IAAI,CACvB,0BACD,EACA,sBAAuB,KACvB,oBAAgB,CACpB,EACI,GAAkB,EA4CtB,GA3CA,EAAM,MAAM,IAAI,QAAQ,CAAC,EAAS,KAC9B,CAAA,EAAA,GAAA,iBAAA,AAAiB,EAAC,UACd,GAAI,CACA,IAAM,EAAS,MAAM,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,EAA0B,EAAS,EAAS,GAC/F,GAAI,EAEA,OACG,GAAI,CAAC,CAAC,GAHQ,UAGU,QAAA,CAAQ,CAAG,YAEtC,EAAQ,GAGZ,EAAkB,GAClB,IAAI,GAAc,EAClB,EAAO,WAAW,GAAG,IAAI,CAAC,AAAC,IAClB,IACD,GAAc,EACd,EAAQ,EAFM,EAEF,SAAS,EAAM,CACvB,QAAS,EAAO,OAAO,CACvB,OAAQ,EAAO,MAAM,CACrB,WAAY,EAAO,UAAU,AACjC,IAER,EAAG,GACH,CAAA,EAAA,GAAA,iBAAA,AAAiB,EAAC,KACT,IACD,GAAc,EACd,EAAgB,EAFF,GAEO,GACrB,EAAO,GAA2B,EAAU,KAAK,GAEzD,EACJ,CAAE,MAAO,EAAK,CACV,EAAO,EACX,CACJ,GACA,CAAA,EAAA,GAAA,iBAAA,AAAiB,EAAC,KACT,IACD,GAAkB,EAClB,EAAgB,KAAK,CAFH,EAGlB,EAAO,GAA2B,EAAU,KAAK,GAEzD,EACJ,GACI,EAAgB,MAAM,CAAC,OAAO,CAE9B,CAFgC,KAE1B,GAA2B,EAAU,KAAK,EAKhD,EAAgB,KAAK,EAE7B,MACI,CADG,CACc,CACb,KAAM,mBACN,MAAO,SACP,WAAY,CAAC,eACb,EACA,WAAY,EACZ,OAAQ,GAAA,cAAc,CACtB,MAAO,GAAA,cAAc,CACrB,KAAM,IACC,EAAa,IAAI,CACvB,AACL,EACA,EAAM,MAAM,EAAA,oBAAoB,CAAC,GAAG,CAAC,EAAgB,EAAS,EAAS,EAE/E,MACI,CADG,CACG,MAAM,EAAA,oBAAoB,CAAC,GAAG,CAAC,EAAc,EAAS,EAAS,EAE7E,CAAE,MAAO,EAAK,CACV,GAAI,EAAgB,GAAM,CACtB,IAAM,EQlUb,AAAL,ERkUgD,EQlU5C,ARkUoB,CQ/TjB,EAAM,MAAM,CAAC,EAHC,GAGI,CAAC,IAHG,CAGE,KAAK,CAAC,EAAG,CAAC,GAAG,IAAI,CAAC,KAHb,KRmUxB,GAAI,CAAC,EACD,GADM,GACA,OAAO,cAAc,CAAC,AAAI,MAAM,6CAA8C,oBAAqB,CACrG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAIJ,IAAM,EAAU,IAAI,QAAQ,CACxB,SAAU,CACd,GAQA,MAHA,CAAA,EAAA,EAAA,oBAAoB,AAApB,EAAqB,EAAS,EAAa,cAAc,EACzD,IAEO,IAAI,SAAS,KAAM,CAItB,OAAQ,EAAY,QAAQ,CAAG,EAAA,kBAAkB,CAAC,QAAQ,CAAG,AQ3U1E,SAAS,AAA+B,CAAK,EAChD,GAAI,CAAC,EAAgB,GACjB,KADyB,CACnB,OAAO,cAAc,CAAC,AAAI,MAAM,wBAAyB,oBAAqB,CAChF,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,OAAO,OAAO,EAAM,MAAM,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC,GAC9C,EAEA,ARgUgH,WAC5F,CACJ,EACJ,CAAO,GAAI,EAA0B,GAEjC,GAFuC,IAEhC,IAAI,EQrUS,ORqUA,KAAM,CACtB,OJnXT,CImXiB,MJpXL,AACL,AIiX6C,EJlXlC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE,CIqXjC,EAEJ,OAAM,CACV,CAEA,GAAI,CAAC,CAAC,aAAe,QAAA,CAAQ,CACzB,EAD4B,IACtB,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,4CAA4C,EAAE,IAAI,CAAC,gBAAgB,CAAC,0FAA0F,CAAC,EAAG,oBAAqB,CAC1N,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,EAAQ,UAAU,CAAC,YAAY,CAAG,EAAU,YAAY,CACxD,IACI,IAEA,EAAQ,UAFQ,AAEE,CAAC,aAAa,CAAG,AAAgD,OAA/C,EAAuB,EAAe,IAAA,AAAI,EAAY,KAAK,EAAI,EAAqB,IAAI,CAAC,KAC7H,EAAQ,UAAU,CAAC,mBAAmB,CAAG,EAAe,UAAU,CAClE,EAAQ,UAAU,CAAC,eAAe,CAAG,EAAe,MAAM,CAC1D,EAAQ,UAAU,CAAC,cAAc,CAAG,EAAe,KAAK,EAK5D,IAAM,EAAU,IAAI,QAAQ,EAAI,OAAO,QACvC,AAAI,CAAA,EAAA,EAAA,oBAAA,AAAoB,EAAC,EAAS,EAAa,cAAc,EAClD,CADqD,GACjD,SAAS,EAAI,IAAI,CAAE,CAC1B,OAAQ,EAAI,MAAM,CAClB,WAAY,EAAI,UAAU,SAC1B,CACJ,GAEG,CACX,CACA,MAAM,OAAO,CAAG,CAAE,CAAO,CAAE,CAEvB,IM5aA,EACA,MAaE,EN8ZI,EAAU,IAAI,CAAC,OM9ZH,AN8ZU,CAAC,EAAI,MAAM,EAEjC,EAA0B,CAC5B,KAAM,IAAI,CAAC,UAAU,CAAC,IAAI,CAC1B,WAAY,EAAQ,UAAU,CAC9B,QAAS,EAAQ,aAAa,CAAC,OAAO,CACtC,0BAA2B,EAAE,AACjC,EAEA,EAAwB,UAAU,CAAC,UAAU,CAAG,IAAI,CAAC,QAAQ,CAAC,UAAU,CACxE,IAAM,EAAc,CAChB,YAAY,EACZ,SM/ZD,CN+ZW,AMtbd,EAAI,OAAO,YAAY,SAuBW,AAvBF,AAChC,EAAW,EAAI,OAAO,CAAC,GAAG,CAAC,EAAA,aAAa,GAAK,KAC7C,EAAc,EAAI,OAAO,CAAC,GAAG,CAAC,kBAE9B,EAAW,EAAI,OAAO,CAAC,EAAA,aAAa,CAAC,EAAI,KACzC,EAAc,EAAI,OAAO,CAAC,eAAe,EAAI,MAK3C,EAA4C,SAAf,AN4aS,EM5aL,MAAM,EAAlB,AAAiD,sCAAhB,EACtD,GAAoB,EAAuB,SAAf,CAAyB,CAArB,MAAM,GAA+B,MAAf,EAAsB,KAAK,EAAI,EAAY,UAAU,CAAC,sBAAA,CAAsB,IAC1G,KAAa,OAAiC,UAApB,OAAO,GAAwC,SAAf,EAAI,MAAM,CAE3F,UACH,qBACA,oBACA,gBACA,EACA,wBAN2B,EAAQ,GAAiB,GAAsB,CAAA,CAO9E,GAG2C,sBAAsB,ANga7D,EACM,EAAe,MAAM,CAAA,EAAA,EAAA,eAAA,AAAe,EAAC,IAAI,CAAC,UAAU,CAAC,IAAI,CAAE,EAAI,OAAO,CAC5E,MACM,EAAe,CAAA,EAAA,EAAA,wBAAA,AAAwB,EAAC,EAAK,EAAI,OAAO,CAAE,OAAc,EAAW,EAAQ,iBAAiB,CAAC,OAAO,EACpH,EAAY,CAAA,EAAA,EAAA,eAAA,AAAe,EAAC,GAI5B,EAAW,MAAM,IAAI,CAAC,kBAAkB,CAAC,GAAG,CAAC,EAAa,IAAI,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,EAAc,IAAI,IAAI,CAAC,gBAAgB,CAAC,GAAG,CAAC,EAAW,UAG7I,GAAI,IAAI,CAAC,mBAAmB,EAAE,AACtB,EAAU,kBAAkB,CAAE,CAC9B,IAAM,EAAM,OAAO,cAAc,CAAC,IAAI,EAAA,kBAAkB,CAAC,yEAA0E,oBAAqB,CACpJ,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,EAGA,OAFA,EAAU,uBAAuB,CAAG,EAAI,OAAO,CAC/C,EAAU,iBAAiB,CAAG,EAAI,KAAK,CACjC,CACV,CAIJ,IAAI,EAAU,EAEd,OAAO,IAAI,CAAC,OAAO,EACf,IAAK,gBAIG,GADA,EAAU,YAAY,EAAG,EACrB,EAAU,kBAAkB,CAAE,CAC9B,IAAM,EAAM,OAAO,cAAc,CAAC,IAAI,EAAA,kBAAkB,CAAC,kFAAmF,oBAAqB,CAC7J,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAGA,OAFA,EAAU,uBAAuB,CAAG,EAAI,OAAO,CAC/C,EAAU,iBAAiB,CAAG,EAAI,KAAK,CACjC,CACV,CACA,KAER,KAAK,eAGD,EAAU,WAAW,EAAG,EAGxB,EAAU,IAAI,MAAM,EAAK,IACzB,KACJ,KAAK,QAGD,EAAU,kBAAkB,CAAG,GAC3B,EAAU,kBAAkB,GAAE,EAAU,IAAI,MAAM,EAAK,GAAA,EAC3D,KACJ,WAAK,EACL,IAAK,WAkIH,EAAS,KAAF,IAAW,GA/HW,IAAK,EAgIlD,EAAkB,CACpB,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GACH,IAAK,SACL,IAAK,eACL,IAAK,MACL,IAAK,OACL,IAAK,SACL,IAAK,WACL,IAAK,SAIG,OADA,GAAa,EADS,EAAA,OACE,aADkB,CAAC,QAAQ,GACZ,CAAC,QAAQ,EAAE,EAAA,CAAM,EACjD,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAEhD,KAAK,QACD,OAAO,CAAM,CAAC,GAAe,EAAK,EAAM,AAAP,CAAQ,GAAe,CAAG,IAAI,IAAI,MAAM,EAAO,KAAK,GAAI,EAAA,CAAgB,AAC7G,SACI,OAAO,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EACM,EAAsB,CACxB,IAAK,CAAM,CAAE,CAAI,EACb,OAAO,GACH,IAAK,UACD,OAAO,CAAM,CAAC,GAAc,GAAK,CAAM,AAAP,CAAQ,GAAc,CAAG,IAAI,MAAM,EAAO,OAAO,CAAE,EAAA,CAAgB,AACvG,KAAK,UACL,IAAK,UACL,IAAK,MACL,IAAK,OACL,IAAK,OACL,IAAK,OACL,IAAK,OACL,IAAK,cACL,IAAK,WAOG,OAJA,GAAa,EADS,EAAA,OACE,aADkB,CAAC,QAAQ,GACZ,CAAC,QAAQ,EAAE,EAAA,CAAM,EAIjD,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAEhD,KAAK,QACD,OAAO,CAAM,CAAC,GAAmB,EAAK,EAAD,AAAO,CAAC,GAAmB,CAAG,IAAI,IAAI,MACvE,AAMA,EAAO,KAAK,GAAI,EAAA,CAAoB,AAC5C,SAII,OAAO,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EA5LwB,EA6LjB,IAAI,IA7LuB,EA6LjB,EAAS,GA5LF,KACJ,CA4KmF,QA3K/E,IAAI,CAAC,OAAO,AACpB,CACA,IAAM,EAAS,CAAA,EAAA,EAAA,SAAA,AAAS,IAElB,UAAE,CAAQ,CAAE,CAAG,IAAI,CAAC,UAAU,CAEpC,OADA,EAAO,oBAAoB,CAAC,aAAc,GACnC,EAAO,KAAK,CAAC,EAAA,yBAAyB,CAAC,UAAU,CAAE,CACtD,SAAU,CAAC,0BAA0B,EAAE,EAAA,CAAU,CACjD,WAAY,CACR,aAAc,CAClB,CACJ,EAAG,SAAU,IAAI,CAAC,EAAE,CAAC,EAAS,EAAa,EAAW,EAAc,EAAc,EAAS,GAC/F,KAGR,GAAI,CAAC,CAAC,aAAoB,QAAA,CAAQ,CAE9B,EAFiC,KAE1B,IAAI,SAAS,KAAM,CACtB,OAAQ,GACZ,GAEJ,GAAI,EAAS,OAAO,CAAC,GAAG,CAAC,wBACrB,CAD8C,KACxC,OAAO,cAAc,CAAC,AAAI,MAAM,sIAAuI,oBAAqB,CAC9L,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,GAEJ,GAAkD,KAAK,CAAnD,EAAS,OAAO,CAAC,GAAG,CAAC,qBAErB,MAAM,OAAO,cAAc,CAAK,AAAJ,MAAU,gLAAiL,oBAAqB,CACxO,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,OAAO,CACX,CACJ,CAQW,SAAS,GAAoB,CAAQ,UAE5C,EAAS,IAAI,IAAI,EAAS,GAAG,IAAI,EAAS,MAAM,IAAI,EAAS,KAAK,IAAI,EAAS,OAAO,AAI1F,CAGA,CAP4F,GAOtF,GAAgB,OAAO,WACvB,GAAqB,OAAO,SAC5B,GAAiB,OAAO,SACxB,GAAqB,OAAO,gBAC5B,GAAa,OAAO,QACpB,GAAiB,OAAO,YACxB,GAAgB,OAAO,WACvB,GAAgB,OAAO,WAKnB,GAA6B,CACnC,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GACH,IAAK,UACD,OAAO,CAAM,CAAC,GAAc,GAAK,CAAD,AAAO,CAAC,GAAc,CAAG,EAAA,cAAc,CAAC,IAAI,CAAC,IAAI,QAAQ,CAAC,GAAA,CAAG,AACjG,KAAK,UACD,OAAO,CAAM,CAAC,GAAc,EAAK,EAAD,AAAO,CAAC,GAAc,CAAG,EAAA,qBAAqB,CAAC,IAAI,CAAC,IAAI,EAAA,cAAc,CAAC,IAAI,QAAQ,CAAC,IAAA,CAAI,AAC5H,KAAK,UACD,OAAO,CAAM,CAAC,GAAc,GAAK,CAAM,AAAP,CAAQ,GAAc,CAAG,IAAI,MAAM,EAAO,OAAO,CAAE,GAAA,CAA2B,AAClH,KAAK,MAID,OAAO,EAAS,OAAO,CAAC,IAAI,AAChC,KAAK,MACL,IAAK,KACD,MACJ,CADW,IACN,QACD,OAAO,CAAM,CAAC,GAAmB,GAAK,CAAD,AAAO,CAAC,GAAmB,CAAG,IAAI,IAAI,MACvE,AAMA,EAAO,KAAK,GAAI,GAAA,CAA2B,AACnD,SACI,OAAO,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EACM,GAA6B,CAC/B,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAd+F,AAcxF,GAEH,IAAK,SACD,MAAO,EACX,KAAK,eACD,OAAO,CAAM,CAAC,GAAmB,GAAK,CAAD,AAAO,CAAC,GAAmB,CAAG,IAAI,eAAA,CAAiB,AAC5F,KAAK,aACD,OAAO,CAAM,CAAC,GAAW,GAAK,CAAD,AAAO,CAAC,GAAW,CAAG,CgBhmB/D,CADM,EAAI,IAAI,IAAI,AhBimBsD,EAAO,IAAI,GgBhmBjF,IAAI,CAAG,iBACT,EAAE,MAAM,CAAG,GACX,EAAE,QAAQ,CAAG,OACN,GhB6lB8E,IAAA,AAAI,CACjF,KAAK,SACL,IAAK,WACD,OAAO,CAAM,CAAC,GAAe,GAAK,CAAD,AAAO,CAAC,GAAe,CAAG,IAAI,EAAS,IAAA,AAAI,CAEhF,KAAK,MAID,MACJ,CADW,IACN,QACD,OAAO,CAAM,CAAC,GAAe,GAAK,CAAD,AAAO,CAAC,GAAe,CAAG,IAAI,IAAI,MAAM,EAAO,KAAK,GAAI,GAAA,CAC7F,AADwH,SAEpH,OAAO,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EAiEM,GAA+B,CACjC,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GACH,IAAK,UACD,OAAO,CAAM,CAAC,GAAc,GAAK,CAAD,AAAO,CAAC,GAAc,CAAG,IAAI,MAAM,EAAO,OAAO,CAAE,GAAA,CAA6B,AACpH,KAAK,UACL,IAAK,UACL,IAAK,MACL,IAAK,OACL,IAAK,OACL,IAAK,OACL,IAAK,OACL,IAAK,cACL,IAAK,WACD,MAAM,OAAO,cAAc,CAAC,IAAI,EAAA,qBAAqB,CAAC,CAAC,MAAM,EAAE,EAAO,OAAO,CAAC,QAAQ,CAAC,sFAAsF,EAAE,EAAK,GAAG,CAAC,EAAG,oBAAqB,CAC5M,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,KAAK,QACD,OAAO,CAAM,CAAC,GAAmB,GAAK,CAAD,AAAO,CAAC,GAAmB,CAAG,IAAI,IAAI,MACvE,AAMA,EAAO,KAAK,GAAI,GAAA,CAA6B,AACrD,SACI,OAAO,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EACM,GAA+B,CACjC,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,AAdwF,GAe3F,IAAK,SACL,IAAK,eACL,IAAK,MACL,IAAK,OACL,IAAK,SACL,IAAK,WACL,IAAK,SACD,MAAM,OAAO,cAAc,CAAC,IAAI,EAAA,qBAAqB,CAAC,CAAC,MAAM,EAAE,EAAO,QAAQ,CAAC,sFAAsF,EAAE,EAAK,GAAG,CAAC,EAAG,oBAAqB,CACpM,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,KAAK,QACD,OAAO,CAAM,CAAC,GAAe,GAAK,CAAD,AAAO,CAAC,GAAe,CAAG,IAAI,IAAI,MAAM,EAAO,KAAK,GAAI,GAAA,CAA6B,AAC1H,SACI,OAAO,EAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,EACA,SAAS,GAA2B,CAAK,EACrC,OAAO,OAAO,cAAc,CAAC,IAAI,EAAA,kBAAkB,CAAC,CAAC,MAAM,EAAE,EAAM,8IAA8I,CAAC,EAAG,oBAAqB,CACtO,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,EACJ,CACA,SAAS,GAAa,CAAK,CAAE,CAAa,CAAE,CAAU,EAClD,GAAI,EAAM,kBAAkB,CACxB,CAD0B,KACpB,OAAO,cAAc,CAAC,IAAI,EAAA,qBAAqB,CAAC,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,8EAA8E,EAAE,EAAW,4HAA4H,CAAC,EAAG,oBAAqB,CACvT,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,GAEJ,GAAI,EACA,OAAO,EAAc,IADN,AACU,EACrB,IAAK,QACL,IAAK,gBAGD,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,OAAO,EAAE,EAAW,gJAAgJ,EAAE,EAAW,qKAAqK,CAAC,EAAG,oBAAqB,CACta,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,EACJ,KAAK,iBACD,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,OAAO,EAAE,EAAW,iLAAiL,EAAE,EAAW,6KAA6K,CAAC,EAAG,oBAAqB,CAC/c,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,EACJ,KAAK,YACD,IAAM,EAAQ,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,MAAM,EAAE,EAAW,+HAA+H,CAAC,EAAG,oBAAqB,CAC1O,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,GACA,MAAO,CAAA,EAAA,EAAA,2CAAA,AAA2C,EAAC,EAAM,KAAK,CAAE,EAAY,EAAO,EACvF,KAAK,mBACD,MAAM,OAAO,cAAc,CAAC,IAAI,EAAA,cAAc,CAAC,oEAAqE,oBAAqB,CACrI,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,KAAK,oBACD,MAAM,OAAO,cAAc,CAAC,IAAI,EAAA,cAAc,CAAC,qEAAsE,oBAAqB,CACtI,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,KAAK,gBACD,MAAO,CAAA,EAAA,EAAA,oBAAA,AAAoB,EAAC,EAAM,KAAK,CAAE,EAAY,EAAc,eAAe,CACtF,KAAK,mBACD,EAAc,UAAU,CAAG,EAC3B,IAAM,EAAM,OAAO,cAAc,CAAC,IAAI,EAAA,kBAAkB,CAAC,CAAC,MAAM,EAAE,EAAM,KAAK,CAAC,mDAAmD,EAAE,EAAW,6EAA6E,CAAC,EAAG,oBAAqB,CAChP,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAGA,OAFA,EAAM,uBAAuB,CAAG,EAChC,EAAM,iBAAiB,CAAG,EAAI,KAAK,CAC7B,CAUd,CAER,EAEA,kCAAkC,2CAxRnB,yDsBliBbF,EAAOC,OAAO,CAAGF,EAAQ,CAAA,CAAA,IAAA,wE+G+L3B,QzGhMA,ID0HI,oBAEJ,gCAAgC,kIC5HhC,GAAA,EAAA,CAAA,CAAA,OFAA,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,OeAA,IAAM,GAAiB,OAAO,YACxB,GAAoB,OAAO,eAC3B,GAAkB,OAAO,YAC/B,OAAM,GACF,YAAY,CAAQ,CAAE,CAAS,CAAC,CAC5B,IAAI,CAAC,GAAkB,EAAG,EAC1B,IAAI,CAAC,GAAgB,CAAG,EAAY,CAChC,KAAM,WACN,SAAU,CACd,EAAI,CACA,KAAM,WACN,SAAU,EAAE,AAChB,CACJ,CAEA,YAAY,CAAQ,CAAE,CACd,AAAC,IAAI,CAAC,GAAe,EAAE,CACvB,IAAI,CAAC,GAAe,CAAG,QAAQ,OAAO,CAAC,EAAA,CAE/C,CAEA,wBAAyB,CACrB,IAAI,CAAC,GAAkB,EAAG,CAC9B,CACA,UAAU,CAAO,CAAE,CACf,GAAI,AAA+B,YAAY,KAAvC,CAAC,GAAgB,CAAC,IAAI,CAI1B,MAAO,GADW,IAAI,CAAC,GAAgB,CAAC,QAAA,AAAQ,EAC/B,GAIjB,IAAI,CAAC,GAAgB,CAAC,QAAQ,CAAC,IAAI,CAAC,EAE5C,CACJ,CAIO,MAAM,WAAuB,GAChC,YAAY,CAAM,CAAC,CACf,IAAI,EACJ,KAAK,CAAC,EAAO,OAAO,CAAwC,AAAtC,OAAC,EAAkB,EAAO,OAAA,AAAO,EAAY,KAAK,EAAI,EAAgB,SAAS,EACrG,IAAI,CAAC,UAAU,CAAG,EAAO,IAAI,AACjC,CAKE,IAAI,SAAU,CACZ,MAAM,OAAO,cAAc,CAAC,IAAI,GAAA,kBAAkB,CAAC,CAC/C,KAAM,IAAI,CAAC,UAAU,AACzB,GAAI,oBAAqB,CACrB,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CAKE,aAAc,CACZ,MAAM,OAAO,cAAc,CAAC,IAAI,GAAA,kBAAkB,CAAC,CAC/C,KAAM,IAAI,CAAC,UAAU,AACzB,GAAI,oBAAqB,CACrB,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,EACJ,CACJ,CftEA,CewEA,GfxEA,GAAA,EAAA,CAAA,CAAA,OOHA,EAAA,CAAA,CAAA,OAAA,IAAA,GAAA,EAAA,CAAA,CAAA,AQ2EuC,OR1EvC,GAAA,EAAA,CAAA,CAAA,OAEA,GAAA,EAAA,CAAA,CAAA,OAEA,IAAM,GAAY,OAAO,qBACnB,GAAY,IAAI,IAAI,CACtB,IACA,IACA,IACA,IACA,IACH,EACD,SAAS,GAAsB,CAAI,CAAE,CAAO,EACxC,IAAI,EACJ,GAAY,MAAR,CAAe,EAA2C,AAAlC,GAAJ,IAAK,EAAgB,EAAK,OAAA,AAAO,EAAY,KAAK,EAAI,EAAc,OAAO,CAAE,CACjG,GAAI,CAAC,CAAC,EAAK,OAAO,CAAC,OAAO,YAAY,OAAA,CAAO,CACzC,EAD4C,IACtC,OAAO,cAAc,CAAC,AAAI,MAAM,kDAAmD,oBAAqB,CAC1G,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAM,EAAO,EAAE,CACf,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,EAAK,OAAO,CAAC,OAAO,CAAC,AAC5C,EAAQ,GAAG,CAAC,wBAA0B,EAAK,GAC3C,EAAK,IAAI,CAAC,GAEd,EAAQ,GAAG,CAAC,gCAAiC,EAAK,IAAI,CAAC,KAC3D,CACJ,CAKW,MAAM,WAAqB,SAClC,YAAY,CAAI,CAAE,EAAO,CAAC,CAAC,CAAC,CACxB,KAAK,CAAC,EAAM,GACZ,MAAM,EAAU,IAAI,CAAC,OAAO,CAEtB,EAAe,IAAI,MAAM,AADf,IAAI,GAAA,eAAe,CAAC,GACI,CACpC,IAAK,CAAM,CAAE,CAAI,CAAE,CAAQ,EACvB,OAAO,GACH,IAAK,SACL,IAAK,MAEG,MAAO,CAAC,GAAG,KACP,IAAM,EAAS,QAAQ,KAAK,CAAC,CAAM,CAAC,EAAK,CAAE,EAAQ,GAC7C,EAAa,IAAI,QAAQ,GAK/B,OAJI,aAAkB,GAAA,eAAe,EAAE,AACnC,EAAQ,GAAG,CAAC,0BAA2B,EAAO,MAAM,GAAG,GAAG,CAAC,AAAC,GAAS,CAAA,EAAA,GAAA,eAAA,AAAe,EAAC,IAAS,IAAI,CAAC,MAEvG,GAAsB,EAAM,GACrB,CACX,CAER,SACI,OAAO,GAAA,cAAc,CAAC,GAAG,CAAC,EAAQ,EAAM,EAChD,CACJ,CACJ,GACA,IAAI,CAAC,GAAU,CAAG,CACd,QAAS,EACT,IAAK,EAAK,GAAG,CAAG,IAAI,GAAA,OAAO,CAAC,EAAK,GAAG,CAAE,CAClC,QAAS,CAAA,EAAA,GAAA,yBAAyB,AAAzB,EAA0B,GACnC,WAAY,EAAK,UAAU,AAC/B,QAAK,CACT,CACJ,CACA,CAAC,OAAO,GAAG,CAAC,+BAA+B,EAAG,CAC1C,MAAO,CACH,QAAS,IAAI,CAAC,OAAO,CACrB,IAAK,IAAI,CAAC,GAAG,CAEb,KAAM,IAAI,CAAC,IAAI,CACf,SAAU,IAAI,CAAC,QAAQ,CACvB,QAAS,OAAO,WAAW,CAAC,IAAI,CAAC,OAAO,EACxC,GAAI,IAAI,CAAC,EAAE,CACX,WAAY,IAAI,CAAC,UAAU,CAC3B,OAAQ,IAAI,CAAC,MAAM,CACnB,WAAY,IAAI,CAAC,UAAU,CAC3B,KAAM,IAAI,CAAC,IAAI,AACnB,CACJ,CACA,IAAI,SAAU,CACV,OAAO,IAAI,CAAC,GAAU,CAAC,OAAO,AAClC,CACA,OAAO,KAAK,CAAI,CAAE,CAAI,CAAE,CACpB,IAAM,EAAW,SAAS,IAAI,CAAC,EAAM,GACrC,OAAO,IAAI,GAAa,EAAS,IAAI,CAAE,EAC3C,CACA,OAAO,SAAS,CAAG,CAAE,CAAI,CAAE,CACvB,IAAM,EAAyB,UAAhB,OAAO,EAAoB,EAAO,CAAS,MAAR,EAAe,KAAK,EAAI,EAAK,MAAA,AAAM,GAAK,IAC1F,GAAI,CAAC,GAAU,GAAG,CAAC,GACf,MADwB,AAClB,OAAO,cAAc,CAAK,AAAJ,WAAe,mEAAoE,oBAAqB,CAChI,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAM,EAA0B,UAAhB,OAAO,EAAoB,EAAO,CAAC,EAC7C,EAAU,IAAI,QAAmB,MAAX,EAAkB,KAAK,EAAI,EAAQ,OAAO,EAEtE,OADA,EAAQ,GAAG,CAAC,WAAY,CAAA,EAAA,GAAA,WAAW,AAAX,EAAY,IAC7B,IAAI,GAAa,KAAM,CAC1B,GAAG,CAAO,CACV,iBACA,CACJ,EACJ,CACA,OAAO,QAAQ,CAAW,CAAE,CAAI,CAAE,CAC9B,IAAM,EAAU,IAAI,QAAgB,MAAR,EAAe,KAAK,EAAI,EAAK,OAAO,EAGhE,OAFA,EAAQ,GAAG,CAAC,uBAAwB,CAAA,EAAA,GAAA,WAAA,AAAW,EAAC,IAChD,GAAsB,EAAM,GACrB,IAAI,GAAa,KAAM,CAC1B,GAAG,CAAI,SACP,CACJ,EACJ,CACA,OAAO,KAAK,CAAI,CAAE,CACd,IAAM,EAAU,IAAI,QAAQ,AAAQ,QAAO,KAAK,EAAI,EAAK,OAAO,EAGhE,OAFA,EAAQ,GAAG,CAAC,oBAAqB,KACjC,GAAsB,EAAM,GACrB,IAAI,GAAa,KAAM,CAC1B,GAAG,CAAI,SACP,CACJ,EACJ,CACJ,CqB7HW,CrB+HX,QqB/HoB,GAAiB,CAAG,CAAE,CAAI,EAC1C,IAAM,EAA0B,AAAhB,crB8HgB,GqB9HT,EAAoB,IAAI,IAAI,GAAQ,EACrD,EAAW,IAAI,IAAI,EAAK,GAExB,EAAa,EAAS,MAAM,GAAK,EAAQ,MAAM,CACrD,MAAO,CACH,IAAK,EAAa,EAAS,QAAQ,GAAG,KAAK,CAAC,EAAQ,MAAM,CAAC,MAAM,EAAI,EAAS,QAAQ,cACtF,CACJ,CACJ,CtBXA,IAAA,GAAA,EAAA,CAAA,CAAA,MAC6B,CACzB,GAAA,oBACH,CNKD,EMNwB,ENMxB,GAAA,EAAA,CAAA,CAAA,OAGA,GAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OAAA,IAAA,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,MAAA,IAAA,GAAA,EAAA,CAAA,CAAA,OAEA,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,M2BWO,OAAM,GACT,QAAQ,CAAQ,CAAE,CACd,GAAI,IAAI,CAAC,QAAQ,CACb,CADe,KACT,OAAO,cAAc,CAAC,AAAI,MAAM,gDAAiD,oBAAqB,CACxG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEJ,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,QAAS,GACtC,IAAI,CAAC,SAAS,EAClB,CACA,eAAgB,CACZ,GAAI,IAAI,CAAC,QAAQ,CACb,CADe,KACT,OAAO,cAAc,CAAC,AAAI,MAAM,iDAAkD,oBAAqB,CACzG,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEA,IAAI,CAAC,SAAS,CAAG,GAAG,AACpB,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,IAAI,MAAM,UAExC,IAAI,CAAC,QAAQ,EAAG,CACpB,CACA,aAAa,CACT,IAAI,CAAC,MAAM,CAAG,IAAI,YAClB,IAAI,CAAC,SAAS,CAAG,EACjB,IAAI,CAAC,QAAQ,EAAG,CACpB,CACJ,C3BvCA,C2ByCA,G3BzCA,GAAA,EAAA,CAAA,CAAA,OQnBA,EAAA,CAAA,CAAA,OAMA,IAAM,GAA8B,KmBsDI,EnBtDG,GAAG,CAAC,yBRe/C,IAAA,GAAA,EAAA,CAAA,CAAA,MACO,OAAM,WAAwB,GAAA,WAAW,CAC5C,YAAY,CAAM,CAAC,CACf,KAAK,CAAC,EAAO,KAAK,CAAE,EAAO,IAAI,EAC/B,IAAI,CAAC,UAAU,CAAG,EAAO,IAAI,AACjC,CACA,IAAI,SAAU,CACV,MAAM,OAAO,cAAc,CAAC,IAAI,GAAA,kBAAkB,CAAC,CAC/C,KAAM,IAAI,CAAC,UAAU,AACzB,GAAI,oBAAqB,CACrB,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACA,aAAc,CACV,MAAM,OAAO,cAAc,CAAC,IAAI,GAAA,kBAAkB,CAAC,CAC/C,KAAM,IAAI,CAAC,UACf,AADyB,GACrB,oBAAqB,CACrB,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EACJ,CACA,WAAY,CACR,MAAM,OAAO,cAAc,CAAC,IAAI,GAAA,kBAAkB,CAAC,CAC/C,KAAM,IAAI,CAAC,UACf,AADyB,GACrB,oBAAqB,CACrB,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,EACJ,CACJ,CACA,IAAM,GAAgB,CAClB,KAAO,AAAD,GAAW,MAAM,IAAI,CAAC,EAAQ,IAAI,IACxC,IAAK,CAAC,EAAS,IAAM,EAAQ,GAAG,CAAC,SAAQ,CAC7C,EACI,GAAa,CAAC,EAAS,IAEhB,AADQ,CAAA,EAAA,GAAA,SAAA,AAAS,IACV,qBAAqB,CAAC,EAAQ,OAAO,CAAE,EAAI,IAEzD,IAAsB,EAYnB,eAAe,GAAQ,CAAM,MAC5B,EAwLI,EAAmE,EAAyC,MA/EhH,EACA,SAzGJ,AAbJ,SAAS,EACL,GAAI,CAAC,KACD,IAAsB,EACsB,SAAxC,CAFkB,OAEV,GAAG,CAAC,uBAAuB,EAAa,CAChD,GAAM,mBAAE,CAAiB,oBAAE,CAAkB,CAAE,CAAA,EAAA,CAAA,CAAA,OAE/C,IACA,GAAa,EAAmB,GACpC,CAER,IAII,MAAM,CAAA,EAAA,GAAA,+BAAA,AAA+B,IAErC,IAAM,EAAkB,KAAuC,IAAhC,WAAW,gBAAgB,CAC1D,EAAO,OAAO,CAAC,GAAG,CAAG,CAAA,EAAA,GAAA,eAAe,AAAf,EAAgB,EAAO,OAAO,CAAC,GAAG,EACvD,IAAM,EAAa,EAAO,aAAa,CAAG,IAAI,IAAI,EAAO,OAAO,CAAC,GAAG,EAAI,IAAI,GAAA,OAAO,CAAC,EAAO,OAAO,CAAC,GAAG,CAAE,CACpG,QAAS,EAAO,OAAO,CAAC,OAAO,CAC/B,WAAY,EAAO,OAAO,CAAC,UAAU,AACzC,GAMA,IAAK,IAAM,IAHE,GAGK,CAFX,EAAW,YAAY,CAAC,IAAI,GAClC,CACsB,CACnB,IAAM,EAAQ,EAAW,YAAY,CAAC,MAAM,CAAC,GACvC,EAAgB,CAAA,EAAA,GAAA,uBAAA,AAAuB,EAAC,GAC9C,GAAI,EAAe,CAEf,IAAK,IAAM,KADX,EAAW,YAAY,CAAC,MAAM,CAAC,GACb,GACd,EAAW,CADS,WACG,CAAC,MAAM,CAAC,EAAe,GAElD,EAAW,YAAY,CAAC,MAAM,CAAC,EACnC,CACJ,CAEA,IAAI,EAAU,QAAQ,GAAG,CAAC,eAAe,EAAI,GACzC,YAAa,IACb,EAAU,EAAW,IADI,GACG,EAAI,GAChC,EAAW,OAAO,CAAG,IAEzB,IAAM,EAAiB,CAAA,EAAA,GAAA,2BAAA,AAA2B,EAAC,EAAO,OAAO,CAAC,OAAO,EACnE,EAAoB,EAAe,GAAG,CAAC,iBACvC,EAAkD,MAAnC,EAAe,GAAG,CAAC,GAAA,UAAU,EAC9C,GAA6C,UAAU,CAAlC,EAAW,QAAQ,GACxC,EAAW,QAAQ,CAAG,GAAA,EAE1B,IAAM,EAAgB,IAAI,IAE1B,GAAI,CAAC,EACD,IAAK,IAAM,KAAU,EADH,CACG,cAAc,CAAC,CAChC,IAAM,EAAQ,EAAe,GAAG,CAAC,EACnB,MAAM,EAAhB,IACA,EAAc,GAAG,CAAC,EAAQ,GAC1B,EAAe,MAAM,CAAC,GAE9B,CAGJ,IAAM,EAAU,EAAa,YAAY,CAAC,GAAG,CAAC,GAAA,oBAAoB,EAC5D,EAAU,IAAI,GAAgB,CAChC,KAAM,EAAO,IAAI,CAEjB,MAAO,CMtHX,CADM,EAAW,CADX,EAA6B,UAAf,OAAO,ENwHU,CMvHN,IAAI,IAAI,GNkH6D,GMjH3F,CADqC,WACzB,CAAC,MAAM,CAAC,GAAA,oBAAoB,EAC1C,EAAc,EAAS,QAAQ,GAAK,GNqHQ,QAAQ,GACvD,KAAM,CACF,KAAM,EAAO,OAAO,CAAC,IAAI,CACzB,QAAS,EACT,OAAQ,EAAO,OAAO,CAAC,MAAM,CAC7B,WAAY,EAAO,OAAO,CAAC,UAAU,CACrC,OAAQ,EAAO,OAAO,CAAC,MAAM,AACjC,CACJ,GAKM,GACF,OAAO,SADc,KACA,CAAC,EAAS,WAAY,CACvC,WAAY,GACZ,OAAO,CACX,GAKJ,CAAC,WAAW,wBAAwB,EAAI,EAAO,gBAAgB,EAAE,CAE7D,WAAW,kBAAkB,CAAG,IAAI,EAAO,gBAAgB,CAAC,CACxD,gBAAiB,EAAO,uBAAuB,CAC/C,YAAa,GACb,mBAAmB,CAAA,GACnB,KAAK,EACL,eAAgB,EAAO,CAHe,MAGR,CAAC,OAAO,CACtC,gBAF8B,KAER,KACX,CACH,QAAS,CAAC,EACV,OAAQ,CAAC,EACT,cAAe,CAAC,EAChB,eAAgB,EAAE,CAClB,QAAS,CAAA,EAAA,GAAA,mBAAA,AAAmB,IAChC,CAER,EAAA,EAIJ,IAAM,EAAiB,EAAO,OAAO,CAAC,SAAS,GAAK,AAA4D,CAA7D,MAAE,EQzKvC,AAAP,OADD,EADc,AACR,UAAW,CAAC,GAA4B,EAC/B,CRyK4D,IQzKvD,EAAI,EAAI,GAAG,IRyKkF,KAAK,EAAI,EAA0B,EAA/C,OAAwD,AAAT,EACpJ,EAAQ,IAAI,GAAe,SAC7B,EACA,KAAM,EAAO,IAAI,CACjB,QAAS,EAAiB,CACtB,UAAW,CACf,OAAI,CACR,GA+DA,GA5DA,AA4DI,GA5DO,MAAM,GAAW,EAAS,KAGjC,GADqC,CACjC,eADiB,EAAO,IAAI,EAAsC,oBAAhB,EAAO,IAAI,EAA0C,WAAhB,EAAO,IAAI,EAAiC,eAAhB,EAAO,IAAI,CAChH,CAId,IAAM,EAAY,EAAM,SAAS,CAAC,IAAI,CAAC,GACjC,EAAkB,IAAI,GAC5B,MAAO,CAAA,EAAA,GAAA,SAAA,AAAS,IAAG,KAAK,CAAC,GAAA,cAAc,CAAC,OAAO,CAAE,CAC7C,SAAU,CAAC,WAAW,EAAE,EAAQ,MAAM,CAAA,CAAE,CACxC,WAAY,CACR,cAAe,EAAQ,OAAO,CAAC,QAAQ,CACvC,cAAe,EAAQ,MAAM,AACjC,CACJ,EAAG,UACC,GAAI,CACA,IAAI,EAAyC,EAA4B,EAA0C,EAInH,IAAM,EAAe,CAAA,EAAA,GAAA,mBAAA,AAAmB,IAIlC,EAAe,MAAM,CAAA,EAAA,GAAA,eAAA,AAAe,EAAC,IAAM,EAAQ,OAAO,CADpC,CACsC,KAC5D,EAAe,CAAA,EAAA,GAAA,wBAAA,AAAwB,EAAC,EAAS,EAAQ,OAAO,CAAE,EARhD,AAAC,IACrB,EAAsB,CAC1B,EAMuG,GAAjB,AAChF,EAAY,CAAA,EAAA,GAAA,eAAA,AAAe,EAAC,CAC9B,KANS,IAAI,AAOb,WAAY,CAPa,AAQrB,iBAAA,CAA+E,CAA5D,MAAmE,AAAlE,EAA6B,EAAO,CAAmC,MAA5B,CAAC,UAAA,AAAU,GAAqB,AAAuF,OAAtF,EAA0C,EAA2B,YAAY,AAAZ,EAAwB,KAAK,EAAI,EAAwC,SAAS,CACvP,iBAAiB,EACjB,aAAc,CACV,mBAAmB,EACnB,eAAgB,CAAC,CAAC,CAAC,AAA6D,MAA5D,CAAmE,EAArC,EAAO,CAAmC,MAA5B,CAAC,UAAA,AAAU,GAA8G,AAAzF,OAAC,EAA2C,EAA4B,YAAY,AAAZ,EAAwB,KAAK,EAAI,EAAyC,cAAc,CACpQ,EACA,wBAAyB,aACzB,EACA,QAAS,EAAgB,OAAO,CAAC,IAAI,CAAC,GACtC,sBAAkB,CACtB,EACA,kBAAwE,MAArD,EAAQ,OAAO,CAAC,GAAG,CAAC,GAAA,2BAA2B,EAClE,QAAS,GAAW,GACpB,0BAA2B,EAAE,AACjC,GACA,OAAO,MAAM,GAAA,gBAAgB,CAAC,GAAG,CAAC,EAAW,IAAI,GAAA,oBAAoB,CAAC,GAAG,CAAC,EAAc,EAAO,OAAO,CAAE,EAAS,GACrH,QAAS,CAKL,WAAW,KACP,EAAgB,aAAa,EACjC,EAAG,EACP,CACJ,EACJ,CACA,OAAO,EAAO,OAAO,CAAC,EAAS,EACnC,EAAA,GAEgB,CAAC,CAAC,aAAoB,QAAA,CAAQ,CAC1C,EAD6C,IACvC,OAAO,cAAc,CAAC,AAAI,UAAU,mDAAoD,oBAAqB,CAC/G,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAEA,GAAY,GACZ,EAAS,OAAO,CAAC,GAAG,CAAC,IADY,SACE,GAOrC,IAAM,EAAsB,MAAZ,EAAmB,KAAK,EAAI,EAAS,OAAO,CAAC,GAAG,CAAC,wBACnE,GAAI,GAAY,IAAY,GAAgB,CAAC,CAAA,CAAe,CAAG,AAApC,CAEvB,IAAM,EAAc,IAAI,GAAA,OAAO,CAAC,EAAS,CACrC,aAAa,EACb,QAAS,EAAO,OAAO,CAAC,OAAO,CAC/B,WAAY,EAAO,OAAO,CAAC,UAAU,AACzC,GACwD,GAChD,EAAY,IAAI,GAAK,EAAQ,GADoC,IAC7B,CAAC,IAAI,EAAE,CAC3C,EAAY,OAAO,CAAG,GAAW,EAAY,OAAO,CACpD,EAAS,OAAO,CAAC,GAAG,CAAC,uBAAwB,OAAO,KAO5D,GAAM,CAAE,IAAK,CAAmB,YAAE,CAAU,CAAE,CAAG,GAAiB,EAAY,QAAQ,GAAI,EAAW,QAAQ,GACzG,EAAC,GAAmB,GAIpB,EAAS,OAAO,CAAC,GAAG,CAAC,IAJoB,eAIA,GAK7C,IAAM,EAAkB,CAAC,IAAyE,OAAO,AAAlE,EAA6B,AAA9B,EAAqC,CAAmC,MAA5B,CAAC,EATY,QASZ,AAAU,GAAqB,AAAuF,OAAtF,AAA6F,EAAnD,EAA2B,CAA6B,WAA7B,AAAY,GAAqB,AAA2I,OAA1I,EAAoE,EAAwC,yBAAA,AAAyB,EAAY,KAAK,EAAI,EAAkE,IAAI,CAAC,AAAC,GAAS,IAAI,OAAO,GAAQ,IAAI,CAAC,EAAY,MAAM,IAI3e,CAJgf,GAI/d,GAAc,CAAA,CAAe,GAAG,AAC7C,EAAW,EADC,MACO,GAAK,EAAY,QAAQ,EAAE,AAC9C,EAAS,OAAO,CAAC,GAAG,CAAC,GAAA,0BAA0B,CAAE,EAAY,QAAQ,EAErE,EAAW,MAAM,GAAK,EAAY,MAAM,EAAE,AAC1C,EAAS,OAAO,CAAC,GAAG,CAAC,GAAA,2BAA2B,CAChD,EAAY,MAAM,CAAC,KAAK,CAAC,IAGrC,CAUE,GAAI,GAAY,GAAW,GAAgB,EAAS,CAClD,IAAM,EAAa,IAAI,IAAI,GACtB,EAAW,YAAY,CAAC,GAAG,CAAC,GAAA,oBAAoB,GAAG,CACpD,EAAW,YAAY,CAAC,GAAG,CAAC,GAAA,oBAAoB,CAAE,GAClD,EAAS,OAAO,CAAC,GAAG,CAAC,uBAAwB,EAAW,QAAQ,IAExE,CAKE,IAAM,EAAW,AAAY,QAAO,KAAK,EAAI,EAAS,OAAO,CAAC,GAAG,CAAC,YACpE,GAAI,GAAY,GAAY,CAAC,EAAiB,CAC1C,IAAM,EAAc,IAAI,GAAA,OAAO,CAAC,EAAU,CACtC,aAAa,EACb,QAAS,EAAO,OAAO,CAAC,OAAO,CAC/B,WAAY,EAAO,OAAO,CAAC,UAAU,AACzC,GAIA,EAAW,IAAI,SAAS,EAAS,IAAI,CAAE,GAE/B,EAAY,IAAI,GAAK,EAAW,IAAI,EAAE,CACtC,EAAY,OAAO,CAAG,GAAW,EAAY,OAAO,CACpD,EAAS,OAAO,CAAC,GAAG,CAAC,W4B5T1B,C5B4TsC,EAAe,EAAa,G4B5TzD,GAAG,G5BmUX,IACA,EAAS,OAAO,CAAC,KADE,CACI,CAAC,YACxB,EAAS,OAAO,CAAC,GAAG,CAAC,oB4BtUZ,C5BsUiC,EAAe,EAAY,QAAQ,GAAI,C4BtUvD,C5BsUkE,I4BtU7D,I5BsUqE,SAE5G,CACA,IAAM,EAAgB,GAAsB,GAAa,IAAI,CAA5B,EAE3B,EAA4B,EAAc,OAAO,CAAC,GAAG,CAAC,iCACtD,EAAqB,EAAE,CAC7B,GAAI,EAA2B,CAC3B,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,EACvB,EAAc,OAAO,CAAC,EADe,CACZ,CAAC,CAAC,qBAAqB,EAAE,EAAA,CAAK,CAAE,GACzD,EAAmB,IAAI,CAAC,GAExB,EAAmB,MAAM,CAAG,GAC5B,AAD+B,EACjB,OAAO,CAAC,GAAG,CAAC,gCAAiC,EAA4B,IAAM,EAAmB,IAAI,CAAC,KAE7H,CACA,MAAO,CACH,SAAU,EACV,UAAW,CelUwB,aAAhC,CAAK,CAAC,GAAgB,CAAC,IAAI,CAAkB,QAAQ,GAAG,CfkUnB,AelUoB,CAAK,CAAC,GAAgB,CAAC,QAAQ,EAAE,IAAI,CAAC,KAAK,QAAK,CAAA,GfkU1D,QAAQ,OAAO,GACjE,aAAc,EAAQ,YAC1B,AADsC,CAE1C,CE1WA,CF4WA,GE5WA,GAAA,EAAA,CAAA,CAAA,MLFA,EAAA,CAAA,CAAA,OAAA,IAAA,GAAA,CG8WmC,CH9WnC,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,MACO,OAAM,GACT,YAAY,CAAU,CAAC,CACnB,IAAI,CAAC,UAAU,CAAG,EACd,CAAA,EAAA,GAAA,cAAA,AAAc,EAAC,EAAW,QAAQ,GAAG,AACrC,KAAI,CAAC,OAAO,CAAG,CAAA,EAAA,GAAA,eAAA,AAAe,EAAC,CAAA,EAAA,GAAA,aAAA,AAAa,EAAC,EAAW,QAAQ,EAAA,CAExE,CAKE,IAAI,UAAW,CACb,OAAO,IAAI,CAAC,UAAU,CAAC,QAAQ,AACnC,CACA,IAAI,WAAY,CACZ,YAAwB,IAAjB,IAAI,CAAC,OAAO,AACvB,CACA,MAAM,CAAQ,CAAE,CACZ,IAAM,EAAS,IAAI,CAAC,IAAI,CAAC,UACzB,AAAK,EACE,CACH,CAFA,IAAS,MAEG,IAAI,CAAC,UAAU,CAC3B,OAAQ,EAAO,MAAM,AACzB,EAJoB,IAKxB,CACA,KAAK,CAAQ,CAAE,CACX,GAAI,IAAI,CAAC,OAAO,CAAE,CACd,IAAM,EAAS,IAAI,CAAC,OAAO,CAAC,UAC5B,AAAK,EACE,EADH,IAAS,EAET,CACJ,EAHoB,IAIxB,QACA,AAAI,IAAa,IAAI,CAAC,UAAU,CAAC,QAAQ,CAC9B,CADgC,AAC/B,EAEL,IACX,CACJ,CCtCA,CDwCA,GCxCM,GAAa,OAAO,GAAG,CAAC,wBDwCW,OCvCnC,GACN,UAAU,CAAC,GAAW,GACrB,CADyB,SACf,CAAC,GAAW,AADgB,CACb,CACtB,iBAAkB,EAClB,sBAAkB,EAClB,iBAAkB,KACtB,CAAC,CILD,IAAA,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,OHNA,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,MACO,OAAM,GACT,YAAY,CAAM,CAAE,CAAG,CAAE,CAAI,CAAC,CAC1B,IAAI,CAAC,MAAM,CAAG,EACd,IAAI,CAAC,GAAG,CAAG,EACX,IAAI,CAAC,IAAI,CAAG,CAChB,CAEA,IAAI,SAAU,QACV,AAAI,IAAI,CAAC,QAAQ,CAAS,CAAP,GAAW,CAAC,QAAQ,CAChC,IAAI,CAAC,QAAQ,CAAG,CAAA,EAAA,GAAA,eAAA,AAAe,EAAC,IAAI,CAAC,OAAO,GACvD,CACJ,CACO,MAAM,GACT,YAAY,CAAW,CAAC,CACpB,IAAI,CAAC,WAAW,CAAG,CACvB,CAEA,SAAS,CAAW,CAAE,CAAU,CAAE,CAQ9B,OAPA,IAAI,CAAC,SAAS,CAAC,WAAY,GAC3B,IAAI,CAAC,UAAU,CAAG,EAGd,IAAe,GAAA,kBAAkB,CAAC,iBAAiB,EAAE,AACrD,IAAI,CAAC,SAAS,CAAC,UAAW,CAAC,MAAM,EAAE,EAAA,CAAa,EAE7C,IAAI,AACf,CACJ,C0B3BA,C1B6BA,C0B7BA,CAAA,CAAA,OAEA,EAAA,CAAA,CAAA,MACO,OAAM,M1B0BoB,K0B1BG,GAChC,YAAY,CAAO,CAAC,CAChB,MAAM,EAAM,IAAI,IAAI,EAAQ,GAAG,EAK/B,IAAK,KAAM,CAAC,EAAM,EAAM,GAJxB,KAAK,CAAC,EAAQ,MAAM,CAAE,EAAI,IAAI,CAAC,KAAK,CAAC,EAAI,MAAM,CAAC,MAAM,EAAG,EAAQ,KAAK,GAAG,IAAI,EAC7E,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,YAAY,CAAG,EAAQ,YAAY,CACxC,IAAI,CAAC,OAAO,CAAG,CAAC,EACY,EAAQ,OAAO,CAAC,OAAO,GAAG,CAClD,IAAI,CAAC,OAAO,CAAC,EAAK,CAAG,CAE7B,CACA,MAAM,UAAU,CAAM,CAAE,CACpB,MAAM,OAAO,cAAc,CAAC,AAAI,MAAM,mDAAoD,oBAAqB,CAC3G,MAAO,OACP,YAAY,EACZ,aAAc,EAClB,EACJ,CACJ,CvBTW,MAAM,GAMX,YAAY,CAAW,CAAC,CACtB,IAAI,CAAC,WAAW,CAAG,EAEnB,IAAI,CAAC,OAAO,CAAG,IAAI,GAAa,EAAY,UAAU,CAC1D,CASE,OAAO,KAAK,CAAW,CAAE,CAAO,CAAE,CAEhC,IAAM,EAAU,IAAI,GAAuB,GAE3C,OAAO,AAAC,GACG,GAAQ,CACX,GAAG,CAAI,CACP,iBAAA,GAAA,gBAAgB,CAEhB,QAAS,EAAQ,OAAO,CAAC,IAAI,CAAC,GAC9B,KAAM,EAAQ,IAAI,AACtB,EAER,CACA,MAAM,QAAQ,CAAO,CAAE,CAAG,CAAE,CACxB,IAAM,EAAQ,CAAA,EAAA,GAAA,cAAA,AAAc,EAAC,CACzB,cAAe,IAAI,CAAC,OAAO,CAAC,SAAS,CACrC,KAAM,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,QAAQ,CACtC,SAAU,EAAQ,OAAO,CAAC,QAAQ,CAElC,SAAU,CAAC,EAEX,eAAe,CACnB,GACM,YAAE,CAAU,CAAE,CAAG,IAAI,CAAC,WAAW,CAAC,iBAAiB,CAAC,IAAI,GAAe,IACvE,QAAE,CAAM,CAAE,CAAG,EAAM,2BAA2B,CAAC,CAAA,EAAA,GAAA,sBAAA,AAAsB,EAAC,EAAQ,OAAO,CAAC,YAAY,GAAG,GACrG,EAAY,EAAI,SAAS,CAAC,IAAI,CAAC,GAC/B,EAAkB,IAAI,GAItB,EAAU,CACZ,SACA,kBAAmB,CACf,QAAS,EACT,OAAQ,CAAC,EACT,cAAe,CAAC,EAChB,QATa,CASJ,AATI,EAAA,GAAA,mBAAA,AAAmB,IAUhC,eAAgB,EAAE,AACtB,EACA,WAAY,CACR,yBAAyB,YACzB,EACA,QAAS,EAAgB,OAAO,CAAC,IAAI,CAAC,GACtC,sBAAkB,EAClB,iBAAiB,CAAC,CAClB,aAAc,CACV,gBAAgB,CAAC,AACrB,EACA,kBAAmB,EAAW,SAClC,AAD2C,EAE3C,cAAe,CACX,QAAS,EACb,CACJ,EAEI,EAAM,MAAM,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,EAAS,GAC3C,EAAoB,CJpEvB,GAAM,gBAAgB,CIsExB,CAKD,GAJI,CAIA,CAJQ,UAAU,CAAC,gBAAgB,EAAE,AACrC,EAAkB,IAAI,CAAC,EAAQ,UAAU,CAAC,gBAAgB,EAE9D,EAAI,SAAS,CAAC,QAAQ,GAAG,CAAC,IACrB,EAAI,IAAI,CAIN,CAJQ,IyBlFa,MAAM,MzB0F9B,EAAM,IAAI,SAAS,GADqB,EAAI,IAAI,CyBzFhB,EzByFkB,GyBzFb,CzByFiB,EAAgB,aAAa,GyBjFrF,EAAO,IAAI,gBACX,EAAW,IAAI,IACrB,EAAO,MAAM,CAAC,EAAK,QAAQ,EAAE,IAAI,CAAC,EAAU,GACrC,EAAK,QAAQ,EzB+EoB,CAC5B,OAAQ,EAAI,MAAM,CAClB,WAAY,EAAI,UAAU,CAC1B,QAAS,EAAI,OAAO,AACxB,EACJ,MAVI,WAAW,IAAI,EAAgB,aAAa,GAAI,GAWpD,OAAO,CACX,CACJ,EAEA,4CDnHA,IAAA,GAAA,EAAA,ACmHqD,CDnHrD,CAAA,MACA,GAAA,EAAA,CAAA,CAAA,MAGO,OAAM,WAAwB,GACjC,QAAO,CAAA,AAAE,CAAU,EAAP,AAA4B,GAAA,iBAAiB,AAAC,AAC1D,aAAY,CAAI,CAAC,CACb,IAAI,EACJ,KAAK,CAAC,EAAK,MAAM,CAAC,WAAW,GAAI,EAAK,GAAG,CAAE,GAAO,IAAI,CAAC,IAAI,CAAG,EAAM,IAAI,CAAC,OAAO,CAAG,IAAI,CAAC,IAAI,CAAC,OAAO,CAAE,IAAI,CAAC,YAAY,CAA+B,AAA5B,OAAC,EAAa,IAAI,CAAC,IAAI,AAAJ,EAAgB,KAAK,EAAI,EAAW,YAAY,CAAE,IAAI,CAAC,EAAmB,CAAG,IAAI,CAAC,IAAI,CAAC,GAAA,iBAAiB,CAAC,EAAI,CAAC,EAAG,IAAI,CAAC,SAAS,EAAG,CACnR,CACA,IAAI,iBAAkB,CAMlB,OAHA,IAAI,CAAC,IAAI,CAAC,GAAA,iBAAiB,CAAC,CAAG,IAAI,CAAC,GAAA,iBAAiB,CAAC,CACtD,IAAI,CAAC,IAAI,CAAC,GAAG,CAAG,IAAI,CAAC,GAAG,CACxB,IAAI,CAAC,IAAI,CAAC,OAAO,CAAG,IAAI,CAAC,OAAO,CACzB,IAAI,CAAC,IAAI,AACpB,CACA,IAAI,gBAAgB,CAAK,CAAE,CACvB,IAAI,CAAC,IAAI,CAAG,CAChB,CAOE,QAAS,CACP,GAAI,IAAI,CAAC,SAAS,CACd,CADgB,KACV,OAAO,cAAc,CAAC,AAAI,MAAM,+DAAgE,oBAAqB,CACvH,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,GAGJ,OADA,IAAI,CAAC,SAAS,EAAG,EACV,IAAI,eAAe,CACtB,MAAO,AAAC,IACJ,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,OAAQ,AAAC,IAClB,EAAW,OAAO,CAAC,IAAI,WAAW,GACtC,GACA,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,MAAO,KAChB,EAAW,KAAK,EACpB,GACA,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,QAAU,AAAD,IAClB,EAAW,KAAK,CAAC,EACrB,EACJ,CACJ,EACJ,CACJ,CACO,MAAM,WAAyB,GAClC,IAAI,kBAAmB,CAInB,OAHI,GAAA,sBAAsB,IAAI,IAAI,EAAE,CAChC,IAAI,CAAC,IAAI,CAAC,GAAA,sBAAsB,CAAC,CAAG,IAAI,CAAC,GAAA,sBAAsB,CAAC,EAE7D,IAAI,CAAC,IAAI,AACpB,CACA,YAAY,CAAI,CAAC,CACb,KAAK,CAAC,GAAO,IAAI,CAAC,IAAI,CAAG,EAAM,IAAI,CAAC,QAAQ,MAAG,CACnD,CACA,IAAI,MAAO,CACP,OAAO,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAI,IAAI,CAAC,IAAI,CAAC,WAAW,AACtD,CACA,IAAI,YAAa,CACb,OAAO,IAAI,CAAC,IAAI,CAAC,UAAU,AAC/B,CACA,IAAI,WAAW,CAAK,CAAE,CAClB,IAAI,CAAC,IAAI,CAAC,UAAU,CAAG,CAC3B,CACA,IAAI,eAAgB,CAChB,OAAO,IAAI,CAAC,IAAI,CAAC,aAAa,AAClC,CACA,IAAI,cAAc,CAAK,CAAE,CACrB,IAAI,CAAC,IAAI,CAAC,aAAa,CAAG,CAC9B,CACA,UAAU,CAAI,CAAE,CAAK,CAAE,CAEnB,OADA,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAM,GACnB,IAAI,AACf,CACA,aAAa,CAAI,CAAE,CAEf,OADA,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC,GAChB,IAAI,AACf,CACA,gBAAgB,CAAI,CAAE,CAClB,IAAM,EAAS,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GACnC,QAAe,IAAX,EACJ,KAD0B,CACnB,CAAC,KADyB,CACnB,OAAO,CAAC,GAAU,EAAS,CACrC,EACH,EAAE,GAAG,CAAC,AAAC,GAAQ,EAAM,QAAQ,GAClC,CACA,UAAU,CAAI,CAAE,CACZ,OAAO,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAC/B,CACA,UAAU,CAAI,CAAE,CACZ,IAAM,EAAS,IAAI,CAAC,eAAe,CAAC,GACpC,OAAO,MAAM,OAAO,CAAC,GAAU,EAAO,IAAI,CAAC,UAAO,CACtD,CACA,YAAa,CACT,OAAO,IAAI,CAAC,IAAI,CAAC,UAAU,EAC/B,CACA,aAAa,CAAI,CAAE,CAAK,CAAE,CACtB,IAAM,EAAgB,IAAI,CAAC,eAAe,CAAC,IAAS,EAAE,CAOtD,OANK,AAAD,EAAe,QAAQ,CAAC,IACxB,IADgC,AAC5B,CAAC,IAAI,CAAC,SAAS,CAAC,EAAM,IACnB,EACH,EACH,EAEE,IAAI,AACf,CACA,KAAK,CAAK,CAAE,CAER,OADA,IAAI,CAAC,QAAQ,CAAG,EACT,IAAI,AACf,CACA,MAAO,CACH,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,QAAQ,CAC/B,CACA,QAAQ,CAAQ,CAAE,CACd,IAAI,CAAC,gBAAgB,CAAC,EAAE,CAAC,QAAS,EACtC,CACJ,CUzHO,SAAS,GAAoB,CAAM,SACtC,AAAI,EAAO,oBAAoB,CACpB,CADsB,WAG7B,EAAO,kBAAkB,CAClB,CADoB,aAInC,CRCW,CQCX,cRD0B,GAAa,CAAG,CAAE,CAAG,CAAE,CAAQ,CAAE,CAAS,EAsDpE,EAEA,KQvDiC,oCRuDQ,gEAjEzC,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,wCCDA,IAAA,GAAA,EAAA,CAAA,CAAA,OACO,SAAS,GAAsB,YAAE,CAAU,QAAE,CAAM,CAAE,EACxD,IAAM,EAAkC,UAAtB,OAAO,QAAsC,IAAX,GAAwB,EAAa,EAAS,CAAC,yBAAyB,EAAE,EAAS,EAAA,CAAY,CAAG,UACtJ,AAAmB,GAAG,CAAlB,EACO,0DACsB,UAAtB,AAAgC,OAAzB,EACP,CAAC,SAAS,EAAE,EAAA,EAAa,EAAA,CAAW,CAExC,CAAC,SAAS,EAAE,GAAA,cAAc,CAAA,EAAG,EAAA,CAAW,AACnD,EAEA,yCAAyC,CMXlC,OAAM,WAAwB,MACjC,aAAa,CACT,KAAK,GACL,IAAI,CAAC,OAAO,CAAG,2BACnB,CACJ,CLLA,CKOA,QLPS,GAAuB,CAAQ,CAAE,CAAK,CAAE,CAAK,CAAE,CAAI,CAAE,CAAC,EAC3D,GAAa,MAAT,EACA,MAAM,AAAI,UAAU,KKK0B,6BLJlD,GAAa,MAAT,GAAgB,CAAC,EACjB,MAAM,AAAI,UAAU,iDACxB,GAAqB,YAAjB,OAAO,EAAuB,IAAa,GAAS,CAAC,EAAI,CAAC,EAAM,GAAG,CAAC,GACpE,MAAU,AAAJ,UAAc,2EACxB,MAAgB,MAAT,EAAe,EAAE,IAAI,CAAC,EAAU,GAAS,EAAK,EAAE,KAAK,CAAG,EAAS,EAAM,GAAG,CAAC,EAAU,GAAQ,CACxG,CACA,SAAS,GAAuB,CAAQ,CAAE,CAAK,CAAE,CAAI,CAAE,CAAC,EACpD,GAAa,MAAT,GAAgB,CAAC,EACjB,MAAM,AAAI,UAAU,iDACxB,GAAqB,YAAjB,OAAO,EAAuB,IAAa,GAAS,CAAC,EAAI,CAAC,EAAM,GAAG,CAAC,GACpE,MAAM,AAAI,UAAU,4EACxB,MAAgB,MAAT,EAAe,EAAa,MAAT,EAAe,EAAE,IAAI,CAAC,GAAY,EAAI,EAAE,KAAK,CAAG,EAAM,GAAG,CAAC,EACxF,mL2EH2C,eAAe,CAAC,EAAE,AAAC,CAAA,EAAA,CAAO,IAAoB,AAApB,IAAA,KAAY,MAAM,EAAE,CAAW,CpCkBC,uDoCjB9C,CAAA,SAAA,GAAA,CAAA,AACjD,EAAA,IAAqB,EAAE,EAAK,AAAC,CAAC,EAAG,CAAC,AAAG,CAAF,AAAG,AAAC,QAAQ,CAAC,EAAE,CAAC,CACtD,CAAC,etDe2H,CAC1H,CAAC,0R6Bd8D,aAEpC,EAAA,OAAA,CAAa,EAAA,KAAA,CAAA,SAAyB,KAAK,CAAE,C+BgDK,A/BhDJ,AAAE,CAAA,gGAIrC,WAG9B,iCAEyB,0HPHW,GAAA,CAAU,CAAC,CAAC,YCblC,EACzB,ICAgF,aDA/D,EACjB,aAAa,EACb,aAAa,EACb,cAAc,EACd,eAAe,EACf,ODeO,KAAA,IAAA,GCfY,EACnB,mBAAmB,EACnB,qBAAqB,EACrB,wBAAwB,EACxB,4BAA4B,GAC7B,yJDuCG,CAAA,CAAA,kCAGkC,EAAS,MAAA,GAAA,uCAM9B,GAAA,EAAA,EAA+B,ClBIkC,AUtB/B,CAAA,eQsBlC,GAAA,EAAA,EAAmC,C8BLG,CoCbH,ApCaI,AAAC,CAAA,E9BQtC,YACF,GAAA,EAA8B,EAAA,EAAgB,wBAIR,GAG/C,wBAIW,QACN,IAAA,GAA6B,E6CvBE,ArCqBlB,CAAA,CAAA,EREwC,oBAI1B,EAAO,EAAA,uCAOC,C2ByQT,0I3B9PzB,CAAA,QAAA,CAAA,CAAA,MAAA,CAAgB,CAAA,CAAA,YACpB,EAAA,KAAA,EAAA,GAAA,yBAAsD,C8DmBD,gB9DhBtC,CAAA,CAAA,oBAIsB,0FAMV,qBAEI,yBAInC,MAAA,WAAA,+BAIO,WAAA,yBAIP,MAAO,WAAA,qBAEgC,GAC3C,C5BgEC,CAAC,CkE4BG,AlE5BF,UAAA,O4B/DK,kEAAkE,CAAC,CAAC,G8DiCD,EAAE,a9D7B3B,E5BoEA,oB4BlE3C,CAAC,oFAAoF,CAAC,CAAC,CAE/F,MAEY,WAAA,2BAEH,yDjBlJwE,EAAA,MACrD,uGAwBsB,CAAA,MAAO,CWuHD,MXvHQ,CAAA,iBZlCxB,QAAA,GAA2B,EGDZ,SAAA,EHCgC,EAAE,CAAC,CIMvC,AJNwC,CKCd,ALDe,YNF5D,2BAA2B,0Ca6BlD,MAAA,0JAQ4B,CAAA,kCAEC,CAAQ,CAAA,OAAQ,aAAA,CAAA,GAAmB,CAAA,CAAS,OAAA,QAAe,CAAA,kEAKzD,IAAA,yBAId,qDAesB,CAAA,8GAQrC,GAAA,MAAA,EAAA,WAAA,qCAGkB,SAH4D,GoFgCT,UpFxBrE,EAAA,EAAA,MAAA,WAL6D,wGAoB9B,CAAA,eACA,mBAAA,oFAGI,6BAKhB,CkDJD,KAAA,+B5DbjB,CCrFD,EAAA,CAAA,CAAA,QAAA,CAAA,MDqF+C,CAAA,CAAA,iFJpFrB,gDAGA,GAAA,OAAA,CAAW,CESJ,AwBQN,AEpBA,ADaG,AHRH,ACGA,CFPC,CrBWO,AgBkBR,AQVE,AGfA,I7BFgB,qBiBDvC,EAAA,IAAA,CAAA,GAAA,OAAA,MAAA,EAAA,SAC0B,CKFqB,QLEZ,CAAC,IAAI,CAAC,ETwBqB,CAAC,CSxBlB,CAAC,KGQ0B,CHRpB,AGQqB,CHRpB,SAAS,CAAA,eAAe,CAAC,CAAC,EAAA,gFAO1C,CuBCc,ACGU,EDHV,EAAA,WvBDE,iBAmPjE,SAAA,GAAuB,CAAQ,CAAE,CAAe,C+CVtB,C/CW9B,GAAA,GAAA,GAAkB,KACV,C+CVC,C/CUQ,EAAA,KACV,IAAA,EAAA,EAAW,CAAC,CAAA,EAAO,MAAM,CAAA,GAAA,EAAU,CAAC,Ga+EG,oBb3E9C,C8C8RC,A9C9RA,OACM,EAAA,EACT,gKPrP6E,GAAgB,CAAC,EAKxF,GAAA,8BAEO,kIO6GN,CAAA,EAAA,EAAA,EAMuC,EAAO,C8C0QK,2B9CtQ/C,QAGI,eACgB,WAClB,OAAO,SAAS,CAAC,QAAQ,CAAC,CiFgDP,AvEtBQ,AGmDN,GAAA,Cb7EU,0BAE/B,CPKC,MOLM,EAAA,2CAIa,CAAC,kBAAA,SAAA,CAAA,iCACO,CAAC,GAAI,CPOjB,GOPuB,C4BwGG,ChDxHH,mBoBqB7C,IAAI,EAAA,EAAO,EAAA,EAAW,MAAA,CAAA,GA7Bf,KA6Be,CACzB,IAAA,EAAA,EAAA,MAA6B,CwE+DH,MxE/De,EAAO,KAAA,CAAM,CAAC,CAAA,QAAe,WAGjE,IAAA,EAAA,EAAA,EAAe,CSyEc,CTzEN,MAAA,CAAQ,EAAE,CAAC,CAAA,mBACX,CAAC,CAAC,iBAER,IAEZ,CoDqBC,A0BT6B,G9EblB,QACA,EoDqBE,A7DiFM,GSpGzB,GAAK,IAAQ,CAAC,ApBnBsC,EAAA,IoBoBpD,CTwGC,ASxGA,EAAA,IAAA,GAAA,IAAA,GAAA,IAAA,GAAA,KAAA,YAAA,IAEuB,KAAD,CAAC,CAAb,CAAa,AAAmB,CSiFX,CIDa,GbhFrB,CagFqB,Eb/E9C,OADyD,cAEzB,CAAC,CAAC,gBAI5B,CagFH,AZTI,GDvEK,EACT,CAAA,EAAA,MAAA,CAAY,CAAG,EAAS,CAAC,CPWf,AOXgB,CAAC,CAAC,mBAIlB,C+CPC,A/COA,UACA,CAAA,CAAA,EAAA,CAAc,E+CPI,E/COI,GAAK,CAAC,CAAG,CAAA,EAAY,CAAC,IAAA,GAAA,EAAkB,CAAC,YAI3E,CAAC,AagFF,CAAA,ObhFe,GAAA,MAAA,EACb,CAAC,EAAI,A4ByGE,CjClFCnF,KKvBG,CAAC,C4ByGM,CAAA,C5BxGV,CAAA,IAAS,GAAA,GAAU,CAAA,EAAY,CAAC,IAAI,AAAK,GAAK,CAAC,CAAI,AoDoB1C,ApDpBuC,GAAS,CAAA,EAAY,CAAC,IAAI,AAAQ,GAAJ,CAAC,AAAO,CAAE,CAAC,SAItG,CAAC,EAAI,CAAC,CAAC,SACQ,CAAE,AAAI,C4ByGD,KAAA,G5BzGW,CPiCK,EOjC0B,KAAxB,EAAQ,UAAA,CAAW,CAAC,CiF2EG,AjF3EF,AAAG,CAAM,CAAC,CAAC,CPiCK,aO9B/D,IAAA,GAAa,C8CwRK,C9CxRH,CAAG,CAAA,EAAA,CAClB,IAAS,CAAC,EAAI,GAAM,CwEuDK,ExEvDC,CoDzDpB,EpD0DP,CAAA,IAAS,GAAA,EAAA,GAAiB,CAAA,EAC1B,CAAC,Ca8EG,Gb9ES,GAAJ,CAAC,AAAO,AoDzDG,CAAC,ApDyDH,UAGhB,CAAC,WAGX,CACT,CAAC,CAAC,oEP5Kc,UACY,SAAA,SAAA,CAAA,IAAA,CAAA,IAAA,CAA6B,KAAA,SAAA,CAAA,YAA0B,CAAC,CAAA,CAAC,AAAC,IAAI,CAAC,CAAC,IkBOzC,oGvB5B4B,MAAA,CAAA,IAAA,CAAA,EAAA,CAAqB,CAAC,CAClG,AsEgFqF,EtE/ExF,CI2BC,AgETA,AK4DA,AzE9EA,AqC+BA,AfJA,A4BZA,CkBGC,+BpEXG,EAAkE,CAAlE,AyFFwD,AIgDA,ArEhDA,ExBExD,IAAA,WAAA,WAAA,E6F8CwD,MAAA,C7F9CyB,IAAI,CAAA,EAAA,CAAA,EAAA,4OwEIvE,2HAAA,gBAA2B,uBAI2C,IAAI,uBAuDtF,IAAA,EAAQ,GAAA,EAAA,EAAA,EAAA,MAAkC,CAAE,CAAC,GAAI,2CAEb,CqBuCC,CMzCD,OAAA,CAAA,C3BEe,CzCoBI,AyCpBF,UAJnC,6BAQW,CAAC,CAAG,WAAa,WAI5C,aAjEuC,CAAA,EAAA,KAAU,GAAA,IAAI,CAAA,EAAA,KAAA,CAAsB,CAAC,CAAU,MACxE,QAAA,EwBoDwC,MxBpD5B,CxBNC,CoC4IC,AnCxH3B,CuBdyB,IAAI,CwBoDwB,EAAA,KxBpDO,CvBgBzD,AuBhB0D,GAE/D,IAAA,CAAA,EAAA,EAAyC,KAAK,CYsIhC,iBZhIe,sBAAA,CAAA,EAAA,KAAA,GAAA,GAAA,IAAA,CAAA,EAAA,KAAA,GAC4B,EAAa,QAAA,AAAQ,CAAC,CAC/E,CAAC,MACS,CAAA,GAAA,AoBuCmG,CAC9G,CAAC,CpBxCU,IAAA,CAAA,EAAA,E/CwH+D,G+CxH/D,QAAiC,CAAC,CAAC,CAAE,GAAA,IAAI,CAAA,EAAA,IAAqB,CAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAChF,IAAA,CAAA,EAAe,GAAA,IAAI,CAAA,EAAA,KAAA,QAAiB,CAAC,GAAA,IjDFiB,AiDEb,CjDFkC,EAAA,MiDEZ,IAAA,CAAC,OAC5D,CAAA,EAAwB,KAAA,oBAKE,sBAAA,EAAoB,SAAS,CAAG,CAAC,CAAC,AAAE,CAAD,CAAc,SAAS,CAAC,AAAX,oBAE3C,CmBX6C,CAAC,CAAC,EzDId,GAAA,CsCOxB,CAAC,CAAA,wBAGhC,GzCcsC,AkDtBJ,IlDsBI,CAAA,EAAA,KyCdzB,QAAQ,CAAC,EAAa,KAAK,CAAC,CAAA,GAAP,CAAO,CAAC,eACzB,4CAOhB,MAAM,mDAzDnB,GAAA,aAAA,CAAA,IAAA,IAAA,iKJmBkB,EtDCwB,wCsDGnB,KAAK,SAAS,CAAC,GAAA,kBAAA,EAAA,KAAqC,SAAS,CACvF,MAAM,CAAC,IAAI,CAAC,KACb,CAAE,CACJ,CAAC,IAF0B,CAAC,CAC1B,qCAQE,GAAA,EAAA,CAAA,EAAA,CAAA,EAAA,CAAA,EAAA,+DAe6B,IAAA,sCAI5B,EAAA,EAAA,QAAA,EAAA,kCAKgC,CAAA,0BACY,4BAKtB,EAAA,oBACM,C7CZC,0D6CiBlB,CAAA,EAAS,CAAC,MAEpB,EAGF,IAAA,GAA6B,gCAaD,OAAA,qCAGd,+BACmB,CAAA,CAAA,EACzB,OAAA,YAAA,QAA6B,MAAY,OAAO,CAAC,CAAC,AAAE,CAAD,KAAO,CAAC,OAAO,CAAC,EAAQ,KAAD,GAAQ,CAAC,CAAC,AAAC,GAAG,CAC/F,CAAC,CAAC,EAAM,EAAF,AAAQ,EAAE,CAAH,AAAM,CAAD,EAGT,oBAAA,WAAA,IAAA,WAAA,EAAA,WAAA,IAEL,eAAA,EAAA,WAAA,GAAA,MAAA,EAIH,EACF,CQ7BA,AR8BF,kCAEmC,CAAC,AVs3BG,8BUp3BZ,mBAAA,8BAEM,CAAC,yBTjG3B,CAAmC,CAAA,CAChB,CAC3B,CAAA,CAAA,8EAMK,gBAAA,CAAA,CAAA,CAEsB,CAAA,CAAA,CAAA,6KAaN,KAAO,GAAA,EAAA,kFAQc,CAAA,UAAA,CAAY,uEAqB/B,CAAA,qCAAA,EAAA,IAAA,gBACC,cAAe,EAAA,GAAA,EACvB,4CAI6B,KAAK,CkCqCS,AGOA,AnBjDA,AlBKP,EAAA,OAAY,CAAA,KAAA,EAExD,MAAA,2BA7B0D,8BAI9B,iBAE1B,EAAA,KAAY,CAAC,oCAAoC,CAAE,EiBdW,IjBcH,CAAC,CmCLU,AnCKT,OACjD,CAAA,cAAA,EAAoB,CrC0Ba,CAAC,CAAA,EqCzBxC,0BAII,QAAS,EAAW,EAAK,InEpBc,AyGYNsG,CtCQH,CAAA,KAAA,EAAA,EAAsB,OAAA,WAoBpE,EAAA,CAAA,2C5B6BK,GAAA,EAAA,KAAA,sB4BlB+B,C1BgBL,AsBAE,6BIRP,CnEXK,AmEYnC,CtDOqC,AsDPV,CAC3B,CAAe,CnEbwC,6DmEoB/C,GAA4C,CACxB,aADsC,CAAC,CAAC,EAEjC,C+BiBwC,K/BjBxC,CAAO,OAAQ,CAAC,AtCuD0B,CmDxDrB,iBbMvB,C+BmBG,AnCJR,IAAA,GIfc,CAAC,sDAO7B,GAAA,wGAKC,IAAA,KAAA,KACL,MAAM,oEAUP,E/CKU,A8EiBA,AvF6EN,CwDnGE,EAAA,KAAgB,CtDWF,CAAC,AwF4CV,AlCvDa,A9CsEL,G8ClEA,EAAY,GtDWK,oCsDR1B,EAAA,EAAA,YACR,CAAA,QAAS,EAAE,AtDaA,WsDLhB,EAAA,EAAA,CACA,EAAA,EAAA,CACA,EAAA,IAAe,CAAC,QAAQ,EAAE,CAAC,AAE3B,ExD2G+B,AwD3G/B,kB/CSsB,Y+CNN,CAAQ,CtDeA,AsDfC,C/CMJ,C4BwGH,A5BxGI,U+CLQ,mBAElB,CAAC,GAEb,CDyRmB,AmC7MV,AxEYF,ClB0BmB,CwDpHP,A/CMI,I+CJhB,EAAA,KAAW,wBAML,EAAY,GAAO,CAAH,CAAC,AlCwFA,AoETI,EAAA,CAAA,UAAA,ClC/Ee,GAAA,IAAI,CAAA,EAAA,IAAQ,CAAC,YACjD,EAAA,GAAoB,IAAA,CAAK,UAAU,CAAE,GAAA,IAAI,CAAA,EAAA,8CAarD,GAAA,OACC,YACQ,OAAO,aAAa,CAAA,gBAEd,EAClB,GD+RkB,AC/Rd,ED+RgB,CAAC,CC9Rb,CkCmFS,MAAA,ClCnFF,CAAA,KAAA,CAAM,CAAE,CtD0CS,MAAA,EsD1CK,IAAA,MAC/B,EAAA,OAAa,EAAA,KAAA,SAEH,GAAA,KAAgB,ClCwFO,CAAC,OkCxFC,CAAC,GAAM,EAAD,CAAC,YAElC,CAAC,SACN,EAAK,CACZ,EAAA,KAAA,CAAW,4BAIF,MAAA,SAIlB,AAEM,eAAA,GACL,CAAA,CACA,CAA2B,MAEtB,EAAA,IAAA,CAAe,CAAC,IDqSA,AlBjLF,CmBnHN,KAAK,EAAE,ADsSA,CCtSC,AAET,KAAA,IAAA,WAAA,SAAA,EAAA,AACsB,gBADtB,WAAA,SAAA,CACsB,OAAA,OAExB,IAAA,GAAA,gKAC4J,CAGpK,AAFG,CAAC,AtCiGS,MAAA,IsC/FH,GAAA,mDAA+D,CAAC,CAAC,AAG7E,IAAA,EAAmB,IAAA,GACb,EAAA,IAAkB,aAGb,IAAM,KAAY,GADhB,GAAqC,EAAS,IAAI,CAAC,CAAC,AAAP,AACf,CtCiGH,EAAE,EsChGnC,CAD2C,GACrC,KAAQ,EAAY,MAAA,CAAA,GAAkB,eAClB,CAAA,GACzB,ClCsFC,GkCtFI,MAAM,CAAA,EAInB,E/CUI,E+CVC,CyB2DD,CAAC,EAAA,KzB3Dc,EAAA,KAAiB,GAAA,KAC5B,EAAA,EAAiB,MAAA,CAAA,gBAG3B,CAAC,kBAM6B,CAAsC,IyB6DhC,EzB5D9B,CD0SC,CC1SM,IAAA,WAEX,UAAA,IAAiB,GtCoZD,EAAA,EsCpZoB,CAAC,ADySF,MCxSjC,GAAA,MAAA,AAAmB,eAIb,EACJ,KAAK,QAAY,YAAc,IAAI,UAAU,CAAC,GAC3B,EADgC,CAAC,OAClD,OAAO,EAAqB,GAAW,GACvC,QAEc,WAAA,EAAgB,MAAA,CAAS,EAAY,MAAM,CAAC,CAAC,SACpD,CAAA,KACH,CtDuC8B,EAAA,CAAA,EsDvCb,EAAK,MAAA,EAC9B,CnExCC,AiCoIA,CkC5FM,EAGkD,AAAlD,CAAmD,CAAC,CAAE,CAAC,CAAvD,CAAA,EazKL,AbyKK,SazK4B,CAAkB,YAO1C,EAAA,EAAA,EAAc,MAAM,CAAG,EAAA,IAAA,WACvB,EAAA,EAAA,KAAA,CAAA,CAAA,EAA6B,EAAE,CYsBH,IZtBQ,EnEIA,OmEJS,CAAC,GAI3B,CAAM,CAAA,EAAA,EAAA,UAFvB,KAE6C,CAAC,mBAM9C,EAAA,EAAA,EAAA,EAAA,EACI,MAAA,EAAA,KAAA,CAAA,AAdI,CAcJ,EAAA,EAAA,EAAA,AAfH,KAeG,CAET,CAAC,EAAA,EAAM,uBboJ+B,EAAI,CAAC,CAAC,OAC5C,EAAA,KAAA,CAAA,EAAc,gBAKxB,EAAS,MAAA,CAAA,aAKX,MAAM,CnEvCC,oBmE6CC,CAAC,KAAK,CAAG,cACJ,CAAG,ClCgJC,CAAA,MkC/IR,MAAA,CAAA,EAAW,CAAC,AAGnB,CtDmCC,MsDnCM,CAAY,CAAA,KA4CrB,WA3CQ,ClC+ID,CkC/IM,CA2CoC,ClCoG1C,GAuCoB,GkCtLN,CAAA,OAAQ,CAAC,CDoTC,GCnTb,CDoTG,QCpTM,CAAA,EAAA,EAAS,MAAM,CnB3KG,EAAA,EmB8KrC,CAAC,EAAM,CAAC,CAAH,ADoTA,ArDhRM,EsDlCT,CAAC,CDsTG,GAAA,CAAA,KAAA,EAAA,CAAA,ICtTgB,CAAC,IAAA,CAAK,MAAA,CAAA,OAAe,sBAGhC,CAAC,KAAA,CACZ,GnB/JO,EAAA,IAAA,CAAA,IAAA,CmB+JS,EtC2YA,CmB1iBO,CmB+JH,CAAA,UACf,IAAI,CAAA,MAAO,EAOlB,OAJA,IAAA,CAAA,KAAA,CAAa,ClC8IH,IkC7IV,IAAA,CAAA,IAAS,CtD0DM,CAAA,CsD1DD,KACV,CAAA,MAAO,CAAG,EAAE,CAAC,AAEV,EAKT,GAFA,IAAA,CAAK,MAAM,CAAA,IAAK,CAAC,ClC2IL,EkCzIZ,EAAS,UAAU,CAAC,KAClB,OAAO,SAGJ,EAAW,CAAC,CAAE,EAAM,CAkBb,CAAC,CAlBe,EAkBZ,CAAC,CADb,EAAQ,CADhB,EAhB0C,GAiBtB,CAjB0B,MAiB1B,CAjB0B,MAmBnC,CAAC,ClC2IH,CkC3IO,CAAD,ADwTA,QCxTU,CAAC,CAAC,CAAA,GAnBmB,IAmBE,EAAI,CAAD,QAAC,CAAU,EAnBhB,GAmBqB,AAAqB,CAAC,AAGhF,GAAM,ClC2IH,EkC3IO,ADsTuD,GCtTpD,GAH0D,IDyTjB,CAAC,AC1U5D,EAAA,UAAoB,CAAC,ElC0IJ,AJyPI,CAAC,AsCnYE,GAAG,CAAC,EAClB,EAAM,SAAS,CAAA,EAAA,EAGzB,AAAkB,UAAlB,YACY,CAAG,EDsTF,GCtTO,ADoTF,KCnTe,CAAtB,AAAuB,GAChC,IAAA,CDoTW,ACpTN,IAAI,CAAC,IAAA,CAAK,GAGV,IAAI,EAEd,uFhC7TiE,CAAG,0CAEvC,CfZG,AeYF,qCAC4B,EAAA,GAAA,CAAc,EAAS,KWfc,CAAC,CAAA,CAAA,EXeG,ELHE,EKGE,CAAC,CAAC,gDAMhE,CAAA,eAAA,CAAA,EAAA,EAAA,UAAA,CAAA,4HAeF,CAAC,GAAG,CAAA,2GAIhC,MAAA,EAAA,EACc,EADd,GACc,gCAMd,GAAA,KAAA,CAAA,CAAA,CAAA,EAAA,EAAA,iBAAA,CAAA,CAER,GAAqB,CgDnBwD,0BhDqBtE,CFyGD,CAAA,GAAA,UExGa,MAAA,oFAcsB,MAAA,OAAa,CAAA,GAC/C,KADwD,CAAC,eJpBW,CAAC,CAAC,O0ECK,4GnD9BtB,CJNmC,kIIkBzE,GAAA,IAAI,CPDwB,EAAA,KOCd,IAAA,CAAA,eAAoB,CAAA,MAAA,EAAiB,IACvE,CAD4E,AAAI,EAAF,AACjE,EAAU,MAAM,CAAjB,AAAU,GAAW,CAAC,aAAa,CAAC,EAAQ,GAAQ,CAAV,CAAO,CAAC,AAAU,EAAM,AAAT,CAAC,EAAO,KAAS,CAAC,CACxF,CAAC,yBAeU,eAAA,CAAA,IAAA,CAAA,GAAA,EAAA,QAAA,gCAgBa,MAAA,QAAA,GAAA,CAAA,CAAmB,IAAA,CAAA,KAAA,OAAkB,CAAC,CoCZD,EpEEM,OgCUK,mDACnB,E8BPC,CAAA,CAAA,qC9BW7C,aAAA,gDACwC,GAAA,IAAA,CACzC,GvBL0D,A2EZC,C3EYA,SuBK9C,CAAC,GAAA,IAAI,CAAA,EAAA,IAAQ,CAAE,GAAK,CAAD,AACF,CAAC,iDASpB,IAAA,CAAA,EAAA,SAIpB,CAAA,CAAA,mHPzEyF,CAAA,8BAC1E,ChCIwC,A4CWU,CAAA,qGZHhD,0GAOT,IAAA,GAAA,yIAKsC,WAAkB,CAAE,0LAcrD,KAAQ,EAAA,iBAAA,gCAuBvB,YAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,2BASU,CRC2C,AuC0FY,C/B1FzD,EqCvBmD,ANiHY,A/BzF/D,EAAA,QAAA,CACA,CoBhBkE,KpBgB5D,GAAqB,EAAQ,GACnC,CADiC,CAC3B,AADkC,CAAC,EACpC,IAAQ,CACc,CAChC,CAAC,AAH8B,OAa3B,CAAA,OAAA,aAAA,CAAsB,EAAA,eAEV,eADM,gDAqB+C,CAAE,ClBwB3C,AkBxBuE,CdkS5D,McjSnC,CAAA,EAAS,EAAA,EAAA,YAEL,CAAA,EAAA,IAAA,EAAA,EAAA,4IAqCmB,CAAA,aAEE,QAEzB,IAAA,CAAA,EAAY,IAAI,EAAI,EAAA,iBACJ,CsDZC,OtDYO,EAAA,CAAA,wCAIT,EAAA,sBAIE,iBAAL,QAIJ,6CAIA,IAAI,CAAA,iBAAkB,oBACD,CCmBC,SDlB9B,yBAMI,2EAiCT,CAAA,CACA,CAAA,CACA,CAAA,CAAA,CAAA,CAAA,OAGM,EAAA,EAAA,EAAwB,EpCGI,AU7BA,C0B4BlC,IAAA,CAAA,IAAS,C3BxFG,ASmEF,ACzCI,EDyCJ,IAAA,EAAA,EAAA,KkBsBN,CAAC,QAAA,CAAA,EAAA,QAAA,GAA4B,wBACN,EAAI,EAAE,AsBzDA,AtB0DnC,CsB1DoC,AgCiBR,AtDwCQ,CCSD,AqBlEE,0BtB6D5B,IAAA,CAAA,IAAA,EAAa,EAAA,CAGb,aAAA,eACsB,6FAcpB,CAAA,OAAQ,CCcH,AhD1HE,iB+C8GI,CAAA,OAAA,CAAA,KAAc,CAAC,OACxB,UAId,oLjB3PiG,EAAE,CAA/C,AAAgD,EIc9B,CCVG,MAAA,ELJJ,IGD5C,EACxB,EHAoE,CAAS,CIgBzC,CAAC,EJhB4C,CAAC,KAAK,CAAC,EGDxF,CHC2F,CAAC,CAAC,AGA1E,GACpB,wOHsCsC,EAAA,OAAA,EAAiB,IAAI,GAAA,QAAA,GAAA,EAAA,GAAA,EAAA,OAAA,EACL,GAAA,GAAA,aAAA,GAAA,EAAA,QAAA,EAAA,OAAA,EAAA,QACkB,CAAC,EAAA,SAAA,GAAA,EAAA,IAAA,EAAA,OACvB,EAAM,IAAA,CAAA,CAAM,CAAC,ADkCZ,CClCa,AuCjBJ,EAAA,CvCkBrD,CAAA,KAAA,CAAA,SAAA,GAAA,IAAA,KAAA,YAQG,SAAyB,AAAzB,UAAA,OAAA,GAAyB,AAAmD,UAAU,CAAC,CAA9D,OAAmB,CY9B0C,CcHD,A1BiCnC,C0BjCoC,AdGD,CAAC,KZ8B7B,aAAa,CAAC,gGAqBvC,EAAA,IAAS,CAAA,KAG9C,CuEKD,AxBCA,E/CNuB,IAAA,eAAA,qCASkB,CYxCR,oBAAA,EAAA,EAAA,KAAA,qEZ+C5B,EAAA,QAAA,CAAA,CAAA,MAAA,EAAA,SAAA,EACwB,WAAA,8CAEqB,CqC5BP,ErC4Ba,IAAA,wEAiBrB,qHAKzB,IAAA,sBACP,QAAA,GAAA,CAAA,OAAA,OAAA,CAA2B,GAAA,CAAA,GAAY,ETPE,CSOC,CAAC,CAAC,CAAC,EAAA,EAAW,GAAA,GAAkB,EAAA,EAAW,KAAK,AACzF,CAD0F,CAAC,CAAC,AAM/F,CANgG,EAMlF,GAAA,KC1BqD,CACpE,CAAC,MDyBc,MAA6C,SAAA,KAOtC,OALrB,EkBuByC,QlBvBzC,UAAA,WAGH,CShBG,AQ2BA,YAAA,UAAA,OjBXoD,KAAA,CAAkB,CAAC,CuBrC/B,AvBqCgC,CAA9B,mDAKjC,UAA2B,CAAC,MAA5B,OACN,IAAA,KAAA,SACkC,CAAC,EAAA,EAAA,MAAA,CAAA,SAGnC,GAGT,GAAA,MAAA,EAA4C,EAAA,mIAIgD,CACvF,CAAC,2CAI2E,GkB2CzB,C4CrDX,O9DUmB,EoC2OF,KpC3OS,iEAGlD,GAAA,OAAgB,EAAM,IAAI,GAAG,CjBvBG,AiBuBD,GAAQ,UACnD,GAAA,GAAA,GACL,EAAA,MAAW,CAAA,EAAM,GAAS,oBAAoB,GAAmB,IAAA,IAAY,EAAE,CAAC,CAAE,GuCCD,AvCDS,KAAK,CAAC,AuCCJ,CvCDK,AuCCJ,CAAC,AvCDI,CAAC,CAC9F,GAAA,GAAA,KACA,C0ClCG,KAAA,CAAA,ExB4FY,AlB1DH,EAAA,GAAA,2CAEH,GAAG,CAAA,EAAO,GAAG,CAAC,GAAA,GAAwB,EDyCE,ACzCI,EAAM,IAAI,CAAE,KAAK,CAAC,CAAC,CAAC,CAAC,GuEsBL,CAAC,AvErBjD,CuEqBkD,SvErBxC,CAAC,wCAErB,CAAA,GAAA,GAAW,CAAC,CAAC,CAAC,EAAA,EAAW,CGoDe,EAAA,GAAA,EHpDS,CnBoED,EmBpEI,C9BzCa,C8ByCV,CAAA,EAAA,EAAQ,CAAA,CAAG,CAAE,kIAIsB,EAAK,GAAA,KAAA,CAAU,CACxH,CAAC,QM/JJ,MAAA,GAAA,UAAA,OAAA,GAAA,AAEiB,UAFjB,OAAA,EAAA,IAEiB,EAAA,UAAA,OAAA,EAAA,IAAA,EAAA,YAAA,OAAA,EAAA,IAAA,EAAA,YAAA,OAAA,EAAA,KAAA,EAAA,YAAA,OAAA,EAAA,WAAA,wBA0DoB,C8DnBK,K9DpBtC,YAAA,OAAA,UA4CU,IA5CV,UAAA,OAAA,GAAA,AAGa,UAHb,OAAA,EAAA,IAGa,EAAA,UAAA,OAAA,EAAA,YAAA,EAAA,GAAA,0CAgDc,WAAW,CwC5BG,KxC4BQ,IAAI,CAAC,iBAlCzC,oBAAA,AACV,UADU,OACV,EAAA,GAAA,EAAA,YAAA,OAAA,EAAA,IAAA,iDAsCqB,EAAE,QAAA,CAAS,KAAK,CAAA,SAAU,GAAG,EAAA,CAAE,yBAKrD,EAAA,MAAA,GAAA,0EAKoE,CkBxCC,EAAA,ElBwCY,IAAI,CAAC,CAAC,0EAStB,mGAIJ,kCAKtB,MAAM,C2BhCC,C3BgCK,IgD7CE,ArBaE,O3BgCO,EgEEA,AhEFE,CgEED,AhEFE,CgD7CD,AhD6CE,yCAK1D,IAAA,MAAW,GAAS,MAHiC,gCAGsB,IpC3DZ,AoC+DjE,MAAA,CAAA,sBAAA,EAAA,OACwB,EAAA,EAAA,EAChB,CAAA,eAAA,EAAkB,EpC1D0D,CoC0D7C,CAAC,AAAE,CpC1DuC,AoC0DxC,CpC1DyC,AoC2D1F,CpC3D2F,AoC2D3F,CpC3D4F,CoC2DzF,aAAa,sBAQuB,SAAA,MAAa,SAC1C,OAAO,mBAAA,CAAA,SACd,CAAA,UAAA,EAAA,EAAA,GAAA,CAAuB,GAAA,CAAA,CAAA,EAAA,EAAA,CAAA,CAAA,EAAA,IAAA,CAAsB,CNT3B,KAAA,CAAA,CMSmC,EAVvC,GAAM,CAAE,CAAH,AACvB,CADwB,AACvB,gFoBpIc,CAAA,mCAAA,wBAGd,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,gBAE2D,CuBShC,EAAA,SvBRtB,CAA+B,CAAA,GAAK,CAA0B,qGAU/C,CAAA,EAAO,+BACsC,sBAExC,EAAA,CAAA,MAAA,GAAA,UAAA,OAAA,4DAK4B,CpCMQ,AgEJJ,AhCgBC,CAAA,cAAA,EIlB2B,CiDQ5DD,IjDRsE,K1BiClC,A0BjCuC,QAAA,IAElG,gDAIkB,MAAA,sDAET,CAAA,GAAA,KAAA,CAAA,EAAA,IAAA,8BAAA,CAAA,aAIsC,CU8KtD,AxB1KqC,CcJwB,MAAM,CAAA,GAAA,CAAA,CAAe,EAC5E,MAEc,EAAA,KAAA,CAAA,OAAmB,EAAA,CAAA,EAAA,6CAK7B,OAAA,CAAA,EAAA,EAAA,IAAA,CAAA,EAAA,wBAEe,mGAMD,CAAA,EAAI,C0CyBL,A1CzBM,GAAA,EAAO,KAAK,CpBmDL,AbnCF,AamCE,EoBnDU,KAAA,oCAIM,C1BwCxB,0E0BrCa,MAAA,kBAI9B,IAAA,GAAA,CAAA;AAAA,EACsD,CUqS7B,CAAA,GAAA,CAAA,GAAA,EAAA,KAAA,EAAA,IAAA,CAAA;AAAA,EAAA;AAAA,EAAA,EAAA,CAAA,8C2BtVa,CAAA,CAAA,CAAA,CAAA,CAAA,kCAIxC,CAAA,kBAAA,EAAqB,CJLW,CAAA,SAAA,CIKY,CrBLX,EiBA0B,CAAC,AhBIrC,OoBE0B,ApBF1B,AoBGzB,EpBHgC,GoBGtB,CAAO,gBlFJoB,CRzBc,qCQ0BY,SAAlB,EAAK,CaxBE,ATErD,GKFoC,ITwBuB,0BA+DvC,SAAA,6CAoDQ,CAAS,EYlEX,UZmElB,GAAA,MAAA,2CAoCP,EAAA,EAAA,OAAA,CAAA,GAAA,CAAA,QAmCN,EAAA,KAlC+B,iCACrB,IAAA,mDAII,aAGsC,EAAO,KuF1Dc,EAAA,CvF0DN,ImB7CM,MAAA,QnBiDrE,QAAA,IACK,EAAA,OAAA,qCAIG,CqCAiC,CAAA,OAAA,CAAA,UrCAR,EAAE,IAAI,AAAC,WAAa,aAAa,GAAC,EAqCvE,EArC+E,CkBxB7D,UlB+DY,EAAA,KAAA,GAAA,GAEG,IAAc,EAAU,CoD/E6B,CAAW,CAAC,CAAC,GpD+E3C,CAAS,EAAE,IAAI,GAAK,EAAS,MAAD,EAAS,CAAC,IAAI,CACvD,CAAC,CAAC,iDAMpB,CANsE,EAMtE,EAAuB,CqCGmB,QrCHV,CAAC,EAAA,QAAA,CAAkB,GmBpEK,MnBoEI,CAAC,CmBpEK,CAAD,AAAE,CACzF,CAAC,AnBoEe,SAAS,OAAS,KAAK,KAAK,CAAC,EAAS,II9EU,IJ8EF,CAAC,EI7E1DG,IAAIC,GJ6E+D,CAAC,CI7EzDlE,OAAO,CAACzB,EJ4BoD,CI5BjD,IJ4BiD,SAE9D,UAEF,OAAO,CAAA,OAAA,EAAA,CAAa,EAAO,CE1EO,MF0EA,CAAC,OAAO,CE1EO,AF0EN,CE1EO,AF0EN,AkEFU,ChExEH,CAAA,EFuFlE,EEvFkE,EF2ErB,OAAA,CAAQ,GuDyLO,EAAE,EAAA,2BvD5KzB,E4BpEK,CN2DR,IbjFQ,CAAC,CAAC,MT0FQ,CAAC,M4BpEQ,sC5BwET,CAAC,6BACV,CXhGC,iBWiG8C,CAAC,AXhGxC,iCkEsQW,evDnLvD,gBACT,CAAC,AA6DK,SAAA,GAAA,CAAA,aAC6B,EAAO,eAAe,CsBvBL,AtBuBM,EAAE,CAAC,OAK7C,CwD9GC,AnEbA,CW2HC,KACZ,AAAC,GAAA,GAAA,IAAgC,AAAW,CAAV,A6DpFZ,c7DoFY,IAAK,GAAyC,IAAtB,AAA0B,CAAzB,AAA0B,CAAzB,AAC7D,E6DrF6B,CAAC,CAAC,I7DoFsC,CAAC,MAAM,GACxE,EAAA,CAAK,AAEd,CADG,AACF,CADG,YAI4C,oBAER,CAAE,CAAC,EACtB,mBAAA,cAEb,CAAA,iEAAA,EAAoE,EAAS,EXlIkB,CAAN,CWkIR,CAAA,EAAA,CAAI,CACtF,AAGP,CAHQ,AAGP,ONhSiC,8MmEIC,KAAO,2GAab,CgBIkC,AJHA,GZD9B,QAAA,CAAe,EAAA,eACV,EAAA,eACD,CQIoB,CEQkB,AFRjB,AEQkB,CAAA,kCVTlC,CcO6B,CXUC,CAAA,oDHRhE,C0B0BsB,EAAA,KAAA,K1B1BE,CAAC,KAAO,kBACnB,KAAK,CAAC,GAAG,EAAI,CAAC,CAAC,CAAC,GGiB4C,EHdjC,CmBFxC,AvCiBF,AkCLE,AHXF,AQDE,CAAA,sDnBQK,KAAA,CAAA,yBACc,IAAA,CAAK,IAAA,yBAKnB,KAAA,0EAMF,CxEN0B,AwFWF,AmBHA,GnCFpB,CAAA,EAAA,2HAuBL,CAAA,GACJ,IAAI,CpDMkC,EAAA,IAAA,CoDNtB,EzCiBE,AyCjBI,GAAK,CAAD,EAAC,IAAI,CAAA,EzCkBW,IyClBA,CAAC,EAAM,CAAG,EAAA,CAAE,CAAC,CAAC,CgBuBG,sChBV3C,GAAA,IAAA,CAAA,EAAA,IAAe,CAAC,CToBuC,CSpBjC,CToBmC,ESpBpC,wBAEf,SAAS,CAAE,AAAD,GAAO,CAAC,ApCqDE,CAAA,QoCrDO,GAAK,2BAChB,QAS1C,EnDyDI,GAAA,CAAA,CAAA,CAAA,CAAA,sBmDvDe,CAAC,EAAM,GAAD,AAAM,CAAD,EAAC,IAAI,CAAA,EAAA,ExB0FS,EwB1FE,CAAC,EAAM,CAAG,EAAA,CAAE,CAAC,CAAC,eACzC,QAAgB,CLYD,yCKUH,gBACI,EAAI,EAAA,oBACR,CAAA,IAAA,CAAA,QAAA,gEAOnB,CAAA,EAAA,WA4BV,CAAA,CAAA,GAAA,CAAA,CAAA,OAII,IAAA,CAAA,EAAA,WAIA,CAAA,OAAiB,CAAjB,OACF,IAAA,CAAA,EAAA,CAAA,EAAA,YACI,C3Dd4B,EAAA,K2DcT,IAAA,CAAA,IAAA,YAGwC,C7D2ErB,GAAA,CAAA,EAAA,I6D3EoC,CAAC,EAAM,CAAC,EAAF,mBAErE,CAAA,EAAA,CAAU,EAAU,MAAM,CAAC,AAAC,CAAC,EAAK,AAAH,CAAI,CAAC,CAAC,IAAI,CAAQ,CAAC,SAChD,CAAC,CAAA,CAAA,SAAA,CAAA,CAAkB,GAAK,G7D6EjC,E6D7E8C,KAG1C,YAAA,WAC8B,CACrC,GAAA,IAAA,CAAA,EAAA,MAAiC,EAAD,CAAY,MAAF,EAAU,CAAC,CnD8CuB,MmD7CvE,MAAA,CAAO,uBAEjB,E3DbyF,CAAC,C2DatF,CAAyB,KAAK,CAAC,AACnC,CxExCsB,AwEuCc,GxEvCd,CAAA,EAAA,KwEwCA,IAAA,CAAtB,G7DoFsD,C6DpFlD,CAAmB,QAClB,CpDrBD,IoDqBM,CAAA,iBAIE,YAAS,KAGf,EAAA,CAAA,CAAa,CL7BH,AK6BI,CAAA,IACf,IAAA,CAAA,EAAA,MAAiC,EAAD,CAAY,MAAF,AAAQ,EAAE,AAOvD,CAPwD,OAOhD,MAAM,CAAC,MAEjB,IAAA,CAAA,EAAA,KAA4B,IAAA,CAA5B,IAAI,CAAyB,KAAK,C3DYwD,A2DZvD,C3DYwD,A2DZvD,C3DYwD,U2DXtE,IAAA,CAAtB,CpDpBoE,CAAC,EoDoBjE,CAAA,GACJ,CoBqCC,GpBrCG,CAAC,KAAK,CAAC,uBAKhB,mLA3E6C,CAAc,QACxD,IAAI,CAAA,EAAA,CAAA,EAAgB,IAAA,CAAC,oBACwB,cAAc,iCAGtC,CxBmKH,A5BzGA,CAAC,CAAC,gBoD1DoB,IAClB,IAAA,CAAC,AACd,IAAI,CAAA,KAAM,CAAC,C3D2FD,CsD1CL,AyB+DE,MpBhHa,gDAGA,CpD4DC,EoD1D9B,GAAA,aAAqB,MAAO,OACO,IAAI,GAAY,EAAM,CvC0IlB,AiCwMA,MMlVyB,CAAC,CAAC,2BAG/C,CAAC,CxBwKH,A5B1GE,A8CsRA,OAAA,UMlVZ,IAAA,CAAA,KAAA,CAAW,QAAA,IAAa,GAAY,E3CoJe,K2CpJR,IACpD,CADyD,AACxD,CADyD,CAAC,CAAC,CAAC,AvC0IN,CAAC,CAAC,MpB7CU,MmC9N3D,8LAUiC,EAAA,EAAA,mKAgBQ,KAEvC,CAAC,KAAA,CAAA,yBAAgC,CjBtBG,CiBsBK,OAAA,mBACG,UAAU,gBAC1B,UAAA,CAAY,AACnB,ElBSY,2DkBRgB,0CAY9C,IAAA,aACY,CAAA,gBAAA,CAAkB,ChD5BC,GgD4BG,CAAC,gBAAgB,CAAA,MAAO,CAAG,CAAC,CAAC,CAAC,8IAe/C,IAAA,CAArB,IAAI,CAAmB,CAAC,+DA0BH,IAAA,CAArB,IAAI,CAAmB,CAAC,MAkB3B,C2BtBF,sBAAA,c3BuBI,IAAA,CAAA,IAAA,oBAC+B,IAAA,CAA9B,IAAI,CAA4B,CAAC,MAuBpC,6BAAA,kBACM,CAAA,IAAA,oBACiC,IAAA,CAApC,IAAI,CAAkC,CAAC,mDAqBnC,CAAA,EAAA,IAAA,GAAqB,IAAA,CAAzB,IAAI,CAAuB,CAAC,oCAInB,CgChFG,AkBqBA,eAAA,gDlDiE2B,gBAAA,CAAiB,MAAM,CAAG,CAAC,CAAC,CAAC,E6BThE,CACR,CAAC,I7BSiB,KAAA,CAAA,sBAA6B,0BACR,IAAA,CAArB,IAAI,CAAmB,CAAC,QACtB,KAAA,CAAA,eAAA,gBACE,CAAA,EAAA,IAAA,GAAiB,IAAA,CAArB,EwB1F6B,ExB0FzB,CAAmB,qCAGtC,EAAA,GAAoB,IAAA,CAAA,EAAA,IAAA,GAA8B,IAAA,CAA9B,IAAI,CAA4B,CAAC,+CAG3B,GAAA,IAAI,CAAA,CkD1DwB,CAAA,IAAA,GlD0DQ,IAAA,CAApC,IAAI,CAAkC,CAAC,cAC7B,KAAA,CAAM,8BAA+B,KqD7BhC,oBrD+BrB,IAAA,CAAA,GAAA,EAAA,KAAmB,aACjC,CAAA,aAAA,GAAA,IAAmB,CAAA,EAAA,IAAA,GAAqB,IAAA,CAAzB,IAAI,CAAuB,CAAC,CAAC,4BAaxD,ClBxD2B,AoC2OJ,ClBlLvB,CAAkC,CfdC,AeenC,CAAA,CAAA,qBAIM,EAAO,OAAA,EAAA,IAAA,CAAc,UAAU,CAAA,KAAA,8BACF,IAAA,IAAA,CAAW,UAAU,CAAC,E5BzFQ,EAAE,C4ByFL,EAAE,AK3FC,oBL6F7C,IAAA,CAApB,IAAI,CAAiB,MAAM,CAAC,AAEtB,CAFuB,CAEvB,MAAA,EAAA,IAAA,CAAA,WAAA,CAA+C,MAAM,CACzD,ChDvGuD,GgDuGlD,CkBiL2D,ClBjLnD,G3BnC+D,CAEnE,ArBtE8D,CqBsE7D,ArBtE8D,CgDuGrD,AhDvGsD,CAAC,CgDuGrD,CAAK,CAAE,CAC5B,CAAE,CADwB,EACrB,CAAO,CAAE,OAAA,IAAY,CAAC,UAAU,CAAC,MAAM,CAAE,CAC/C,CAAC,sBACa,8BACoC,EAAA,UAGrC,mBAAA,CACA,ClBpEkB,AiB8DJ,CAAA,CCQ5B,CqBlEsC,AxCqCqC,CAAA,6CmBgC/C,UAErB,MAAA,IAAA,CAAW,CnC7FC,AOLA,ApBdJ,oBAAA,CAAA,EgDgHiC,EAAA,oBAIlC,CfrBD,CAAA,CAAA,CeyBU,CAAA,KAEjB,EAAA,4CACkD,CnCjGnB,A2DejB,CxBmFd,EAAA,AACG,UADH,OACG,GAAiD,UAAU,GAA/B,EAAY,IAAA,EAAuB,GAAa,QAAF,AAAU,EAAE,IAAI,CAAC,AAC9F,CAAA,mBAAA,IAAmD,Cf1BD,Ce0BM,GAAW,CAAA,CAAE,CAAC,EAGzD,EAAO,KAHG,AAGH,CnCpGI,AmCoGJ,CnBvCG,CIUC,Ce6BJ,CAAA,AAAW,UACZ,GAAA,KAChB,EAAA,SAAA,EAAgB,YACG,+EAGjB,CACL,KAAA,qBAEE,SAAA,EAAA,SAAA,oCAEkB,QAAQ,CAAC,WAAW,CrCCZ,CAAA,GqCA1B,ChD3HK,AkG6B8B,C9EV7B,SAAA,EAAA,Q4BwGmB,CAAC,GnC/FW,CAAC,CAAC,KmC+FI,OACpC,CnBvBP,CAAA,SAAA,SmBwBQ,WAKP,IAGH,EAAA,CAAA,MACD,IAAM,CkDlGyB,AlDkGxB,CkDlGyB,GAAA,EGmE5B,erDgCD,CqDhCC,GAAA,oBrDiC0B,C5BxGC,CAAA,EAAA,Q4BwGa,CAAC,QAAQ,CAAC,IAAA,CAAK,CAAG,C5BxGE,A4BwGD,CAAA,QAAA,AAAS,CfvBC,AbjFC,A4BwGD,KAIxE,EAAA,UAAA,EAAA,EAAA,GAEY,CAAA,AAAE,CAAC,AjClFFgF,EiCmFF,CkByKqB,YlBzKhC,EAAA,IAAM,CkByK0B,iBlBtK5B,ChDrIC,AkEoTE,QAAA,QlB9KO,CfzBH,CoETW,MAAA,CrDkCC,IAAI,EAAI,EAAA,QAAA,CAAA,QAAmB,CAAC,IAAI,YACrC,CAAC,CAAA,QAAS,CAAC,UAAA,wBACC,WAAW,CnCxEK,AmCyExC,CnCzEyC,MmCyEjC,CmBhHK,AnBgHJ,A5BxGA,CAAA,QAAA,CAAA,M4BwGgB,GAG5B,CAAmC,OAEvC,eAEiB,CnCxEG,CAAC,AmCwEG,IAAD,IAAC,CAAU,CAAC,GAClC,CAAC,WAAA,CAAY,GAAS,OAGvB,IAAI,EAAA,EAAA,EAAW,EAAoB,EAAE,EAAA,kBACU,GmBnHjB,kBnBmHsC,CACrE,EAAA,0BAIE,EACA,SAAU,oBAEZ,KAEc,EAAe,OAAO,CAAA,EAAG,EAAE,OAAO,CAAC,mBAE3B,4CAA4C,CAAC,CAAC,GAElE,CAAA,EAAS,UAAA,EAAY,QAAQ,CAAC,iBAIV,EAAQ,EnC7EI,CAAC,OmC6EK,CAAE,CnC7EG,AmC6EF,CnC7EG,CoBkDD,O2D7BrB,e5CyDV,IAAI,CAAiB,Cf1B9B,C2D/BkB,C3D8BD,A2D9BE,c5C0DO,EAAE,QACrB,CAAE,UAAW,CAAA,CAAA,CAAS,EfzBd,AeyBwB,CmBjH7C,ClCwF+B,CAAC,CAAC,CAAC,GeyBmB,CAAC,MfzBV,Ie4BtC,CAAD,CAAG,A4CxDI,C3D8BT,A2D9BU,A1B2OA,AlB1KL,GAAI,GAAA,IAAiD,EAAM,CAAC,CAAH,GACxD,EAAA,CAAA,mBAAA,EAAgC,KAAK,C5BxGS,AP4BF,QAAA,CmC4EG,GAAK,ChDlJF,CAAA,EgDkJO,KAAA,SAAA,CAAA,GAE9D,4BAAA,CAA8B,CAAC,KAE3B,WAAA,CAAA,qBAAoB,UAAc,CAAO,iBAdvC,CACP,IAAA,EAAA,CAAA,mBAAA,EAAsC,IAAI,CAAA,SAAU,CAAC,GAAK,CAAD,CAAC,uBAAA,EAA4B,MAAM,CAAC,IAAI,CAC/F,GAEC,GAAA,CAAA,GAAc,KAAA,AAFA,CAChB,QAC8B,CAAC,IAC7B,AADiC,IACjC,CAAA,MAAU,CmBjHY,EtDoCE,AsDpCA,CtDoCC,AsDpCA,CtDoCC,aAAA,CmC6EI,CAAC,gBAElB,CAAC,+BAAsB,CAAO,CAAE,CAAC,CAAC,GAAJ,KAEhD,IAUI,CAAC,Cf5BC,Ce6BK,AvCxRmB,mBuCwRnB,EvCxRS,KAAA,CuCwRyB,GnC9EN,CAAC,CAAC,CAAA,EmC8Ea,CnC9ER,ImC8Ea,CAAC,GAAQ,CACpE,AADgE,CAC/D,AAAC,AAD+D,CAAC,CAAC,IACjE,EAAc,KACR,EAAA,aAAA,MAAmC,EAAM,MnC7EY,CAAA,CmC6EF,OAAO,mBAChD,CAAA,qBAAS,GfzBO,OeyBO,KfzBS,Oe2BlD,ChDtJkE,AgDsJjE,IAGK,EAAa,EnBgSE,CAAC,EqC3GM,ClBrLH,EAAG,EfxBI,AiC6ME,MAAA,CAAA,ElBrLW,IAAI,CAAC,CAAC,AAC7C,EAAA,GAAU,CfzB2C,GeyBvC,CAAA,EAAA,IAAA,GAA6B,IAAA,CAAjC,IAAI,CAA8B,UAAU,AACxD,CADyD,AACzD,CAD0D,UAC1D,CAAa,C4CvDC,A/ErBI,qBmC2E2B,eAI/C,MAEJ,EAIJ,CAAC,CnC5EG,AmCqFL,mDAjT+B,IAAA,CAArB,IAAI,CAAmB,CAAC,OAAO,EAAI,IAAI,AAChD,CADiD,AAChD,CAAA,EAAA,sBAYc,QAAA,CAAS,C4CyOyC,K5CzOnC,CAAC,KACtB,CAAC,EAAE,AnCsNJ,EmCtNI,GAAA,2BAEJ,GAAmB,SAE6B,CAK3C,IAJK,SACA,EAAkC,CkBsexB,MlBte+B,EAAI,eACX,GkBsetB,C0B3PH,G5C3OgC,EAAI,C4C2O9B,K5CtO/B,MAAA,IAAU,GAAY,6EACxB,CAAC,CAAA,EAAA,eAYM,IAAI,EAAI,IAAA,CAAK,QAAA,CAAA,MAAA,CAAA,EAAqB,GAAK,CAAC,CAAE,CAAC,CkB8dH,EAAA,KlB7drC,EAAA,IAAc,CAAC,QAAQ,CAAC,CAAC,AnBojBV,CAAA,WmBnjBc,CkB+dD,ElB/dU,CkB+dD,WAAA,gBlB9d1B,UAAU,CAAC,GmB2KC,GAAA,CnB3KO,AmB2KP,CnB3KQ,AkB+dA,EAAA,AAAe,aAAf,ElB/dO,IAAI,EAAiB,CkB+dd,CAAC,AlB/de,CAAC,CAAC,CAAC,GAAA,SAK1E,CAAC,CAAA,EAAA,WAYC,IAAK,IAAA,EAAQ,EnCqMF,EAAA,CAAA,QmCrMe,CAAA,MAAA,CAAU,EAAG,CAAC,EAAI,Cf8SL,AJ4PJ,AmB1iBU,CnCqMH,ImCrMU,CAAC,AACnD,IAAM,EAAA,IAAc,CAAC,QAAQ,CAAC,CnB0iBT,AmB1iBU,CAAA,OAEf,IAAA,MAAA,EAAA,OAAA,EAEa,AAFb,CnB4iBQ,SmB5iBR,OAAA,EAAA,OAEQ,CkBudC,CrCmFD,IAAA,CmBziBjB,QAAA,CAAA,IAAa,CAChB,AAAC,GACO,AADP,cAAA,EACG,IAAI,EAAA,EACJ,UAAU,CmB8JD,AyBuDI,CAAA,KAAA,A5CrNK,CAAC,EAAW,aAAN,CAAC,CAAC,IAAI,EAAA,EAAqB,EAAA,GAAO,EAAQ,KAAD,OAAa,CAAC,CACpF,EACD,CAAC,cACqB,CAK5B,AAL6B,CnCsNG,AmCjN/B,CAAA,EAAA,WAQC,IAAM,EAAA,mBACe,CAAC,eACL,eACD,CAAC,CAChB,CACD,AADE,IACG,GAAM,CAAA,MAAA,CAAO,CAAE,GAAI,IAAA,CAAK,gBAAgB,CAAE,CAAC,MACnC,CAAC,iBACiB,EAAM,CnC+MG,CAAC,CAAC,cmC/MY,CAAC,EAC7C,aAAA,EAAA,EAAuB,CkB8cH,YlB9cgB,eACxB,EkB8cA,ElB9cU,YAAY,CAAC,CAG7C,OAAO,CACT,CAAC,CAAA,EAAA,SAgCe,CAAkC,EAChD,CmB0HD,EnB1Ha,MAAR,CnB+hBS,CmB/hBF,CAAC,EAAY,CnB+hBS,CmB/hBF,CAAC,CAAG,GAAG,CAAC,AkBkbR,IlBjbvB,IAAI,GACR,OkBibqB,wHlB9a3B,CAAC,CAAA,EAAA,SAmK4B,CAAmB,QAEtB,QAAQ,CAAC,CAAC,SAAC,OAChB,IAAf,EAAe,YACf,IAAI,CAAC,EkB+QE,OAAA,ClB/QQ,uHH9V4C,UAAU,6FAYtC,EAAA,OAAA,EAAiB,CAAC,uC7CnCnD,4BAsBN,CiBmBC,KAAA,WAAA,WjB6LK,EA5LA,CA4LA,AAAgB,GAAkB,gBAtMsB,MAUxD,EAAA,GAVwD,GAWtD,MAOA,IA0DA,EAyBA,EA6BA,EAqBA,6HAhJC,AAGH,EAHG,EAAA,IAAA,GAGH,EAHG,IAID,EAAoB,MAAA,KAGpB,C2GOC,CAAA,iB3GNiB,CAAA,EAAA,EAAA,aAAA,EAAA,EAAA,CAAA,KAGlB,wCACiD,iBAKxC,GAAA,EAAA,2CAEQ,UAAA,CAAA,mBAGwB,CgFiBK,4BAAA,GAAA,GAAA,EhFhBhB,EAAA,GAAa,OAAO,G2EsCK,O3EtCK,CAAC,EAAW,C2EsCN,AAAS,Q3EtCM,CAAC,KAAK,CAAC,CAAC,CAAC,CAC5F,CAAC,GiCkVa,0CjC5U0B,CAAC,EAAI,IoCyDR,GpCzDe,UAAU,CAAA,EAAY,SAAS,CAAA,SACnF,CAAC,AoCyD4C,CpCvDtC,uCAIgB,EAAA,EAAiB,CAAC,EAAA,QAAY,UAAU,CAAA,EAAY,SAAS,CAAC,SACrF,KAK2C,wBAAvB,CAAA,EAAA,EAAgB,CamBC,AbnBA,CAAC,EAAK,IACzB,GAAA,EAAA,EAAA,GAA+B,WAAA,UAAqB,CAAC,CW6FG,CAAC,AX7FO,QqDYpD,CAAA,CrDZ8D,eAMjD,CgD8Fe,wBhD9FtC,CAAA,EAAA,EAAA,IgD8FsC,IhD7FlC,GACtB,EAAA,EAAA,GAAA,EAAA,EAAA,GAAA,YAAA,UAEsB,CAAC,EAAA,SAAoB,CAAC,KAAK,CAAC,CAAC,CAAC,CACtD,CAAC,MAKmC,wBAAA,IAAA,GAAA,GAAA,EAAA,EAAA,GACQ,MAAM,E+D4BR,Cf8DgC,Ae9D/B,Cf8DgC,CAAC,KhD1FhB,CAAC,CqDWE,CrDXS,OqDWQ,CAAC,CAAA,CrDXC,KAAK,CAAC,CAAC,CAAC,CAC1F,CAAC,WAOC,WACU,C6BwEC,I7BvEF,YAEE,GADN,AACM,CAAA,AAAsB,MAAtB,CAAA,CAAsB,EAAA,EAAmB,GAAoC,OAA1B,C4FiC9B,C5FjCyC,EAAQ,C4FiCjD,A5FjCkD,CAAC,A4FiClD,A5FjCuD,CAAK,AAAf,AAAc,CAAE,A4FiC9D,C5FjCgE,CAAC,CAC1F,AAAU,C6B0EP,AmB4BF,AkDrEI,OlGjCK,CAAA,EAAA,EAAmB,CAAC,SAGT,CAHkB,IAGb,CAAC,iCAEhB,EAAA,SAAoB,CAAC,EAAO,AkEwRD,CAAC,CAAC,AlExRC,EAAQ,OAAA,mCApIpD,iDA0IyD,GiC6FK,CjC7FM,aAC9D,CAAC,OAEJ,KAAA,KAAU,CAAC,EAAW,SAAA,CAAA,EAAA,EAA4B,WAAW,CAAC,IAAI,CAAC,CAAC,CAAG,CauBf,EbvBkB,IAGrE,kCAGZ,+BAKe,MAAV,CAAU,CAAA,EAAA,EAAA,gBAEoB,EAAO,EAAb,C4F8ED,A5F9EY,EAAR,EAAiB,QACrC,C+C6GC,mB/CzGL,C4F+EG,CMnDO,QlG9BI,GAGb,CqB2FS,arB3FK,CAAA,EAAM,EAAK,CAAF,MAAI,WAAiB,G4F+EG,A5F/EG,WAAA,CAAA,EAAkB,cAAc,CWkIf,AXlImB,EAC/F,CAAC,A4F+EA,M5F/EA,EAAA,QACwB,OAAO,CACzB,CoBwBI,MpBxBE,CAAC,AkG8BS,ClG9BR,CqGgGI,GrG7FO,YAAK,IAEnC,CAAC,IAF2C,EAE3C,EAAW,CkE+SW,ArDnPV,Ab5DA,Ka6DM,EAAA,Kb5DJ,Ea4DI,Ab5Da,EACzB,CmEsBuB,CnEtBP,EqGyGG,sCrGvG1B,C6BmHG,G7BlHI,CACT,CAAC,CAAC,EAEe,CmEsBH,AyB+DF,gB5FnFI,cAEsB,CAAC,KAHL,EwE3BM,gBxEiCR,OAAZ,CAAA,EAAO,C6BqHiB,iB7BhHpC,EAAY,CiCgHG,GjCpHO,SAOV,2CAGX,CACT,CAAC,CAAC,EAFS,AAIM,EkE4TJ,ArD9PA,Gb7DX,C6B2HC,EAAA,IAAA,EAAA,O7BhI6B,GAMF,EAAM,CiCoHP,EjCpHO,CAAA,CAA6B,KkEkUlC,uBlEhUzB,CoBuCO,MAAA,KAAA,KAAA,CAAA,mBpBpCL,GAAI,CAAC,GACC,GAAG,GAAK,CmEkCU,CAAA,AnElCC,EAAA,MAAiB,CAAG,CAAC,CAAA,CAC1C,OAAA,KAAA,KAAA,CAAA,EAAA,SAAA,CAAA,EAA0C,CasEW,CbtEA,WAAW,CAAC,GAAG,WAC/D,C6BoIS,AqCiMA,IAAA,KlErUC,CAAC,CgDqJG,ChDrJQ,C6BoIS,Q7BpIA,CAAC,CAAC,CAAA,EAAa,WAAW,CAAC,GAAG,UAC7D,CAAC,CAAA,CAAG,CAEf,EAAoB,EiC2HE,CAAC,IjC3HI,SAIzB,EAAA,MAEe,OAAP,CAAA,EAAO,EAAA,KACJ,CAAA,EAAA,EAAA,CAAY,MAAM,EkE0UE,MlE1UM,CAAA,CAAW,CAAC,EAAA,GAAA,UAE9B,EAAA,GAAkB,EAApB,AAAmB,AAAC,CAAnB,AAAmB,8CAG7B,EiC+HI,GAAA,CAAA,EjC/Ha,GiC+HK,MjC/HI,CAAA,EAAQ,IgDsJE,MhDrJzC,EAAG,CAAC,AACgC,iBAAnB,CAAA,EAAQ,Ca2EG,CAAC,CAAC,Cb3Ea,Ea2EI,Ab3EQ,GAAP,AACrD,CADsD,CAAW,AACjD,EADyC,yBAEvD,CACF,OAAA,KAAY,C4FiGG,IAAA,CAAA,E5FjGc,OmEsCS,EnEtCA,CAAC,EAAO,CmEsCF,CnEtCa,QAAD,GAAY,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,QAClE,C6B0bH,A7B1bI,SACgB,CAAC,CAAC,KAK7B,EAAY,E6B0bJ,AhB3WI,Ub9ED,GAAU,SAAU,QAAQ,CAAC,CAAU,CAAC,EAAO,CAAC,CAAE,CAAL,AAAM,KAK7D,MAI+B,EAAiB,Ca8ET,GgBuWC,E7Brbc,GAAG,SAAS,GAAG,CAAC,C6BqbX,A7BrbY,C6BqbX,wGI/hBlD,EAAA,yEAKJ,CAAA,EAAA,+CAW6B,qFAQhB,CAAA,cAEyB,6CAI3C,GAAA,CAAA,UAAuB,CAAE,A8BtH+C,CAAA,c9BuHnD,CAAE,GAAG,GAAS,C+C1HgC,G/C0HlC,GAAS,CAAE,4BAA6B,QAAQ,CAAE,CAAE,CACxF,CACF,CAAC,kCAyMF,CAAA,CAAA,wIAM8D,sBAE5C,IAAA,CAAlB,IAAI,CAAgB,CAAC,qCAE8B,CACjD,CAAE,GAAA,CAAA,CAAW,OAAQ,CFlUiD,CAAC,AEkU9C,CAAE,CAAA,IACtB,CyC/T2B,GAAA,KzC+TV,IAAI,CAAC,UAAA,CAAW,MAAA,2BAEnC,UAAA,UAC6B,CAAC,YACnB,IAAA,CAAd,IAAI,CAAW,8EAKa,CAAA,GAAC,IAAI,CAAA,EAAA,IAAA,GAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,2BAIrB,CAC9B,CAAA,CAAA,yFAKyC,IAAA,CAAA,UAAA,CAAA,KAAA,sBAEvB,GiCpCI,CAAA,CjCoCtB,IAAI,CAAgB,CAAC,KAChB,GiCrCiC,CAAC,MjCqClC,iCACyE,IAAI,CAAC,UAAU,gCAG5D,EAAA,yBAEN,CAAC,GAAA,IAAI,CAAA,EAAA,IAAA,GAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,OAG1C,CAAA,EAAA,IAAA,GAAU,CAH4B,GAG5B,CAAd,IAAI,CAAW,KAAK,CAAC,CAAC,AACP,EAAA,gBAEI,CAAA,MAAA,EAAA,4BAGd,IAAA,CAAA,kBAAA,CAAA,GAAwB,IAAI,CAAA,EQpTuB,IAAA,GRoTX,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,6FApPb,OAAS,EAAA,EAAA,CAAC,YAG7B,CAAqC,eACxC,CAAA,EAAA,GeKgB,CfLG,CAAC,EAAO,EuEPgD,CAAC,CvEOlD,AuEPmD,CvEO7C,CAAC,CAAC,oKAa3B,CAAC,C4COoD,CAAC,A5CP9C,C4CO+C,G5CPhD,CAAM,CAAC,CAAG,KAAK,CAAC,WAID,CAA0B,gCAGpD,IAAA,CAAA,EAAA,IAAA,GAA8B,IAAA,CAA9B,IAAI,CAA2B,KAAK,CAAC,CAAC,4CAGrB,CAAC,AeKA,ADnBA,AgB5CN,Q9B2DK,OAAA,CAAQ,CpBpEG,CoBoEI,CpBpEG,IAAA,CoBoEI,CpBpEE,AoBoED,kCAI/B,OAAS,aAAA,EAAA,OAAA,EAAA,+CAGW,EAAe,KiC+LG,EjC/LI,CAAA,CJdP,MIce,CAAC,CAAC,KACvE,KAAK,CAAC,gBAAA,SACK,KAAK,CAAA,OAAA,2BACqB,GH7CS,OG8C1B,OAAA,CAAA,MAAA,IAKL,QAAb,KAAA,CAAA,OAAa,EAAA,EAAA,OACE,EAAA,OAAW,CoE3BD,MtDyBZ,IdEwB,EAAA,EAAA,OAAA,EAAA,qCAI1C,MAAA,EAAA,KAAmB,CAAA,OAAQ,8BAK3B,EAAA,QAAA,EAAA,SAAA,MAAA,EAAA,OAA0D,EAAE,OAAS,EHpDZ,WGoDyB,KAC/E,CZfD,IAAA,CAAA,yBYeiC,mBACX,EAAE,C2DdK,4C3DmBxB,QAAA,EAAA,SAAA,MAA6B,EAAA,OAAsB,EAAE,Ce0BG,Gf1BC,GAAK,WAAW,EAAE,CAAC,8CAEnE,QAAA,EAAU,CZXS,AR3DA,kBoBuEV,Cb9EO,AwE+DJ,OAAA,EAAA,SAAA,E3DeoB,0BAIb,IAAA,CAAzB,IAAI,CAAsB,cAAc,CAAC,CAAC,eAExB,EAAE,CAAC,GACjC,IAAI,CAAA,EAAA,IAAA,GAAuB,IAAA,CAA3B,IAAI,CAAwB,GAES,IAAI,EAArC,C2DnBD,CAAA,G3DiBuC,CAAC,CAAC,kBAEX,KAC/B,CZV8B,AuETN,A5F9EE,GiCiGtB,CAAA,EAAA,IAAA,GAAuB,IAAA,CAA3B,IAAI,CAAwB,EAAgB,EAAM,GAAD,OAAP,aAA+B,CAAC,CAAC,CAIxD,EAAO,KAAK,CAAC,UAAU,EAAI,EAAE,CAAE,CAAC,AACjD,EAAA,uBAA6B,CbhFC,EAAA,EAAA,KagFkB,EAAE,CAAC,GACrD,IAAA,CAAA,EAAA,IAAA,GAA2B,IAAA,CAA3B,IAAI,CAAwB,GAGxB,AAAiC,EjCpGE,IiCoGI,CAAC,CAAlC,GAHgC,CAAC,CAAC,kBAGX,EAC/B,GAAA,IAAI,CAAA,EAAA,IAAA,GAAuB,IAAA,CAA3B,IAAI,CAAwB,EAAgB,EAAM,GAAD,OAAP,aAA+B,CAAC,CAAC,EAAhD,CAIzB,uBAAuB,CAAG,EAAS,KAAK,CAAC,eAGd,KAAA,CAAA,UAAA,EAAoB,EAAA,CAAA,OAC5B,EAAe,OAAO,CAAA,UAAW,EAAA,CAAA,EAAA,KAAsB,CAAC,CAAC,AAC7E,GAAA,UAIiB,OAAS,WAC7B,CADyC,CAAC,A2DvBtC,E3DwBA,CAAC,CJES,IIFJ,CAAC,GbjFG,mCaiFoC,CAChD,CbjFK,IaiFC,EAAiB,QAAA,EAAU,IAAI,CACrC,MAAA,EAAqB,CiCwMS,IjCxMJ,GiCwMW,kBjCvMD,CAAC,SAAS,CAC9C,iBAAkB,EAAiB,GoELW,KpEKH,CAAA,gBAAA,iBAC1B,EAAA,QAAA,EAAwB,WAAa,EAAE,MAG9C,Eb9EA,Ca8EkB,Eb9Ef,AoDzDU,MvC2IjC,CAAC,CAAA,EAAA,SAEsB,CAA6C,CAAE,CAAqB,EoEDc,CAAC,CAAC,CpEEnG,GAAQ,IAAI,CAAA,EAAA,IAAA,GAAA,IAAA,CAAJ,IAAI,CAAsB,cAAc,yBACR,AAKrB,CALsB,CAKP,OAAO,CAAC,UAAU,EAAE,CAAC,EAAc,CAAC,MAE1E,CkCzFC,GlCuFuE,EkCvFvE,MAAA,+BlC2FmB,Eb5EE,EAAA,Ea4EI,Ce8BH,Af9BI,AkCzFJ,kDlC6FK,Cb7ED,kBa6EJ,CAAiB,KAClC,EAAA,GAAY,IAAI,CAAA,EAAA,IAAQ,EAAE,KAAK,EAAE,IAAI,CACzC,AAAC,GAAS,CAAL,AAAI,EAAF,AAAgC,IAAI,AAAK,CAAJ,CAAS,EAAD,MAAS,CAAC,IAAI,GAAK,EAAiB,CAAlD,OAA0D,CAAC,IAAI,CAC5D,AAD8C,CAC7C,CAAC,UAElC,CiC4MG,oCjC5MmC,GAF8C,aAG9D,CAAC,IAAI,CiC4MG,CAAC,KjC3MjC,YACI,EkCxFa,AlCwFI,QAAQ,CAAC,EkCxFa,OlCwFJ,kBAE5C,GAAmB,GAAa,EkCzFmB,AlCyFT,CeyBD,QfzBU,CAAC,EAAiB,QAAQ,CAAC,KAAV,IAAmB,CAAC,CAAA,GAAA,SAAA,OAAA,KACpD,KAAK,CAAA,EAAkB,QAAQ,CAAC,SAAS,CAAC,CAAA,iBJQhD,KIFtC,CAAC,CAAA,EAAA,SAEsB,CAA6C,MAC5D,EAAA,GAAA,IAAY,CAAA,EkCrF6B,CAAD,CAAC,EAAA,GlCqFR,IAAA,CAAzB,IAAI,CAAsB,QAErB,MAFmC,CAAC,AAEpC,CAFqC,AAErC,OAAA,EAAA,CAAA,EAA0B,YAAA,CAAA,yBAGpB,GAAA,IAAI,CAAA,EAAA,IAAA,GAAgC,IAAA,CAApC,IAAI,CAAkC,CAAC,AAE9D,IAAA,CAAA,KAAA,CAAW,eAAgB,CJYG,QIXnB,EAAe,EAHiC,KAG1B,CAAC,OAAO,QAC/B,Cb9ES,Ca8EQ,CjC3HC,AmEmCM,ClCwFQ,SAAS,CAAC,EAAe,OAAO,CAAC,IAAT,GAAgB,CAAC,CAAC,AAAG,CAAF,GAAc,GAIjG,EAAe,OAAO,CAAC,OAAO,EAAI,CAAC,EAAM,GpBnDG,CAAC,CAAC,OAAA,GoBoDhD,EpBnDI,AoBmDE,YAAY,EAAG,EAErB,C2D9BC,G3D8BG,CAAC,KAAK,CAAC,eAAgB,CAAE,EeyBF,MfzBW,EAAe,CpBnDZ,AmC4ES,MfzBU,CAAC,OAAO,CAAE,CAAC,CAAC,GAGvD,QAAA,EAAU,SAAW,CAAC,EAAA,qBAA2B,EAAE,CAAC,gCAGhE,KAAA,CAAA,wBAAA,CAAiC,QAAA,EAAwB,QAAQ,CAAC,OAAO,CAAE,CAAC,CAAC,GAGjE,QAAA,EAAU,EeuBF,ChDtJG,MAAA,CAAA,EiC+HiB,CjC/HD,oBiC+HsB,EAAE,CAAC,EAC/D,qBAAqB,CAAA,CAAA,aAEhB,CJuTC,CsCpZG,sBlC6FqB,SAAW,EAAe,QAAQ,CAAC,OAAO,CAAE,CAAC,CAErF,AAFsF,CAErF,CAAA,EAAA,wBAGe,C2DlCD,C3DkCG,CAAC,AkC9FA,IlC+FT,IAAI,GAAA,CAAY,IkC7FK,CAAC,CAAC,kClC6FkC,CAAC,CAAC,MAElD,GAAA,IAAI,CAAA,EkC5FiC,MAAA,GlC6FjD,EkC5FE,MlC6FC,EADO,EACH,GAAA,0CAAsD,CAAC,CAAC,UAEpE,IAAI,CAAA,EAAkC,OAAS,EAAA,EAAA,CAAC,AAChD,GAAA,IAAI,CAAA,EAAsB,EAAE,CAAA,IAAA,CACrB,AAkPX,SAAS,CACyB,CAChC,CAAyC,CJ7HN,UI+H7B,IAAE,CAAE,SAAE,CAAO,SAAE,CAAO,OAAE,CAAK,oBAAE,CAAkB,CAAE,GAAG,EAAM,CAAG,CAAL,CA2FhE,MA3F6E,CAAC,AA2FvE,EiCwHM,IjCjNR,CAAI,GtB/ciB,WsBidf,EAAQ,EAuFa,CAvFV,CAClB,CADc,AACb,SAAE,CiCuNuB,GAAA,YjCvNd,CAAA,CAAA,MAAA,CAAoB,UAAE,CAAQ,CAAE,GAAA,EAAe,EAAyB,EAAE,IAC/E,EACH,MAAM,IAAI,CiCuNC,EjCvNW,AADJ,CACI,AADH,CiCwNK,AADJ,gCACI,EjCvNkC,EAAK,CAAE,CAAC,CAAH,AAAI,AAGrE,GAAM,SAAE,EAAU,IAAI,CAAP,EiCsNF,YjCtNW,CAAa,IiCsNZ,CAAC,OjCtNa,CAAU,CAAE,GAAG,EAAa,CAAG,EAChE,EAAO,EAAH,AAAW,CADwD,CAAZ,AAAa,EACtC,CAApB,AAAqB,AACzC,CAD0C,EACtC,CAAC,EACH,EADO,EAAE,CAAC,CACJ,GJ7HY,CI6HR,GAAY,CAAA,wBAAA,EAA2B,EAAK,CAAE,CAAC,CAAH,GAGpD,EAAe,KACT,KiCqNM,CjCtNC,EiCuNC,CjCtNC,CAAE,CAAA,CAAA,KAAA,CAAU,CAAA,CAAK,KAC9B,AAAQ,GiCsNL,GjCtNW,CAAC,CACjB,MAAM,EiCqNoB,CACjB,AADkB,CjCrNjB,GAAY,CAAA,GiCsNI,OjC9NiI,iCiC8NjI,EjCtN0C,EAAK,CAAE,CAAC,CAAH,AAAI,GAG3E,CAAA,EACF,CJ5HG,GI2HM,CAAC,CACJ,GiCoNG,CjCpNC,GAAA,CAAA,sCAAA,EAAqD,EAAK,CAAE,CAAC,CAAH,AAAI,MAGnE,CACL,GAAG,CAAU,EJ5HI,IAFD,GI+HP,GJ5HG,QI8HV,IiCoNQ,UAAA,CjCpNS,UAAW,QAAU,CAAE,MACxC,UACS,EAAQ,KAAD,EAAQ,EAAI,oBAE9B,EACA,iBACA,EAEJ,CAAC,OAED,AAAI,EACK,CACL,GAAG,CAAU,EiCuNH,GjCzNE,CAAC,CAGb,EACA,KiCkNqB,oBjCjNrB,EACA,KiCwNW,CjCzNH,CACD,CAAE,CACP,GAAG,CAAW,GJ1HO,CAAC,YI4HtB,YACiB,IiC8NsC,GjC9N/B,EAAI,IAAI,KiC8NuC,CAAC,CAAC,KjC7N7D,EAAW,GAAG,CAAC,CAAC,CJzHF,CIyHa,CAAC,EAAE,EAAE,AAC1C,EADmC,CAC7B,CiC6N+B,SjC7NnB,CAAE,CAAE,MAAI,IAAE,CAAE,CAAE,GAAG,CiC6N+B,CjC7NrB,CAAG,EAC1C,CAAE,EADmC,QACnC,CAAe,MAAE,CAAI,CAAE,AiC6NO,GjC7NJ,EAAM,CAAK,GAAL,AAAW,CAAA,CAAE,CAAC,AACtD,GAAI,MAAA,AAAY,CAAC,CACf,MAAA,IAAU,GAAY,CAAA,KiC6NgB,WAAA,EjC7NG,CiC6NW,CjC7NN,GiC6Nc,UAAA,EjC7NE,CiC6NW,AjC7NV,CAAA;AAAA,EAAS,GiC6Na,AjC7NV,GAAA,CAAY,CAAC,CAAC,AAE3F,GAAY,GJzHW,GIyHL,AAAd,CAAe,CACjB,EJ1Hc,AIyHR,IACA,IAAI,GAAY,CAAA,OAAD,SAAC,EAAmB,EAAK,GAAA,UAAA,EAAgB,CAAC,CAAA;AAAA,EAAW,GAAG,AAAC,GAAS,CAAE,CAAC,CAAC,AAE7F,EAFwF,CAAC,AAE7E,MAAR,AAAc,CAAC,GAAX,IACA,IAAA,GACJ,CAAA,gBAAA,EAAmB,EiC6NuC,EAAA,WAAA,EjC7NlB,CAAC,CAAA;AAAA,EAAoB,GAAG,AAAC,GAAS,CAAE,CAC7E,CAAC,AAEJ,EAH6E,CAAC,AAG1E,MAAA,AAAc,CAAC,CACjB,MAAM,IAAA,GACJ,CAAA,gBAAA,EAAmB,EAAK,GAAA,UAAA,EAAgB,CAAC,CAAA;AAAA,EAAyB,GAAG,AAAC,GAAS,CAAE,CAClF,CAAC,AAGJ,EAJkF,CAAC,GiC8NrE,AjC1NP,CAAE,GAAG,CAAQ,EiC0NG,EjC1ND,OAAI,EAAM,EAAF,MAAU,CAAE,CAAE,GAAG,CAAM,MAAE,EAAM,EAAF,OAAW,CAAE,CAAI,CAAE,CAAE,AAClF,CAD8E,AAAK,AAClF,CAAC,GAID,IACF,CiCoOK,ArC9VE,AI0HG,GiCoOmB,CrCnWN,KIgIjB,KAAgB,SAAE,OAAO,AAAE,EAAM,MiCoOM,EjCpOG,EAAQ,KAAD,EAAQ,CJzHC,CAAC,AIyHE,CJzHD,GIyHK,CAAE,eAC5E,aAAa,QAIjB,CAAC,CACF,SACD,QACA,EACA,OAAA,qBACI,EAAqB,oBAAE,CAAkB,CAAE,AJtHhB,AqC0VN,CjCpOyB,AJtHlB,AIsHgB,CAAC,AAAC,CAAE,CAAC,AACtD,CAAC,cAE0C,MAAM,CAAC,CAAC,EtBjhBb,SAnBf,CgE7DC,AZRA,AlCgDA,MAAA,CAAA,GAAA,ClBqBW,SAC2B,CsBuPG,AMhTA,A4BhBR,ArC4BQ,AgDgFW,MAAA,CnEnCN,UAAU,CAAC,CwDzEL,AxDyEM,AAEtE,CiEtDwC,ATrByB,axD6E7D,aACU,CuDyLG,yDvDrLU,CAAC,UAAU,asB2hBrD,CAAC,CAlVU,EAAiC,GAAA,IAAI,CAAA,EAAA,IAAQ,CAAC,CAAC,kBA2DhD,EAAiB,GAAA,IAAI,CAAA,EAAA,MAAU,eAAe,CAAC,UACX,KAInC,C2D9F2D,W3D0FP,CAAC,A2D1FkB,I3DiGtD,CAA0B,kBAC9C,EAAW,GAAA,CJyPkB,CAAC,CAAC,CAAA,CAAA,EAAA,mBIxPf,CJyPL,AhBtWQ,C+EmBL,A3D0FQ,CAAG,MAUxB,GAAM,CAAA,MAAA,CAAO,CAAA,cAAA,CAAA,OAAiB,CAAA,UAAO,EAAW,IAAI,CAAE,GAAG,EAAO,GAThE,UAAU,KAMA,CAAA,EAAW,GALxB,EAAW,GAAA,IAAA,CAAA,EAAsC,KACxC,CACP,QAAS,EAAE,OAM0D,EAAM,E2DzF3C,CAAC,I3DyFiD,EAAE,CAAC,MAC1E,EkC/IoC,AlC+I3B,CkC/I4B,MlC+I5B,CAAQ,EAAA,IAC1B,AAAC,QAAQ,CAAC,MACa,CAAC,EAAM,CAAG,EAAJ,aAAM,QAAe,EAAO,GAAT,AAAO,IAAS,CAAE,CAAA,CAAE,UAAE,EAAU,GAAG,CAAK,CAAE,CAAZ,AAAa,MAIxF,CAAD,CAAC,QAAA,CAEE,CAAC,AiC2KE,GjC1KF,CAAA,QAAA,CAAS,SAAE,CiC2KO,AjC3KA,CAAE,GAAA,EAAS,CAAG,KACxB,GADgC,CAAC,AAC7B,CAAC,CAAC,EiC4KQ,EjC3KrB,MAAA,CAAA,EAAc,QAAQ,CAAE,GAE/B,OACE,EADW,AiC4KC,AjC3KL,CiC2KM,GjC3KP,IAAC,AAAQ,EAAC,GiC2Kc,EAAE,CAAC,CjC3KV,GAAA,CAAA,CAAP,OAAO,CAAK,EAAA,AAAE,EAAC,AAC/B,ClBrGSY,CkBqGF,CJ0PA,OI1PQ,CAAC,OAAO,CAAC,IAAA,IAAQ,CJ0PK,GIvPnC,OACF,EADW,AACJ,CADK,AkCzIQ,CAAC,MAAA,AlC0IN,EAAC,OAAO,GAAA,CAAA,CAAP,OAAO,CAAK,EAAA,AAAE,EAAC,AAC/B,EAAO,IAAD,IAAS,CAAC,OAAO,CAAC,IAAI,CAAC,GAAG,OAAO,CAAC,CAb1C,AAa2C,CJ+O1C,CI5PM,QAAA,CAAW,Ce5SO,Mf4SA,MAAM,CAAC,CAAA,EAAI,GAkBxC,GAAA,MACS,EiC4KE,WjC5KW,CAAA,KAEhB,IAAI,CAAA,EAAA,MAAY,GAAA,GAAsB,IAAI,CAAA,EAAA,IAAQ,CAAC,EAAE,CAAC,GAClC,UAAU,CAA5B,EACF,MAAA,IAAU,MAGU,gBAAgB,EAAE,CAApC,AAAqC,EACvC,ClBhGkD,KkBgGlD,IAAA,aAKC,MAAA,CAAO,EAAQ,CiCgLC,GjChLH,AAEf,CAFsB,CAAC,AAEvB,CAFwB,QAI7B,GAAM,SAAE,CiC+KG,EAAA,OjC/KM,CAAO,CAAE,WAF8B,IAEjB,MAAE,CAAI,YAAE,CAAA,CAAA,GAAe,CJrItC,CAAC,AIqI2C,CAAG,CAAL,OACpD,UACP,MAAA,CAAO,EAAO,OAAO,CAAE,OAG5B,EAAO,GADI,CACL,GAAQ,CAAC,OAAA,CAAU,CAAC,EAAO,IAAD,GAAQ,CAAC,OAAO,EAAI,EAAA,CAAE,CAAC,AAAG,CAAA,EAGxD,GAAM,CAAF,EAAS,GAAD,IAAQ,CAAA,IAAA,CAAQ,CAAA,CAAI,CAAC,AiCgLJ,AjC/K7B,IACG,EiCgLI,AjChLG,EiCgLI,KAAA,CAAA,ajChLiB,EAG3B,AAH6B,CAAC,CiCuLrB,CAPyB,EAOzB,CAAA,GjCpLW,EAAO,CiCqLf,GjCrLc,AJjIP,GIiIe,CAAC,QiCqLR,KjCrLqB,CAAC,IAAI,CAAG,EAAc,IAAI,AAAJ,CAAK,CAC3E,EAAc,GADuD,IJhIpD,CqCsTL,CjCrLW,EAAE,CAC3B,CAAA,EAAA,EAAO,OAAO,CAAC,aAAA,AAAa,EAAC,SAAS,EAAA,EAAA,CAAT,SAAS,CAAK,EAAA,CAAE,CAC7C,CAD8C,CACvC,CiCsLA,CAAC,EjCtLF,GJlIK,AIkIG,CAAC,SiCsLa,IjCtLA,CAAC,IiCsLQ,KAAA,EjCtLK,EAAc,SAAS,CAAC,CAAX,GALlD,OAAO,CAAC,CJnIS,YImII,CAAG,GAS/B,IACF,EAAO,GiCwLG,CjClMoC,CAAC,EAUjC,CAAA,OAAQ,CAAG,CAAC,EAAO,OAAO,CAAC,OAAO,EAAI,EAAA,CAAE,CAAI,AAAH,EAEvD,CAAK,EAAO,EAFqD,CAAC,IAE/C,CAAA,OAAQ,EAAI,GAAA,IAAI,CAAA,EAAA,IAAA,GAAgC,IAAA,CAApC,IAAI,CAAkC,EAAE,CAAC,EAC/D,GiCuLK,IjCvLE,CAAC,MAAM,CAAG,CiCuLC,EjCvLY,EAAO,OAAO,CAAC,OADa,CACN,CAAC,CAAC,CAI7D,EAGF,IAAK,GAAM,CiC+LA,AjClMC,EAAE,CAAC,GAGF,CAAA,IJpIc,AIoIP,CJpIQ,AIoIN,CJjIO,KIiIL,CAAI,CiC+LA,AjC/LE,SAAA,CAAY,CAAA,GAAK,CiC+LQ,CjC/LF,GAFjD,AAAC,EAAO,EiC6LI,EjC7LL,GAAQ,CAAC,KJjIW,CAAC,EqC8TF,CAAC,CAAA,GjC7LC,CiC+LzB,CAAA,OjC/LuC,CAAC,UAAU,CAAA,EAAK,AAAL,CAAM,CAEN,GiC+LU,AjC/LE,CAAC,AACpE,IAAM,CiC+LG,CjC/LS,CAAA,EAAA,EAAQ,OAAO,CAAC,UAAA,AAAU,CAAA,CAAC,EAAK,GAAA,CAAA,CAAL,EAAK,CAChD,EADgD,AAChD,CAAoD,CACtD,CADuD,CAAC,KACjD,CiC8LK,KjC9LC,CAAC,EAAW,GACrB,IAAI,EAAU,CiCkMC,CjClMC,CAAG,CAAA,EACnB,GAAA,CAAA,EAAgB,IAAI,CAAG,CAAA,EiCoMpB,GAAA,CAAA,EjCnMW,CiCoMC,OjCpMO,GAAlB,CAAkB,CAAR,OAAD,CAAS,CAAK,CAAE,IAAI,CAAE,EAAE,AAAC,IAAI,EAAI,EAAE,CAAE,SAAS,CAAE,EAAE,CAAA,CAAE,EACjE,AADkE,EAChE,AiCoMI,CAAA,OjCpMI,EAAU,QAAA,CAAU,IAAI,CAAG,EAAE,AAAC,IAAA,AAAI,CAAC,eAC9B,CAAC,AAClB,EAAU,GJzHK,KIyHI,CAAC,SAAS,EAAI,EAAE,AAAC,SAAS,CAAC,AAE1C,AtBrRV,SACJ,CAAA,CAAA,CAAA,OsBoRiC,EtBjRlB,CAAA,CAAA,UAAa,CoCPA,CAAA,ApCOM,CAAC,CAAI,CAAC,EAAA,KAAY,8BAKjD,GAAA,GAC8B,IAAc,EAAU,CoD7E5B,CAAA,MpD6EoC,EAAE,IAAI,GAAK,EAAS,IoD5E5D,IpD4EoE,CAAC,EoD5EvD,EAAA,oCpDgFiB,QAAA,CAAA,CAAA,CAAe,AAEzE,CAF0E,AAEzE,CsBqQmC,GAAA,IAAI,CAAA,EAAA,ClB7Ee,GkB6EP,CAAE,SAAS,CAAC,EAAE,CAAC,EAC9B,CAAC,gBAAgB,CAAG,GAAa,AJzH3C,EIyHqD,OAAD,AAAV,CAAoB,CAAC,UAAS,CAAC,CAAC,AAGzF,EAGJ,OAAO,GAGR,IiCsMe,CjCzMC,EAGT,aAAA,AAAa,EAAC,EAAA,IJxHY,GIyHS,EAAE,CJxHpB,AIyHjB,AADsC,EAItC,CJ3He,CI2Hb,CACR,EAAA,CAAA,CAJe,aAMV,EAAA,CAAG,QAAS,AAAC,IAChB,IAAM,EAAS,EAAU,EAAb,GAAkB,EAAN,AAAQ,CAAC,AAC7B,CJ3HO,CI4HT,EAAO,GiCiNE,CjClNC,AACJ,GAAQ,CAAC,GAEf,EAFoB,AAEV,IAAA,CAAA,EAAD,GAIb,IAAA,CAAK,EAAE,CAAA,MAAA,KAEL,IAAK,IAAM,QADJ,EiCuNI,ArC/UA,AIyHU,CJxHC,EIyHpB,EAAO,IiCyNM,GjCzNC,CAAA,KAAA,GAEhB,EAAU,IiC0NJ,EjC1NI,CAAA,CACZ,CAAC,CAAC,CAAC,AAEH,IAAA,CAAK,EAAE,CAAC,EiCyNA,MAAA,AjCzNU,IAEhB,IAAK,IAAM,QADJ,EACc,GACnB,EiCyNM,AjCzNC,IADqB,CAAE,CAAC,AAClB,CAAA,KAEL,MAAM,CAAG,CAAC,AACtB,CADuB,AACtB,CAAC,CAAC,IAEC,CAAC,EAAE,CAAC,QAAS,AAAC,GAAG,EJ1HF,AI0HI,GAEhB,IAAM,QADJ,EACc,EADV,CAET,EAAO,IADqB,CAAE,CAAC,AACxB,CAAA,GAET,EAAU,MAAM,CAAG,CAAC,AACtB,CADuB,AACtB,CAAC,CAAC,AAEI,CACL,IAAI,CAAE,KAAK,IAAkD,AAC3D,AAAK,EAAU,AAD8C,EACzD,IAAiB,CASd,CATgB,AiC8NoB,CjC9NnB,EJ3HN,GImIJ,CACE,CADQ,CiCsNK,GjCrNR,CADQ,EAAG,CAAC,AACV,IAAI,EAAE,CAAK,CAAE,CAAC,AARnC,AAAI,EACK,AAOuB,CAPrB,GADD,CAAC,OACO,EiCwNU,MjCxNO,CAAI,CAAE,CAAC,AAEnC,CAFgC,CiC2NxB,EjCzNJ,GiCsN8C,CAAC,CAAC,GjCtNP,CAAA,EAAU,IAC5D,CADsE,CAAJ,AACxD,EAD0D,EACtD,CAAC,EAAN,OAAQ,OAAO,EAAE,CAAM,CAAE,CAAC,CACpC,CAAC,CADgC,GAC5B,CAAE,AAAD,GAAY,CAAF,CAAJ,AAAK,AAAS,CAAE,CAAd,CAAS,CAAC,CAAC,CAAQ,CAAE,EAAO,GAAF,CAAM,EAAE,CAAK,CAAE,CAAC,AAAE,CAAD,AAAG,CAAP,IAAY,CAAE,OAAW,EAAF,EAAM,EAAE,CAAI,CAAE,CAAC,CAAH,AAAI,CAAC,MAK1F,UACN,IAAI,CAAC,EiCqN+B,CAAC,EjCrN3B,EAAE,CAAC,AACN,CAAE,KAAK,KJ1HgB,CI0Hd,EAAW,IAAI,EAAE,CAAI,CAAE,CAAC,CAAH,AAExC,AACH,CADI,AACH,AAED,kBAAA,QACiB,AACR,IADY,EACN,CADa,IAAI,CAAC,EJ1HJ,II0HU,CAAC,aAAa,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAE,IAAI,CAAC,UAAU,CAAC,CACnE,AADoE,gBACpE,EAChB,CAAC,CAqGH,AApGC,SAoGQ,GAAI,CAAU,EACrB,OAAO,KAAA,SAAA,CAAA,EACT,CAAC,AA+JD,SAAS,GAAA,CAAA,EAET,CAAC,AAED,SAAA,GAAqB,CAAS,EJ5QT,AI4QY,CAAC,iBrB/0BxB,6CAI2C,CqBzBrB,EAC9B,CrBwBuD,CAAC,sFAchD,EAAA,yDAEyD,CoEzBhC,iBpEoBwB,mHiEhBK,CAAA,OAAA,+EA4Cc,EAAA,MAAA,GAAe,CAAK,CAAE,CAErD,CDlCoC,ACkCnC,YAaS,CAAA,wBAC9B,CAAA,EAAA,CAAA,kBAAA,EAA0B,EAAA,CAAc,CAAA,wBAqBxD,IAAA,CAAA,OAAA,CAAA,IAAA,CAAA,EAAA,CAAA,kBAAA,EAA2C,EAAA,CAAc,CAAE,MAAE,C4B5CJ,CtCQH,AUoCa,E4B3CpE,C5B2CuE,CAAO,CAAE,CVpCf,AUoCgB,iEAmBnC,GAA4B,GF7BvB,AZRA,IcqCyB,EF7Bd,AZRA,AcqCqB,GAAA,CAAU,CAAE,CAAC,CAAC,OAalG,CAAA,CAAA,CAAA,CAAA,QACE,IAAA,CehCkC,AfgClC,OAAA,CAAA,MAAA,CAAA,EAAwB,CAAA,kBAAA,EAAqB,EAAY,CG3CV,AH2CY,CAAA,UAItD,CAAA,CACY,CAAA,ClE2J1B,IAAK,IAAA,KAAA,SAAA,EAAyB,CAAE,CAC9B,GAAA,AAAS,YAAqB,CAA9B,EAAS,IAAA,OACD,IAAA,GAAA,CAAA,wEAAA,EACuE,EAAK,CwDvHhB,CAAC,ExDuHmB,CAAA,EAAA,CAAI,CACzF,CAAC,GXvIoB,CAAA,IW0IpB,CSlHD,CTkHgC,AAA1B,QAAQ,CAAC,MAAM,CI1FD1G,GyDHC,A3DUQ,AEPN,AfhDF,GW2IhB,IAAA,GACJ,CAAA,MAAA,EAAA,EAAc,IElF4B,IAAA,CFkFnB,IAAI,CAAA,0FAAA,CAA4F,CACxH,CAAC,0EkE7JqB,wEAIM,GAAoB,EAAY,iCA6BhD,aAEX,IAAI,CAAA,OAAA,CAAA,EAEJ,mBAIqC,CAAA,OAAQ,CAAA,EAA+C,C7ExFxC,C6EyF1D,ChEtEC,AwFwCA,AtDYA,A8BkBA,CzDhFG,yCyDyF8C,CAAA,IAAA,CAAA,OAAa,CAAE,EAAM,mHtB/IpE,WAAA,CAAc,wBhC7CkC,OAAA,6CA0D7B,IAAA,sCAGd,EAAA,IAAA,gVApBA,EAAA,GAAA,CAAA,CAA6B,EAAA,EAAA,CAAA,CAAA,EAAA,CAAe,GAAK,EAAE,gFAqBJ,CAAC,wBAEnC,GAAA,CAAA,iCAIG,iDAKA,CAAA,2BAI+B,sHI/DlB,4BAA8B,GAAS,QAAQ,CnBEY,AmBFX,yGUwBjF,GAAA,qDAK8B,KAAK,qGClBP,CDaD,OCbS,GAAG,CRnBiC,AfNzB,AuByBD,CAAE,UAAU,CAAE,CAAE,KAAK,CAAE,EAAK,EAAD,GAAM,CAAE,CAAE,CAAE,IAAI,CAAC,OAAO,CAAC,CACnG,CAAC,WrBrBiJ,CACpJ,CAAC,kEqDeqD,GAAA,IAAqC,CAAC,CCtBvB,CxDaC,CoBKN,AoClBO,IAAA,oDDwBlE,CAAA,IAAA,GAAA,IAAA,CAAA,OAAA,uInBrB4C,CAAA,2DAOG,0DAUR,GAAA,YAA+B,CAAA,gEASjB,CAAE,wLkCNpC,CAAA,EAAA,CAAA,YAAA,EAAA,EAAA,CAAA,CAAA,0EAWG,CAAA,CAAA,CAAA,CAAA,2CACkB,CasB7B,CAAA,CAAA,CbtB4C,CoBEA,C3E4BlC,KoERW,CAAC,CAAC,+BbnBI,0GAe9B,SACD,GAAA,uFAUgB,EAAA,CAAA,YAAA,EAAA,EAA8B,CAAE,CAAE,qTYpDA,MAC3D,iDAEuD,6IlBFN,IAAI,CAAA,OAAQ,CAAC,0HYFlB,2DAGiB,GAAA,QAAiB,CAAC,YAazD,CAAA,CAAA,yNHbZ,+CACmD,GAAS,CI0DG,AhEhC9C,CAAO,sD4DPL,mBAAA,GAA2D,0GAkBvE,CAAC,MAAA,CAAA,EAAA,CAAA,iBAAA,EAAA,EAAA,CAAyC,CAAE,KACnD,YACY,sCAAgD,ClCMG,CAAC,AlBwCA,MoD9CI,eAkBhE,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,sDAaU,CpERyB,AWSvC,CAAA,MAAA,CyDD8B,CACxC,GAQA,OAAE,EAAO,GAAG,CAAA,SAAkB,GAAa,EAAG,IhBvBE,UgBuBa,iBAAiB,CAAE,CAAE,GAAS,IAAF,GAAS,CAAC,CAAC,CAAE,CACvG,CAAC,8G7BxEiD,IAAA,CAAA,OAAA,qHyBdS,CAAA,yDAGC,GAAS,uBAS5C,CAAA,CAAA,CAAA,CAAA,gBACT,C7DkBC,A2EQE,CAAA,yBdzBG,CAAA,EAAA,CAAA,SAAA,EAAiB,EEUI,CrD6GA,AqD7GA,SAAA,EFVkB,EAAA,CAAW,CAAE,cAEhE,GAAA,oCAA2D,ChCgBiB,CoBhBvD,yFYWkB,C7CuBC,ATgBhC,SAAA,EAAA,EAAA,CsDvCuD,ChCgBC,AgChBC,yDAGf,GAAS,GXaI,KWbI,iDAchD,CAAA,EAAA,CAAA,SAAA,EAAA,EAAA,SAAA,CAAA,CAAsC,GAAqB,ChD+CL,wCgD5C1C,uCAU1C,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,6DAK2C,EAAA,UAAA,EAAsB,EAAA,CAAA,CAAa,kDAEjB,GAAA,QAAiB,CAAC,oEDhEjD,EAAA,CAAA,gEACoD,CrCHF,0DqCMnB,GAAA,QAAiB,CAAC,GXDtC,+BWWnB,EAAA,CAAA,yDAC2C,ChCKC,AEHC,CAAC,AFGD,AgCLG,ChCKF,A0B0CI,CAAC,CAAC,GAAA,CM/CI,CAAE,CHIpC,EAAA,qEGDkC,kGvB5BrB,yK/BsEP,CAAA,6XAcnD,MAAM,CAAC,aAAA,AAAa,EAAC,EAAA,uDAUO,KAAA,6HAkBpB,IAAA,UAAA,uBAGW,CNhDD,AvBrBM,oD6B0EW,yCAQT,QAQf,EAAA,KAAuB,EAAG,CAAC,KACJ,0CAL2B,EAAA,IACpD,EAAA,IAAc,CAAA,uBACd,GTzDgF,CSyD5E,CAAC,AAAC,GAAW,CwCjCW,CxCiCH,CAAE,EAAL,CAAC,CAAC,CAAQ,CAAE,EAAO,GAAF,CAAM,EAAE,CAAK,CAAE,CAAG,AAAF,CAAC,AAAG,CAAP,IAAY,MAAE,EAAW,IAAI,CAAA,CAAA,CAAN,AAAY,CAAE,CAAC,CAAC,CAAC,gBAMhG,IAAA,CAAK,KAAA,wBACgC,CAAE,CAAC,mCAMtC,EAAA,IAAA,sBACmB,mBAAA,CAAA,gCAKzB,CAAA,CAAA,CAAA,CAAA,qBAKE,EAAA,OAAA,EAAA,IAAA,CAAA,UAAmC,CAAA,KAAA,kDACoB,KAAA,UAEpD,UAAA,YACiB,CkCtCL,AIjBE,C+BmBc,A7BEf,gBxCkCsB,CAAA,EAAuC,IAAI,CAAC,UAAU,CAAC,eAC9E,KAAA,yBACf,IAAI,ClBwB+E,AkBxBpE,ClBwBsE,iBkBtBlE,CAAA,MAAA,EAAS,2DAGM,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,6CAIF,aAAa,CAAA,CAAA,IAAA,CAAA,IAAW,CAAC,CAAE,IAAI,CAAC,ChBlDL,SAAA,qBgBsDnE,C7BpEC,CAAC,K6BoEK,0BAAA,CACQ,CAAA,CACH,CAAA,CAC8B,CACxC,CAAA,CAAA,KAEM,EAAA,IAAA,eACK,CAAA,IAAA,EAAA,uBACqB,CAAC,EAAO,CIaQ,CJbF,CAAR,CAAQ,KAChC,aACI,GAAA,OAAgB,CwChCC,4BxCgC8B,CIcH,oBJRhD,2BACd,CAAS,CACT,CAAa,CmBwByB,AnBvBtC,CAAwC,CAAA,CAChB,CAAA,KAElB,EAAA,GAAA,YqCqLkb,CACrb,CAAC,CrCrLQ,KACQ,EAAE,IAAA,CAAK,UAAA,CAAW,KAAK,qBAClB,CAAC,CwEjBL,OAAA,IxEiBoB,IAAA,CAAK,EhB5DI,AmCsFA,QnB1BM,CAAC,ChB5DG,CAAC,GgB4DC,CmB0BG,CnB1BD,cAGH,SAAU,GACjE,EAAA,MAAA,EAAA,iBAAoC,CAAA,EAAQ,CCzCC,CAAA,ID0C9C,CAAA,yDAIA,UAAA,GAEqB,MACxB,IAAI,CAAA,EAAA,IAAA,IAAU,IAAA,CAAd,IAAI,CAAW,KAAK,CAAC,CAAC,WAEH,CAAA,MAAA,EAAA,cACb,IAAI,8BAGY,CAAA,EAAA,IAAA,IAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,OAGnC,4BAAA,CAAA,CAAA,CAEU,CACf,CAAA,CAAA,KAEM,EAAS,IAAI,4CAEY,CAAC,EAAQ,EhBnEuB,CAAF,CF8FD,AE9FE,CAAC,EgBoEjD,UACC,GAAA,GAAA,OAAmB,6BAA+B,QAAQ,cAMpE,sBAAA,CAAA,CAEL,CT7EgC,AS6EtB,CACV,CAAiC,ClB2BN,AkB1B3B,ClB0B6B,AAAC,CAAA,KkBxBxB,EAAA,IAAa,oBAEjB,EAAO,EmBuBU,A5BxGI,APSE,iBOTF,CAAA,EAAA,ESiFsB,EAAQ,yDAEY,aAG1D,wBAIA,GAAA,IAAI,CAAA,GAAA,kBAIX,OAAO,GAAA,IAAA,CAAA,GAAA,IACT,CAAC,mCAGQ,CmBuBY,CAAC,EAAA,CAAA,EAAA,InBtBtB,CAAC,yBAGC,OAAA,GAAO,IAAA,CAAA,GAAA,IACT,OAEM,eAAA,kBACM,CAAC,IAAI,GAER,OAAO,MAAA,CAAO,GAAA,EIJiB,AoELQ,EAAA,CAAA,EAAA,YxEY1C,eAAA,cACE,IAAA,CAAK,IAAA,GAEJ,OAAO,KhBpDK,CAAA,CAAA,GgBoDE,EIPmB,CAAC,CJOhB,CAAA,EAAA,EhBpD8D,CAAC,CAAC,AgBoD9C,CAAC,CAAC,MAGzC,CTrFD,SAAA,cSsFO,CAAC,IAAI,EAAE,KACZ,CqCiMsB,CAAC,C0BhOD,CAAA,CAAA,EAAA,KAAA,MAAA,M/D+BM,CmBsBhB,AkB2KiC,CAAC,oCrC/L5C,GAAA,C2C/I4B,CN+UL,EAAA,CAAA,EAAA,wCrC5L9B,CAAe,CAAA,CACqB,CACpC,CAAwB,CAAA,qBAIlB,CsCnGD,CtCmGQ,OAAA,EAAS,IAAA,CAAK,UAAU,CAAC,CTtFb,AoD7DE,I3CmJgB,qBAClB,CAAC,CTrFG,CAAC,MSqFK,C2CnJK,CAAC,CAAC,A3CmJJ,CAAG,CAAD,GAAK,CAAC,C+DnCH,S/DmCa,CAAC,KAAK,EAAE,CAAC,CAAC,KAG5D,EAAA,IAAsC,C7B1H7B,AiCgHE,AjChHF,C6B0HqC,QAAQ,GACtD,EAAS,MAAM,ETtFA,YSsFmB,CAAC,EAAM,CAAE,CAAJ,EAAO,CAAO,CAAE,OAAQ,IAAI,CAAC,UAAU,CAAC,MAAM,CAAE,CAAC,CAAC,UAIpF,IAAM,SAFb,CAAC,UAAA,GAEY,MACf,CADgC,CAAC,ATxFJ,ESyF7B,CAAA,EAAA,IAAA,IAAc,IAAA,CAAd,IAAI,CAAW,KAAK,CAElB,AAFmB,CAAC,CAEpB,UAAA,CAAkB,MAAA,EAAQ,SAAS,CAAC,AqCqMA,CAAC,iBrCjMlC,IAAA,CAAK,CIRL,MJQY,CAAA,GAAA,IAAK,CAAA,EAAA,IAAA,IAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,AACzC,CAD0C,AACzC,MAEe,uBACd,CAAS,CACT,CAAgB,CAChB,CAA2B,CqCiMwC,ArCjMxC,CqCiMyC,ArCjMzC,CqCiM0C,ArChM7C,UAEA,oBAEJ,EAAA,IAAA,CAAO,ChB9Df,SAAA,CAAA,KAAA,KgB+DH,gBAAgB,CAAC,QAAS,CsCjGK,GAAA,IAAA,CtCiGM,UAAU,CAAC,KAAK,EAAE,CAAC,CAAC,0BAInD,MAAM,EAAA,MAAA,CAAW,EAAU,E7BpIN,A6BoIY,CmBiBL,AnBjBO,GAAG,CAAA,CAAS,MAAM,A7BpIR,C6BoIU,IAAI,CAAC,UAAU,CAAC,C7BpIP,CAAC,I6BoIY,CAAE,CAAC,CAAC,UAIrF,IAAM,SAFb,CAAC,UAAU,GAEW,E+DzCF,C3D6BG,AJazB,AhBhEW,A+EsBY,CACtB,E/DyCD,CADgC,CAAC,EAC7B,CAAA,EAAA,IAAA,IAAU,IAAA,CAAd,IAAI,CAAW,KAAK,CAAC,CAAC,YAEF,MAAM,EAAE,IsCpGI,CAAC,CAAC,CtCoGC,EAAE,KAC/B,IAAA,UAGD,IAAA,CAAA,OAAA,CAAA,GAAA,IAAA,CAAA,EAAA,IAAA,IAA6B,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,AAiT1C,OAAO,gBAAgB,CAAwB,CAAA,CAAA,CAAA,KACxC,GAAA,CAAA,EAAY,EAAW,GAAI,IIzTI,ClBhDP,CcyWS,CAAA,OAAA,CAAA,GAAiB,CAAC,IhB5WZ,AgB6WrC,ChB7WsC,CAAC,AgB6WnC,ChB5WG,C+EqBC,Y/DuVU,CAAC,E7BtbI,CAAA,G6BubtB,EAAI,CAAG,eAIT,ChB7WG,AoBqDF,CJwTU,CAAA,CAAA,EAAQ,CAAC,EsCpZM,UnE9B7B,U6BmbgB,A7BnbhB,G6BybyB,KAND,IAMF,EAN0B,CAAC,AAMxB,CANO,AAC5B,CIxT6B,AJwT5B,EAAI,ChB7WK,MoBqD8C,QJmUrC,oBAAkC,QAAQ,EAA9B,AAAgC,CAAC,MAA1B,KAC7B,E+DxVE,G/DuVqC,EAE9C,GAAW,UAAP,EsCjZA,KtCiZO,GAA+C,AAA/C,GqC/FkD,OrC+FO,AAAzD,CAA0D,GqC/FG,CAAC,CAAC,CrC+F/B,AqC/FgC,C0BxPvC,C/DwVzC,GAAA,aACe,IAAA,GAAmB,GAClC,EsC/YM,AAAC,CAAA,GtC+YQ,CAAA,GADgC,CAAC,WACjB,CAAA,EAAkC,QAC5D,C7BrbK,Aa8EF,EAAA,MgBuWO,CqCxFD,ClE7Ve,K6BqbP,CAAA,IAAc,MAAA,OAAa,CAAC,GAAa,CAAC,WAC7C,GAAoB,QAAQ,EAArB,OAAO,CAAC,C7BpbS,CAAC,A6BobO,AAAa,QAAQ,CAAC,QAAf,CAAC,EAAgB,CAAC,UACzD,GACjB,QACF,CAEA,ChBtWO,AgBkWyB,GAI3B,IAAM,KAAc,EAAA,CACvB,EADmB,CACf,CAAA,GAAA,SACQ,AAAJ,MAAU,CAAA,KANuD,+CAMvD,EAAuD,EAAU,CAAE,CAAC,CAAC,AAGvF,IAAA,CAHmF,CAGnF,EAAA,KAAA,CACA,GqCtFS,ArCsFI,MAAT,AAAe,CAAC,eACV,KAAK,CAAA,GACP,AAAI,CqCnFK,CrDlRG,IgBqWF,0DAGlB,GAAI,UAAA,OAAA,EACF,MAAM,A+DtVsB,GAAA,GAAA,CAAA,qEAAA,E/DsV4D,EAAK,CAAE,CAAC,CAAH,AAAI,OAG1E,CAAC,EAAA,AACV,MAAM,CAAC,EACrB,EmB3iB+B,AnB2iB/B,IAAA,CAAA,GAEA,CAAQ,CAAC,EAAA,CAAS,IAAI,CAAC,ChB/UW,CAAC,CAAC,YgB+UE,CAAA,EAAW,EAErD,CAAC,AACD,EhB/UO,YgBiVP,CADK,CAAC,Gd9VGA,AiC7LE,CnB4hBL,MAAM,CAAA,CI1PF,sBAAA,EJ0P4B,EAAG,Cd/VM,aAAA,Ec+VW,EAAU,YAAA,EAAe,EAAQ,CAAE,CAAC,CAAC,CAE9F,CAAC,CAFyF,AsCjYtF,CAAA,CtCmYI,SAGN,EmB7hBI,AnB2jBH,CA9BE,OA8BF,CAAgB,CAAA,QACjB,CACT,CAAC,AAES,CmB1jBP,InB0jBY,CAAC,uBACd,CAAoC,AsClaZ,CtCmaxB,CAAe,CACf,CAAwB,CAAA,CIzRgB,CAAC,CiC6KnB,KrC8Gf,MAAM,IAAI,CAAC,aqC5GS,eAAA,CrC4GoB,EAAQ,EAAQ,EACjE,CAAC,CAD8D,KAG/C,ImB/hBJ,gBAAA,CnBgiBM,CAChB,CAAU,CAAA,CACiB,CAC3B,CqCjH2C,ArCiHnB,CAAA,CI9RiB,EAAE,KJgSpC,MAAA,IAAU,CAAC,CqClHH,qBrCkHyB,CAAC,EAAM,EAAF,AAAY,EAAQ,EACnE,CAAC,AmBliBE,CnBiiBsD,AAAQ,GAAS,CAAC,CAAC,yBAI7D,CAAA,CACH,CACV,CqCrHoC,ArCqHI,CACxC,CAAwB,CAAA,QAEjB,MAAA,IAAU,CAAC,GmBpYC,oBAxK+G,CAC/H,CAAC,CnB2iBwC,CAAC,EmBpYA,AnBoYM,EAAF,AAAS,EAAQ,CAAV,CAC1D,CAAC,CACF,AAFmE,GAAS,CAAC,CAAC,YApanE,CAA2B,EACnC,IAAI,IAAI,CAAC,KAAK,CqCoTL,ArC9ST,GI+HY,IJnIZ,GAAA,IAAI,CAAA,GAAiB,EAAA,KAErB,GAAA,GIoIoB,CAAA,CAAA,EAAA,IAAA,IJpIH,IAAA,CAAjB,IAAI,CAAc,GAElB,EAFuB,AAEvB,CAFwB,CAAC,GAEN,EACjB,IAAK,2BAIA,yBACA,oBACL,IAAA,yBACA,IAAA,6BACA,IAAA,2BACK,gDAEL,IAAK,wBACL,IAAK,uBACL,IAAK,qBACH,GAAA,CIiIU,GJjIN,CAAA,EAAA,IAAA,IAAW,IAAA,CAAf,IAAI,CAAY,GAChB,EADqB,CAAC,CAAC,CAGzB,KAAK,0BACL,IAAK,8BACL,IAAA,wBACA,IAAK,4BACL,IAAK,6BACA,4BACL,IAAK,6BACH,IAAI,CAAA,EAAA,IAAA,IAAe,IAAA,CAAnB,IAAI,CAAgB,KAAK,CAAC,CAAC,CAG7B,KAAA,yBACA,IAAK,6BACL,IAAK,uBACL,IAAK,2BACL,IAAK,8CACgB,IAAA,CAAnB,IAAI,CAAgB,KAAK,CAAC,CAAC,MAGxB,QAEH,MAAM,AAAI,MACR,IqCiUgB,kFrC7TtB,CAAC,AACH,CAAC,CAAA,GAAA,WAGC,GAAI,IAAA,CAAK,KAAA,OACD,IAAA,GAAgB,CAAA,wCAAyC,CAAC,CAAC,AAGnE,GAAA,CAAK,GAAA,IAAI,CAAA,EAAA,KAAA,MAAkB,MAAM,mCAEjC,OAAO,GAAA,IAAI,CAAA,EAAA,IACb,CAAC,CAAA,GAAA,SAEqC,CAAyB,EAC7D,GAAM,CAAC,EAAoB,EAAW,CAAG,GAAA,IAAI,CAAA,EAAA,IAAA,IAAmB,IAAA,CAAvB,IAAI,CAAoB,EAAO,GAAF,AAAE,IAAI,CAAA,EAAA,IAAiB,CAAC,CAAC,GAA/B,KAIrD,KAHX,EAGkB,CAHlB,EqCgUqB,ErChUjB,CAAA,EAAoB,EAAkB,IAAA,CAAC,AAC3C,GAAA,IAAI,CAAA,EqCgUuB,CrCjUe,GACpB,CAAC,EAAmB,EAAE,CAAC,CAAG,EAE1B,GAAY,CAAC,IAC3B,EAHiC,AAGf,EqCiUA,ArCjUmB,IAHqB,CAAC,EAGf,CAAC,CqCiUD,CrCjUS,KAAK,CAAC,CAAC,GAC7C,IqCgUkD,ErChU1C,MAAM,EAAE,AACnC,CADoC,CqCmUhC,ErClUA,CAAC,KAAK,CAAC,CI2HC,aJ3Hc,EAAgB,IAAI,CAAC,AAEnD,CAFoD,AqCwUrD,ArCtUE,OAF4C,AAIrC,EAAA,KAAW,EACjB,IAAK,6BACC,CAAC,KAAK,CAAC,MqC4UM,CAAC,SrC5US,CAAA,EAAQ,IAAI,CAAC,CAAC,AACzC,EqC2U6E,GrCzU/E,CqC4UC,IrC5UI,6BACH,CIyHD,SJvHI,KqCgVG,yBrC/UF,CAAC,CqC+US,IrC/UJ,CAAA,eAAA,EAAuB,GqC+UW,CrC/UP,CAAC,KAAK,CAAE,KAEnC,CIwHD,GJxHK,CAAC,KAAK,CAAC,CqC+UC,MrC/UM,CAC1B,CAD4B,CAAC,EACxB,IAAM,CqCgVG,CAFuB,AjCtNxB,GJxHS,EAAM,CIwHC,CiCyNb,AjCzNU,EJxHM,CAAC,KAAK,CAAC,OAAO,CAAE,CAAC,AAE/C,GqC+UwC,ArC/UpB,MAAM,EAAtB,EAAQ,IAAI,EAAc,EAAQ,IAAI,CAAL,AAAO,CAAC,AAC3C,IAAI,EqCkVM,ArClVM,EAAQ,IAAI,CAAC,AACzB,AADmB,EqCmVb,ArClVK,CqCkVJ,CAAC,AAAS,ArClVa,OAAO,CAAC,EAAQ,KAAD,AAAM,CAAC,CAAC,AACzD,GAAI,CIyHO,EAAE,AJzHoB,EIyHlB,GJzHH,CAA2B,EAAvB,AAAyB,CAAC,CAAjB,IAAI,CAC3B,CADsB,GAClB,CAAC,KAAK,CAAC,WAAW,CAAE,EAAW,EAAS,IAAI,CAAf,AAAgB,CAAN,AAAO,KAElD,MAAM,KAAK,CAAC,sEAEhB,CAAC,AAED,GqCiVM,AjCvNC,AJ1HH,EAAQ,CI0HK,IJ1HA,EAAI,GAAA,IAAI,CAAA,EAAA,IAAqB,CAAE,CAAC,AAE/C,GAAI,CI0HK,EJ1HL,IAAI,CAAA,EAAA,IAAgB,CACtB,CADwB,CAAC,KACzB,GAAQ,IAAI,CAAA,EqCmVqC,EAAF,CAAC,CAAC,CrCnVpB,IAAI,EAC/B,AADiC,CAAC,GAC7B,MAAM,CACT,IAAI,CAAC,KAAK,CAAC,UAAU,CAAE,GAAA,IAAI,CAAA,EAAA,IAAgB,CAAC,IAAI,CAAE,GAAA,IAAI,CAAA,EAAA,IAAiB,CAAC,CAAC,AACzE,KACF,CADQ,IACH,YAAY,CACf,IAAI,CAAC,KAAK,CAAC,eAAe,CAAE,GAAA,IAAI,CAAA,EAAA,IAAgB,CAAC,UAAU,CAAE,GAAA,IAAI,CAAA,EAAA,IAAiB,CAAC,AAEvF,CAFwF,AAEvF,AAGH,GAAA,IAAI,CAAA,EAAwB,EAAQ,KAAD,AAAM,CAAA,IAAA,AAC3C,CAD4C,AAC3C,AAED,GqCiVqC,ArCjVrC,CqCiVsC,GrCjVlC,CAAA,EAAmB,EAAmB,OAAO,CAAC,EAAQ,KAAD,AAAM,CAAC,AAAvB,CAAuB,IAAA,AAClE,CADmE,AAClE,AAGH,CI0HD,IJxHD,CAFQ,IAEH,KIyHC,sBJxHN,IAAK,oCAE+B,IAA9B,GAAA,CqC+UI,CrC/UmC,EAAnC,CAAA,EAAA,IAAqB,CAAgB,CAAC,AAC5C,IAAM,CqC8U4B,CAAC,ArC9UZ,EAAM,GAAD,CAAK,CAAC,KAAd,EAAqB,CAAC,GAAA,IAAI,CAAA,EAAA,IAAqB,CAAC,CAAC,AACrE,GAAI,EACF,OAAQ,EAAe,IAAI,CADT,CAAC,AAEjB,AAD2B,CAAC,GACvB,II0HU,SJzHb,IAAI,CAAC,KAAK,CAAC,CI0HS,CAAC,aJ1HK,CAAE,EAAe,UAAU,CAAE,CAAb,EAAa,IAAI,CAAA,EAAA,IAAiB,CAAC,CAAC,AAC9E,KACF,KAAK,MAAM,CACT,GI2He,CJ3HX,CAAC,KAAK,CAAC,WAAY,EAAe,IAAI,CAAE,GAAA,IAAP,AAAW,CAAA,EAAA,IAAiB,CAAC,AAEtE,CAFuE,AAEtE,AAEL,CqC8UoB,ArC9UnB,AAEG,GAAA,IAAI,CAAA,EAAA,MACN,AADyB,CI8H4B,AJ9H3B,GACtB,CAAC,KAAK,CAAC,GI8HK,WJ9HU,EAAM,GAAD,CAAK,CAAC,CAAC,GAGxC,IAAI,CqCoVsB,OrCpVF,EAAS,IAAA,AACrC,CADsC,AACrC,AACH,CAAC,CAFsC,AAEtC,GAAA,SAEqC,CAAyB,EAC7D,IAAM,EAAqB,GAAA,IAAI,CAAA,EAAA,IAAA,IAAmB,IAAA,CAAvB,IAAI,CAAoB,GAGnD,EAHwD,CAAC,CAAC,GAC1D,GAAA,IAAI,CAAA,GAA2B,AADmB,CI6HvB,CJ5HsB,IAAA,CAAC,AAE1C,CI2HH,CJ3HS,KAAK,EAAE,AACnB,CADoB,CAF2B,EAG1C,CqCiVe,yBrChVlB,IAAA,CAAK,KAAA,CAAM,iBAAA,EAAwB,IAAI,CAAC,CAAC,AACzC,KACF,IqCgVkD,CAAC,AjCtNA,AJ1H9C,CqCgV+C,AjCtNA,uBJzHlD,CqCkVD,GrClVO,EAAQ,EAAM,CAAT,EAAQ,CAAK,CAAC,KAAK,CAC9B,AAD+B,GAC/B,EACQ,GI4HG,SJ5HS,EAAA,AACS,YAAY,EADrB,EACZ,YAAY,CAAC,CqCgVD,GrChVK,EI4HA,AiCoNkB,CAAC,CrC/UpC,YAAY,CAAC,UAAU,EACW,AADX,YACuB,EACpD,AAF6B,CAE5B,CADkB,YAAY,CAAC,IAAI,CAEpC,IAAK,IAAM,KAAY,EAAM,GAAD,SAAa,CAAC,UAAU,CAAE,AAChD,CADiD,CACxC,CI4HN,IJ5HW,EAAI,GAAA,IAAI,CAAA,EAAA,IAAsB,EAAE,CAAC,EAC7C,CAAC,KAAK,CACR,gBACA,EACA,EAAmB,CqC6U2C,CAAhB,UrC7Uf,CAAC,UAAU,CAAC,EAAS,KAAK,CAAa,AAAnB,CACpD,CAAC,CAEE,GIyHG,AJzHH,IAAI,CIyHwB,GAAA,MJzHL,AACzB,CAD0B,GACtB,CAAC,CqC6US,CAAC,GrC7UL,CAAC,cAAc,CAAE,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,AAGpD,CIwHG,EJxHH,IAAI,CAAA,EAAyB,EAAS,KAAK,CAAA,AAAN,IAAM,CAAC,AAC5C,GAAA,CIwHM,GJxHF,CAAA,GAAoB,EAAmB,CqC8Ub,WrC9UyB,CAAC,GAAd,OAAwB,CAAC,EAAS,KAAK,CAAN,AAAO,CAAA,IAAA,CAC9E,AAD+E,GAC/E,AqC8US,IrC9UL,CAAA,GAAA,IAAiB,EAAE,IAAI,CAAA,KAAM,CAAC,iBAAiB,CAAE,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,CAKtF,IAAI,CAAC,KAAK,CAAC,EIyHF,YJzHgB,CAAE,EAAM,GAAD,CAAK,CAAC,KAAK,CAAE,GAC7C,UACG,KAF4D,CAAC,CAAC,qBAGnE,IAAK,yBACL,CqCmVC,GrCnVI,SqCmVS,uBrClVT,0BACH,GAAA,IAAI,CAAA,QAA2B,EAAS,IAAA,CAEpB,AAFqB,EI2HzB,AJ3HwB,YAEpC,AADY,EIyHH,CAAA,EiC+NJ,CjC/NI,CJzHc,AAChB,YAD4B,CAC5B,IAAK,EACV,GAAA,CIyHkB,CiC6N+B,EAAA,CAAA,GAAA,MrCtV1B,CAAC,AAC1B,IAAI,CAAC,KAAK,CAAC,EqCsVM,aAAA,GAAA,IrCtVc,CIyHoB,GAAA,MJxHnD,GAAA,IAAI,CAAA,GAAoB,OAAS,EAAA,EAAA,CAAC,KAGlC,CAAC,CqCuVD,IrCvVM,CAAC,cAAe,EAAA,IAAU,CAAE,EAI1C,CAAC,AACH,CAAC,CAAA,GAAA,SAEmC,CAP0B,AAOC,CAPA,CAAC,AAQ9D,GAAA,IAAI,CAAA,EAAA,KAAS,IAAI,CAAC,GAClB,EADuB,CAAC,CAAC,AACrB,CAAC,KAAK,CAAC,QAAA,EACb,CAAC,CAAA,GAAA,SAEkB,CAAyB,EAC1C,OAAQ,EAAM,EqCoVF,GrCpVO,EACjB,AADmB,AqCoVJ,CrCpVK,GACf,iCACH,GAAA,IAAI,CAAA,EAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAG,EAAM,GAAD,CAAK,CAAC,AAC5C,EAAM,GAAD,CAAK,CAAC,AqC+VA,IrC7Vf,4BACC,EAAW,GAAA,IAAI,CAAA,EAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAiB,CAAC,AACrE,GAAI,CAAC,EACH,MAAM,CIyHC,CJ1HM,CAAC,GACF,yDAGd,IAAA,EAAW,EAAM,IAAI,CAAC,EqC6VE,GrC3Vf,GIuHC,EJvHI,CAAE,CAAC,AACf,CqC2Vc,GrC3VR,EAAc,EAAe,AAAC,OAAnB,QAAkC,CAAC,EAAU,EAAK,EAAD,EAAN,CAAY,CAAiB,CAAC,AAC1F,GAAA,GqC4VI,AAAoB,CrC5VpB,CAAA,EAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAG,CAC1C,CAAC,AAED,CIuHC,CADE,KJtHI,EAH8C,CAG9C,AAH+C,IAG3C,CAAA,CqC2VsB,CAAA,IrC3VJ,CAAC,EAAM,GAAD,CAAK,CqC2Vf,ArC3VgB,EAAE,CAAiB,CAAC,IAE1D,CIsHD,+BJrHC,yBACL,IAAK,4BACL,IAAK,0BACL,IAAA,qCACM,CAAA,CqC0VwB,CAAC,IrC1VP,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAG,EAAM,GAAD,CAAK,AAEtD,CAFuD,AAEtD,AAED,GAAI,GAAA,IAAI,CAAA,EAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAE,OAAO,GAAA,IAAI,CAAA,EAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAiB,AACvG,CADwG,MAClG,AAAI,KAAK,CAAC,wBAClB,CAAC,CAAA,GAAA,SAGC,CAA2B,CAC3B,CAA6B,EAE7B,CqCuVD,GrCvVK,EAAoC,EAAE,CAAC,KAA7B,EAEN,CqCuVO,CrCvVD,II2QI,CAAA,EJ1QhB,GI2QG,CJ3QE,IqC0VE,qBrCxVL,MAAO,GAAO,IAAI,CAAE,EAAW,CAAC,IAE7B,GAF2B,oBAG9B,GAAI,CAAC,EACH,MADW,AACL,EADO,CAAC,EACH,CACT,gGAIO,EAAM,IAAI,CAAC,GAGlB,EqCmVqB,ArCnVhB,GqCqVC,ErCrVI,CAAC,OAAO,CACpB,CADsB,CAAC,AqCqVF,ErCpVhB,IAAM,KAAkB,EAAK,EAAD,GAAM,CAAC,CAAf,MAAsB,CAAE,AAC/C,CADgD,EqCsV7C,ErCrVgB,KAAK,IAAI,CqCqVC,CrCrVQ,AqCqVP,CAAC,KrCrVK,CAAQ,CAAE,CAAC,AAC7C,IAAI,EAAiB,EAAS,MAAD,CAAQ,CAAC,EAApB,AAAmC,CqCqV9B,IrCrVmC,CAAC,CAAC,EACnD,GqCqVgB,ArCtV2B,IACpC,CAAC,EAAe,EqCqVwB,GrCrVnB,CAAC,CAAG,GAAA,IAAI,CAAA,EAAA,IAAA,IAAmB,IAAA,CAAvB,IAAI,CAC3C,EACA,EAEJ,CAAC,KACC,CADK,CAAC,AACG,EAJO,EACA,CACf,CAAC,AAEM,CAAQ,CAAC,CAL+C,CAKhC,KAAK,CAAC,CAAG,EAEzC,EAAW,CAFoB,GAEhB,CAAC,GAAN,AAKhB,MAAO,CAAC,EAAU,EALkB,AAOtC,CAPuC,CAAC,GAOxC,KqC4UoD,wBrC3UpD,IAAK,GqCkVH,wBrCjVF,IAAK,4BAEH,GAAI,EACF,MADU,AACH,CAAC,CADI,CAAC,AACK,EAAW,AAE7B,IAFgB,GAEV,KAAK,CAAC,yDAAyD,CAAC,CAAC,AAG7E,MAAM,KAAK,CAAC,yCAAyC,CAAC,CAAC,CACxD,GAAA,SAGC,CAAmC,CACnC,CAA0C,EAE1C,OAAO,EAAe,AAAC,eAAe,CAAC,CqC2UnB,AAAS,CAAC,ErCxUhC,CAAC,CAAA,GAAA,SAkEiC,CAAqB,EAGrD,OAFA,GAAA,IAAI,CAAA,GAAuB,EAAM,GAAD,CAAK,CAAA,IAAA,CAAC,AAE9B,EAAM,GAAD,EAAM,EACjB,IAAK,qBAEL,IAAK,oBAEL,IAAK,yBAHH,KAKF,CALQ,IAKH,6BACL,IAAK,uBACL,IAAK,oBACL,IAAK,uBACL,IAAK,oBAAoB,CACzB,AAD0B,IAC1B,wBACE,GAAA,IAAI,CAAA,EAAa,EAAM,GAAD,CAAK,CAAA,IAAA,CAAC,AACxB,EqCgSM,CAAC,ArChSP,IAAI,CAAA,GAAA,IAAiB,EAAE,CACzB,AAD0B,IAC1B,CAAK,KAAK,CAAC,GqCgSS,CAAC,UrChSI,CAAE,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,AAClD,GAAA,CqCgSU,CAAC,ErChSP,CAAA,QAAoB,EAAS,IAAA,CAAC,AAKxC,CAAC,AACH,CANyC,AqCqSrC,ArC/RH,KqCgSG,6VmCj7BsC,EAAA,MAAA,EAAA,EAAA,CAAA,CAA2B,6EAWE,CAAA,sBACzC,CAAA,yCACa,EAAA,MAAA,EAAkB,EAAA,CAAA,CAAA,4DAGW,CtEtCC,CAAC,CAAC,KsEsCK,CAAC,2EAcE,EtCjCD,wBsCoCvD,CAAE,cAAA,uCAStB,CAAA,CAAA,CAAA,CAAwC,CAAwB,CAAA,IAC/D,CAAA,UAAA,CAAA,CAAA,CAAgB,mDACqC,EAAA,OAAA,CAAA,CAAgB,IACtE,CAAA,aACoB,gCAAoC,ExBIG,CwBJM,IxBIK,CAAC,CAAC,CwBJA,CAAC,CAAC,qDAclD,CAAA,EAAA,EAAA,8BACA,CAAA,WAAe,GAAY,ChClBX,MgCkBkB,CAAC,YAShD,CAAA,CAAA,CAAA,CAAA,CAAA,gCAI4B,CAAC,EAAA,IAAc,CAAC,IxB8B2C,CAAC,CAAC,CwB9BtC,CAAA,IAAK,CAAC,OAAO,CAAC,IAAI,CAAE,EAAM,EAAF,KAAS,CAAC,CAAC,AAQlG,KAAA,CAAA,CAAA,CAAA,CAGJ,CAAsD,CAAA,KAEhD,EAAA,GAAuB,8CAIzB,mCAAoC,GAAS,cAAc,EAAE,CrD6BsC,gBqD7BxB,WAIxE,CAAA,qBACc,CAAQ,CAAA,CAAK,MAAM,ElChDA,EAAA,CkCgDK,QAAA,CAAA,EAAA,EAAA,IACtC,CAAA,aACW,GAAS,CvEjBK,MuEiBE,CT3BK,wCSgCnC,IAAA,gDAGM,EAAA,IAEJ,GAAA,GAAA,iCACwC,cAEN,OAAO,CAAA,GAAI,CAAC,CvEtBS,iCuEwB7C,EAAmB,ChFeL,QgFfc,KhFeD,WgFbf,CxF5Ca,AF0FF,EsBhBA,AtBgBA,S0F/CC,CAAC,A1F8CR,A0FzCf,QAGd,KAAA,qGAMS,WAQR,CAAgB,CAAE,CAAA,CAAA,CAAA,CAAA,QAChB,GAAA,qBAAqC,CAAC,EAAU,CxFrCD,GwFqCK,CAAA,CAAN,CxFrCD,KwFqCe,CAAC,IAAI,CAAA,OAAA,CAAS,CxFrCD,GwFqCK,CAAE,EAAM,EAAF,KAAS,CAAC,CAAC,cA4BtG,CAAkC,CAAA,CACV,CAAA,IAElB,CAAA,UAAA,CAAW,CAAA,GAAK,EAAA,CAAA,SACf,IAAA,CAAA,OAAY,CAAA,IAAK,CAAA,EAAK,CAAA,ErG9FF,C4FgFC,MAAA,EAAA,EScsB,GxF5DpC,GAAA,EwF4D6C,EAAK,UxF3DzC,UAAA,CwF2D+D,CAAE,MACtF,MACU,cACe,cAAA,oBAA2C,OAAO,CAAC,CAAC,QACrE,EAAO,CHlEK,A/BbJ,KAAA,EAAA,CAAA,qCkC0FlB,CAA8C,CAC9C,CAAsD,CAAA,iBAEhC,CAAC,iBAAiB,CAAC,EAAO,EAAQ,gBAC3C,IAAI,CAAC,IAAI,CAAC,EAAI,EAAA,CAAI,EAAA,qEAaiB,CAAC,EAAO,IAAI,CAAA,OAAQ,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAE,EAAQ,IAAF,AAuuBlG,GAAA,KAAA,CAAa,CxFjxBH,qN2F5JoC,CjExCC,C6D0BG,eIce,GAAA,QAAiB,CAAC,E/BhDG,CAAC,CAAC,S+ByD7D,CAAA,CAAA,CAAA,oBACJ,CAAA,GAAA,CAAA,EAAA,CAAA,SAAA,EAAA,EAAA,CAAA,CAAA,6DAE2D,CnBpDC,AmBoDA,aAShC,CAAA,CAAA,CAAA,kDAE7C,mDAE2D,GAAA,qEAUN,EnBjDE,2DmBmDqB,CHPC,AGOA,AnBjDA,8DmBuErC,C5BvCC,uB4B0CnB,CAAC,2CAAqD,CAAC,E7B3C9C,iE6ByDX,CAAA,YAAa,CAAC,EAAM,OAAO,CAAC,CAAC,qBACxB,CAAA,EAAA,EAAA,CAAA,WAAsB,C1EjCG,C0EiCC,SAAS,EAAI,OAAO,CAAC,CAAC,A1EjCE,uD0EwC3B,CAAC,CpEtBG,AyCEJ,C2BoBO,IAAI,CAAC,C3BpBD,MAAA,CAAA,I2BoBa,CAAC,OAAO,CAAE,0BAqnCxE,ClF9rCC,ATiBR,oHoErBkD,CAAA,OAAA,qCACuB,wCAI7E,QAAA,CAAA,oG/CvEmB,IAAA,CAAA,eAAA,MAAuB,MAAgB,CAAE,OAAQ,EAAI,CDjBzD,CHGyC,AIcgB,IAAO,CJdf,EIcmB,KAAK,8G2BjBxB,EAAM,QAAA,CAAU,CAAE,MCKM,oKWL1B,uEAejC,QAAQ,CoBG7B,EAAA,CpBHuC,CAAE,CAAE,CoBG7B,CACtB,CAAC,CpBJsD,CAAC,OAAO,CAAC,CAChE,CAAC,6FAYuE,CAAA,2EAWJ,CAAA,GAAgC,2GAWjC,CWbA,CXaM,CAAE,CAAA,+BAEpC,CAAE,CyBaU,A/DAL,AJnBF,A0EANgC,mBhCwJrC,CnB/ID,MAAA,CAAA,wJgCzCyD,6DAOF,CAAE,+CAU3B,cAAe,GAAmC,OAAE,EAAO,GAAG,CAAA,2DAO/C,EAAA,CAAA,CAAA,oCAEO,qG7B9BjC,IAAA,CAAA,EAAA,CAAA,eAAA,EAAA,EAAA,MAAA,CAAA,CAAA,2CAWN,CACd,CAAA,CAAA,CAAA,CAAA,2EAI8C,EAAA,OAAA,EAAyB,CyCXlB,CAAA,CAAA,CAAA,OzCW8B,CyCXT,CzCWgB,GAAA,CAAU,qEAY5E,EAAA,MAAA,CAAsB,CAC5C,GAAA,CACE,EuBhB4D,MvBgBrD,GAAG,CAAO,CAAE,mGAamD,ExBqG7C,CAAA,CAAA,+JiD1IgC,wCAOtC,CAAA,EAAA,CAAA,eAAA,EAAuB,EAAA,CAAA,CAAA,8DAWC,EAAA,CAAgB,CAAE,MAAE,EAAM,GAAA,CAAA,UAMpE,CAAA,CAAwB,CAAA,CAAA,gDACoB,EAAA,CAAA,CAAkB,sDOlC7B,CAAA,CAAA,EAAA,eAAA,KAIJ,EAAA,eAAA,CAAuB,8EAGmB,CdiBC,CcjBI,CjBA1B,EAAE,YiBAuC,wCAGT,4EASpD,CrEGC,ACwB/B,A0BhB6B,AZMlB,AxBgCwB,A8EjDJ,+DAUiC,SAC1C,C1DGG,G0DHC,iBACL,mC/CNC,0CAGT,CAAC,IAAA,CAAA,EAAgB,gCAE7B,aAAA,EAAiB,EZsCoB,IAAA,CYtCZ,EAAA,UAAA,CAAA,EAAoB,CcJmB,CAAC,IdId,CAAG,aAAa,CkD+IzD,gBlD/I0E,CkD+IpE,AlD/IqE,CAC1F,gBAIK,EAAA,EAAA,MAAA,+BAEO,EAAA,EAAA,EAAA,sBACqB,8CAEa,M+CPK,CckBM,QdZ5D,kI3BzC2F,CAAE,CAAE,GAM/F,IANsG,CAAC,AAMvG,CANwG,AAMxG,CAAA,CAAA,CAAA,CAAA,CAAA,4EAOkC,EAAK,aAAA,CAAA,CAAA,GAEnC,OAAE,KAAU,CAAO,CAAE,CACtB,CAAC,2FVbiF,CCJC,ADIA,CAAC,ACJA,uFDoB5D,CAAA,CACD,CAAA,oEAGuC,QAO/D,C0BoGC,CAAA,E1BnGyC,CAAA,CAAA,CAAA,CAClB,CAAA,kCAEW,CAAA,OAAA,EAAA,EAAA,KAAA,CAAA,CAAyB,GAA6B,CoBhBvD,A1C+BM,A2EzBtBoE,wBrDmBE,CAAA,CAAA,CAAA,CAAA,2DAE4B,CgChBE,KAAA,EhCgBO,EAAA,CAAA,CAAS,UAM7D,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,aACG,CAAA,CAAA,CAAA,uCAC+B,EAAA,MAAA,EAAgB,EAAA,CAAA,CAAA,6NmDxBT,CAAE,6BAOpC,OAAA,CAAA,IAAA,CAAA,EAAA,CAAA,OAAA,EAAA,EAAA,CAAA,CAAA,WAAgD,CIlBE,oEJ4BkB,GAAG,CAAO,CAAE,CAAC,A7BXlB,oD6BkBlC,EAAA,CAAA,CAAA,OAuzBvC,IAAA,CAAA,4DI11BuB,SAAA,GAAA,MAAwC,KAAS,CzBkBA,AAAC,CAAA,CyBlBU,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,M5EKI,CAAC,CAAC,G4ECnF,CAAA,CAAA,qCACe,EAAA,CAAA,CAAU,C5DcA,A2DhBC,iECYkB,EAAO,CtDAV,EAAA,CsDAoB,wDAOrC,CAAE,CpFcE,0FoFLhB,oBAAoB,CAAE,IAAW,sCAQhE,kBAAA,CACM,CAAA,CAAA,aAAA,EAAA,GAAA,SACa,EAAA,IAAwB,CAAA,CAAkD,CAAA,CAAE,CAAA,CAAxD,UAEf,IAAA,CAAK,YAAa,C9E2DP,AhB9CQ,CuFoCD,gBOjDmB,2DAKzB,GAAG,CAAA,EAAM,MAAM,EAAG,gBAGxD,EAAA,MAAA,IAAiB,CAAA,QAAA,CAAA,cACA,EAAA,eACqB,C1FGO,C2EwBP,wCe1BQ,EAAE,4BAAA,EAA+B,Ef2BC,CAAA,aAAA,Ce3BsB,iIRnErC,GAAA,CAAA,0CAqB1C,sCAAA,QAA+C,GAAG,CAAA,kFxDlCpB,CAAC,OAAA,+H2DmBgB,CACtE,GACA,CAD8B,AAC5B,CAD4B,AF8BZ,EpB9BoB,CsBChC,GAAE,MAAM,CAAE,EtBDmC,KsBC3B,EtBD6B,CsBC1B,CAAO,CAAE,CACrC,CAAC,aAmBmD,CAAA,CAAE,CACvD,CAAwB,ChFN2B,uDgFQK,EAAwB,YAAA,CAAc,CAAA,+DA6B3D,CAAA,CAAK,EACxC,OAAA,IAAA,CAAA,OAAA,CAAA,MAAA,CAAA,EAAA,CAAA,yBAAA,EACkC,EAA2B,aAAA,EAAgB,EAAY,CAAE,CACzF,OAAO,CADgF,AAExF,CAAC,kNN/DsD,CFD3B,ACIU,ACFrC,GAAA,OACE,EAAO,CDGV,CAAC,CAAA,CCHmB,iK3CSiC,GAAA,CAAA,YAe/C,CAAA,CAAA,CAAA,CAAA,gDAC0C,EAAe,CAAA,CAAI,E2BQlC,6C3BUH,oBAAA,GAAgD,OAAE,KAAU,CAAA,UAatF,CAAA,CAAyB,CAAA,CAAA,iDACoB,EAAe,IuC+BF,GAAA,CvC/BW,CAAE,OAAO,eAmB3D,CAAA,kCAGlB,CAAA,kBAAA,EAAA,EAAA,OAAA,CAA6C,CACjD,CrDZiF,EqDajF,OAAE,ErDb+F,CAAC,CAAC,CqDa5F,ArDb6F,AqDaxF,CAAO,CAAE,CACtB,CAAC,MAaE,CAAA,CAAA,CAAA,CAAA,qBACgB,IAAA,CAAA,EAAA,CAAA,kBAAA,EAAA,EAA6C,MAAA,CAAQ,CrDXA,EqDY3E,CAAC,AN4DA,UMhDuD,CAAA,YAC3C,CAAA,OAAA,CAAA,IAAA,CAAA,EAAA,CAAkB,kBAAA,EAAA,EAAA,OAAA,CAA6C,CAAE,OAAO,AA4elF,WAAA,CAAA,oBKvlB2B,6DAC2B,CAAC,OAAA,6DAEmB,CAAA,OAAA,mMdnBM,OAAA,gHhBQnD,MAAE,CKmHJ,CoChHiD,AgBFA,ApDkHhD,ALnHS,GAAG,CAAO,EAAI,IAAI,CAAC,OAAO,CAAC,CAChE,CAAC,8DA4BoC,CwD7BuC,EAAA,CAAA,QxD6BnB,EAAK,EAAD,IAAO,GAAI,CAAK,CAAE,CAAE,EAAJ,EAAQ,CAAC,OAAO,CAAC,CACrB,CAAC,0EA2BP,OAAA,EAAA,MAAmB,E6BzCC,CAAA,kG8BlBjF,IAAA,CAAA,OAAA,CAAA,UAAA,CAAA,UAAA,GAAA,UAOF,CAAA,CAAA,CAAA,CAAA,yCACqC,EAAK,CAAA,CAAA,oFtClBE,GAAG,CDsBvB,8F0CXkC,ClFHW,AsEiFd,mDY3EC,8DAab,EAAA,OAAA,CAAA,CAAA,0BAEb,iFAea,EAAM,IfyBkB,CAAA,CAAA,CAAA,CezBR,2CAGX,CpCYG,CxB8BU,sC4DzBvD,CAAA,OAAA,CAAA,IAAA,CAAA,EAAA,CAAA,gBAAA,EAAqC,EnD0BG,OAAA,CAAA,CmD1Bc,YAErD,uCACiD,CnEWK,AoFRF,AjBHF,wF1B3DT,6FdAH,GAAA,IAAA,CAAoC,OAAO,oBACpD,IAAA,CAAK,OAAA,kB7B4Cd,MAC5B,EAAA,EAAA,MAAA,CAAA,GAAA,CAAA,AACH,6DA0IL,SAAA,CAAA,CAAA,CAAA,QANoD,SAAxB,EAUW,EAAO,KAAA,EAVM,AAUN,EAAA,CAVM,EAUO,E0ChDA,A1CgDS,IAAA,CAT3D,EAAA,IAAA,CAAA,AAAkB,GAAA,AAAuB,aAAvB,EAAc,IAAI,EAAmB,EAAK,IAAI,GrBpEH,AqBoEQ,gBAa1E,CmD7CG,EnD6CA,CAAA,kBAjBE,AAmBgB,GAnBhB,SAAA,sBAmB6B,EAAU,CgFfD,OAAe,CAAA,CAAA,EhFeK,SAAS,CAAC,CAAA,GAAA,OACjD,KAAA,KAAA,CAAA,EAAA,SAA6B,EAAA,wCA7I3C,EAAA,EAAA,OAAA,CAAA,GAAyD,CAAA,kBAC7C,sBAAA,CACP,CACL,GAAA,CAAU,iBAC8B,IAAI,CkFPM,AlFOL,CmC5BW,AmDGM,6DtF6E5C,EAAA,QACR,EAAA,IAAA,EAAA,MAAA,WACQ,CAAC,QAGnB,CY8CD,CHtCG,ADwBF,AmD1DE,G3D0BG,CAAA,kHAvCmB,CAAA,EAAA,gBAA2B,CAAC,6CAIjB,0CAGT,0EAMQ,MAAyB,CAAzB,EAAA,MAAA,UACrB,CmF0CO,AtCk1BM,CAAC,C3C74BD,AqEqBR,AjFkDN,GUtDO,CAAC,iBA0I5B,SAAA,GAAA,CAAqC,MACnC,EAAkB,EAAA,KACnB,CQSC,CACH,ERVQ,KAAU,EAAI,MAAA,CAAQ,CR9DD,AQ8DE,EACZ,WAAW,CAAC,A8C9EL,CAAC,C9C8EjB,IAAA,KAIN,IAAA,KAAiB,EAAO,OAAO,CAAE,CAAC,6BAEzB,CAAA,EAAA,IAAA,eAKD,CAAA,EAAA,IAAA,CAAA,GACjB,CAAC,G6Bk2IQ,aAAA,CAAA,kY0C/7Ie,EAAA,IAAA,CAAA,UAAA,CAAA,KAAA,8BACe,CzD1HM,GAAA,IyD0HI,CAAA,UAAW,CAAC,KAAA,wBAEvC,CT1IiF,CAAA,EAAA,CAAA,IS0I/F,CAAgB,CAAC,8CAIA,+BACqB,CACtC,C3DhB0F,CAAC,W2DgBzE,CAClB,gBACK,CAAO,CAAE,MAAM,CAAE,IAAI,CAAC,UAAU,CAAC,MAAM,CAAE,MAAM,EAAE,CAAI,CAAE,CAC7D,CAD2D,AAC1D,kCAGa,EAAA,SAAA,CAAA,MAAuB,CAAA,KACzB,SAAU,CAAI,C7BtIuC,A6BsIrC,CAAA,CACzB,CZzI8B,EAAA,CYyIpB,CAAE,MAAM,CazIiE,AbyI/D,IAAI,CAAC,E7D3IU,Q6D2IA,CAAC,MAAM,CAAE,CAC/C,CAAC,G7D5IgD,0C6DiJlD,IAAI,CAAW,CZxI0C,CAAC,AAAC,CAAA,yEY6ItC,ClBtIkB,GAAA,CkBsIlC,IAAI,CAAc,yGA1GO,C9DQyD,CAAA,kB8DLlD,CrDToB,AiDrBA,CI8BQ,CxDgBC,AgD/CA,CAAA,0BQkC9D,EAAA,CAAA,EAAA,2EAMmC,IAAA,CAAxB,IAAI,CAAqB,KAAK,CAAC,CAAC,kBAGnC,IAAA,mCACuB,eACH,CAAC,EAAM,CUxBK,AtGhBiB,CsGgBhB,AtGhBiB,A+BgBzD,U6DwB8C,CAAC,CAAC,G7DvBxC,CqE0C4C,ERjBrD,MAAA,IAAA,GAAA,CAAA,wBAAA,EAAA,EAAuD,IrEtBY,QqEsBA,CAAA,CAAE,CAAC,CAAC,6BAGvD,C5F1CO,AoBgBN,CAAA,OAAA,CAAA,EAAA,aAAA,CwE0BkC,OAEjD,MAAA,IAAA,GAAsB,CAAA,yBAAA,EAAA,EAAkC,aAAa,CvC/BQ,CuC+BN,CAAC,CAAC,GAEvE,eAAgC,CAAhC,AAAiC,AZzBI,EYyBrC,IAAA,cACoB,CAAA,C9DOX,yCAAA,E8DPwD,EAAQ,Ge3BK,CAAA,CAAA,Cf2BC,CAAC,CAAC,+BAG7C,C5FzCK,gB4F2CzB,IAAI,CnDZKG,C+DqDK,oDZpCS,C7DXO,AsE6BJ,ATlBF,QACtB,MAAA,CAAA,EAAA,YAAyB,CAAC,CAAC,I9DSqB,C0C1CZ,A1C0Ca,C0C1CZ,CAAC,uCoBmCX,EAAM,YAAY,CAAA,CAAE,CAAC,CAAC,AAErD,iBAAiB,CAAC,uDAE/B,CAAA,0CAOS,IAAA,CAAA,GAGtB,EAAA,GAAA,wBAGgB,CACZ,MAAM,IAAI,GAAA,6EAIJ,IAAA,GAAgB,CAAA,yCAA0C,CAAC,CAAC,kBAE3B,G9DU6C,C8DV7C,OAClB,AA4M3B,SAAS,AACP,C/EbyB,AoBsGR,A2DzFC,C5CpNN,C4CqN0B,C/EblB,O+EepB,C/EEC,M+EFM,MAA6B,KvElOH,EAAO,IAAA,EAAM,SAAS,CAAC,CyDiFD,CciJhD,SAAA,CAAA,WvEnTwB,gBuEmTxB,sEvElUD,YAAA,EAAA,IAAA,wBAGyB,CAAA,GAAA,CAAA,IAAmB,mBAGvC,MuE6Tb,CAAC,CAjN0B,EAAA,GAAA,IAAwC,CAAA,GAAA,oBAC3D,CAAA,GAAkB,E5FjCwC,qB4F4ElB,WAC7B,IAAA,CAAA,GAAA,KACf,GAAA,CAAA,EAAA,IACqB,2BAAL,CpBrEC,AnD+DM,auEQjB,CAAA,0EAAA,EAA6E,EAAM,C5C6BnE,G4C7BmE,CAAA,CAAM,CAC1F,CAAC,UAEO,IAAA,CAAA,GAAgC,EAAM,GAAD,KAAS,CAAA,IAAA,CAAC,OAIpD,EAAA,IAAA,mCAEJ,C5F/EG,C6BkFC,M+DHW,CAAC,IAAI,CAAA,EAAO,CvEDX,GuECe,CAAC,CAAC,CShBL,STmBzB,8BAA+B,KAC5B,EAAA,EAAA,MAAA,CAAyB,EAAA,YAAkB,CAAA,CACjD,GAAA,CAAK,C1B4MG,C0B3MN,MAAA,IAAA,GAAsB,CAAA,wBAAA,EAA2B,EAAM,EpB1CpC,UAAA,CAAA,CAAA,EoB4CrB,CxE/DO,GAAA,EwE+DM,EAAO,IAAI,CAAC,QAErB,CAAA,eAAA,AAA+B,mBAA/B,EAA2B,CxE/DK,GwE+DD,mBAEf,iBAAA,AAA6B,kBAAkB,CAA/C,EAAoB,IAAI,GjFwCK,AiFvC/C,EAAA,OAAmB,EAAE,CAAC,A/ErDM,E+EsDnB,EvEMQ,AQOE,KAAA,CAAA,EAAA,I+DXZ,OAAA,CAAQ,CzBlEkE,GAAA,CyBkE7D,CvESO,SuEL/B,E/DoBI,EAAA,6B+DpB+B,CACjC,C/EnDC,GAAA,E+EmDc,EAAS,CzBlEH,KyBkES,CAAC,EAAM,YAAY,CAAC,CAAC,YACtC,QACW,E5F/EG,sBAAA,EAAA,EAAA,Y4F+E0C,CAAA,CAAA,6BAG7D,EAAA,EAAA,OAAA,CAAA,EAA+B,EScO,WTdM,CAAC,CAAC,AACpD,CSa0D,ETb1D,CAAA,EACE,G/ExCe,AqDgQJ,G0BxNL,IAAA,GAAA,CAAA,yBAAA,EAA4C,C/ExCa,CAAC,A+EwCR,C/ExCS,CAAK,CAAC,CAAC,S+EwCH,CAAA,CAAE,CAAC,CAAC,G/EvCvE,A+EyCY,gBAAZ,EScM,AlC/EA,AyBiEE,IAAI,CACd,MAAM,IAAA,GAAA,CAAA,0CAAA,EAA6D,EAAQ,IAAI,CAAL,AAAK,CAAE,CAAC,CAAC,EAE7E,IAAI,EAAI,CvEcS,CuEdH,KAAK,CAE7B,UAEG,yCAA0C,CAAC,E1BgOI,E0B/N5C,EAAA,EAAA,MAAwB,CAAC,EAAM,YAAY,CAAC,CAAC,mBAE3B,CAAA,wBAAA,EAA2B,EAAM,G3DwBH,A2DxBE,SAAa,CAAA,CAAE,CAAC,CAAC,iBAEpC,CAAC,AxEvDJ,oBwEwDhB,CxEvDD,CAAA,EAAA,KAAA,AwEuDgB,OAGnC,0CAEQ,EAAA,EAAA,MAAwB,CAAC,E1BgOI,Y0BhOc,CAAC,CAAC,GAC/C,CAAC,QACG,E1B+NM,E0B/NF,CzB/DC,CnBmHK,CAAA,C4CpDM,wBAAA,EAAA,EAAiC,YAAY,CAAA,CAAE,CAAC,CAAC,A1BgOvB,G0B9N9B,qBAAa,CAAC,IAC1B,C5FrFC,CAAA,EAAA,O4FqFuB,EAAE,CAAC,EAAM,GAAD,UAAc,CAAC,CAAC,MAEpD,MAAA,IAAU,GAAY,CAAA,E1BkOA,GrDtPgB,oBAAA,E+EoBY,EAAM,GAAD,UAAc,CAAA,CAAE,CAAC,CAAC,GAEtD,E/DmCM,gB+DnCY,CAAC,AAApC,EAAA,IAAA,8DACoE,EAAQ,IAAI,CAAL,AAAK,CAAE,CAAC,CAAC,AAExF,CxElDK,CAAA,IAAA,EwEkDW,EAAM,C5CwDK,I4CxDA,AAC7B,CAAC,I1ByOQ,8B0BrOT,IAAI,CAAA,GAA4B,EAAM,GAAD,KAAS,CAAA,IAAA,CAAC,OAK5C,GAGR,OAAA,aAAA,AAAoB,EAAA,EAAA,KACb,EAAmC,EAAA,CACnC,EAGA,EAAE,CACR,GAAW,cAEN,EAAA,CAAG,QAAS,AAAC,YACS,KAAK,C/DqCC,C+DrCC,CAC5B,EACF,CxEpDO,CAAA,OwEoDO,CAAA,SAEA,CAAA,YAIX,CAAA,MAAQ,aAEF,QADJ,EACc,UAAW,WAGhC,EAAU,MAAM,CAAA,oBAGD,AAAC,C5F/FC,G4FiGjB,C5F/FG,CmEkCK,CAAC,CyB6DJ,IAAM,E/DuVA,GhB5WO,CmC4EH,AmBpHQ,AyB6DN,IAAI,UAAW,CAAC,aAGd,CAAC,C/DwVC,A+DxVA,kBAGN,AAAC,mBACT,GACc,KACZ,MAAM,CAAC,C/DwVG,C+DtVnB,GAAU,MAAM,CAAG,CACrB,CAAC,CAAC,OAGM,I/EnBQ,c+E6BL,CAAE,G1B2PO,E0B3PF,CADA,EAAA,KAAA,SACe,CAAK,CAAE,C5C3OyB,A4C2OxB,EAAH,CAPrB,MAAA,KAAA,EAAkB,MAAM,GAE5B,IAAA,QAA6C,CAAA,EAAU,IAC5D,EAAU,IAAI,CAAC,EAAN,OAAQ,OAAO,EAAE,CAAM,CAAE,CAAC,CACpC,CAAC,CADgC,GAC5B,CAAC,AAAC,GAAW,CAAF,CAAJ,AAAK,AAAS,CAAE,CAAd,CAAS,CAAC,CAAC,CAAQ,CAAE,EAAO,GAAF,CAAM,EAAE,CAAK,CAAE,CAAC,AAAE,CAAD,AAAG,CAAP,IAAY,MAAE,EAAW,IAAI,EAAE,CAAI,AAAZ,CAAc,CAAC,CAAH,AAAI,CAAC,gBAMhG,IAAA,CAAK,KAAK,EAAE,A/DmVF,E+DlVD,MAAA,KAAA,EAAkB,KAAA,CAAA,CAAU,gCAUnC,IAAI,CAAC,IAAI,gBACM,CAAA,G3DyF6B,CAAA,Q2DxF7C,C5CrNK,CkBsdH,MAAA,I0BjQkB,C3D0FZ,EAAA,0D2DzFN,CACT,CAAC,CACF,kFG3UuB,EAAA,YAAA,CAAwB,CAC1C,CvBNuC,CWCoC,CAAA,OYMzE,EDLgC,GCKtB,CAAO,oC3BZG,CAAA,+DAEuC,CAAA,qFU6CO,CAAA,OAAA,0BACC,IAAI,CAAC,OAAA,gFAkCH,EAAA,CAAA,IAGvE,C7DjEmF,U6DiExE,CAAC,kBACW,YAA2B,CAA3B,EAAA,MAAA,uEAuCY,EAAU,CAAE,ChDrFS,iDgD0F3C,kBACyB,6GAqBhB,SAAW,CpChHC,CAAC,KoCgHO,GvCxFK,EAAA,kBuC8FjD,CAAA,CAAA,QAEO,IAAA,CAAA,OAAA,CAAA,SAAA,CAAA,MAAA,CAAA,EAAA,GAAA,WAAA,CAAA,GAEsB,CclFwD,EAAA,EdkFpB,C/B3FrD,U+BkGZ,CAAA,CACA,CAAA,CAAA,8BAEkD,CAAA,OAAA,CAAU,ChDhFV,CgDgFgB,UAe7D,CAAA,CAAA,CAAA,CAAA,QACE,IAAI,CAAC,OAAA,CAAA,IAAA,CAAA,EAAA,CAAA,WAAA,EAAA,EAAA,OAAA,CAAkD,CAAE,OAAO,CAAC,CAAC,OAczE,OAAO,IAAA,CAAA,OAAA,CAAA,IAAA,CAAA,ahD3F8F,CACpG,CAAC,MgD0FK,QAAgD,GAAG,CAAO,wBAoyM3D,WAAA,CAAA,4EgBx+MY,EAAA,MAAA,CAAgB,CAChC,GAA4B,QAAQ,CCK7B,EAAA,CDLuC,CAAE,CAAE,IAAA,CAAK,OAAO,CEGzC,AFH0C,CEIhE,AFHA,CAAC,AEGA,iGUIqD,CAAA,wFAQ/B,CAAA,EAAA,CAAA,SAAA,EAAA,EAAyB,CHuBoB,CzEed,AyEfc,CzEeb,IAAA,CAAA,CAAA,8C4EnB3B,CAAA,SAAA,EAAA,EAAA,SAAA,CAAA,CAAiC,C3EYA,W2EZkB,CAAE,CAAC,CAAC,gBDgBiB,I/E1EtE,MAAU,oDAEoD,aAAlB,EAAO,MAAA,aACjE,CAAA,sCAEY,yBAGK,CAAA,yCAAA,CAA2C,wBAK1D,kF2CKQ,CAAA,CAAA,CAAA,8DAGgD,CRRA,8GQuBlD,CAAA,8CACqB,EAAA,cAAA,EAAA,EAAA,CAAA,CAAA,iCAEJ,iBAAmB,GAAS,IAAF,GAAS,CAAC,CAAC,2GAcO,OAAA,CAAS,CAAA,0C+BgBmH,CAC/M,CAAC,oD/BHE,EAAA,MAAA,IAAA,CAAA,MAAA,CAAA,EAAA,8BACsC,EAAA,CAAA,+CAWT,CAAA,mCAE7B,CAAA,eAAA,EAAA,EAAA,cAAA,EAAkD,EAAO,KAAA,CAAA,CAAQ,CACrE,GACA,OADoC,AAClC,CADkC,CAC3B,GAAF,AAAK,CAAO,CAAE,OAAO,CAAE,GAAa,CAAC,CAAE,OAAJ,MAAiB,CAAE,eAAe,CAAE,CAAE,GAAS,IAAF,GAAS,CAAC,CAAC,CAAE,CACrG,CAAC,cAWa,CAAA,CAAA,CAAA,8FAOkC,gBAAgB,CtCjBzD,gBsCiBuE,CtCjBzD,sDsCsBiC,CACnD,EACA,oBACA,CxCgCmB,CAAC,EwC/Bf,CAAA,6CAML,CrE1CG,AoBcF,AT6EA,CAAC,AkBnBE,AI0QA,EAAA,oBoCvSkB,yBAGlB,CAD2B,CAC3B,EAAA,cAAsC,cAEN,OAAO,CAAC,CvCQW,EuCRR,CAAC,6CAER,EAClC,CAAA,MAAW,C6BHa,AhC03BK,GHp4BwB,CMYL,yDAUjD,6BAWL,cAAA,CAAA,CAAA,OAEF,C6BH8B,A7BGzB,CAAA,QAAA,EAAY,EAAE,C6BH8B,A7BGiB,CACpE,CAAA,CAAA,IAEa,SAAA,GAA2B,AAA3B,CAA4B,AgCuBJ,ChCvBxB,MAAA,6HAEuG,CACjH,CAAC,AAME,EAAA,KAAA,GAAA,CAHA,AAG4B,GAHK,gBAAA,EAGkB,EgCoBE,CxEaf,CwEbe,IAAA,ShClBvC,OAAA,sBAEqB,yBAKlC,CpC6CD,GAAA,KoC7Ca,EAAA,eACc,IuBgCM,CvBhCD,CAAA,MAAO,CAAC,CAAE,IAAI,CAAA,EAAQ,QAAA,YAAqB,CAAE,CAAE,UACjE,EAAA,EAAA,OAKd,EAAA,MAAA,GAAkC,CxCqCsC,EkCtDnC,CAAA,CAAA,GMiBgB,GAAG,CAAC,CGrCzC,CAAC,EToB4C,CAAC,CAAC,MMiBM,CAAC,CAAC,EAGvE,GAAoB,8KN5JgB,iBAAmB,GAAA,yBAU7D,CAAA,CAAA,wEAG6D,OAAA,EAAA,EAAgB,CAAE,CAAE,G5BQI,CAAC,CAAC,0BYPI,CACxF,CAAC,0EgBQiC,sFAIb,gBAAkB,eAAe,CAAE,C6BsIpC,A7BtIsC,GAAA,QAAiB,CiBF1C,AjBE2C,CiBF1C,ejBYb,CAAA,oDAE6B,EAAA,MAAA,CAAqB,CAAA,GAA+B,aAE7F,wDACkE,CAAC,I3CJI,yD2CoBhE,CAAC,MAAA,CAAA,EAAA,CAAA,eAAA,EAA6B,ChCPlB,CAAA,OAAA,EAAA,EgCOiD,CAAE,CAAA,gDAEzB,CYQE,AZRA,CAAE,CcqCiB,EAAA,QdrCA,CAAC,AYQA,SZD3E,cAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,6DAMyC,C1CWL,S0CHpC,KAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,+HAS2E,GAE9E,CAAC,KAFsF,GAI3E,kBACqB,QAAA,CAC9B,CpDiEwC,CAAA,kDoD5D5B,C/D9B2B,C+D8BzB,CjCkB+B,AiClB9B,QAEa,UAEjB,CjCiBK,KiCjBC,wBAEX,EAAA,0BAEyB,iBACW,CAAC,KAEvC,IAAA,EAAuB,EAAa,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,sBAAsB,CAAC,CAAC,YAEtD,CpDgEO,QAAA,EqCArB,CAAA,MAAA,Se5Db,CMUS,AWzBF,A3DsDA,A0CvCN,AACH,SAJkC,CAAC,C/D5BS,sD+D+C9C,OAAO,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,OACM,MAAA,IAAA,CAAA,OAAA,CAAA,KAAwB,CAAC,MAAA,CAAA,QAAqB,QAAA,YAAqB,CAAE,ApD+E9C,CAAC,AoD/E+C,yBACpD,QAAS,EAAS,EAAE,WAKpD,CMmBD,aAAA,CAAA,CNjBH,ClDXgC,AAAE,CAAD,AAAC,CAAA,CAAA,KkDc5B,EAAA,MAAiB,C3CjBG,GAAA,CAAA,MAAA,CAAA,E2CiBwB,EAAM,EAAF,mBACpC,IAAA,CAAK,EAAe,EAAA,EAAA,CAAa,cAQ1B,CAAA,CAAA,CAAA,uBAGA,CsC0BH,ArD0DE,AepFI,SACrB,IAAA,CAAA,OAAA,CAAA,UAAA,CAAA,EACD,CAAA,eAAA,EAAA,EAAiC,MpD8ET,CAAA,EoD9EmB,EAAM,IAAA,IAAA,CAAU,CAC/D,EpD6EoD,CoD5EpD,CAAE,GAAG,CAAO,CAAE,QAAS,GAAa,EAAG,aAAa,CAAE,eAAe,CAAE,CAAE,GAAS,IAAF,GAAS,CAAC,CAAC,CAAE,CAC9F,CAAC,CAEL,wEY5J4C,IAAA,CAAA,OAAA,8FAOE,yDAGkB,EHjB/B,CAAA,QGiBgD,8DAQhC,EAAA,CAAA,CAAA,iCAEJ,iBAAmB,GAAS,QAAQ,CAAC,C8BXC,U9BmB3D,CAAA,CAAA,CAAA,CAAA,CAAA,kDAI2C,uDAGP,EAAI,GAAA,QAAiB,CAAC,QAQ/E,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,iDAGiD,GAAA,sBAGtC,GAAA,4CAAmE,4IAmBzD,CAAA,CAAA,CAAA,CAAA,CAAA,QAId,IAAA,CAAA,OAAA,CAAA,UAAA,CAAA,EACD,CAAA,eAAA,EAAA,EAAA,OAAA,CAAA,CAAA,GAAA,0BAKQ,2CAC6C,CAAE,IAAW,QAAQ,CAAC,IAiZrF,GAAA,KAAA,CAAA,yGDnf+F,IAAI,CAAC,CHJI,CAAC,KGIE,CAAC,CAAC,CAAC,mDAOnE,EAAA,CAAS,CAAE,cAQ1B,CAAA,6CAEiD,YAAY,CuBNN,AjEAA,ALAE,A0EgDF,E1EhDE,0M+C2BL,C8BgDC,AnBpDA,AXIA,6BAQzE,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,uCAEa,EAAA,MAAA,CAAe,CAAA,GACG,MAAE,EAAM,GAAG,CAAO,CAAE,CAAE,IAAI,CAAC,OAAO,8F3CpD7B,CAAA,OAAA,CAAS,aAAA,CAAA,EAC7B,GAAG,CAAA,kBAEb,CAAA,eAAA,CAAA,EAAA,EAAA,EAA2C,uBAejD,gBAAA,CAAA,CAAA,CAAA,CAGJ,EoDCsC,ApDDF,IAAI,CAAC,OAAO,CAAC,aAAa,CAC9D,EAAoB,GAAG,CAAA,mEAKA,YACrB,CAAC,GiBqB6C,gBjBtB1B,CAAC,MAAA,6HAKvB,CsCWsF,GtCXlF,CAAiB,eAEoB,EAAA,MAAQ,CAC3C,EAAA,GAAA,IAAA,CAAA,GAAA,IAAA,IAAyC,IAAA,CAAvB,IAAI,CAAoB,EAAY,0BAC1C,IAAA,CAAA,GAAA,IAAA,IAAuB,IAAA,CAAvB,IAAI,CAAoB,EAAY,mBAAmB,CAAC,CAAC,qBAClC,IAAA,CAAvB,IAAI,CAAoB,EAAY,QAAF,IAAc,CAAC,CAAC,0BAI1D,4FAM0B,qEAKK,oCAMnC,EAAA,EAAA,KAAA,CAAA,KAAA,GAAA,CAAA,GAAA,EAAA,UAE2B,CAAA,OAAA,EAAA,SAAwB,CAAA,GAAA,iBAItC,CAAC,CdEmB,CAAC,AwFAA,QAAA,GAAA,MAAA,CAAA,IAAA,CAAA,EAAA,OAAA,CAAA,S1EDC,IAAK,UAAA,GAAA,MAAA,CAAA,IAAA,CAAA,EAAA,gBAIT,EAAA,CAAA,EAAA,EAAsB,CAAA,EAAI,EAAA,CAAS,CAAC,AqE6CA,ArE7CE,CAAD,AAAC,EAAG,EAAS,CAAA,EAAI,CqE6CP,CrE7CO,CAAS,CAAC,EqE6CE,oBrE1CvE,CXDG,CAAC,OWCK,CAAA,MAEvC,EsCkB6C,CtCjB3C,CsCiB2D,ItCjBrD,KsCiB+D,CtCjBzD,CsCiB2D,AtCjBzD,KAAM,MsCiBgE,GtCjBvD,CAAE,EACjC,EACA,CAAC,EADI,MACI,CAAC,CACX,CAAC,6FAUI,CyClBiB,GzCkBb,cAAA,MAAoB,CAAC,EyDKtB,kCzDD6B,oGAaxB,CAAA,yBVcwE,MUb7C,EVa6C,IAAA,gLUXiF,CACpK,CAAC,aAIa,CAAgB,CAAE,CAAY,C6DOa,K7DNvD,oCACmC,UAGlB,GAAA,CAAI,CEwDL,kDFtDsB,GACG,EAAA,CAAA,UAIhD,CAAC,2EmCsOU,GAAQ,iBAAiB,cAClC,EAAe,GjCoCG,MuB1U2D,CUsSjE,WAA+B,IAAI,SAC/C,EAAU,GAAQ,EAAX,EAAU,eAAoB,CAAC,EAAI,IAAI,eAC9C,EAAgB,GAAQ,IAAD,IAAV,eAAkC,CAAC,EAAI,IAAI,CACxD,GAAG,EAAI,CACU,CADV,AACU,CAAE,CAAA,6DAmnB8B,IAAA,WAC/C,CAAA,IAAA,GAAA,IAAA,8EAGoC,YACnC,CAAc,IAAA,GAAA,IAAA,kBACR,CAAoB,IAAI,GAAA,IAAA,yBACK,6BACY,CAAC,CAAC,CkCp2BR,sDlCs2BY,2BACZ,CAAC,sBACb,cAC3B,CAAA,IAAoB,CpC/2BH,EoC+2Be,IAAI,+CAEZ,GAAc,IAAA,eACrC,CAAA,IAAA,GAAA,IAAA,yBAC+B,C7Cr3BX,AUbI,AsE6BJ,EAAA,InCq2BiC,iGAloBnD,IAAA,GAAA,yGAKF,EAAA,kGASO,uBAAuB,EvDzLF,qBuD+LH,GAN+B,CvDzLH,AuDyLI,KHzPL,CAAC,CAAC,GGgQ7C,EAAA,OAAA,EAAmB,GAAA,eAAA,CAClC,CWhKK,AerFJ,AZtBA,AhFZA,GAAA,CAAA,MkEuRU,CAAA,EAAA,MAAA,EAAA,wDAKK,EAAA,QAAgB,CAAA,yBAAA,IAAgC,CAAC,EAAA,GAAA,GAAA,cAC1B,CvDtLS,2BAAA,IuDsLwB,GAAA,sBAE5C,YAAA,iBACV,EAAA,UAAA,EAAsB,CAAC,CrDnQG,AqDmQF,aACrB,CmCzNH,InCyNQ,EAAA,cjD1YxB,IAAA,OAAA,0LiD2YF,IAAA,CAAA,GAAgB,GAAoB,CAAhB,CAAC,CAAe,CAAA,CAAC,KAEhC,QAAQ,CAAG,OAEX,MAAA,CAAA,UAAA,OAAA,EAAsC,EAAA,+BAC1B,CAAG,AgC1PA,AlD2EF,MkBgLd,CAAA,OAAA,CAAA,oBACc,CAAA,iBAsBlB,CmC5NC,MnC6MK,IAAA,IAAA,CAAA,WAAA,CAAA,sCAEiB,CClRG,WDmRZ,IAAI,CAAA,UAAA,SACP,IAAI,CAAA,OAAQ,ClBpKG,AkBqKxB,OAAQ,C7CzMG,G6CyMC,CAAC,CmC5NH,KAAA,CnC6NV,SAAU,CMrPG,AxEvCA,GkE4RC,CAAC,CvD1KK,OuD0KG,OAChB,IAAI,CAAA,KAAA,CACX,aAAc,IAAI,CAAA,YAAa,CAC/B,ClE3RG,MkE2RK,IAAI,CAAC,MAAM,CmC5ND,AH9BM,ahC2PV,IAAI,CAAA,YAAa,CAC/B,QAAS,IAAI,CAAA,OAAA,eACE,IAAI,CAAC,aAAa,OAIrC,CAAC,AmC5NA,A1FyDA,AkB5BA,eqCyMC,OAAA,IAAW,CAAA,QAAS,CAAA,YAAa,CAGzB,CnBxLT,C1BlBG,c6C0MsB,CAAE,CvDpKT,OuDoKe,CAAA,MAAA,CAAO,CAAmB,CAAA,QAI5C,YAAY,CAAyB,CAAA,QAC5C,GAAa,EAAG,CgC5Qa,ahC4QE,CAAA,OAAA,EAAU,IAAI,CAAC,MAAM,CAAA,CAAE,CAAE,CAAC,CAAC,AACnE,CADoE,AACnE,AAES,EvDnKN,aAAA,CAAA,CAAA,QuDoKK,ArD3JL,SAAoB,CAAW,CAAA,EAA2B,CAAA,CAAA,MAI9D,MAFM,EAAA,aArF2B,WAEtB,KAAA,IAAA,EAAA,gBAAA,EAA0E,AAA1E,SAAmF,EAAnF,AAAqF,CAAC,MAAtC,EAAK,EAAD,IETG,UFSc,OACxE,AAAI,UAAA,0EAGZ,GAAA,KAAoC,IAApC,EAAA,eAAA,EAAmD,AAAgC,EgBkD9C,CAAC,MhBlDsD,EAAE,CAAC,MAArC,EAAK,EAAD,aAAgB,OACtE,AAAI,UAAA,4EAGH,SAAA,OAAA,EwF0CuC,AxF1CvC,KwF0CuC,IxF1CvC,EAAA,OAAuC,EwF0CA,AxF1C4C,AwF0C5C,UxF1CsD,EwF0CtD,AxF1CwD,CAAC,MwF0CzD,EAAA,OxF1CuC,OAC3E,COhCD,SAAA,yCPmCU,OAAO,EAAA,GAAa,COjCT,CAAC,KPiCe,SACpB,aAAL,E2D1FoC,U3D0FhB,EAAA,OAAY,EAAiC,A2D1F7B,Y3D0FyC,EAAE,CAAC,AAAhC,EAAK,EAAD,KAAQ,OAC3E,UAAA,2EAGK,CgBoDC,ATrFF,4BPmCL,COhCG,EPgCC,GAAY,CwF6CC,CxF7CI,MAAM,C2D3FG,A3D2FF,CAC/B,CADiC,CAAC,IAClC,UAAoB,uCAER,EsDzCJ,A/CUQ,IAAA,KPiCd,EAAY,EAAA,CAAW,EAAO,CAEpC,AAFqC,AO9BA,EPgCrC,GAAA,MAAA,IACA,CAAA,AAA2B,CoB8CD,WpB9C1B,OAAA,EAAgB,MAAM,EqDsPF,AjCxMM,CAAH,AiCwMF,ErDtP4B,EAAK,EAAD,KAAO,CAAC,EAAE,CAAC,YAM9D,CsD5CC,AlCyFA,CpB9CC,AsD3CA,CAAC,CtD2CI,WAAA,EAAA,EAAoB,WAAW,E2D7FI,A3CoJsB,EhBvDtB,CgBuDyB,EhBtDrD,E2D9FmC,A3D8FnC,WAAgB,CAAC,AACtB,QAF0D,CAAC,GAE9C,IACH,EADS,AO7BX,CP6BY,AqD8Pd,A9C3RG,CAAC,C4B2GG,EnC7EI,CAAG,UAAY,YAElB,GmC6ED,QnC7EY,CoBmDH,ApBnDI,sBAG0B,SAAS,gCAChE,AAAI,UAAU,qDAGhB,EACJ,AAA0B,SAA1B,EAAA,SAAA,CAA0B,AACvB,CAAA,GADuB,CACvB,CAAA,EAAA,eAAA,EAEC,GAAA,SAAA,CACF,CAAC,CAAA,EAAM,SAAS,OAEb,gBAC0C,oBAAnB,cAAc,CAAiB,CoBkDf,AAAgB,AjCxHV,CasEc,cAAA,CAAA,GAA0B,CbtET,CAAC,YasEsB,CAExG,KmC2E4B,CACrB,InC5EI,mBAEwB,WAAjC,OAAO,EAAA,gBAAqB,CAAiB,CAAC,CAAC,EAAK,EAAD,cAAiB,CAAC,AAAE,CAAD,EAAU,KAAD,WAAiB,CAClG,YAAa,EoBmDF,ApBlDX,QAAS,EsDrCI,AtDsCb,gBmC+E0C,WnC9ExC,OAAO,EAAA,eAAoB,CmC8Ea,EnC9ES,CmC8ET,cnC9EwB,CAAC,AmC8ES,AnC9EP,CmC8EQ,AnC9ET,EAAU,KAAD,UAAgB,gBAC7E,CAAC,CAAC,EAAK,EAAD,MgB8DO,MhB9DQ,WAC1B,KAAA,IAAA,EAAA,SAAA,CAAwC,GAAS,SAAS,CAAC,AAAE,CAAD,CAAM,SAAS,qCACtC,MAAM,CAAC,AAAE,CAAD,AmC6EJ,EAAA,MnC7EoB,GmC6EH,cnC3EnE,AAA2B,kBAApB,EAAA,eAAoB,CAAiB,CmC4EU,CnC5EL,eAAe,CAAC,AAAE,CAAD,EAAU,KAAD,UAAgB,SACpF,YAAA,OAAA,EAAA,OAAA,CAAqC,EAAK,EAAD,KAAQ,CAAE,AAAD,CbzEC,AayEA,EAAU,OAAO,kBAE1C,CgB4WiB,CAAC,gBhB5W5C,EAAK,gBAAA,CAAiC,EAAI,EAAA,cAAiB,CAAC,AAAE,CAAD,EAAU,gBAAgB,6BAGrF,gBACgB,qBAAA,aAAA,CAA+B,EAAK,EAAD,WAAc,CAAC,AAAE,CAAD,EAAC,aAAsB,WAChE,CoBqDD,CAAC,AiC6ME,gBrDlQrB,EAAA,SAAA,CAA+B,EAAK,EAAD,OAAU,CAAC,AAAE,CAAD,EAAU,KAAD,IAAU,MAEzD,mBAAd,EgB6WF,AhB7WO,IAAI,CAAkB,Cb3ED,CAAC,Aa2EK,EAAD,EAAK,Cb3ED,Aa2EE,AAAE,CAAD,uBAEd,kBAA5B,EAAK,kBAAkB,CAAiB,EAAK,EAAD,gBAAmB,CAAC,AAAE,CAAD,EAAU,KAAD,aAAmB,CAE1G,CAAC,CAI6C,GAKd,YAAY,CAAC,MAAhC,EAAA,MAAc,QACN,Eb/EI,IAAA,KagFJ,GACR,GAAQ,EAAQ,CgB2Wb,KhB3WmB,CAAC,EAAE,GACzB,EAAQ,MAAA,MAIb,EAAiB,EAAE,CoB8GX,ApB9GY,GAEP,GgBuWC,OhBvWhB,OAAO,GAA4B,AgBuWnB,CAAkB,G7Brbe,Aa8EV,GgBuWvB,QhBtWX,OAGH,EAAA,EAAA,CAAA,EAAsD,KqDgRG,MrDhRQ,CAAC,CAAC,AACnE,EAAyC,EqDgRF,KrDhRS,GAA/B,GAAmC,EAAQ,EqDgRxC,GrDhRuC,SAAe,CAAC,UAElE,GACK,ImC3NgF,AnC2NhF,CmC3NiF,AnC2NjF,CmC3NkF,CnC2NlF,EAGpB,EAAA,IAAA,EAAkB,CAAC,CACR,IAAI,CAAC,CsDpCD,CtDoCS,CgBsWL,GAAA,EhBnWnB,CmChNG,GnCgNG,EAAA,IAAkB,gBACf,EAAI,EAAA,EAAO,C+EiBD,CAAC,A/EjBS,MAAA,CAAA,EAAU,CAAC,CAAE,CAAC,QACpB,CAAC,CAAA,AAEtB,CAAA,EAAA,SAAqB,EAAiB,CoByGD,KpBzGO,CAAC,AAApB,CAAG,AmCrMsB,CnCqMrB,EAAA,EAG7B,CqDiRG,CAAC,CACH,ErDhRC,gBA5R4F,CAChG,CAAA,CAAA,CACyB,CACzB,CAA2B,CAAA,CACT,CAAA,CACM,CACxB,CAAoC,CACpC,CAAkC,CAClC,CAA8B,CAC9B,CAAwC,CACxC,AoB4TkB,CpB5T8B,CAChD,CAAkC,CAClC,CAAwC,CACxC,CAAyB,CACzB,CAAoC,CACpC,CAA8B,kBAEpB,gDAK+D,CAAC,QAErD,GAAA,CAAA,qFAMG,qCAQU,6CAI3B,UAAA,GAAA,GAAA,sBAC+B,SAC9B,aAAA,KiB4BK,IAAA,kCjBnBU,mBAE4B,GmEJK,GnEIE,EqFgBa,CAAA,qCrFTlC,8EOuHb,EPvHa,COuHL,CAC3B,EAAA,UAAA,AAAgC,CAAC,I+CPI,E/COrC,GAII,EAAK,WAAW,EAAA,EAAQ,CwEoDL,C5F9FL,SAAA,CAAA,QAAA,EoB0CkC,C4BwGP,CAAA,W5BxGsB,CAAC,C4BwGP,O5BxGe,CAAA,GP5H5B,CAAC,AO4HgC,CAAC,IP3HxE,OAET,EAAA,EAEE,EAAA,EAAgB,GAAS,OAAA,CAAS,CmCwEmB,CnCxEV,MAAO,iBAGlD,UAEoB,EAAA,GAAA,OAAA,CAAuB,EAAS,QAAS,kCAGZ,IAAM,CAAC,IAG1D,EAAA,EAAA,SAEa,kBAKS,CqDmQD,ApC5OA,YjBvBY,GAAA,MAAc,CAAC,0BAM3B,MAAA,CAAS,CgB4DD,AhB5DE,CAAA,EAAA,IAAW,CAAA,MAAA,KAAgB,KAAK,CgB4DD,AhB5DU,CAAE,CAAC,CAAC,EmCsFP,CAAC,CAAC,CAAC,AnCtFA,sBAItE,EAAA,OAAA,IAAA,CAAA,aACqB,CAAC,GAAA,iBAGkB,GAAQ,EoByEN,KAAA,CAAA,MpBzEqB,KAAK,CAAC,CAAC,AAAE,CAAD,KAAO,CAAC,GAEjF,EAAA,CAFuF,CAAC,CAAC,AAEzF,CgB8DY,EhB9DZ,IAAA,AAC6C,CAAC,CAAC,CAAC,CADhD,EACkC,MAAA,CAAe,EAAiB,CbvBiB,GauBb,CAAC,AAAE,CAAD,OAEtD,GAAA,GAFqE,CAAC,AAEtE,AAA+B,GAAG,CAAlC,EAAA,MAA0B,CmCiG5B,8BnC7FO,MAAA,CAAA,EAAA,EAAA,YAErB,sBAEkC,KAAA,MAAA,KAAA,CAAA,EAA4B,KAAA,CAAA,CAAW,CAAC,EAAW,CAAC,MAEjE,CQ2DC,iBRtD5B,IAAM,EAAc,GAAA,EAAgC,EAAY,OAAO,CAAC,KAAK,CAAA,OAAA,EACvE,EAAA,GAAA,GAE6B,AAF7B,YAAA,OAAA,EAE6B,EAAA,EACQ,GACrC,EACF,EAAmB,GAAY,IAAM,EAAc,IAAA,EAAoB,CAArD,EAAqD,UAEnD,CFoGD,MEnGjB,EAAA,IAAuB,iBACE,MAE7B,COVS,CAAA,EAAA,EPaP,EACA,C+E6CsC,C/E5CtC,EACA,EACA,EACA,EACA,OADS,GAFO,IACE,CAEH,AAEoB,GAAA,GAA4B,GAAO,C+EwCX,I/ExCkB,CADhE,CAEb,EACA,EACA,CAHoF,CAEhF,AAEJ,EACA,EACA,EACA,CAJS,CAKT,AAHM,EAIN,GALa,AAEJ,EAEF,MAMN,CAPe,EAwIhB,CAAG,CAtIa,AAsIZ,CArIL,CgBwekC,AhBvepC,CAAC,AAoIS,AgBmW0B,AhBlWjC,EAEA,CAFG,CAEH,EAEA,CqD6QgC,CrD7QxB,CgBgWoB,AqCnFM,MlBrdR,SnCqMP,AAGK,CACxB,EAAQ,KAAD,aAAmB,CAC1B,EAAQ,KAAD,IAAU,CACjB,EAAQ,KAAD,UAAgB,CACvB,EAAQ,KAAD,CAAO,CAAC,AAAE,CAAD,CAAS,KAAD,EAAQ,CAAC,AAAE,CAAD,GAAK,CACvC,EAAQ,KAAD,CAAO,CACd,EAAQ,IAAI,CAAL,AACP,EAAQ,KAAD,IAAU,CACjB,EAAQ,KAAD,QAAc,CACrB,EAAQ,KAAD,CAAO,CACd,EAAQ,KAAD,IAAU,CACjB,EAAQ,KAAD,WAAiB,CACxB,EAAQ,KAAD,EAAQ,CACf,QAKA,EAAA,CALW,CACZ,AAIC,CAHH,CAAC,EAGoB,CAAC,EAAQ,SAAA,EACjC,EAAA,CAAwC,IAAxC,EAAA,cAAA,CAA+C,IAAM,GAYrD,CgB8UC,QhBxVW,eAAe,GACN,cAAmB,CAAC,SAApB,IAEP,CqD8PC,yBrD3PD,mBAIP,EAAA,MAAa,CAAG,CAAC,CAAC,AAAE,EAAS,AsDrDT,EDoTT,ArD/P2B,EAAE,AqD+PpB,ArD9P7B,CADkD,AqD+PpB,ArD9P7B,CqD4EuB,EAAO,aAAe,UAAU,CAAE,iBAItD,MAAO,CAAA,EAAG,IAAI,CAAC,WAAA,CAAY,IAAI,CAAA,GjClMA,CAAA,EiCkMO,GAAA,CAAS,AACjD,CADkD,ACzRjD,A9C8EA,A6C4MA,AmC3MA,wBnC8MC,CvDhKC,KuDgKM,CAAA,qBAAA,EAAA,KAAA,CAAiC,AAC1C,CAD2C,AvD/J1C,AEnFA,AqDmPA,MlB1K4B,CAAC,CAAC,AfzBgB,QiCsM7C,CAAc,CACd,CMlQmB,ANkQN,CAAA,CAAA,CAEb,CjCvM8B,CAAA,CiCyM9B,CMrQC,MNqQM,GAAgB,ElEpTA,MkEoTQ,CAAC,EAAQ,EjCxMZ,AiCwMmB,E0BhOA,A1BgOS,C0BhOR,C1BiOlD,CrDxPC,AqDwPA,AMrQA,ANuQD,IrCvMK,AwEZA,AnCgN4D,CAAC,CAAC,AAG7D,aAAA,CACJ,IAGI,CMjVK,CN8UH,EAAS,IrD5P4E,AqD4P5E,CrD5P6E,AqD4P7E,CrD5P8E,OqD4PjE,CAAC,ClBhLH,KAAA,CkBiL1B,ClEvTC,EkEuTU,YAAP,OAAO,EAAuB,ClEtT7B,EAAE,IkEsTkC,EAGzC,GAAA,CACE,ClB/KC,CkB+KO,MAAM,GAChB,CrClMG,AqCkMF,MAAQ,EAAU,CAAC,AAClB,GAAA,aAAA,GAAA,MAAA,QACM,ClEpTD,GkEoTK,C9CnRO,EAAA,CAAA,4CAAA,E8CoRgC,EAAI,OAAO,CAAA,CAAE,CAE5D,CAAE,AADF,MACS,GAAG,AAEhB,IAHiB,AAKb,AAAiB,iBAAV,GAAsB,CAAC,OAAO,CACjC,CrDtPK,GqDsPD,GACR,CAAA,uEAAA,EAA0E,EAAK,CAAE,CAClF,CADgF,AAC/E,OAEJ,CjC1MC,GiC0MG,CAAC,MAAM,CAAG,GACP,CACT,CAAC,AAED,SACE,CAAY,CACZ,CAAA,CACA,CAAmC,C0BxOR,C1B0O3B,IAAM,EAAU,CAAE,ClE/TD,EkE+TC,IAAI,CAAA,GAAA,IAAA,IAAA,IAAA,CAAJ,IAAI,CAAqB,EAAI,GAAmB,IAAI,CAAC,OAAO,CACxE,AADyE,MAE7E,AlE/TK,CoBmCE,WAAA,AE5NwB,G4CyfrB,EACA,GADR,AACmB,ClEjUlB,A4FsFF,C1B2O4B,ClEjUxB,AkEiUH,IAAI,AAAc,ClEhUX,EkEgU4B,CAAC,MAAQ,EAAK,EAAD,QAAW,CAAC,GAAG,CAAC,CAAC,AAAE,CAAD,CAAM,EAAD,GAAM,CAAC,CAAC,CAAC,CAAC,AAAE,CAAD,AAAC,CAAI,CAAC,CAAC,AAEvF,CAFwF,CAEzE,IAAI,CAAC,YAAY,SAClC,CAAC,2D5CzeT,CAAC,AMyDA,CsCgbmB,CjC7MH,CjCnHO,KkEiUV,CAAE,GAAA,CAAe,GADI,CACC,AADA,CACK,ArCtMN,CqCsMM,CAAE,CAGlB,CjC7MT,CjCrHkD,QkEkU1D,OAAO,GAAsB,GAAS,CAAC,CAAL,KAAW,OAAO,CAAC,KAAK,CAAC,EAAE,CAAC,CrDhQC,CAAC,CAAC,CqDiQzD,CAAG,IAAI,CAAA,cAAe,CAAC,EAAA,EAG5B,EAAI,CrChMD,AqCgMA,OAAS,EACrB,CAAC,C9C3RG,K8CgSY,eAAe,CAAA,CAAA,OACvB,IAAI,CAAC,WAAW,EACxB,CAAC,AAQS,CCrST,A/CGG,K8CkSY,eACd,CAAoB,CAAA,CAAA,IAAA,CAAA,SACb,C0B1OuB,A1B0OhB,CrDhQ2B,CAAA,CAAA,OqDmQpB,CAAqC,ClE1UpB,YkE2U3B,CAAA,aAAc,CAAC,MAAO,ClE1UC,CkE0UK,GAGzC,KAAU,CAAY,CAAA,CAAA,CAAA,QACb,IAAA,CAAA,aAAkB,CAAC,OAAA,EAAA,EAC5B,CCzSG,ADySF,AAED,MAAW,CAAY,CAAA,CAAA,CAAA,QACd,IAAA,CAAA,aAAkB,CAAA,QAAU,EAAM,EAC3C,CAAC,AAED,CAH+C,CAAC,ArDlQA,CqDkQC,ArDlQA,AqDqQ9C,CrDrQ+C,AqDqQzC,CjC7MN,A2DjCA,AAAE,CAAD,A1B8OmB,C0B9OlB,A1B8OuD,CAAA,CAC1D,CC1SC,MD0SM,IAAI,CAAC,G0B7OG,U1B6OU,CAAC,MAAO,EAAM,GAGzC,OAAY,CAAY,CAAE,CAAA,CAAA,QACjB,IAAI,CAAC,E0B9OF,W1B8Oe,CAAA,SAAW,EAAM,EAAF,CrC0GD,cqCtGvC,CAAA,CACA,CAAY,CACZ,C0BlPuB,A5FlGA,CkEoVc,ClEpVd,OkEsVhB,IAAA,CAAA,OAAY,CACjB,GC9SqB,KD8Sb,CC9SmB,MD8SZ,CAAC,CC9SmB,CAAC,CD8Sd,CAAF,CAAC,EAAK,CAAC,AAAC,IAAI,AACvB,EADyB,EAAE,IACzB,CC9SC,CAAC,KD8SM,EAAM,GAAG,CAAI,CAAA,CAAE,CAAC,EAKvC,QAAA,CAC8C,CAAA,EACV,ClBheC,ChDuID,EkEyVI,CCjTH,QDmT5B,CClTD,GDkTK,GAAA,IAAe,CAAE,E0BxPN,A5CzOU,CAAC,CkBieD,CAAA,WAAY,CAAA,EAAA,OAA4B,GrC+FG,AqC9F7E,CAAC,AAEO,CCnTP,AnExCA,CAAC,IkE2VY,YACZ,CAAiD,CACjD,CAA+B,CAC/B,A0B5PwB,CAAkD,A1B4PnC,AjClKiB,CAAC,AiCkKlB,C0B5PqC,A1B8P5E,IAAM,EAAU,MAAM,GjCnKC,CAAC,CJ4PG,CAAC,AqCxFD,I0B3PA,M1B2PU,EAAI,IAAI,CAAC,ErCyFqB,QhBxW3D,AqD+QgD,CAAC,GrCyF6C,CAAC,CAAC,AqCxF1E,CAA1B,CrCyFD,ChBzWK,IqDiRa,CAAA,EAGrB,ClBveG,KkBueG,IAAI,CAAC,cAAA,CAAe,GAE1B,GAAM,KAAE,CAAG,CAAA,IAAA,CAAK,CAAA,QAAA,CAAS,CAAE,CAAG,G0B7PD,C3D0FK,EiCmKE,G0B7PD,C1B6PK,CAAC,I0B7PA,Q1B6PY,CAAC,CrDhRG,CqDgRM,YACjD,ClBxeO,CkBweM,GAG3B,OAAA,IAAU,CAAA,cAAe,CAAC,EAAK,KAAE,CrCsFL,SqCtFU,QAGhC,EAAe,ClB/dG,AmB2KF,MDoTQ,CAAmB,CAAC,IAAI,EAAE,CAAC,CAAC,CAA1B,KAAK,KlB/dO,CkB+dD,IAAkB,CAAb,AAAc,CAAC,AAAC,ClB/dG,OkB+dK,CAAC,EAAE,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAE,GAAG,CAAC,CACvF,AADwF,ErD/QzE,AsDpCf,AtDoCE,KAAa,IqDgRD,CrDhRC,CqDgRmC,EAAE,CAAC,AAAE,CAAD,AAAC,GlB/dI,CAAC,OAAA,EkB+dS,EAAmB,CAAE,CAAC,AlB9d9F,EkB+de,ElBheiE,CAAC,AnBsjBrE,CqCtFO,CAAC,GAAG,EAAE,CAAC,ArCsFN,EqCvFuE,IAGpF,IAAI,C0B/PG,A1B+PF,CAAA,KAAM,CACnB,CAAA,CAAA,EAAI,CrDjRuB,CqDiRX,CrCoFc,CAAC,CAAC,cAAA,CqCpFG,CACnC,GAAqB,iBAAD,aAEV,EAAA,MAAc,yBAGb,CjCxKH,CAAA,OiCwKc,IAIpB,EAAQ,MAAA,EAAQ,QAClB,CCxTC,ADuT0B,CAAC,ACvT1B,IDwTI,IAAI,OAGN,EAAA,IAAA,gBACA,EAAA,MAAiB,IAAI,CAAC,ErCiFN,cqCjFsB,CAAC,CrD9PG,CAAC,AqD8PC,CrD9PA,AqD8PF,ArD9PK,CAAC,AqD8PD,CAAA,CAAW,GAAY,CrCiFP,IqCjFY,CAAC,WAAW,CAAC,CAAC,CACnE,8BAEO,CrD9PC,IqD8PI,CAAE,CAAC,IACnC,EAAA,CAAA,UAAA,EAA4B,EAAgB,mBAAA,CAAqB,CAAC,GACpE,EAAA,MAAc,EAAA,QAChB,CAD2B,CAAC,ErD9PE,CAAC,CqD+PzB,CCtTG,GDsTC,GAMZ,IAAM,ClB7cC,AnC+ME,CqD+PP,GAAa,ClB9cmB,GkB+chC,eAAe,IAAI,CAAC,IlB9cQ,GkB8cD,IAAa,IAAL,CAAC,EAAW,CAAR,EAAY,EAAW,MAAM,AAAT,CAAC,AAAS,CAAR,CAAiB,KAAK,CAAN,AAAO,CAAC,AAAE,CAAD,CAAC,CAAE,CAAC,CAAC,AAC7F,CAD8F,AjC1K7F,EiC2KG,ClB9cG,CkB2dL,UAZU,GjC1KK,CiC0KD,EAAA,AADM,CAAC,GACD,CAClB,CAAA,CAAA,EAAI,EAAY,UAAA,GAAA,EAAgB,EAAY,OAAH,CAAC,CAAC,EAAY,CAAC,AAAE,CAAD,OAAS,CAAA,GAAA,EAAM,EAAY,CAAE,CACvF,CAAC,OADoF,AAExE,CAAC,CAAC,KAAK,CACnB,CAAA,CAAA,EAAI,EAAY,aAAA,EAAgB,EAAY,OAAH,CAAC,CAAC,EAAY,CAAC,AAAE,CAAD,OAAS,CAAA,EAAA,EAAK,EAAY,CAAA,CAAG,CACtF,GAAqB,CACnB,GAFiF,aAC/D,UAElB,GAAG,UACS,EAAA,EACZ,QAAS,EAAS,OAAO,IAGtB,IAAI,CAAC,YAAY,CAAA,EAAU,EAAkB,GAAuB,MAE7E,GAAU,GAF+E,CAAC,AAE5E,CAF6E,AAE5E,CAAC,IAAI,CAAA,CAAA,CAAA,EACd,CCzTsB,CAAC,aAAA,EAAA,EDyTiB,MCzT2B,MDyTb,SAAQ,8BAAA,CAAgC,CACnG,CAAC,GACQ,IAAI,CAAC,CAAC,KAAK,CACnB,CAAA,CAAA,EAAI,ClBhRqB,CAAC,AkBgRV,ClB/QnB,CAAC,QkB+QkB,GAAA,EAAgB,EAAY,OAAH,CAAC,GAAa,CAAC,AAAE,CAAD,OAAS,CAAA,8BAAA,CAAgC,CAClG,GAAqB,iBAAD,IAClB,MACA,aACY,EAAc,EAC1B,OADmC,CAC1B,EAAS,OAAO,IAGzB,CrCnTO,OqCoTH,CjC/KG,EiC8KI,CACH,EAEZ,CjC/KC,MiC+KK,IAAI,GAA0B,CAAE,EAAtB,CAAC,EAAkB,AAAQ,CAAE,CAAQ,CAAE,CAAC,AAC1D,CAD2D,AAC1D,AAED,IAHuD,AAGjD,EAAiB,MAAa,OAAO,CAAC,OAAO,EAAE,CAAC,CACnD,MAAM,CAAC,CAAC,CAAC,EAAK,EAAD,CAAM,iBAAA,GACnB,GAAA,CAAI,CAAC,CAAC,EAAM,EAAM,AjChLN,EiCgLQ,CAAA,KAAU,EAAO,EAAH,GAAU,IAAI,CAAC,SAAS,CAAC,IAC3D,CADgE,CAAC,CAAC,CAC9D,CAAC,IACF,EAAe,CAAA,CAAA,EAAI,EAAY,CrCnTP,CqCmTU,ArCnTT,EqCmToB,EAAG,EAAc,EAAA,AAA/B,EAAoC,CAAtB,CAA0B,CAAD,KAAR,AAAe,CAAA,CAAA,EAAI,EAAG,CAAA,EACxF,EAAS,EAAE,CAAC,AAAE,CAAD,EAAL,QAAiB,CAAC,AAAE,CAAD,OAC7B,CAAA,aAAA,EAAgB,EAAS,MAAD,AAAO,CAAA,IAAA,EAAO,EAAc,EAAS,EAAA,CAAI,CAAC,AAElE,GAAI,AAF6C,AAAY,CAEzD,EAAU,EAAE,CAAE,CAAC,AACjB,IAAM,CrCvTkB,CAAC,AqCuTL,IrCtTQ,CIkIP,AJlIQ,CAAA,IAAA,CqCsTE,WAAW,CAAC,GAC3C,GAAI,EAD+C,CAC/C,AADgD,CAAC,CAChB,CAAC,AACpC,IAAM,EAAe,CAAA,UAAA,EAAa,EAAgB,cAAA,KAAA,CAAqB,CAAC,AAexE,ErCzTM,KqC6SN,ErCvTM,IqCuTA,GAA2B,EAAS,IAAA,EAC1C,GAAU,IAAI,CAAC,CAAC,IAAI,CAAC,CrCtTO,CAAC,CqCsTL,EAAY,GAAA,EAAM,EAAY,CAAE,CAAC,CAArB,AAAsB,GAChD,IAAI,AADwC,CACvC,CAAC,KAAK,CACnB,CAAA,CAAA,EAAA,EAAgB,kBAAA,EAAqB,EAAY,CAAA,CAAG,CACpD,GAAqB,CACnB,GAF+C,aAC7B,ArCvTI,CAAC,EqCwTJ,GACnB,IAAA,EAAc,GAAG,CACjB,ErCzT0B,AIiIxB,CJjIyB,IqCyTnB,EAAS,MAAM,KjCxLK,IiCyLnB,EAAS,OAAO,YACb,EAAc,KAGvB,IAHgC,AAG5B,CjC1L2B,AiC0L1B,YAAY,CACtB,EACA,EACA,GAFO,AAEgB,EACvB,EAAS,MAAD,CAFQ,AAEA,CADmB,AAEpC,CAAC,AAGJ,GALuB,CAKjB,EAAe,EAAc,CAAA,2BAAA,CAA6B,CAAG,AAAF,CAAE,AAAD,oBAAC,CAAsB,CAAC,AAE1F,GAAU,IAAI,EAAE,IAAI,CAAC,CAAA,EAAG,EAAY,GAAA,EAAM,EAAY,CAAE,CAAC,CAAC,AAE1D,IAAM,EAAU,CAFsC,KAEtC,EAAe,IAAI,EAAE,CAAC,IjC/LE,CiC+LG,CAAC,AAAC,GAAa,EjC/LL,CiC+LiB,GAAG,AAAE,CAAD,AjC/LL,MiC+La,CAAC,CAAC,AAC9E,EAAU,OjC/LG,CiC+LK,yCAAC,CjC/LH,EiCgMhB,EAAa,EAAA,KAAA,EAAsB,CAezC,MAAM,CAbN,GAAU,GrCjUF,CqCiUM,CAAC,CAAC,KAAA,CACd,CAAA,CAAA,EAAI,EAAY,kBAAA,EAAqB,EAAY,CAAA,CAAG,CACpD,GAAqB,IAD4B,aAC7B,IAClB,EACA,ErCnUQ,CqCmUL,CAAE,EAAS,GAAG,CACjB,OAAQ,EAAS,CrClUJ,KqCkUU,CACvB,QAAS,CjCnMH,CiCmMY,OAAO,CACzB,OrChUS,AqCgUF,CAAE,EACT,ErCjUe,CAAC,CAAC,EI4HA,KiCqML,IjCpMA,AiCoMI,CAAC,GAAG,EAAE,CAAG,SAAS,CAIrB,QjCvMI,OiCuMW,CAAC,EAAS,MAAD,AAAO,CAAE,EAAS,EAAY,EAAS,CAAvB,KAAY,AAAU,CAAQ,CAAC,CAAC,UAIjF,IAAI,CAAC,CAAC,IAAA,CAAK,GACrB,GAAU,CrCjUsB,GqCiUlB,CAAC,CAAA,KAAM,CACnB,CAAA,CAAA,EAAI,EAAY,gBAAA,CAAkB,CAClC,GAAqB,qBACnB,EACA,GAAG,CAAE,EAAS,GAAG,GAAJ,KACL,EAAS,MAAD,AAAO,CACvB,KrCjUiC,EqCiU1B,CAAE,EAAS,OAAO,CACzB,WAAY,EAAc,KAIvB,IAJgC,MAI9B,MjCzMM,EiCyME,EAAE,aAAS,UAAU,KAAE,ErCjUI,oBqCiUU,IrCjUM,QqCiUe,CAAS,CAAE,AACxF,CADyF,AAGzF,MAHsF,KAIpF,CAAY,CAAA,CAC2B,CACvC,CAAqB,CAAA,QAEd,IAAI,CAAC,cAAc,CAAC,EAAM,CAAE,CAAJ,KAAU,CAAE,WAAO,EAAM,EAAF,CAAK,CAAI,CAAE,CAAC,CAAC,eAOnE,CjC/MY,CAAA,CAAA,AiCgNgB,CAAA,CAG5B,OAAO,IAAI,GAAwC,IAAA,CADnC,CAC0D,GADtD,CAAC,WAAW,CAAC,EAAS,IAAI,MAAE,GACmC,IAAI,CAAC,CAAC,oBAIzF,CAAgB,CAChB,CAAA,CACA,CAAU,CrC/UyB,AqCgVnC,CAA2B,CAAA,IAErB,QAAE,CAAM,CrCjVJ,OqCiVM,CAAM,CAAE,GAAA,EAAY,CAAG,GAAQ,CAAJ,AAAI,CAAE,AAC7C,CAD8C,GAC9C,EAAe,EjCtNN,ciCsNsB,CAAC,QAAA,IAAe,EAAA,KAAA,IAEnD,IAAM,EAAA,WAAA,IAA2B,EAAW,KAAK,EAAE,CAAE,EAAE,CAAC,AAElD,CAFmD,CAGvD,WAAA,cAAmC,EAAI,EAAQ,IAAI,YAAa,UAAkB,CAAC,cAAc,CAAC,CACjG,AAAmB,iBAAnB,EAAe,IAAI,EAA6B,OAAZ,EAAQ,IAAI,CAAL,CAAkB,MAAM,CAAC,aAAa,IAAI,EAAQ,IAAI,CAAL,AAAM,AAE/F,CAFgG,CAEpE,ErClVf,MqCmVT,CjC1NC,CAAA,MAAA,CiC2NT,GAAI,EAAiB,CAAE,CrClVH,MqCkVW,MAAM,CAAE,CAAC,AAAE,CAAD,AAAC,CAAE,CAAC,ArClVJ,OqCmVjC,GjCzNK,GiC0Nb,GAAG,CjCzNC,AiCyNM,CjCzNC,AiC2NT,CjC3NU,IiC8NZ,EAAa,CAHH,CAAC,IAGQ,CAAG,EAAO,IAAD,OAAY,EAAA,CAAE,CAAC,AAG7C,GAAA,CAEE,OAAO,GjCzNC,GiCyNK,IAAI,CAAA,KAAA,CAAA,IAAW,MAAC,EAAW,EAAK,CAAF,CAC7C,CAAC,EADuC,KAC9B,CAAC,AACT,IjCzNS,QiCyNG,CAAC,GAEjB,CAAC,AAEO,GAJgB,CAAC,CAAC,AAIb,CAAC,YAAY,CAAA,CAAA,CAExB,IAAM,EAAoB,EAAS,EjCxNb,IAAW,CiCwNS,CAAA,GAAI,CAAC,wBAG/C,AAA0B,IjCzNF,IiCyNU,CAA9B,GACsB,GADe,EjCrNd,IiCsNQ,CrChV9B,AqCgVD,IAGoB,EAHkB,CAGf,EAAE,CAAzB,CrC/U6B,CqC+UpB,ArC/UqB,IIyHnB,AiCsNqB,EAAjB,EjCtNA,AiCyNnB,AAAwB,EjCzNH,CiCyNM,EAAE,CAA7B,EAAa,IAAuB,EAAjB,EAGK,GAAG,EAAE,CAAzB,EAAS,ErC/UiB,EqC+UM,CjCpNxB,CiCoNO,KAGf,EAAS,MAAD,AAAO,EAAI,GAAA,CrC/UL,AqC+UQ,EAAE,OAAO,IAAI,QAMvC,CAA4B,CAC5B,CAAwB,CACxB,CAAoB,CACpB,CAAqC,CAAA,KAEjC,EAGE,CjCxNC,CAAA,GAAA,IiCwN6C,kBACpD,GAAI,EAAwB,CAAC,GrCrVC,CqCsVtB,EAAY,OjCvNO,IiCuNI,EACzB,CAAC,MAAM,CAAC,KAAK,CAAC,KAChB,CAFiD,CAAC,AAElC,CAFmC,AAEnC,CAEpB,CAAC,AAGD,EANgC,CAAC,CAM3B,EAAmB,CrClVZ,EqCkV6B,GAAG,CAAC,QAAN,KAAmB,CAAC,CAAC,OACpC,EAAe,CAAC,ErClVT,EqCmVxB,EAAA,IAD8B,OAC9B,GAIJ,EAHG,CrClVG,MqCkVI,KAAK,CAAC,EjCtNE,CiCyNF,KAAK,KAAA,CAAA,GAHY,AAGc,CAHb,GAGiB,CAAC,GAAG,EAAE,CAFxB,AAEyB,IAF1C,AAAqB,CAIzC,AAJ0C,CAIzC,AAID,ErC1V8B,CqC0V1B,CAAC,CAAC,EjC9NuB,CiC8NN,CAAC,EAAI,GAAiB,EAAgB,EAAE,CAAG,CAAI,CrC9UlD,AqC8U8C,AAAK,ArC7UzC,CAAA,AqC8U5B,EADuC,CrC/Ud,CqCgVnB,EAAa,EAAO,IjCpNL,CiCoNK,KAAW,CjCpNH,CiCoNO,GjCpND,CiCoNK,CAAA,UAAW,CAAC,AACzD,EAAgB,IAAI,CAAC,kCAAkC,CAAC,EAAkB,EAC5E,CAAC,AAGD,OAJsF,AAEtF,CAFuF,CAAC,EAAd,EAEpE,GAAM,CjCpNH,CiCoNE,CAEJ,IAAI,CAAA,WAAY,CAAC,CjCrNH,CiCqNY,EAAmB,CAAC,CAAE,CAAxB,CACjC,CAAC,AAEO,SAH2C,AAAkB,CAAC,CAAC,wBAG5B,CAAwB,CAAE,CAAkB,CAAA,CAYrF,OALqB,AAKd,KALmB,GAAG,CANH,AAMI,GAND,AAMqB,CANpB,EAWR,CALgC,CAAC,GAAG,CAAC,AAK/B,CALgC,CAHzC,CAG2C,CAH9B,CAGe,EALzB,IAQP,CAAC,CAAmB,AAHqC,CAAC,EAAE,CAGxD,GAN6B,CAMzB,AAN0B,CAMzB,CjCxNH,KiCwNS,CAH0D,CAAC,AAGzD,AAAG,CAHuD,AAGnD,CAAC,AAET,CrClVG,CAAC,CqCmVrC,CAAC,AAED,AAHqC,CAAC,KAGhC,aACJ,CAAiC,CACjC,YAAE,CrCrVgC,CAAC,AqCqVpB,CAAC,CAAA,CAA8B,CAAA,CAAE,CAAA,CAEhD,CAFY,GAEN,EAAO,CAAK,EjC7NJ,CiC6NO,CAAY,AAApB,CAAsB,CAAC,AAC9B,MrCvV0B,EqCuVxB,CAAM,CAAA,KAAA,CAAM,OAAE,CjC7NL,gBiC6NY,CAAc,CAAE,CAAG,EAE1C,EAAM,CAAH,EAF8C,CAAC,AAE5C,CAAK,QAAA,CAAS,EAAA,EAAyC,EACnE,CAAA,YAAiB,GAAS,wC5Cr0BS,C4EwBC,CxBlBH,OAAA,CpDNY,2CAG/C,GAAA,EAAA,gDAC4D,CAG9D,AaoBiE,AbvBF,CAG9D,AAH+D,CAG9D,C4CoRC,AA0iB2B,UAAA,EAA2C,OAAO,EAC5E,EAAQ,KAAD,EAAQ,CAAG,EAAA,OAAe,EAAA,IAAQ,CAAC,OAAA,CAC1C,GAAM,aAAE,CAAW,MAAE,CAAI,CjC7NP,AiC6NS,CAAA,IAAA,CAAA,SAAiB,CAAC,SAAE,CAAO,CAAE,CAAC,CAAC,AACpD,EAAa,CADmC,KAC7B,IAAI,CAAA,YAAa,CAAC,SAAW,SAAc,EjC7NR,YiC6NgB,aAAa,IAazF,MAAO,CAAE,IAXyB,QAChC,UACS,EACT,GAAI,EAAQ,GADO,EACR,CAAO,EAAI,CAAE,MrCvVU,AqCuVJ,CAAE,EAAQ,KAAD,CAAO,CAAE,CAAC,GAC5C,ErCvVG,QqCuVe,CAAC,cAAc,EACpC,CjC/NwB,GiC+NpB,SAAa,WAAmB,UjC9NL,IiC8NmB,EAAI,CAAE,MAAM,CAAA,OAAU,CAAC,AAC3E,GAAG,GAAS,CAAJ,AAAM,MAAI,CAAE,CAAC,AACrB,GAAK,IAAI,CAAC,YAAoB,EAAI,CjC5NhB,AiC4NgB,CAAE,CACpC,GAAK,EAAQ,IrCrVG,CqCqVJ,ArCrVW,CAAC,CAAC,KqCqVQ,EAAI,CAAA,CAAE,CAAC,KAG5B,EAAK,GjC/NgB,KiC+NP,EAAQ,OAAO,CAC7C,CAAC,AAEO,KAAK,CAAC,aAAa,SACzB,CAAO,QACP,CAAM,aACN,CAAW,CACX,YAAU,CAMX,CAAA,CACC,IgC3uBuB,EAbrB,EhCwvBF,EAAsC,CAAA,CAAE,CAAC,AACrC,IAAI,CAAC,iBAAiB,ErC9VI,AqC8VW,KAAK,EAAE,CAAlB,AAAmB,IAC1C,EAD6B,AACrB,cAAc,EAAA,CAAA,EAAU,CrC7VtB,aqC6VoC,CAAG,IAAI,CAAC,qBAAqB,EAAA,CAAE,CAAC,AACnF,CAAA,CAAmB,IAAI,CAAC,iBAAiB,CAAC,CAAG,CjCpOD,CiCoOS,cAAc,CAAC,CAGtE,IAAM,EAAU,GAAa,CrC7VT,UqCgWR,mBACR,YAAY,CAAE,IAAI,CAAC,YAAY,EAAE,CACjC,0BAA2B,OAAO,MAC9B,EAAQ,EADgC,CAAC,EAClC,AjCpOU,EiCoOF,CAAC,AAAE,CAAD,sBAA0B,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,EAAQ,KAAD,EAAQ,CAAG,IAAI,CAAC,AAAC,CAAA,AAAE,CAAC,AAAE,CAAD,AAAC,CAAE,CgC7tB9F,AhC6tB+F,OgC7tB/F,0IAnBG,cA9GwC,EAAE,EA8GjC,WAAW,EAAA,kBAMM,oBACF,UAClB,aAAiB,QAClC,UAAA,EAAiC,0DAGjC,UAAA,EAAA,sBACwC,CAAC,6BA5BzC,AAAa,SALT,EAzFkC,CjEkGG,AerGA,IAAA,KAAA,CkDGQ,IAAI,CAAC,CA8F3B,MACd,cAAA,QAAA,EAAA,MACA,CrEiDD,SAAA,MqEhDC,C9ElBD,cAAA,A8EkBuB,U9ElBvB,E8EkBuC,uBAE5C,qEAhGkB,6BAAA,CAAA,KAAqB,OAAO,CAAC,AAAC,ClBpBf,AkBoBe,IAAM,OAAA,EAAS,IAAI,EAAI,SAAS,EAI9E,wLAM2B,WAAmB,OAAA,CAAA,OAAA,CAmH/C,ChC8tBF,CACA,EADG,WjCpOe,CAAC,CAAC,MiCqOC,CAAE,AADA,CrCzVO,CAAC,EqC0VJ,CAAC,SjCrOa,GiCqOD,CACxC,gBAAgB,CAAE,CjCnOO,GAAA,CiCmOF,OAAO,QAE1B,IAAI,CAAC,WAAW,CAAA,OAClB,CAAC,CrC1VG,OqC0VK,CAAC,CjClOK,CAAC,CAAC,WiCkOO,CAC5B,EACA,EAAQ,KAAD,EADI,AACI,CAChB,CAAC,CAAC,AAIH,OAFA,IAAI,CAAC,eAAe,CAAC,GAEd,EAAQ,EAFa,CAAC,CAAC,CAEhB,CAAO,CAAC,ErC7ViB,CAAC,CAAC,MqCgWzB,CAAE,CrCvVL,OAAA,MqCuVgB,CAAI,CAAE,OAAO,CAAE,CAAU,CAAE,CAAoC,CAAA,IAIxF,CAAA,MAAO,CAAC,CACH,CAAE,WAAW,CAAE,GrC3VO,IqC2VI,EAAF,EAAM,CAAE,MAAS,CAAE,CAAC,CAAH,GAE5C,EAAU,GAAa,CAAC,CAAjB,MrCzVgB,CqCyVD,EAAY,CACxC,AAEE,IADA,QACY,MAAM,CAAC,IAAI,AAAC,CAAA,KADC,OAET,aAAA,aACA,QAAQ,EACP,UAAhB,OAAO,GAEN,EAAQ,MAAM,CAAC,GAAG,CAAC,GrCrVG,IATsE,CACzF,CAAC,QqC+VJ,UAAkB,CAAA,EAHiC,EAG5B,EAAI,aAAiB,OrCrVP,IqCqV0B,IAAI,CAAC,CAEtE,EADA,EACI,SAAY,QAAQ,EAExB,EADA,EACI,SAAY,IAHsB,WAGP,EAE7B,WAAmB,cAAc,EAAI,IAAI,AAHgB,QrCnVsB,CAAC,AqCsV1B,UAAkB,CAAC,cAAc,CAAC,AAEnF,CADP,AACS,CADR,UACmB,MAAE,EAAW,IAAI,CAAE,CAAgB,CAAE,AAA1B,CAA2B,AAE1D,AAAgB,CAFuC,MrCjVzB,KqCoV9B,KADO,IrCnVW,AqCmVP,AACV,MAAM,CAAC,aAAa,IAAI,GACtB,CAD0B,ArClVI,CAAC,IqCmVzB,CAAC,QAAQ,IAAI,GrClVS,AqCkVD,CAAJ,ArClVM,KqCkVI,GAAI,GAA6B,CAAzB,WAAI,OAAO,EAAK,EAAD,EAAK,AAAK,CAAU,AAAC,CAAC,AAE1E,CAAE,CADT,CAAC,SACmB,MAAE,EAAW,IrCnVD,AqCmVK,CAAE,EAAR,CAAiC,EAAkC,AAAtD,CAAwD,AAAvD,CAAoD,AAAI,AAE9F,CAF2F,AAAnC,EAExD,ErClVyB,EqCkVrB,CAAA,GAAA,IAAS,CAAA,IAAA,CAAb,IAAI,CAAU,MAAE,IAAI,MAAE,CAAO,CAAE,CAAC,AAE3C,CAAC,AAF2C,GAAJ,sDAphBd,2BAA2B,CAAC,EAA7C,IAAI,CAAC,OAAO,AACrB,CAAC,CAuhBM,CrChVN,EAAA,MqCgVY,CAAG,EAAI,AAAP,CAAQ,AACd,GAAA,eAAe,CAAG,QAAQ,UAEf,CrC7UoE,AqC6UjE,GACd,GADoB,AACpB,CADqB,OACb,CAAG,GACX,GAAA,AADiB,CAAC,iBACA,CrCvQD,AqCuQI,GACrB,GAD2B,AAC3B,CAD4B,kBAAkB,AAA5B,CAA6B,KACtB,CrCvQH,AqCuQM,GAC5B,GADkC,AAClC,CADmC,gBAClB,CAAG,GACpB,GAD0B,AAC1B,CAD2B,CADiC,AAAnC,CAAoC,UAEhD,CAAG,GAChB,CAF4C,AAA3B,CAA4B,CACvB,AACtB,CADuB,ErCvQF,UqCwQR,CADA,AAAuB,AACpB,CADqB,EAErC,GADsB,AACtB,CADuB,aACT,AADD,AAAuB,CACnB,AADoB,GAErC,GADuB,AACvB,CADwB,MrCvQE,QqCuQZ,AAAwB,AACvB,CADwB,AACrB,GAClB,GADwB,AACxB,CADyB,eAAe,AAAzB,CAA0B,EACtB,CAAG,GACtB,GAAA,AAD4B,CAAC,KrCvQC,CAAC,YqCwQZ,CAD6B,AAA7B,AACG,CAD2B,EAEjD,GAD4B,ArCvQJ,AqCwQxB,CAD6B,ArCvQJ,mBqCuQuB,AAA7B,CAA8B,AAC5B,CAAG,CrCvQH,CAAC,CqCwQtB,GAD8B,AAC9B,CAD+B,qBAAqB,AAA/B,CAAgC,CAC7B,CAAG,CrCvQH,CAAC,CqCwQzB,GADiC,AACjC,CADkC,wBAAwB,AAAlC,CAAmC,EAC/B,CAAG,GAE/B,GAFqC,AAErC,CAFsC,KAEtC,CAAS,GAyBlB,GAAO,CAzBkB,CAAC,CAyBpB,KAzBS,AAAiB,CAAC,EAyBf,CAAG,ErCjSa,CqCkSlC,CA5B2E,AAAtC,CAAuC,CA4BrE,GAAD,CAAK,CADqB,AAClB,CADmB,EAEjC,GAAO,GAAD,OAAW,CAAA,GACjB,GAAO,GAAD,EAAM,CAAG,GACf,GAAO,GAAD,GAAO,CAAG,GAChB,GADsB,AACf,CADgB,EACjB,EAAM,CAAG,GrChSD,AqCiSd,EADoB,CAAC,AACd,GAAD,QAAY,CAAG,GACrB,GAAO,GAAD,EAD0B,CAAC,AACpB,CAAG,ErCjSkB,AACpB,CqCiSd,GADsB,AACf,CADgB,SACN,CAAG,MACb,IADuB,CAAC,EACjB,CAAG,MACV,CADiB,CAAC,UACN,CrChQC,AqCgQE,MACf,QAAQ,CAAG,GAClB,GAAO,EADmB,CACpB,AADqB,CAChB,CAAG,GACd,CADkB,CAAC,CACZ,GAAD,IAAQ,CAAG,GACjB,GAAO,CADiB,CAAC,CACnB,IAAQ,CAAG,GACjB,GAAO,GAAD,MAAU,CAAG,CADe,CAAC,CAEnC,GAAO,GADqB,AACtB,CADuB,IACd,CAAG,GAClB,GAAO,EADmB,CAAC,AACrB,UAAc,CAAG,GACvB,GAAO,GAAD,EAAM,CAAG,CADqB,CAAC,CAErC,EADoB,CAAC,AACd,GAAD,OAAW,CAAG,GACpB,GAAO,GAAD,CADwB,CAAC,CAClB,CAAG,MAAM,CAAC","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339]}